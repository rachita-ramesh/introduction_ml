{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### arrays, one d, 2 d arrays (matrices vectors)\n",
    "#### tensors ##### accelerated over a gpu\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([1,2,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu') #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([1,2,2,3]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Gradient descent (gradient matrix) \n",
    "torch.zeros([1,2,3],requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minmize $X^2+4X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(0.0,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=x*x+4*x ### forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad ### Grad of x at 0 wrt z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=x*x+4*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad ### Start accumulating the value of gradients,\n",
    "### Pass 1\n",
    "### grad=4\n",
    "### Pass 2\n",
    "### grad_now+grad_prev=4+4=8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Forward pass\n",
    "#### backward()\n",
    "#### zero out the graidients\n",
    "### xnew=xold-lr*(sum(grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z 0.0, x: -0.03999999910593033\n",
      "Z -0.15839999914169312, x: -0.07919999957084656\n",
      "Z -0.31052735447883606, x: -0.11761599779129028\n",
      "Z -0.4566304683685303, x: -0.15526367723941803\n",
      "Z -0.5969479084014893, x: -0.19215840101242065\n",
      "Z -0.7317087650299072, x: -0.22831523418426514\n",
      "Z -0.8611330986022949, x: -0.2637489140033722\n",
      "Z -0.9854321479797363, x: -0.29847392439842224\n",
      "Z -1.104809045791626, x: -0.3325044512748718\n",
      "Z -1.2194585800170898, x: -0.3658543527126312\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(0.0,requires_grad=True)\n",
    "lr=0.01\n",
    "for i in range(10):\n",
    "    z=x*x+4*x\n",
    "    z.backward() ### dz/dx\n",
    "    with torch.no_grad(): ##Disables any gradient computation\n",
    "        x-=lr*x.grad\n",
    "        x.grad.zero_()\n",
    "    print(f\"Z {z}, x: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Autodiff\n",
    "### xy=750=>x=750/y\n",
    "## x+10y Minimize this\n",
    "### 750/y+y*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z: 760.0, x: 8.399999618530273\n",
      "Z: 173.2857208251953, x: 8.406291961669922\n",
      "Z: 173.28179931640625, x: 8.41242504119873\n",
      "Z: 173.27809143066406, x: 8.418403625488281\n",
      "Z: 173.27456665039062, x: 8.42423152923584\n",
      "Z: 173.27120971679688, x: 8.429913520812988\n",
      "Z: 173.2680206298828, x: 8.435453414916992\n",
      "Z: 173.26498413085938, x: 8.4408540725708\n",
      "Z: 173.26211547851562, x: 8.446120262145996\n",
      "Z: 173.25936889648438, x: 8.451254844665527\n",
      "Z: 173.25677490234375, x: 8.45626163482666\n",
      "Z: 173.25428771972656, x: 8.46114444732666\n",
      "Z: 173.25193786621094, x: 8.465906143188477\n",
      "Z: 173.24969482421875, x: 8.470550537109375\n",
      "Z: 173.24755859375, x: 8.475079536437988\n",
      "Z: 173.24554443359375, x: 8.479496955871582\n",
      "Z: 173.2436065673828, x: 8.483805656433105\n",
      "Z: 173.2417755126953, x: 8.488008499145508\n",
      "Z: 173.24002075195312, x: 8.492108345031738\n",
      "Z: 173.23837280273438, x: 8.496108055114746\n",
      "Z: 173.23678588867188, x: 8.500009536743164\n",
      "Z: 173.23529052734375, x: 8.503815650939941\n",
      "Z: 173.23385620117188, x: 8.507528305053711\n",
      "Z: 173.2324981689453, x: 8.511151313781738\n",
      "Z: 173.231201171875, x: 8.51468563079834\n",
      "Z: 173.22998046875, x: 8.518134117126465\n",
      "Z: 173.22879028320312, x: 8.521498680114746\n",
      "Z: 173.22767639160156, x: 8.524782180786133\n",
      "Z: 173.22659301757812, x: 8.527985572814941\n",
      "Z: 173.2255859375, x: 8.531111717224121\n",
      "Z: 173.22463989257812, x: 8.534162521362305\n",
      "Z: 173.22372436523438, x: 8.537138938903809\n",
      "Z: 173.22283935546875, x: 8.540043830871582\n",
      "Z: 173.2220001220703, x: 8.542879104614258\n",
      "Z: 173.22120666503906, x: 8.545645713806152\n",
      "Z: 173.220458984375, x: 8.548345565795898\n",
      "Z: 173.2197265625, x: 8.550980567932129\n",
      "Z: 173.21905517578125, x: 8.553552627563477\n",
      "Z: 173.2183837890625, x: 8.556062698364258\n",
      "Z: 173.2177734375, x: 8.558512687683105\n",
      "Z: 173.21717834472656, x: 8.560904502868652\n",
      "Z: 173.21661376953125, x: 8.563239097595215\n",
      "Z: 173.216064453125, x: 8.56551742553711\n",
      "Z: 173.21556091308594, x: 8.567741394042969\n",
      "Z: 173.21507263183594, x: 8.569912910461426\n",
      "Z: 173.214599609375, x: 8.57203197479248\n",
      "Z: 173.21417236328125, x: 8.574100494384766\n",
      "Z: 173.2137451171875, x: 8.576120376586914\n",
      "Z: 173.21331787109375, x: 8.578091621398926\n",
      "Z: 173.21295166015625, x: 8.580016136169434\n",
      "Z: 173.21258544921875, x: 8.581894874572754\n",
      "Z: 173.2122344970703, x: 8.58372974395752\n",
      "Z: 173.2119140625, x: 8.58552074432373\n",
      "Z: 173.21157836914062, x: 8.587268829345703\n",
      "Z: 173.21127319335938, x: 8.58897590637207\n",
      "Z: 173.21099853515625, x: 8.590642929077148\n",
      "Z: 173.21072387695312, x: 8.592269897460938\n",
      "Z: 173.21044921875, x: 8.59385871887207\n",
      "Z: 173.210205078125, x: 8.595409393310547\n",
      "Z: 173.20997619628906, x: 8.596923828125\n",
      "Z: 173.20974731445312, x: 8.598402976989746\n",
      "Z: 173.20953369140625, x: 8.599846839904785\n",
      "Z: 173.20932006835938, x: 8.601256370544434\n",
      "Z: 173.20913696289062, x: 8.602632522583008\n",
      "Z: 173.2089385986328, x: 8.603976249694824\n",
      "Z: 173.20877075195312, x: 8.6052885055542\n",
      "Z: 173.20858764648438, x: 8.60657024383545\n",
      "Z: 173.20843505859375, x: 8.607821464538574\n",
      "Z: 173.20828247070312, x: 8.60904312133789\n",
      "Z: 173.2081298828125, x: 8.610236167907715\n",
      "Z: 173.20799255371094, x: 8.611401557922363\n",
      "Z: 173.20785522460938, x: 8.612539291381836\n",
      "Z: 173.20773315429688, x: 8.61365032196045\n",
      "Z: 173.20761108398438, x: 8.61473560333252\n",
      "Z: 173.20748901367188, x: 8.615795135498047\n",
      "Z: 173.20736694335938, x: 8.616829872131348\n",
      "Z: 173.207275390625, x: 8.617840766906738\n",
      "Z: 173.2071533203125, x: 8.618827819824219\n",
      "Z: 173.2070770263672, x: 8.619791030883789\n",
      "Z: 173.20697021484375, x: 8.620732307434082\n",
      "Z: 173.20687866210938, x: 8.621651649475098\n",
      "Z: 173.20680236816406, x: 8.622549057006836\n",
      "Z: 173.20672607421875, x: 8.623425483703613\n",
      "Z: 173.20664978027344, x: 8.624281883239746\n",
      "Z: 173.20657348632812, x: 8.625118255615234\n",
      "Z: 173.20651245117188, x: 8.625934600830078\n",
      "Z: 173.20645141601562, x: 8.626731872558594\n",
      "Z: 173.20639038085938, x: 8.627511024475098\n",
      "Z: 173.20632934570312, x: 8.628271102905273\n",
      "Z: 173.20626831054688, x: 8.629014015197754\n",
      "Z: 173.20620727539062, x: 8.629739761352539\n",
      "Z: 173.20614624023438, x: 8.630448341369629\n",
      "Z: 173.20611572265625, x: 8.63114070892334\n",
      "Z: 173.2060546875, x: 8.631816864013672\n",
      "Z: 173.20602416992188, x: 8.632476806640625\n",
      "Z: 173.2059783935547, x: 8.633121490478516\n",
      "Z: 173.2059326171875, x: 8.633750915527344\n",
      "Z: 173.20590209960938, x: 8.634366035461426\n",
      "Z: 173.2058563232422, x: 8.634966850280762\n",
      "Z: 173.20582580566406, x: 8.635553359985352\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.0,requires_grad=True)\n",
    "lr=0.01\n",
    "for i in range(100):\n",
    "    z=(750/x)+x*10\n",
    "    z.backward()\n",
    "    with torch.no_grad():\n",
    "        x-=lr*x.grad\n",
    "        x.grad.zero_()\n",
    "    print(f\"Z: {z}, x: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ML problem: \n",
    "import pandas as pd\n",
    "reg=pd.read_csv(\"../sony/data/regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0        8.0         307.0       130.0  3504.0          12.0  70.0   \n",
       "1  15.0        8.0         350.0       165.0  3693.0          11.5  70.0   \n",
       "\n",
       "   origin  \n",
       "0     1.0  \n",
       "1     1.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mpg=b0+b1*cyl ## as a matrix product?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dloss/db0, dloss/db1\n",
    "#### loss=f(b0,b1)\n",
    "##loss=eq\n",
    "##loss.backward()\n",
    "##b0.grad\n",
    "##b1.grad\n",
    "X=reg[['cylinders']].values\n",
    "y=reg[['mpg']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## W dim?=> dloss/dW,dloss/db\n",
    "W=torch.randn(1,1,requires_grad=True)\n",
    "b=torch.randn(1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loss?\n",
    "loss=sum((y-XW+b)^2)/n\n",
    "loss.backward()\n",
    "W.grad\n",
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.tensor(X)\n",
    "y=torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 106.57937383717696, W: [[1.5394461]], b: [-12.498031]\n",
      "Loss: 106.29652724282161, W: [[1.5306689]], b: [-12.550415]\n",
      "Loss: 106.01465406982496, W: [[1.5219065]], b: [-12.602709]\n",
      "Loss: 105.73375239029292, W: [[1.5131594]], b: [-12.654913]\n",
      "Loss: 105.4538148533757, W: [[1.5044272]], b: [-12.707027]\n",
      "Loss: 105.17483884401985, W: [[1.4957101]], b: [-12.759052]\n",
      "Loss: 104.8968210069427, W: [[1.4870082]], b: [-12.810987]\n",
      "Loss: 104.61976103636141, W: [[1.4783207]], b: [-12.862833]\n",
      "Loss: 104.34365403355959, W: [[1.4696487]], b: [-12.91459]\n",
      "Loss: 104.06849371735905, W: [[1.4609914]], b: [-12.966257]\n",
      "Loss: 103.79428275126844, W: [[1.452349]], b: [-13.017836]\n",
      "Loss: 103.52101361310103, W: [[1.4437215]], b: [-13.069325]\n",
      "Loss: 103.24868271208203, W: [[1.4351087]], b: [-13.120727]\n",
      "Loss: 102.97728938506957, W: [[1.426511]], b: [-13.17204]\n",
      "Loss: 102.70682585822372, W: [[1.417928]], b: [-13.223265]\n",
      "Loss: 102.43729364242495, W: [[1.4093596]], b: [-13.274402]\n",
      "Loss: 102.16868574302856, W: [[1.4008062]], b: [-13.32545]\n",
      "Loss: 101.9010047640723, W: [[1.3922671]], b: [-13.3764105]\n",
      "Loss: 101.63424392719688, W: [[1.383743]], b: [-13.427283]\n",
      "Loss: 101.36840038466318, W: [[1.3752334]], b: [-13.478069]\n",
      "Loss: 101.10346696857538, W: [[1.3667387]], b: [-13.528768]\n",
      "Loss: 100.83944657207539, W: [[1.3582585]], b: [-13.579379]\n",
      "Loss: 100.57633189425486, W: [[1.3497927]], b: [-13.629903]\n",
      "Loss: 100.31412440868142, W: [[1.3413416]], b: [-13.68034]\n",
      "Loss: 100.05281752603965, W: [[1.332905]], b: [-13.73069]\n",
      "Loss: 99.79240902915474, W: [[1.3244832]], b: [-13.780953]\n",
      "Loss: 99.53289683086567, W: [[1.3160756]], b: [-13.831131]\n",
      "Loss: 99.27427338304174, W: [[1.3076826]], b: [-13.881222]\n",
      "Loss: 99.01654162565809, W: [[1.2993039]], b: [-13.931227]\n",
      "Loss: 98.75969341752857, W: [[1.2909396]], b: [-13.981146]\n",
      "Loss: 98.5037277684382, W: [[1.2825896]], b: [-14.030979]\n",
      "Loss: 98.24864168729665, W: [[1.2742538]], b: [-14.080727]\n",
      "Loss: 97.99443261730507, W: [[1.2659328]], b: [-14.130388]\n",
      "Loss: 97.74109908437582, W: [[1.257626]], b: [-14.179964]\n",
      "Loss: 97.48863842243667, W: [[1.2493335]], b: [-14.229455]\n",
      "Loss: 97.23704367063091, W: [[1.2410551]], b: [-14.278861]\n",
      "Loss: 96.98631226261628, W: [[1.2327911]], b: [-14.328182]\n",
      "Loss: 96.73644225327435, W: [[1.2245412]], b: [-14.3774185]\n",
      "Loss: 96.48743114163213, W: [[1.2163055]], b: [-14.42657]\n",
      "Loss: 96.23927704862936, W: [[1.208084]], b: [-14.4756365]\n",
      "Loss: 95.99197747220049, W: [[1.1998769]], b: [-14.524619]\n",
      "Loss: 95.74552638659085, W: [[1.1916834]], b: [-14.573517]\n",
      "Loss: 95.49992469960344, W: [[1.1835042]], b: [-14.622331]\n",
      "Loss: 95.25516651145746, W: [[1.175339]], b: [-14.671061]\n",
      "Loss: 95.01124919913075, W: [[1.1671882]], b: [-14.719707]\n",
      "Loss: 94.76817127068546, W: [[1.1590513]], b: [-14.768269]\n",
      "Loss: 94.5259298817889, W: [[1.1509284]], b: [-14.816748]\n",
      "Loss: 94.28451859372065, W: [[1.1428194]], b: [-14.865143]\n",
      "Loss: 94.04393987965155, W: [[1.1347246]], b: [-14.913455]\n",
      "Loss: 93.80418681530303, W: [[1.1266433]], b: [-14.961684]\n",
      "Loss: 93.56525705880594, W: [[1.118576]], b: [-15.00983]\n",
      "Loss: 93.32714842416925, W: [[1.1105225]], b: [-15.057894]\n",
      "Loss: 93.08985907273593, W: [[1.102483]], b: [-15.105874]\n",
      "Loss: 92.85338694636683, W: [[1.0944574]], b: [-15.153772]\n",
      "Loss: 92.6177251570165, W: [[1.0864456]], b: [-15.201588]\n",
      "Loss: 92.38287626920909, W: [[1.0784473]], b: [-15.249321]\n",
      "Loss: 92.14883341928909, W: [[1.0704631]], b: [-15.296972]\n",
      "Loss: 91.9155945857501, W: [[1.0624925]], b: [-15.344542]\n",
      "Loss: 91.68315825547626, W: [[1.0545356]], b: [-15.392029]\n",
      "Loss: 91.45152124433464, W: [[1.0465924]], b: [-15.439435]\n",
      "Loss: 91.22067785915773, W: [[1.038663]], b: [-15.486759]\n",
      "Loss: 90.99063023209378, W: [[1.030747]], b: [-15.534002]\n",
      "Loss: 90.76137154011904, W: [[1.0228447]], b: [-15.581163]\n",
      "Loss: 90.53290406672578, W: [[1.0149562]], b: [-15.628243]\n",
      "Loss: 90.30522244473264, W: [[1.0070812]], b: [-15.675243]\n",
      "Loss: 90.07831923122174, W: [[0.99921966]], b: [-15.722162]\n",
      "Loss: 89.85219662331951, W: [[0.99137163]], b: [-15.769]\n",
      "Loss: 89.62685315078838, W: [[0.983537]], b: [-15.815758]\n",
      "Loss: 89.40228213898385, W: [[0.9757159]], b: [-15.862434]\n",
      "Loss: 89.17848586582821, W: [[0.96790826]], b: [-15.909031]\n",
      "Loss: 88.95545795402309, W: [[0.9601142]], b: [-15.955547]\n",
      "Loss: 88.73319685791502, W: [[0.95233357]], b: [-16.001984]\n",
      "Loss: 88.51170043897277, W: [[0.9445662]], b: [-16.04834]\n",
      "Loss: 88.29096583434749, W: [[0.9368121]], b: [-16.094616]\n",
      "Loss: 88.07099186830436, W: [[0.9290715]], b: [-16.140814]\n",
      "Loss: 87.85176787295342, W: [[0.9213443]], b: [-16.186932]\n",
      "Loss: 87.63330025743231, W: [[0.9136301]], b: [-16.23297]\n",
      "Loss: 87.41558726129708, W: [[0.90592915]], b: [-16.278929]\n",
      "Loss: 87.1986177239991, W: [[0.8982418]], b: [-16.324808]\n",
      "Loss: 86.98239927493378, W: [[0.89056754]], b: [-16.37061]\n",
      "Loss: 86.7669205094124, W: [[0.88290644]], b: [-16.416332]\n",
      "Loss: 86.55217989465888, W: [[0.8752587]], b: [-16.461975]\n",
      "Loss: 86.33818422257363, W: [[0.86762387]], b: [-16.50754]\n",
      "Loss: 86.12492258030417, W: [[0.8600023]], b: [-16.553026]\n",
      "Loss: 85.91239314884028, W: [[0.8523936]], b: [-16.598434]\n",
      "Loss: 85.70059406368182, W: [[0.84479827]], b: [-16.643764]\n",
      "Loss: 85.48952348366416, W: [[0.83721596]], b: [-16.689016]\n",
      "Loss: 85.27917971123543, W: [[0.8296469]], b: [-16.734192]\n",
      "Loss: 85.06955201714128, W: [[0.82209045]], b: [-16.77929]\n",
      "Loss: 84.860646820288, W: [[0.81454694]], b: [-16.824308]\n",
      "Loss: 84.65246222574288, W: [[0.80701655]], b: [-16.869251]\n",
      "Loss: 84.44498858129145, W: [[0.7994992]], b: [-16.914116]\n",
      "Loss: 84.23823210859764, W: [[0.7919949]], b: [-16.958902]\n",
      "Loss: 84.03219094634537, W: [[0.7845033]], b: [-17.003613]\n",
      "Loss: 83.82685486704993, W: [[0.7770247]], b: [-17.048246]\n",
      "Loss: 83.62222155257871, W: [[0.7695587]], b: [-17.092804]\n",
      "Loss: 83.41828970460764, W: [[0.76210576]], b: [-17.137283]\n",
      "Loss: 83.21506570844782, W: [[0.75466555]], b: [-17.181686]\n",
      "Loss: 83.01253908716674, W: [[0.7472385]], b: [-17.226013]\n",
      "Loss: 82.81070862636678, W: [[0.73982394]], b: [-17.270264]\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "for i in range(100):\n",
    "    diff=y-torch.matmul(X.float(),W)+b\n",
    "    loss=sum(diff*diff)/y.shape[0]\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        W-=lr*W.grad\n",
    "        b-=lr*b.grad\n",
    "        W.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    print(f\"Loss: {loss.item()}, W: {W.detach().numpy()}, b: {b.detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### linear classifier.\n",
    "### Can you estimate a linear classifier using autodiff\n",
    "### Loss for linear classifier?\n",
    "### log loss as a function of W and b, p=f(X,W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls=pd.read_csv(\"../sony/data/classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_pregnant</th>\n",
       "      <th>Plasma_glucose</th>\n",
       "      <th>Blood_pres</th>\n",
       "      <th>Skin_thick</th>\n",
       "      <th>Serum_insu</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes_func</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No_pregnant  Plasma_glucose  Blood_pres  Skin_thick  Serum_insu   BMI  \\\n",
       "0            6             148          72          35           0  33.6   \n",
       "1            1              85          66          29           0  26.6   \n",
       "\n",
       "   Diabetes_func  Age  Class  \n",
       "0          0.627   50      1  \n",
       "1          0.351   31      0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cls[['No_pregnant']].values\n",
    "y=cls[['Class']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loss=‚àí[ùë¶ùëôùëúùëî(ùëù+tol)+(1‚àíùë¶)ùëôùëúùëî(1‚àíùëù+tol)]\n",
    "### p=1/(1+e^-z)\n",
    "### z= XW+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5830082893371582, W: tensor([[0.2285]], requires_grad=True), b: tensor([1.4390], requires_grad=True)\n",
      "Loss: 1.5427392721176147, W: tensor([[0.2093]], requires_grad=True), b: tensor([1.4335], requires_grad=True)\n",
      "Loss: 1.5032926797866821, W: tensor([[0.1904]], requires_grad=True), b: tensor([1.4282], requires_grad=True)\n",
      "Loss: 1.4647493362426758, W: tensor([[0.1717]], requires_grad=True), b: tensor([1.4228], requires_grad=True)\n",
      "Loss: 1.4271955490112305, W: tensor([[0.1533]], requires_grad=True), b: tensor([1.4175], requires_grad=True)\n",
      "Loss: 1.3907232284545898, W: tensor([[0.1351]], requires_grad=True), b: tensor([1.4123], requires_grad=True)\n",
      "Loss: 1.3554285764694214, W: tensor([[0.1173]], requires_grad=True), b: tensor([1.4071], requires_grad=True)\n",
      "Loss: 1.321410059928894, W: tensor([[0.0999]], requires_grad=True), b: tensor([1.4020], requires_grad=True)\n",
      "Loss: 1.288766622543335, W: tensor([[0.0829]], requires_grad=True), b: tensor([1.3970], requires_grad=True)\n",
      "Loss: 1.2575944662094116, W: tensor([[0.0663]], requires_grad=True), b: tensor([1.3921], requires_grad=True)\n",
      "Loss: 1.22798490524292, W: tensor([[0.0501]], requires_grad=True), b: tensor([1.3872], requires_grad=True)\n",
      "Loss: 1.200018286705017, W: tensor([[0.0345]], requires_grad=True), b: tensor([1.3824], requires_grad=True)\n",
      "Loss: 1.1737607717514038, W: tensor([[0.0194]], requires_grad=True), b: tensor([1.3777], requires_grad=True)\n",
      "Loss: 1.1492608785629272, W: tensor([[0.0049]], requires_grad=True), b: tensor([1.3731], requires_grad=True)\n",
      "Loss: 1.1265448331832886, W: tensor([[-0.0090]], requires_grad=True), b: tensor([1.3686], requires_grad=True)\n",
      "Loss: 1.1056150197982788, W: tensor([[-0.0223]], requires_grad=True), b: tensor([1.3641], requires_grad=True)\n",
      "Loss: 1.0864485502243042, W: tensor([[-0.0349]], requires_grad=True), b: tensor([1.3598], requires_grad=True)\n",
      "Loss: 1.0689982175827026, W: tensor([[-0.0469]], requires_grad=True), b: tensor([1.3556], requires_grad=True)\n",
      "Loss: 1.0531946420669556, W: tensor([[-0.0583]], requires_grad=True), b: tensor([1.3514], requires_grad=True)\n",
      "Loss: 1.0389496088027954, W: tensor([[-0.0690]], requires_grad=True), b: tensor([1.3474], requires_grad=True)\n",
      "Loss: 1.0261621475219727, W: tensor([[-0.0791]], requires_grad=True), b: tensor([1.3434], requires_grad=True)\n",
      "Loss: 1.0147205591201782, W: tensor([[-0.0886]], requires_grad=True), b: tensor([1.3396], requires_grad=True)\n",
      "Loss: 1.0045104026794434, W: tensor([[-0.0975]], requires_grad=True), b: tensor([1.3358], requires_grad=True)\n",
      "Loss: 0.9954161047935486, W: tensor([[-0.1058]], requires_grad=True), b: tensor([1.3321], requires_grad=True)\n",
      "Loss: 0.987325131893158, W: tensor([[-0.1136]], requires_grad=True), b: tensor([1.3285], requires_grad=True)\n",
      "Loss: 0.9801309704780579, W: tensor([[-0.1209]], requires_grad=True), b: tensor([1.3249], requires_grad=True)\n",
      "Loss: 0.9737336039543152, W: tensor([[-0.1278]], requires_grad=True), b: tensor([1.3214], requires_grad=True)\n",
      "Loss: 0.9680419564247131, W: tensor([[-0.1341]], requires_grad=True), b: tensor([1.3180], requires_grad=True)\n",
      "Loss: 0.9629726409912109, W: tensor([[-0.1401]], requires_grad=True), b: tensor([1.3147], requires_grad=True)\n",
      "Loss: 0.9584508538246155, W: tensor([[-0.1456]], requires_grad=True), b: tensor([1.3114], requires_grad=True)\n",
      "Loss: 0.9544102549552917, W: tensor([[-0.1508]], requires_grad=True), b: tensor([1.3082], requires_grad=True)\n",
      "Loss: 0.9507915377616882, W: tensor([[-0.1556]], requires_grad=True), b: tensor([1.3050], requires_grad=True)\n",
      "Loss: 0.9475427269935608, W: tensor([[-0.1601]], requires_grad=True), b: tensor([1.3019], requires_grad=True)\n",
      "Loss: 0.9446180462837219, W: tensor([[-0.1643]], requires_grad=True), b: tensor([1.2988], requires_grad=True)\n",
      "Loss: 0.9419770240783691, W: tensor([[-0.1682]], requires_grad=True), b: tensor([1.2957], requires_grad=True)\n",
      "Loss: 0.9395846724510193, W: tensor([[-0.1718]], requires_grad=True), b: tensor([1.2927], requires_grad=True)\n",
      "Loss: 0.9374103546142578, W: tensor([[-0.1752]], requires_grad=True), b: tensor([1.2898], requires_grad=True)\n",
      "Loss: 0.9354269504547119, W: tensor([[-0.1784]], requires_grad=True), b: tensor([1.2869], requires_grad=True)\n",
      "Loss: 0.9336112141609192, W: tensor([[-0.1813]], requires_grad=True), b: tensor([1.2840], requires_grad=True)\n",
      "Loss: 0.9319422841072083, W: tensor([[-0.1841]], requires_grad=True), b: tensor([1.2811], requires_grad=True)\n",
      "Loss: 0.9304027557373047, W: tensor([[-0.1866]], requires_grad=True), b: tensor([1.2783], requires_grad=True)\n",
      "Loss: 0.9289767742156982, W: tensor([[-0.1890]], requires_grad=True), b: tensor([1.2755], requires_grad=True)\n",
      "Loss: 0.9276506304740906, W: tensor([[-0.1912]], requires_grad=True), b: tensor([1.2727], requires_grad=True)\n",
      "Loss: 0.9264126420021057, W: tensor([[-0.1933]], requires_grad=True), b: tensor([1.2700], requires_grad=True)\n",
      "Loss: 0.9252517819404602, W: tensor([[-0.1952]], requires_grad=True), b: tensor([1.2672], requires_grad=True)\n",
      "Loss: 0.9241597056388855, W: tensor([[-0.1970]], requires_grad=True), b: tensor([1.2645], requires_grad=True)\n",
      "Loss: 0.9231278300285339, W: tensor([[-0.1987]], requires_grad=True), b: tensor([1.2619], requires_grad=True)\n",
      "Loss: 0.9221492409706116, W: tensor([[-0.2002]], requires_grad=True), b: tensor([1.2592], requires_grad=True)\n",
      "Loss: 0.9212180972099304, W: tensor([[-0.2016]], requires_grad=True), b: tensor([1.2566], requires_grad=True)\n",
      "Loss: 0.9203285574913025, W: tensor([[-0.2029]], requires_grad=True), b: tensor([1.2540], requires_grad=True)\n",
      "Loss: 0.9194760918617249, W: tensor([[-0.2042]], requires_grad=True), b: tensor([1.2513], requires_grad=True)\n",
      "Loss: 0.9186564087867737, W: tensor([[-0.2053]], requires_grad=True), b: tensor([1.2488], requires_grad=True)\n",
      "Loss: 0.9178659319877625, W: tensor([[-0.2063]], requires_grad=True), b: tensor([1.2462], requires_grad=True)\n",
      "Loss: 0.9171013236045837, W: tensor([[-0.2073]], requires_grad=True), b: tensor([1.2436], requires_grad=True)\n",
      "Loss: 0.9163598418235779, W: tensor([[-0.2082]], requires_grad=True), b: tensor([1.2411], requires_grad=True)\n",
      "Loss: 0.9156387448310852, W: tensor([[-0.2090]], requires_grad=True), b: tensor([1.2386], requires_grad=True)\n",
      "Loss: 0.9149360656738281, W: tensor([[-0.2097]], requires_grad=True), b: tensor([1.2360], requires_grad=True)\n",
      "Loss: 0.9142497181892395, W: tensor([[-0.2104]], requires_grad=True), b: tensor([1.2335], requires_grad=True)\n",
      "Loss: 0.9135779738426208, W: tensor([[-0.2111]], requires_grad=True), b: tensor([1.2310], requires_grad=True)\n",
      "Loss: 0.9129191040992737, W: tensor([[-0.2116]], requires_grad=True), b: tensor([1.2285], requires_grad=True)\n",
      "Loss: 0.9122722148895264, W: tensor([[-0.2121]], requires_grad=True), b: tensor([1.2261], requires_grad=True)\n",
      "Loss: 0.9116355776786804, W: tensor([[-0.2126]], requires_grad=True), b: tensor([1.2236], requires_grad=True)\n",
      "Loss: 0.9110085368156433, W: tensor([[-0.2130]], requires_grad=True), b: tensor([1.2212], requires_grad=True)\n",
      "Loss: 0.9103897213935852, W: tensor([[-0.2134]], requires_grad=True), b: tensor([1.2187], requires_grad=True)\n",
      "Loss: 0.9097787737846375, W: tensor([[-0.2137]], requires_grad=True), b: tensor([1.2163], requires_grad=True)\n",
      "Loss: 0.9091746807098389, W: tensor([[-0.2140]], requires_grad=True), b: tensor([1.2138], requires_grad=True)\n",
      "Loss: 0.9085767865180969, W: tensor([[-0.2143]], requires_grad=True), b: tensor([1.2114], requires_grad=True)\n",
      "Loss: 0.9079844951629639, W: tensor([[-0.2145]], requires_grad=True), b: tensor([1.2090], requires_grad=True)\n",
      "Loss: 0.9073973298072815, W: tensor([[-0.2147]], requires_grad=True), b: tensor([1.2066], requires_grad=True)\n",
      "Loss: 0.9068149924278259, W: tensor([[-0.2149]], requires_grad=True), b: tensor([1.2042], requires_grad=True)\n",
      "Loss: 0.906236469745636, W: tensor([[-0.2150]], requires_grad=True), b: tensor([1.2018], requires_grad=True)\n",
      "Loss: 0.9056623578071594, W: tensor([[-0.2151]], requires_grad=True), b: tensor([1.1994], requires_grad=True)\n",
      "Loss: 0.9050914645195007, W: tensor([[-0.2152]], requires_grad=True), b: tensor([1.1970], requires_grad=True)\n",
      "Loss: 0.9045238494873047, W: tensor([[-0.2152]], requires_grad=True), b: tensor([1.1946], requires_grad=True)\n",
      "Loss: 0.9039594531059265, W: tensor([[-0.2152]], requires_grad=True), b: tensor([1.1923], requires_grad=True)\n",
      "Loss: 0.9033976197242737, W: tensor([[-0.2153]], requires_grad=True), b: tensor([1.1899], requires_grad=True)\n",
      "Loss: 0.9028384685516357, W: tensor([[-0.2152]], requires_grad=True), b: tensor([1.1875], requires_grad=True)\n",
      "Loss: 0.9022815823554993, W: tensor([[-0.2152]], requires_grad=True), b: tensor([1.1852], requires_grad=True)\n",
      "Loss: 0.901727020740509, W: tensor([[-0.2152]], requires_grad=True), b: tensor([1.1828], requires_grad=True)\n",
      "Loss: 0.9011746048927307, W: tensor([[-0.2151]], requires_grad=True), b: tensor([1.1805], requires_grad=True)\n",
      "Loss: 0.9006239771842957, W: tensor([[-0.2150]], requires_grad=True), b: tensor([1.1782], requires_grad=True)\n",
      "Loss: 0.9000754356384277, W: tensor([[-0.2149]], requires_grad=True), b: tensor([1.1758], requires_grad=True)\n",
      "Loss: 0.8995283246040344, W: tensor([[-0.2148]], requires_grad=True), b: tensor([1.1735], requires_grad=True)\n",
      "Loss: 0.8989830613136292, W: tensor([[-0.2147]], requires_grad=True), b: tensor([1.1712], requires_grad=True)\n",
      "Loss: 0.898439347743988, W: tensor([[-0.2145]], requires_grad=True), b: tensor([1.1688], requires_grad=True)\n",
      "Loss: 0.8978970646858215, W: tensor([[-0.2144]], requires_grad=True), b: tensor([1.1665], requires_grad=True)\n",
      "Loss: 0.8973562717437744, W: tensor([[-0.2142]], requires_grad=True), b: tensor([1.1642], requires_grad=True)\n",
      "Loss: 0.8968166708946228, W: tensor([[-0.2140]], requires_grad=True), b: tensor([1.1619], requires_grad=True)\n",
      "Loss: 0.8962785601615906, W: tensor([[-0.2139]], requires_grad=True), b: tensor([1.1596], requires_grad=True)\n",
      "Loss: 0.8957417011260986, W: tensor([[-0.2137]], requires_grad=True), b: tensor([1.1573], requires_grad=True)\n",
      "Loss: 0.8952059745788574, W: tensor([[-0.2135]], requires_grad=True), b: tensor([1.1550], requires_grad=True)\n",
      "Loss: 0.8946714997291565, W: tensor([[-0.2133]], requires_grad=True), b: tensor([1.1527], requires_grad=True)\n",
      "Loss: 0.8941381573677063, W: tensor([[-0.2130]], requires_grad=True), b: tensor([1.1504], requires_grad=True)\n",
      "Loss: 0.8936060070991516, W: tensor([[-0.2128]], requires_grad=True), b: tensor([1.1481], requires_grad=True)\n",
      "Loss: 0.8930748105049133, W: tensor([[-0.2126]], requires_grad=True), b: tensor([1.1458], requires_grad=True)\n",
      "Loss: 0.8925447463989258, W: tensor([[-0.2123]], requires_grad=True), b: tensor([1.1435], requires_grad=True)\n",
      "Loss: 0.8920158743858337, W: tensor([[-0.2121]], requires_grad=True), b: tensor([1.1412], requires_grad=True)\n",
      "Loss: 0.8914878964424133, W: tensor([[-0.2118]], requires_grad=True), b: tensor([1.1389], requires_grad=True)\n",
      "Loss: 0.8909609913825989, W: tensor([[-0.2116]], requires_grad=True), b: tensor([1.1366], requires_grad=True)\n",
      "Loss: 0.8904352188110352, W: tensor([[-0.2113]], requires_grad=True), b: tensor([1.1344], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "X=torch.tensor(X)\n",
    "y=torch.tensor(y)\n",
    "W=torch.randn(1,1,requires_grad=True)\n",
    "b=torch.randn(1,requires_grad=True)\n",
    "tol=0.0000000001\n",
    "lr=0.01\n",
    "for i in range(100):\n",
    "    z=torch.matmul(X.float(),W)+b\n",
    "    p=1.0/(1+torch.exp(-z))\n",
    "    loss=-(y*torch.log(p+tol)+(1-y)*torch.log(1-p+tol)).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        W-=lr*W.grad\n",
    "        b-=lr*b.grad\n",
    "        W.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    print(f\"Loss: {loss.item()}, W: {W}, b: {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MLP, define models, batches of data very easily, optimizers, loss functions\n",
    "mnist=pd.read_csv(\"../sony/data/mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=np.array([[0.8,0.1,0.1],[0.7,0.2,0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.1, 0.1],\n",
       "       [0.7, 0.2, 0.1]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals=np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.1, 0.1],\n",
       "       [0.7, 0.2, 0.1]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8, 0.2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[range(2),actuals] ## for all rows give me values in columns denoted by indices in actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=mnist['label'].values\n",
    "X=mnist.drop('label',axis=1).values\n",
    "X=X/255.0\n",
    "X=torch.tensor(X)\n",
    "y=torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1=torch.randn((784,3),requires_grad=True)\n",
    "b1=torch.randn(3,requires_grad=True)\n",
    "W2=torch.randn((3,10),requires_grad=True)\n",
    "b2=torch.randn(10,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define how computations will happen in the forward pass\n",
    "def net(W1,b1,W2,b2,X):\n",
    "    z1=torch.matmul(X.float(),W1)+b1\n",
    "    a1=torch.sigmoid(z1)\n",
    "    z2=torch.matmul(a1,W2)+b2\n",
    "    p=torch.softmax(z2,axis=1)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce(p,y):\n",
    "    return -torch.log(p[range(y.shape[0]),y.long()]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.986879587173462\n",
      "Loss: 2.9846160411834717\n",
      "Loss: 2.98236346244812\n",
      "Loss: 2.9801225662231445\n",
      "Loss: 2.9778926372528076\n",
      "Loss: 2.975675106048584\n",
      "Loss: 2.973466634750366\n",
      "Loss: 2.97127103805542\n",
      "Loss: 2.969085454940796\n",
      "Loss: 2.9669106006622314\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "for i in range(10):\n",
    "    p=net(W1,b1,W2,b2,X)\n",
    "    loss=ce(p,y)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        W1-=lr*W1.grad\n",
    "        W2-=lr*W2.grad\n",
    "        b1-=lr*b1.grad\n",
    "        b2-=lr*b2.grad\n",
    "        W1.grad.zero_()\n",
    "        W2.grad.zero_()\n",
    "        b1.grad.zero_()\n",
    "        b2.grad.zero_()\n",
    "    print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.array([[0.8,0.1,0.1],[0.7,0.2,0.1],[0.1,0.1,0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.1, 0.1],\n",
       "       [0.7, 0.2, 0.1],\n",
       "       [0.1, 0.1, 0.8]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0,0] ## 0,\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1,1] ## 1,\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[2,2] # 2,\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8, 0.2, 0.8])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[range(3),y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W1=nn.Parameter(torch.randn((784,3),requires_grad=True))\n",
    "        self.b1=nn.Parameter(torch.randn(3,requires_grad=True))\n",
    "        self.W2=nn.Parameter(torch.randn((3,10),requires_grad=True))\n",
    "        self.b2=nn.Parameter(torch.randn(10,requires_grad=True))\n",
    "    def forward(self,X):\n",
    "        z1=torch.matmul(X.float(),self.W1)+self.b1\n",
    "        a1=torch.sigmoid(z1)\n",
    "        z2=torch.matmul(a1,self.W2)+self.b2\n",
    "        p=torch.softmax(z2,axis=1)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.9440, -2.2863,  0.5219],\n",
       "         [-0.1077,  0.3833,  2.2591],\n",
       "         [ 0.2427,  0.2368,  0.3286],\n",
       "         ...,\n",
       "         [-0.5358, -1.3426,  0.2377],\n",
       "         [ 0.1022,  0.8008, -0.2817],\n",
       "         [ 0.0049,  1.5412,  0.4890]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.6149, -1.5055,  0.4591], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.9947,  0.5324, -0.4181,  0.5281,  0.1517,  1.7104,  0.0648,  0.1053,\n",
       "          -0.9055, -0.1474],\n",
       "         [-0.1860,  0.4197, -0.5564,  1.6358, -1.2533, -0.4074, -0.3594, -1.3828,\n",
       "          -0.5344,  0.0820],\n",
       "         [ 0.2188, -3.7559, -1.1455, -1.0347,  2.7765,  0.2268, -0.3581,  0.9246,\n",
       "           0.5373, -0.8488]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.7605,  1.0399, -0.4413,  2.6787, -1.3123,  0.3906,  1.3570, -0.7819,\n",
       "         -2.3241,  0.1289], requires_grad=True)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in mod.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 3.486020565032959\n",
      "Loss 3.4807889461517334\n",
      "Loss 3.4756033420562744\n",
      "Loss 3.4704623222351074\n",
      "Loss 3.465364933013916\n",
      "Loss 3.460310935974121\n",
      "Loss 3.4553003311157227\n",
      "Loss 3.4503302574157715\n",
      "Loss 3.445402145385742\n",
      "Loss 3.4405159950256348\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "for i in range(10):\n",
    "    p=mod(X)\n",
    "    loss=ce(p,y)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for p in mod.parameters():\n",
    "            p-=lr*p.grad\n",
    "        mod.zero_grad()\n",
    "    print(f\"Loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Linear(784,30)\n",
    "        self.layer2=nn.Linear(30,10)\n",
    "    def forward(self,X):\n",
    "        X=self.layer1(X)\n",
    "        X=torch.sigmoid(X)\n",
    "        X=self.layer2(X)\n",
    "        X=torch.softmax(X,axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 2.3723344802856445\n",
      "Loss : 2.370436906814575\n",
      "Loss : 2.368586540222168\n",
      "Loss : 2.366779327392578\n",
      "Loss : 2.365013599395752\n",
      "Loss : 2.3632888793945312\n",
      "Loss : 2.361604690551758\n",
      "Loss : 2.359957695007324\n",
      "Loss : 2.3583481311798096\n",
      "Loss : 2.3567757606506348\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "for i in range(10):\n",
    "    p=mod(X.float())\n",
    "    loss=ce(p,y)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for p in mod.parameters():\n",
    "            p-=lr*p.grad\n",
    "        mod.zero_grad()\n",
    "    print(f\"Loss : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=Net()\n",
    "opt=optim.SGD(mod.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3883562088012695\n",
      "Loss: 2.3864028453826904\n",
      "Loss: 2.3844897747039795\n",
      "Loss: 2.3826146125793457\n",
      "Loss: 2.380776882171631\n",
      "Loss: 2.378976821899414\n",
      "Loss: 2.377211809158325\n",
      "Loss: 2.3754818439483643\n",
      "Loss: 2.3737852573394775\n",
      "Loss: 2.372122287750244\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    p=mod(X.float())\n",
    "    loss=ce(p,y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    print(f'Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3023386001586914\n",
      "Loss: 2.302335262298584\n",
      "Loss: 2.302332878112793\n",
      "Loss: 2.302330493927002\n",
      "Loss: 2.3023269176483154\n",
      "Loss: 2.302324056625366\n",
      "Loss: 2.302320718765259\n",
      "Loss: 2.3023183345794678\n",
      "Loss: 2.3023154735565186\n",
      "Loss: 2.3023126125335693\n"
     ]
    }
   ],
   "source": [
    "### Pre-defined loss\n",
    "mod=Net()\n",
    "opt=optim.SGD(mod.parameters(),lr=0.01)\n",
    "criteria=nn.CrossEntropyLoss()\n",
    "for i in range(10):\n",
    "    p=mod(X.float())\n",
    "    loss=criteria(p,y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset ==> DataLoader\n",
    "X=mnist.drop('label',axis=1).values\n",
    "y=mnist['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create a dataset class\n",
    "class MNIST(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        x=self.X[idx]\n",
    "        y=self.y[idx]\n",
    "        batch={\"X\":x,'y':y}\n",
    "        return batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=MNIST(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=DataLoader(d,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'y': tensor([1, 0, 1, 4, 0, 0, 7, 3, 5, 3, 8, 9, 1, 3, 3, 1, 2, 0, 7, 5, 8, 6, 2, 0,\n",
       "         2, 3, 6, 9, 9, 7, 8, 9])}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9903792142868042\n",
      "Loss: 1.8198597431182861\n",
      "Loss: 1.7438639402389526\n",
      "Loss: 1.730023980140686\n",
      "Loss: 1.727125883102417\n",
      "Loss: 1.6779325008392334\n",
      "Loss: 1.6951528787612915\n",
      "Loss: 1.6813631057739258\n",
      "Loss: 1.681824803352356\n",
      "Loss: 1.7020763158798218\n"
     ]
    }
   ],
   "source": [
    "mod=Net()\n",
    "opt=optim.SGD(mod.parameters(),lr=0.01)\n",
    "criteria=nn.CrossEntropyLoss()\n",
    "epochs=10\n",
    "for i in range(epochs):\n",
    "    for batch in D:\n",
    "        x=batch['X'].float()\n",
    "        Y=batch['y']\n",
    "        p=mod(x)\n",
    "        loss=criteria(p,Y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:03<00:28,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1 Loss: 1.9944322109222412 Acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|‚ñà‚ñà        | 2/10 [00:06<00:26,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 2 Loss: 1.823850393295288 Acc: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [00:10<00:24,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 3 Loss: 1.7938601970672607 Acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:13<00:20,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 4 Loss: 1.752509355545044 Acc: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:17<00:16,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 5 Loss: 1.7382416725158691 Acc: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:20<00:13,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 6 Loss: 1.7352384328842163 Acc: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:24<00:10,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 7 Loss: 1.712043046951294 Acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:29<00:07,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 8 Loss: 1.6906734704971313 Acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:34<00:04,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 9 Loss: 1.6669563055038452 Acc: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:37<00:00,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10 Loss: 1.6398967504501343 Acc: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mod=Net()\n",
    "opt=optim.SGD(mod.parameters(),lr=0.01)\n",
    "criteria=nn.CrossEntropyLoss()\n",
    "epochs=10\n",
    "for i in tqdm(range(epochs)):\n",
    "    for batch in D:\n",
    "        x=batch['X'].float()\n",
    "        Y=batch['y']\n",
    "        p=mod(x)\n",
    "        pred_class=p.argmax(axis=1)\n",
    "        acc=(pred_class==Y).float().mean().item()\n",
    "        loss=criteria(p,Y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    print(f\"Iter: {i+1} Loss: {loss.item()} Acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=np.array([[0.80,0.10,0.10],[0.20,0.70,0.10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=pd.read_csv(\"/Users/gunnvantsaini/Data/Work/ML Course/Module 5 Neural Networks/Data/fashion_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=pd.read_csv(\"/Users/gunnvantsaini/Data/Work/ML Course/Module 5 Neural Networks/Data/fashion_train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>114</td>\n",
       "      <td>130</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  774  775  776  777  778  779  780  781  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "1  0  0  0  0  0  1  0  0  0  0  ...  119  114  130   76    0    0    0    0   \n",
       "\n",
       "   782  783  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "\n",
       "[2 rows x 784 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x129e093d0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(f.iloc[6].values.reshape((28,28)),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  9\n",
       "1  0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 3, 2, 7, 5, 1, 6, 4, 8])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l['0'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dataset\n",
    "## Which takes the path of the folder where these files are\n",
    "## Return dictionary {'X':flattened image,'y':label}\n",
    "### DataLoader which returns batches of size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionData(Dataset):\n",
    "    def __init__(self,path_of_folder):\n",
    "        path_to_features=path_of_folder+\"/fashion_train.csv\"\n",
    "        path_to_labels=path_of_folder+\"/fashion_train_labels.csv\"\n",
    "        self.X=pd.read_csv(path_to_features).values\n",
    "        self.y=pd.read_csv(path_to_labels)['0'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self,idx):\n",
    "        x=self.X[idx]\n",
    "        y=self.y[idx]\n",
    "        batch={'X':x,'y':y}\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=FashionData(\"/Users/gunnvantsaini/Data/Work/ML Course/Module 5 Neural Networks/Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=DataLoader(d,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'y': tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4, 3, 1, 4, 8,\n",
       "         4, 3, 0, 2, 4, 4, 5, 3])}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(D)) ### Try writing your own model and the training loop, free to use any number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import FashionData, Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=FashionData(\"/Users/gunnvantsaini/Data/Work/ML Course/Module 5 Neural Networks/Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=D=DataLoader(d,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp=pd.read_csv(\"/Users/gunnvantsaini/OneDrive/project_codes/content/dl_basics/sony/data/facial-keypoints-detection/training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_eye_center_x</th>\n",
       "      <th>left_eye_center_y</th>\n",
       "      <th>right_eye_center_x</th>\n",
       "      <th>right_eye_center_y</th>\n",
       "      <th>left_eye_inner_corner_x</th>\n",
       "      <th>left_eye_inner_corner_y</th>\n",
       "      <th>left_eye_outer_corner_x</th>\n",
       "      <th>left_eye_outer_corner_y</th>\n",
       "      <th>right_eye_inner_corner_x</th>\n",
       "      <th>right_eye_inner_corner_y</th>\n",
       "      <th>...</th>\n",
       "      <th>nose_tip_y</th>\n",
       "      <th>mouth_left_corner_x</th>\n",
       "      <th>mouth_left_corner_y</th>\n",
       "      <th>mouth_right_corner_x</th>\n",
       "      <th>mouth_right_corner_y</th>\n",
       "      <th>mouth_center_top_lip_x</th>\n",
       "      <th>mouth_center_top_lip_y</th>\n",
       "      <th>mouth_center_bottom_lip_x</th>\n",
       "      <th>mouth_center_bottom_lip_y</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.033564</td>\n",
       "      <td>39.002274</td>\n",
       "      <td>30.227008</td>\n",
       "      <td>36.421678</td>\n",
       "      <td>59.582075</td>\n",
       "      <td>39.647423</td>\n",
       "      <td>73.130346</td>\n",
       "      <td>39.969997</td>\n",
       "      <td>36.356571</td>\n",
       "      <td>37.389402</td>\n",
       "      <td>...</td>\n",
       "      <td>57.066803</td>\n",
       "      <td>61.195308</td>\n",
       "      <td>79.970165</td>\n",
       "      <td>28.614496</td>\n",
       "      <td>77.388992</td>\n",
       "      <td>43.312602</td>\n",
       "      <td>72.935459</td>\n",
       "      <td>43.130707</td>\n",
       "      <td>84.485774</td>\n",
       "      <td>238 236 237 238 240 240 239 241 241 243 240 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.332936</td>\n",
       "      <td>34.970077</td>\n",
       "      <td>29.949277</td>\n",
       "      <td>33.448715</td>\n",
       "      <td>58.856170</td>\n",
       "      <td>35.274349</td>\n",
       "      <td>70.722723</td>\n",
       "      <td>36.187166</td>\n",
       "      <td>36.034723</td>\n",
       "      <td>34.361532</td>\n",
       "      <td>...</td>\n",
       "      <td>55.660936</td>\n",
       "      <td>56.421447</td>\n",
       "      <td>76.352000</td>\n",
       "      <td>35.122383</td>\n",
       "      <td>76.047660</td>\n",
       "      <td>46.684596</td>\n",
       "      <td>70.266553</td>\n",
       "      <td>45.467915</td>\n",
       "      <td>85.480170</td>\n",
       "      <td>219 215 204 196 204 211 212 200 180 168 178 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
       "0          66.033564          39.002274           30.227008   \n",
       "1          64.332936          34.970077           29.949277   \n",
       "\n",
       "   right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n",
       "0           36.421678                59.582075                39.647423   \n",
       "1           33.448715                58.856170                35.274349   \n",
       "\n",
       "   left_eye_outer_corner_x  left_eye_outer_corner_y  right_eye_inner_corner_x  \\\n",
       "0                73.130346                39.969997                 36.356571   \n",
       "1                70.722723                36.187166                 36.034723   \n",
       "\n",
       "   right_eye_inner_corner_y  ...  nose_tip_y  mouth_left_corner_x  \\\n",
       "0                 37.389402  ...   57.066803            61.195308   \n",
       "1                 34.361532  ...   55.660936            56.421447   \n",
       "\n",
       "   mouth_left_corner_y  mouth_right_corner_x  mouth_right_corner_y  \\\n",
       "0            79.970165             28.614496             77.388992   \n",
       "1            76.352000             35.122383             76.047660   \n",
       "\n",
       "   mouth_center_top_lip_x  mouth_center_top_lip_y  mouth_center_bottom_lip_x  \\\n",
       "0               43.312602               72.935459                  43.130707   \n",
       "1               46.684596               70.266553                  45.467915   \n",
       "\n",
       "   mouth_center_bottom_lip_y  \\\n",
       "0                  84.485774   \n",
       "1                  85.480170   \n",
       "\n",
       "                                               Image  \n",
       "0  238 236 237 238 240 240 239 241 241 243 240 23...  \n",
       "1  219 215 204 196 204 211 212 200 180 168 178 19...  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1. coordinates={''}\n",
    "####2 .img (reshape==>150,150) ### np.resize()\n",
    "### [1,2,3,4] 1,1\n",
    "kp['Image'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([238., 236., 237., ...,  70.,  75.,  90.])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## mapping a function\n",
    "np.array(kp['Image'].iloc[0].split(\" \"),dtype=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_array(row):\n",
    "    return np.array(row.split(\" \"),dtype=\"float\")\n",
    "kp['Image_new']=kp['Image'].map(split_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [238.0, 236.0, 237.0, 238.0, 240.0, 240.0, 239...\n",
       "1       [219.0, 215.0, 204.0, 196.0, 204.0, 211.0, 212...\n",
       "2       [144.0, 142.0, 159.0, 180.0, 188.0, 188.0, 184...\n",
       "3       [193.0, 192.0, 193.0, 194.0, 194.0, 194.0, 193...\n",
       "4       [147.0, 148.0, 160.0, 196.0, 215.0, 214.0, 216...\n",
       "5       [167.0, 169.0, 170.0, 167.0, 156.0, 145.0, 106...\n",
       "6       [109.0, 109.0, 125.0, 141.0, 145.0, 139.0, 120...\n",
       "7       [178.0, 177.0, 178.0, 179.0, 179.0, 179.0, 181...\n",
       "8       [164.0, 158.0, 118.0, 76.0, 66.0, 69.0, 59.0, ...\n",
       "9       [226.0, 227.0, 225.0, 224.0, 221.0, 220.0, 215...\n",
       "10      [52.0, 51.0, 54.0, 57.0, 57.0, 56.0, 55.0, 55....\n",
       "11      [142.0, 124.0, 123.0, 133.0, 140.0, 147.0, 151...\n",
       "12      [86.0, 93.0, 106.0, 114.0, 112.0, 110.0, 111.0...\n",
       "13      [75.0, 65.0, 63.0, 75.0, 70.0, 78.0, 84.0, 97....\n",
       "14      [119.0, 106.0, 101.0, 106.0, 89.0, 66.0, 67.0,...\n",
       "15      [52.0, 54.0, 74.0, 76.0, 55.0, 48.0, 47.0, 41....\n",
       "16      [201.0, 200.0, 202.0, 193.0, 124.0, 59.0, 53.0...\n",
       "17      [202.0, 201.0, 201.0, 202.0, 201.0, 200.0, 200...\n",
       "18      [181.0, 182.0, 182.0, 181.0, 182.0, 184.0, 186...\n",
       "19      [64.0, 56.0, 53.0, 51.0, 57.0, 74.0, 85.0, 86....\n",
       "20      [240.0, 240.0, 240.0, 239.0, 235.0, 233.0, 231...\n",
       "21      [245.0, 245.0, 245.0, 252.0, 210.0, 95.0, 46.0...\n",
       "22      [185.0, 185.0, 187.0, 185.0, 184.0, 184.0, 184...\n",
       "23      [241.0, 241.0, 241.0, 240.0, 241.0, 239.0, 235...\n",
       "24      [109.0, 106.0, 57.0, 10.0, 11.0, 18.0, 17.0, 1...\n",
       "25      [254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254...\n",
       "26      [5.0, 2.0, 5.0, 9.0, 10.0, 5.0, 6.0, 8.0, 4.0,...\n",
       "27      [196.0, 195.0, 192.0, 192.0, 191.0, 191.0, 189...\n",
       "28      [177.0, 175.0, 176.0, 175.0, 177.0, 177.0, 176...\n",
       "29      [160.0, 157.0, 159.0, 152.0, 143.0, 160.0, 176...\n",
       "                              ...                        \n",
       "7019    [66.0, 60.0, 81.0, 68.0, 66.0, 49.0, 41.0, 61....\n",
       "7020    [39.0, 33.0, 26.0, 20.0, 15.0, 12.0, 10.0, 8.0...\n",
       "7021    [75.0, 75.0, 76.0, 77.0, 78.0, 81.0, 86.0, 93....\n",
       "7022    [136.0, 145.0, 170.0, 181.0, 163.0, 149.0, 144...\n",
       "7023    [152.0, 149.0, 139.0, 129.0, 105.0, 81.0, 73.0...\n",
       "7024    [15.0, 15.0, 14.0, 13.0, 14.0, 14.0, 14.0, 19....\n",
       "7025    [47.0, 47.0, 47.0, 47.0, 46.0, 46.0, 47.0, 44....\n",
       "7026    [17.0, 19.0, 19.0, 19.0, 18.0, 16.0, 15.0, 13....\n",
       "7027    [28.0, 28.0, 26.0, 25.0, 24.0, 26.0, 37.0, 38....\n",
       "7028    [85.0, 86.0, 86.0, 86.0, 84.0, 84.0, 84.0, 83....\n",
       "7029    [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17....\n",
       "7030    [18.0, 38.0, 48.0, 36.0, 18.0, 14.0, 13.0, 11....\n",
       "7031    [8.0, 15.0, 20.0, 16.0, 12.0, 10.0, 11.0, 19.0...\n",
       "7032    [196.0, 180.0, 171.0, 159.0, 153.0, 156.0, 160...\n",
       "7033    [146.0, 142.0, 153.0, 168.0, 133.0, 54.0, 22.0...\n",
       "7034    [65.0, 62.0, 67.0, 96.0, 99.0, 94.0, 82.0, 56....\n",
       "7035    [155.0, 157.0, 159.0, 157.0, 157.0, 159.0, 161...\n",
       "7036    [247.0, 244.0, 241.0, 238.0, 233.0, 227.0, 218...\n",
       "7037    [242.0, 244.0, 247.0, 226.0, 212.0, 226.0, 237...\n",
       "7038    [59.0, 55.0, 59.0, 65.0, 93.0, 145.0, 185.0, 2...\n",
       "7039    [43.0, 49.0, 57.0, 67.0, 81.0, 98.0, 97.0, 94....\n",
       "7040    [139.0, 140.0, 143.0, 141.0, 141.0, 140.0, 140...\n",
       "7041    [164.0, 165.0, 167.0, 168.0, 169.0, 170.0, 172...\n",
       "7042    [254.0, 235.0, 191.0, 141.0, 106.0, 93.0, 94.0...\n",
       "7043    [150.0, 150.0, 132.0, 63.0, 44.0, 74.0, 86.0, ...\n",
       "7044    [71.0, 74.0, 85.0, 105.0, 116.0, 128.0, 139.0,...\n",
       "7045    [60.0, 60.0, 62.0, 57.0, 55.0, 51.0, 49.0, 48....\n",
       "7046    [74.0, 74.0, 74.0, 78.0, 79.0, 79.0, 79.0, 81....\n",
       "7047    [254.0, 254.0, 254.0, 254.0, 254.0, 238.0, 193...\n",
       "7048    [53.0, 62.0, 67.0, 76.0, 86.0, 91.0, 97.0, 105...\n",
       "Name: Image_new, Length: 7049, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp['Image_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 0]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,5,6,7,8,0] #3 by 3 np.resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
