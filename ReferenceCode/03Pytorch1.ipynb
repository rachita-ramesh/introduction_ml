{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch Primer**\n",
    "\n",
    "- Introduction to tensors\n",
    "- Simple tensor operations\n",
    "- Gradient Computations\n",
    "- Doing gradient descent using pytorch\n",
    "- Write a simple linear regression\n",
    "- Write a logistic classifier\n",
    "- Write an MLP\n",
    "\n",
    "Pytorch Tensors are just like Numpy Arrays but they can be accelerated using GPU. Just like numpy arrays they also support matrix algebra operations, apart from that, these tensors support the abilty to compute gradients on the fly, so implimenting gradient descent operations is very straight forward as one doesn't have to compute  gradients using analytical solutions.\n",
    "\n",
    "First we will see how the tensors behave particularly their behaviour with regards to gradient computation. We will see how to do gradient descent on polynomials, write linear regressor, logistic classifier and an MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "## Torch base class will help in creating tensors, tensors help in representing training \n",
    "## data as well as model parameters, these are the primitive datatypes that pytorch uses\n",
    "data1=torch.tensor([12,34,56],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=torch.tensor(([32,45,56],[56,67,78]),dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32., 45., 56.],\n",
       "        [56., 67., 78.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of data1 is torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(f'The size of data1 is {data1.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Many time we may want to interact with pytorch elements and execute some arbitrary code, for that we may need to convert the torch objects to regular python objects\n",
    "data1.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data2.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[32., 45., 56.],\n",
       "         [56., 67., 78.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sometimes we may need to add dimensions or remove dimensions from a tensor, sqeeze() and unsqueeze() methods come in handy there\n",
    "data2.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.squeeze(0).squeeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32., 45., 56.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We can also index these tensors in a manner very similar to numpy arrays\n",
    "data2[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32., 45.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32., 45.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32.0, 45.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0,0:2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32., 45.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0,0:2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0,1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2550, 0.4493, 0.4206],\n",
       "        [0.9682, 0.6712, 0.5070]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### We can create tensors of zeros, ones and filled with random numbers.\n",
    "torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9706e+00,  5.4347e-01, -9.3301e-01,  1.1585e-02, -2.1092e-01,\n",
       "          -2.8636e-01, -4.3048e-01, -7.7243e-01,  1.0074e+00,  2.6563e-02,\n",
       "          -1.7835e-01,  5.0962e-01, -9.2152e-01,  3.1352e-01,  5.9287e-01,\n",
       "          -9.9271e-01],\n",
       "         [ 3.5445e-01, -4.5338e-01,  1.1851e+00, -4.7767e-02,  9.5983e-02,\n",
       "           4.7104e-01,  6.2098e-03,  5.8078e-01, -5.7278e-01, -1.2683e+00,\n",
       "           9.5227e-01, -1.0499e+00,  1.0286e+00,  2.0051e-01, -3.4999e-01,\n",
       "           1.6797e+00],\n",
       "         [ 1.0216e+00, -9.3826e-01,  1.7736e+00, -7.0998e-01, -1.6478e+00,\n",
       "          -1.0165e+00, -1.5938e+00,  4.6973e-01,  7.2446e-01, -6.7441e-01,\n",
       "           1.3860e+00,  9.3168e-01,  2.7636e-01,  1.0726e+00, -2.0641e-01,\n",
       "           1.4069e+00],\n",
       "         [ 1.7036e+00,  1.4027e+00,  6.6465e-01, -8.3085e-01, -3.8858e-01,\n",
       "          -7.2094e-01, -1.2111e+00,  1.1046e+00, -3.3502e-01,  1.1410e+00,\n",
       "          -4.3375e-01, -2.2293e-01,  1.7995e-01, -3.2397e-01, -3.9472e-01,\n",
       "          -2.3414e+00],\n",
       "         [ 6.9475e-01,  1.8804e-01,  4.0649e-01, -4.9098e-01,  1.0735e+00,\n",
       "           2.8363e-02,  4.0137e-01, -6.9306e-01,  5.7521e-01, -2.9884e-02,\n",
       "          -1.8201e-01, -1.0446e-01,  7.3167e-01,  2.7017e-01, -2.0196e+00,\n",
       "           2.6729e+00],\n",
       "         [-6.5355e-02, -2.7044e-01,  2.3487e+00,  3.8221e-01, -9.5775e-01,\n",
       "           2.2321e-01, -1.4853e+00,  1.5281e+00,  2.6897e-01, -1.1510e+00,\n",
       "           7.2439e-01, -8.3649e-01,  5.2105e-01, -7.3778e-01, -5.9956e-01,\n",
       "           2.1703e-01],\n",
       "         [ 4.3994e-01, -2.3218e-01,  3.6837e-01,  2.2988e-01,  2.0051e-02,\n",
       "          -7.0980e-01, -6.0926e-01, -8.3589e-01,  5.2482e-01,  8.7791e-01,\n",
       "           5.6120e-01, -2.0030e+00,  2.6179e+00,  5.3901e-01,  9.5040e-02,\n",
       "           1.3805e+00],\n",
       "         [ 1.4724e+00, -3.3184e-01,  1.1931e+00,  5.9620e-01, -9.7742e-01,\n",
       "          -1.6420e-01, -8.4777e-01,  3.3824e-01,  9.3218e-01,  1.7817e+00,\n",
       "           2.5187e-01, -1.3852e+00, -6.9638e-01, -7.2786e-01, -6.0899e-01,\n",
       "          -4.8555e-01],\n",
       "         [ 1.3705e+00, -1.1456e+00, -7.4373e-01,  2.3364e-02, -2.5171e-01,\n",
       "          -6.4681e-01, -9.0689e-01,  1.7415e+00, -2.2629e+00, -2.0690e-01,\n",
       "          -2.2017e-01, -4.0607e-01, -4.0294e-01,  1.7004e+00,  6.0720e-01,\n",
       "          -1.3461e-01],\n",
       "         [ 4.1802e-02, -1.0588e-01, -2.2294e-01,  1.5034e+00,  3.7722e-01,\n",
       "           1.1990e-01, -1.5403e+00, -2.0416e-01, -6.4588e-01, -5.6479e-01,\n",
       "           1.0943e+00, -1.0481e+00, -9.6331e-01, -4.0876e-01, -5.5611e-01,\n",
       "           3.6549e-01],\n",
       "         [ 1.2006e+00, -4.5350e-01,  1.8707e-01,  1.4435e+00,  1.4256e+00,\n",
       "           7.4213e-02,  8.3443e-01,  8.1335e-01, -5.2135e-01,  6.5158e-01,\n",
       "           1.0019e-01, -6.2908e-01,  4.0441e-01,  5.6646e-01,  1.1376e+00,\n",
       "          -1.2401e+00],\n",
       "         [ 1.6526e+00,  2.3122e+00, -5.1175e-01, -4.4565e-01,  3.9992e-01,\n",
       "          -6.0401e-01,  9.4857e-02,  7.5872e-01, -4.0716e-01,  2.6189e-01,\n",
       "          -6.9521e-02,  3.8996e-01,  9.8575e-01, -6.3887e-01, -2.2346e+00,\n",
       "          -2.3611e-01],\n",
       "         [-1.2899e+00,  1.1468e+00,  2.2953e+00,  1.0757e+00, -6.8149e-01,\n",
       "           1.2767e+00, -7.1706e-01, -5.7228e-01, -7.6316e-01,  1.6311e+00,\n",
       "           1.9718e+00, -1.4676e+00,  2.9642e-01,  1.2849e+00, -3.4543e-01,\n",
       "           4.6138e-01],\n",
       "         [ 8.0942e-01,  5.6166e-04, -1.0255e+00,  2.6979e-01, -4.9641e-01,\n",
       "          -1.6393e-01,  2.1398e+00, -8.1192e-01,  6.1368e-01,  7.3052e-01,\n",
       "          -6.1705e-01,  2.7960e-01,  4.6360e-01,  1.1660e+00, -2.5870e+00,\n",
       "           1.3487e+00],\n",
       "         [ 1.1272e+00,  4.8760e-01,  4.5296e-01, -1.0091e+00, -1.4453e+00,\n",
       "          -7.4498e-01, -2.4506e-01,  6.1798e-01,  6.3445e-01, -1.5909e+00,\n",
       "          -8.9487e-01, -1.5146e+00,  7.4391e-01,  1.2419e+00,  4.9753e-01,\n",
       "           3.5103e-01],\n",
       "         [ 4.0215e-02,  2.3135e+00, -1.3571e+00, -8.7838e-01, -6.5923e-01,\n",
       "           2.9965e-03, -1.1940e-01, -1.4286e+00, -1.0186e+00,  3.3978e-01,\n",
       "           8.8839e-01, -1.7114e+00,  4.3940e-01, -3.0282e-01, -1.7055e-01,\n",
       "          -3.5231e-04]],\n",
       "\n",
       "        [[-4.6946e-01, -6.6346e-01,  5.4372e-01,  6.8613e-01, -2.1679e-02,\n",
       "           7.2673e-01,  1.4201e+00,  4.2864e-01, -4.2684e-03,  5.6813e-01,\n",
       "           1.2240e+00,  5.1655e-01, -1.8494e+00,  6.7152e-01, -7.9902e-01,\n",
       "          -1.9206e+00],\n",
       "         [-5.7753e-02, -7.4096e-01,  8.6743e-01, -1.5371e+00, -5.5688e-01,\n",
       "          -1.6763e+00,  3.6241e-01,  2.1906e-02,  1.5593e-01,  9.4076e-01,\n",
       "          -3.8919e-01,  1.5091e+00, -6.7693e-01, -5.8317e-01,  8.7411e-01,\n",
       "          -7.6473e-02],\n",
       "         [ 2.2384e-01,  1.8249e-01,  2.7891e-01, -7.9035e-01, -7.2959e-01,\n",
       "           9.7419e-01, -1.6326e-01, -8.7082e-01, -5.2636e-01, -9.8460e-02,\n",
       "          -1.0284e+00, -6.1261e-01,  6.5553e-02,  1.5225e-01,  1.4962e-01,\n",
       "           3.3782e-01],\n",
       "         [-5.6739e-01, -5.6260e-01,  2.0237e+00, -8.8896e-01,  1.6180e+00,\n",
       "          -4.7074e-01, -8.0267e-01, -1.8652e+00, -9.3279e-01,  1.5223e+00,\n",
       "           4.1896e-03, -4.3639e-01, -9.3384e-01, -1.1294e+00, -1.4533e+00,\n",
       "           6.8299e-01],\n",
       "         [ 7.8114e-01, -3.5541e-01, -7.7964e-01,  1.6467e+00,  1.7465e+00,\n",
       "           1.1393e+00,  6.2946e-01,  9.0389e-01,  6.9581e-01, -3.5062e-01,\n",
       "           2.0290e+00, -8.8066e-02,  2.3984e-01,  2.8486e-01, -3.4191e-01,\n",
       "           8.5469e-01],\n",
       "         [ 2.2221e-01,  2.8951e-01,  1.2226e+00,  1.3501e+00, -1.4161e+00,\n",
       "           1.4282e+00,  5.4208e-01,  1.4154e+00, -3.2704e-01,  2.7391e-01,\n",
       "           1.2118e-01, -1.0486e+00, -3.0571e-02, -3.5456e-01, -6.4539e-01,\n",
       "           8.5045e-01],\n",
       "         [-1.3317e+00,  7.1547e-01, -7.6824e-02,  1.1448e+00, -1.0060e-01,\n",
       "          -4.0050e-01, -1.4051e-01,  1.2556e+00, -1.9360e-01,  3.4312e-01,\n",
       "           1.9016e+00, -1.1321e-02,  1.1328e+00,  3.6961e-01,  9.0792e-01,\n",
       "          -2.6699e-01],\n",
       "         [ 8.0622e-01, -8.2421e-01, -6.1279e-01,  1.4537e+00,  3.5150e-01,\n",
       "           1.7880e+00, -1.1350e+00, -1.2841e+00, -1.5820e+00, -8.5064e-01,\n",
       "          -3.1146e-01,  1.2726e+00,  1.3450e-02, -1.7853e-01,  1.1852e+00,\n",
       "           1.0499e+00],\n",
       "         [ 1.7630e+00, -3.7067e-01, -1.9137e-02,  1.7994e-01, -1.8881e+00,\n",
       "          -6.5259e-01,  5.2012e-02, -5.0056e-01,  9.1808e-01,  1.3061e+00,\n",
       "          -2.3296e-01,  5.8676e-01,  5.9585e-03,  1.7355e+00,  1.0883e+00,\n",
       "          -7.4977e-01],\n",
       "         [-2.2330e-01, -1.7192e+00, -1.3476e+00,  1.3163e+00, -1.1865e+00,\n",
       "          -1.5525e+00,  5.0639e-01,  4.1370e-01, -2.0495e+00, -2.5507e+00,\n",
       "           1.0347e+00,  2.2786e+00,  8.5217e-01,  9.0726e-01, -4.0662e-01,\n",
       "          -1.7424e+00],\n",
       "         [-9.1939e-01, -1.3526e+00,  6.9104e-01, -8.8799e-01,  1.1700e+00,\n",
       "          -8.1177e-01, -1.3722e+00, -6.9929e-01,  1.8682e-01,  2.5511e-01,\n",
       "          -4.2030e-02, -1.1253e-01, -4.0053e-01, -1.2408e-01,  1.5946e+00,\n",
       "           2.2814e+00],\n",
       "         [ 2.7425e-01,  6.7211e-01, -1.1307e+00, -8.0741e-02, -8.7343e-01,\n",
       "          -1.5238e+00, -1.1844e+00, -3.4177e-01, -1.0928e+00,  6.9804e-01,\n",
       "          -1.2608e+00,  3.0498e-01, -5.8568e-02,  4.7291e-02, -3.1042e-01,\n",
       "          -3.6866e-01],\n",
       "         [-1.0650e+00, -1.6029e+00, -1.3667e+00,  1.3219e+00,  1.5227e+00,\n",
       "           2.4653e-01, -2.3567e+00, -1.2373e+00,  7.6061e-02,  3.5943e-01,\n",
       "          -3.5669e-01,  9.6534e-01,  3.0446e-01, -7.6754e-01,  7.6230e-02,\n",
       "          -1.2858e-01],\n",
       "         [-5.4682e-01, -4.9754e-01,  3.8133e-01, -8.0919e-01, -2.0519e-01,\n",
       "          -7.9344e-01,  1.4580e-01, -1.1241e-01,  9.4318e-02,  2.2885e-01,\n",
       "           2.9857e-01,  1.8840e-01,  7.7411e-01,  5.8292e-01, -3.8445e-01,\n",
       "          -1.0285e+00],\n",
       "         [-7.7895e-01, -4.4175e-02, -4.0247e-01, -1.0242e+00,  7.1248e-01,\n",
       "           8.3612e-01,  4.0415e-01,  1.4638e+00, -1.3418e-01,  3.2345e-01,\n",
       "          -2.1157e+00, -6.7815e-01,  1.1410e-01, -1.4086e+00,  2.6179e-01,\n",
       "           1.2677e+00],\n",
       "         [ 1.5636e+00, -1.0634e+00,  2.8010e-01, -9.7432e-01,  1.8983e-01,\n",
       "          -1.4544e+00, -2.7405e-01, -1.5074e+00, -4.6802e-01, -1.7873e+00,\n",
       "           1.4480e+00,  8.1350e-02, -6.0744e-01, -1.2581e+00,  2.1388e-01,\n",
       "           5.4200e-01]],\n",
       "\n",
       "        [[ 4.2603e-01,  2.2272e+00,  9.9781e-01,  1.2448e+00,  2.7737e-01,\n",
       "           8.2897e-01, -6.9214e-01,  9.7496e-02, -4.6750e-01, -2.0198e-01,\n",
       "           5.5015e-02,  1.5531e+00,  4.4772e-01, -7.6770e-01, -2.9421e-01,\n",
       "           7.1605e-01],\n",
       "         [ 3.7439e-01,  1.1115e+00, -2.0049e+00,  1.5683e+00,  6.1543e-01,\n",
       "           2.1772e-02, -1.5468e-01,  1.1675e+00,  2.0643e+00, -1.1599e+00,\n",
       "          -1.4115e+00, -1.3700e+00,  2.3140e-01,  1.3190e+00, -9.7869e-01,\n",
       "           3.1567e-01],\n",
       "         [ 1.7265e-01,  1.6982e+00,  7.9029e-01,  1.9955e+00,  3.5509e-01,\n",
       "           9.4486e-01, -1.7024e-01, -9.4114e-01,  6.8140e-01,  5.8023e-01,\n",
       "          -1.2817e+00,  7.2467e-01, -6.1303e-01, -9.9987e-01, -8.7345e-01,\n",
       "           8.8068e-01],\n",
       "         [-9.2966e-01,  7.3756e-01, -1.7306e+00, -2.7477e-01,  2.5648e+00,\n",
       "          -1.8511e+00,  4.5062e-02,  1.4419e+00,  1.0942e+00, -1.3020e-02,\n",
       "           1.5272e+00, -1.3384e+00, -7.4627e-01,  1.9289e-01, -5.3852e-01,\n",
       "          -4.2193e-01],\n",
       "         [ 6.8337e-01, -1.0723e+00,  6.1687e-01,  2.6095e-02, -6.6556e-01,\n",
       "           1.2848e+00,  4.4693e-01,  8.0696e-01,  5.6990e-01, -1.1359e+00,\n",
       "           7.4928e-01, -1.5658e+00,  6.0652e-01, -1.3496e+00, -4.9206e-01,\n",
       "          -1.0678e+00],\n",
       "         [-7.9828e-01,  9.6584e-01, -6.0412e-01,  8.6043e-01,  7.4969e-01,\n",
       "           4.3104e-01,  5.4312e-01,  3.1107e-01,  1.8142e+00,  1.1871e-01,\n",
       "           2.5359e-01,  4.3095e-01,  5.3387e-01, -1.9679e+00,  6.6970e-01,\n",
       "           4.1951e-01],\n",
       "         [-2.9764e-02, -2.1893e-01,  1.9004e-01,  2.3397e+00, -6.1185e-01,\n",
       "          -4.9952e-01,  1.7174e-01, -7.8013e-02,  2.6933e-01, -3.0561e-01,\n",
       "           6.7691e-01, -3.2335e-01,  5.0599e-02,  4.5114e-01,  4.9927e-01,\n",
       "           1.8254e+00],\n",
       "         [ 1.3656e+00,  1.4522e+00,  1.5040e+00, -3.0878e-01, -2.4080e-02,\n",
       "          -4.5370e-01,  2.0110e-01, -5.4832e-01, -8.5834e-01,  1.0534e+00,\n",
       "           3.7662e-01, -8.3596e-01,  7.0209e-02,  8.1892e-01, -5.1926e-01,\n",
       "           1.5674e+00],\n",
       "         [ 1.9579e+00,  2.1523e-01,  1.1322e+00,  1.4240e+00, -3.0110e-01,\n",
       "           4.4422e-01, -1.0853e-01, -1.8726e+00, -1.2361e-01,  7.8653e-02,\n",
       "           5.4107e-02,  7.4786e-01,  5.4245e-01, -1.2153e+00, -5.1206e-01,\n",
       "          -5.1106e-01],\n",
       "         [ 2.6805e-01, -3.5344e-01,  2.3614e-01,  1.5714e+00, -4.8378e-01,\n",
       "          -1.9424e+00,  1.3281e-02, -1.9639e+00, -8.6688e-01, -3.6160e-01,\n",
       "           1.2702e-01,  7.2196e-01,  2.1198e+00, -6.2255e-01,  8.8059e-01,\n",
       "           5.1473e-01],\n",
       "         [ 3.7473e-01,  5.9167e-01,  4.2111e-01,  1.0663e+00, -1.0749e-01,\n",
       "          -4.7854e-01,  1.5678e+00,  5.1356e-01,  8.4557e-01, -8.0990e-01,\n",
       "           1.2283e+00,  7.5262e-01, -8.1277e-01,  8.2255e-01, -1.5058e+00,\n",
       "          -1.9301e-01],\n",
       "         [-9.9072e-01,  2.9686e-01,  1.8909e+00, -1.4271e+00,  3.3095e+00,\n",
       "          -1.8101e-01,  4.8745e-01, -4.1341e-01,  1.3553e+00,  7.4978e-01,\n",
       "           6.7063e-01,  5.9842e-01,  8.1641e-01, -3.5969e-01, -1.1483e+00,\n",
       "          -9.1769e-02],\n",
       "         [-6.9396e-02,  7.4984e-01, -6.9146e-01, -3.2452e-01, -2.9652e-01,\n",
       "          -1.1237e-01, -1.0691e+00, -2.5989e+00, -2.2841e-01,  1.1040e+00,\n",
       "          -8.0473e-01,  2.0937e+00, -7.1098e-01,  1.9559e+00, -1.6343e-01,\n",
       "          -5.2725e-01],\n",
       "         [-3.3940e-01,  1.2103e+00,  3.3963e-01,  5.5228e-01,  1.4239e-01,\n",
       "           3.2991e-01, -1.3070e+00,  5.8406e-02,  2.2269e-01,  6.1850e-02,\n",
       "          -1.8751e+00,  8.4274e-01, -2.4840e-01, -5.9551e-01, -1.3412e-02,\n",
       "          -2.3431e+00],\n",
       "         [-1.5491e+00, -1.6744e+00,  4.4304e-01, -1.2254e+00,  1.1102e+00,\n",
       "           1.1396e+00, -9.4514e-01, -4.9825e-01, -5.4585e-01,  5.2503e-03,\n",
       "          -1.1576e+00, -8.3881e-01, -1.2596e-01, -2.2129e-01,  2.4872e+00,\n",
       "          -1.2946e+00],\n",
       "         [ 5.0798e-01,  2.6986e-01, -5.7455e-01,  5.5420e-02,  8.5974e-01,\n",
       "          -3.5527e-01, -3.2306e-01, -8.1580e-01, -1.1224e+00, -1.0496e-01,\n",
       "           3.6343e-03,  1.7798e+00,  4.9443e-01,  9.9622e-01, -4.8303e-01,\n",
       "           5.1248e-01]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((3,16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.8091e-45, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see how we can impliment gradient descent using pytorch on a simple polynomial\n",
    "\n",
    "Imagine we wanted to minimize the following expression:\n",
    "$x^2+4x-18$\n",
    "\n",
    "We can do this using gradient descent. First let's create a simple computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([0.0],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=x**2+4*x-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad ### 2x+4 at x=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=x**2+4*x-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad # What is going on? https://pytorch.org/docs/stable/autograd.html .grad is \n",
    "       # actually just the sum of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad  # We need to manually \"zero\" the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Let's impliment the gradient descent ####\n",
    "x=torch.tensor([0.0],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.0 4.0 0.0\n",
      "-18.15839958190918 3.9200000762939453 -0.03999999910593033\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "for i in range(2):\n",
    "    z=x**2+4*x-18\n",
    "    z.backward()\n",
    "    print(z.item(),x.grad.item(),x.item())\n",
    "  #  x-=lr*x.grad we don't want to include the weight update step in the gradient computation so while updating we turn off grad tracking\n",
    "  # x.grad.zero_()\n",
    "    with torch.no_grad():\n",
    "        x-=lr*x.grad\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can attempt to build our own regression model using pytoch, let's first load our data and create simple mechanics to build a regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reg_d=pd.read_csv(\"data/regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0        8.0         307.0       130.0  3504.0          12.0  70.0   \n",
       "1  15.0        8.0         350.0       165.0  3693.0          11.5  70.0   \n",
       "\n",
       "   origin  \n",
       "0     1.0  \n",
       "1     1.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_d.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=reg_d['mpg'].values\n",
    "X=reg_d[['cylinders']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.tensor(y)\n",
    "X=torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([398, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=torch.randn(1,1)\n",
    "b=torch.randn(1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=torch.matmul(X.float(),W)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([398, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=pred-y.reshape(398,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([398, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=torch.sum(diff*diff)/diff.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(951.7673, dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss 672.07, W =-0.36, b = 0.63\n",
      "Iteration 2, loss 670.4, W =-0.36, b = 0.63\n",
      "Iteration 3, loss 668.74, W =-0.35, b = 0.63\n",
      "Iteration 4, loss 667.09, W =-0.34, b = 0.63\n",
      "Iteration 5, loss 665.44, W =-0.34, b = 0.63\n",
      "Iteration 6, loss 663.8, W =-0.33, b = 0.63\n",
      "Iteration 7, loss 662.16, W =-0.32, b = 0.63\n",
      "Iteration 8, loss 660.52, W =-0.32, b = 0.64\n",
      "Iteration 9, loss 658.9, W =-0.31, b = 0.64\n",
      "Iteration 10, loss 657.28, W =-0.31, b = 0.64\n",
      "Iteration 11, loss 655.66, W =-0.3, b = 0.64\n",
      "Iteration 12, loss 654.05, W =-0.29, b = 0.64\n",
      "Iteration 13, loss 652.44, W =-0.29, b = 0.64\n",
      "Iteration 14, loss 650.84, W =-0.28, b = 0.64\n",
      "Iteration 15, loss 649.25, W =-0.27, b = 0.64\n",
      "Iteration 16, loss 647.66, W =-0.27, b = 0.64\n",
      "Iteration 17, loss 646.07, W =-0.26, b = 0.65\n",
      "Iteration 18, loss 644.5, W =-0.26, b = 0.65\n",
      "Iteration 19, loss 642.92, W =-0.25, b = 0.65\n",
      "Iteration 20, loss 641.35, W =-0.24, b = 0.65\n",
      "Iteration 21, loss 639.79, W =-0.24, b = 0.65\n",
      "Iteration 22, loss 638.23, W =-0.23, b = 0.65\n",
      "Iteration 23, loss 636.68, W =-0.22, b = 0.65\n",
      "Iteration 24, loss 635.14, W =-0.22, b = 0.65\n",
      "Iteration 25, loss 633.59, W =-0.21, b = 0.66\n",
      "Iteration 26, loss 632.06, W =-0.21, b = 0.66\n",
      "Iteration 27, loss 630.53, W =-0.2, b = 0.66\n",
      "Iteration 28, loss 629.0, W =-0.19, b = 0.66\n",
      "Iteration 29, loss 627.48, W =-0.19, b = 0.66\n",
      "Iteration 30, loss 625.96, W =-0.18, b = 0.66\n",
      "Iteration 31, loss 624.45, W =-0.18, b = 0.66\n",
      "Iteration 32, loss 622.95, W =-0.17, b = 0.66\n",
      "Iteration 33, loss 621.44, W =-0.16, b = 0.67\n",
      "Iteration 34, loss 619.95, W =-0.16, b = 0.67\n",
      "Iteration 35, loss 618.46, W =-0.15, b = 0.67\n",
      "Iteration 36, loss 616.97, W =-0.15, b = 0.67\n",
      "Iteration 37, loss 615.49, W =-0.14, b = 0.67\n",
      "Iteration 38, loss 614.02, W =-0.13, b = 0.67\n",
      "Iteration 39, loss 612.55, W =-0.13, b = 0.67\n",
      "Iteration 40, loss 611.08, W =-0.12, b = 0.67\n",
      "Iteration 41, loss 609.62, W =-0.12, b = 0.67\n",
      "Iteration 42, loss 608.16, W =-0.11, b = 0.68\n",
      "Iteration 43, loss 606.71, W =-0.1, b = 0.68\n",
      "Iteration 44, loss 605.27, W =-0.1, b = 0.68\n",
      "Iteration 45, loss 603.82, W =-0.09, b = 0.68\n",
      "Iteration 46, loss 602.39, W =-0.09, b = 0.68\n",
      "Iteration 47, loss 600.96, W =-0.08, b = 0.68\n",
      "Iteration 48, loss 599.53, W =-0.07, b = 0.68\n",
      "Iteration 49, loss 598.11, W =-0.07, b = 0.68\n",
      "Iteration 50, loss 596.69, W =-0.06, b = 0.69\n",
      "Iteration 51, loss 595.28, W =-0.06, b = 0.69\n",
      "Iteration 52, loss 593.87, W =-0.05, b = 0.69\n",
      "Iteration 53, loss 592.47, W =-0.05, b = 0.69\n",
      "Iteration 54, loss 591.07, W =-0.04, b = 0.69\n",
      "Iteration 55, loss 589.68, W =-0.03, b = 0.69\n",
      "Iteration 56, loss 588.29, W =-0.03, b = 0.69\n",
      "Iteration 57, loss 586.9, W =-0.02, b = 0.69\n",
      "Iteration 58, loss 585.52, W =-0.02, b = 0.69\n",
      "Iteration 59, loss 584.15, W =-0.01, b = 0.7\n",
      "Iteration 60, loss 582.78, W =-0.01, b = 0.7\n",
      "Iteration 61, loss 581.41, W =0.0, b = 0.7\n",
      "Iteration 62, loss 580.05, W =0.01, b = 0.7\n",
      "Iteration 63, loss 578.7, W =0.01, b = 0.7\n",
      "Iteration 64, loss 577.34, W =0.02, b = 0.7\n",
      "Iteration 65, loss 576.0, W =0.02, b = 0.7\n",
      "Iteration 66, loss 574.65, W =0.03, b = 0.7\n",
      "Iteration 67, loss 573.32, W =0.03, b = 0.71\n",
      "Iteration 68, loss 571.98, W =0.04, b = 0.71\n",
      "Iteration 69, loss 570.65, W =0.05, b = 0.71\n",
      "Iteration 70, loss 569.33, W =0.05, b = 0.71\n",
      "Iteration 71, loss 568.01, W =0.06, b = 0.71\n",
      "Iteration 72, loss 566.69, W =0.06, b = 0.71\n",
      "Iteration 73, loss 565.38, W =0.07, b = 0.71\n",
      "Iteration 74, loss 564.07, W =0.07, b = 0.71\n",
      "Iteration 75, loss 562.77, W =0.08, b = 0.71\n",
      "Iteration 76, loss 561.47, W =0.09, b = 0.72\n",
      "Iteration 77, loss 560.18, W =0.09, b = 0.72\n",
      "Iteration 78, loss 558.89, W =0.1, b = 0.72\n",
      "Iteration 79, loss 557.61, W =0.1, b = 0.72\n",
      "Iteration 80, loss 556.32, W =0.11, b = 0.72\n",
      "Iteration 81, loss 555.05, W =0.11, b = 0.72\n",
      "Iteration 82, loss 553.78, W =0.12, b = 0.72\n",
      "Iteration 83, loss 552.51, W =0.12, b = 0.72\n",
      "Iteration 84, loss 551.24, W =0.13, b = 0.72\n",
      "Iteration 85, loss 549.98, W =0.14, b = 0.73\n",
      "Iteration 86, loss 548.73, W =0.14, b = 0.73\n",
      "Iteration 87, loss 547.48, W =0.15, b = 0.73\n",
      "Iteration 88, loss 546.23, W =0.15, b = 0.73\n",
      "Iteration 89, loss 544.99, W =0.16, b = 0.73\n",
      "Iteration 90, loss 543.75, W =0.16, b = 0.73\n",
      "Iteration 91, loss 542.52, W =0.17, b = 0.73\n",
      "Iteration 92, loss 541.29, W =0.17, b = 0.73\n",
      "Iteration 93, loss 540.06, W =0.18, b = 0.73\n",
      "Iteration 94, loss 538.84, W =0.18, b = 0.74\n",
      "Iteration 95, loss 537.62, W =0.19, b = 0.74\n",
      "Iteration 96, loss 536.41, W =0.2, b = 0.74\n",
      "Iteration 97, loss 535.2, W =0.2, b = 0.74\n",
      "Iteration 98, loss 533.99, W =0.21, b = 0.74\n",
      "Iteration 99, loss 532.79, W =0.21, b = 0.74\n",
      "Iteration 100, loss 531.59, W =0.22, b = 0.74\n",
      "Iteration 101, loss 530.4, W =0.22, b = 0.74\n",
      "Iteration 102, loss 529.21, W =0.23, b = 0.74\n",
      "Iteration 103, loss 528.03, W =0.23, b = 0.74\n",
      "Iteration 104, loss 526.85, W =0.24, b = 0.75\n",
      "Iteration 105, loss 525.67, W =0.24, b = 0.75\n",
      "Iteration 106, loss 524.49, W =0.25, b = 0.75\n",
      "Iteration 107, loss 523.33, W =0.25, b = 0.75\n",
      "Iteration 108, loss 522.16, W =0.26, b = 0.75\n",
      "Iteration 109, loss 521.0, W =0.27, b = 0.75\n",
      "Iteration 110, loss 519.84, W =0.27, b = 0.75\n",
      "Iteration 111, loss 518.69, W =0.28, b = 0.75\n",
      "Iteration 112, loss 517.54, W =0.28, b = 0.75\n",
      "Iteration 113, loss 516.39, W =0.29, b = 0.76\n",
      "Iteration 114, loss 515.25, W =0.29, b = 0.76\n",
      "Iteration 115, loss 514.11, W =0.3, b = 0.76\n",
      "Iteration 116, loss 512.98, W =0.3, b = 0.76\n",
      "Iteration 117, loss 511.85, W =0.31, b = 0.76\n",
      "Iteration 118, loss 510.72, W =0.31, b = 0.76\n",
      "Iteration 119, loss 509.6, W =0.32, b = 0.76\n",
      "Iteration 120, loss 508.48, W =0.32, b = 0.76\n",
      "Iteration 121, loss 507.36, W =0.33, b = 0.76\n",
      "Iteration 122, loss 506.25, W =0.33, b = 0.77\n",
      "Iteration 123, loss 505.14, W =0.34, b = 0.77\n",
      "Iteration 124, loss 504.04, W =0.34, b = 0.77\n",
      "Iteration 125, loss 502.94, W =0.35, b = 0.77\n",
      "Iteration 126, loss 501.84, W =0.35, b = 0.77\n",
      "Iteration 127, loss 500.75, W =0.36, b = 0.77\n",
      "Iteration 128, loss 499.66, W =0.36, b = 0.77\n",
      "Iteration 129, loss 498.57, W =0.37, b = 0.77\n",
      "Iteration 130, loss 497.49, W =0.37, b = 0.77\n",
      "Iteration 131, loss 496.41, W =0.38, b = 0.77\n",
      "Iteration 132, loss 495.34, W =0.38, b = 0.78\n",
      "Iteration 133, loss 494.27, W =0.39, b = 0.78\n",
      "Iteration 134, loss 493.2, W =0.39, b = 0.78\n",
      "Iteration 135, loss 492.13, W =0.4, b = 0.78\n",
      "Iteration 136, loss 491.07, W =0.4, b = 0.78\n",
      "Iteration 137, loss 490.02, W =0.41, b = 0.78\n",
      "Iteration 138, loss 488.96, W =0.41, b = 0.78\n",
      "Iteration 139, loss 487.91, W =0.42, b = 0.78\n",
      "Iteration 140, loss 486.87, W =0.42, b = 0.78\n",
      "Iteration 141, loss 485.82, W =0.43, b = 0.78\n",
      "Iteration 142, loss 484.79, W =0.43, b = 0.79\n",
      "Iteration 143, loss 483.75, W =0.44, b = 0.79\n",
      "Iteration 144, loss 482.72, W =0.44, b = 0.79\n",
      "Iteration 145, loss 481.69, W =0.45, b = 0.79\n",
      "Iteration 146, loss 480.66, W =0.45, b = 0.79\n",
      "Iteration 147, loss 479.64, W =0.46, b = 0.79\n",
      "Iteration 148, loss 478.62, W =0.46, b = 0.79\n",
      "Iteration 149, loss 477.61, W =0.47, b = 0.79\n",
      "Iteration 150, loss 476.6, W =0.47, b = 0.79\n",
      "Iteration 151, loss 475.59, W =0.48, b = 0.8\n",
      "Iteration 152, loss 474.58, W =0.48, b = 0.8\n",
      "Iteration 153, loss 473.58, W =0.49, b = 0.8\n",
      "Iteration 154, loss 472.58, W =0.49, b = 0.8\n",
      "Iteration 155, loss 471.59, W =0.5, b = 0.8\n",
      "Iteration 156, loss 470.6, W =0.5, b = 0.8\n",
      "Iteration 157, loss 469.61, W =0.51, b = 0.8\n",
      "Iteration 158, loss 468.63, W =0.51, b = 0.8\n",
      "Iteration 159, loss 467.64, W =0.52, b = 0.8\n",
      "Iteration 160, loss 466.67, W =0.52, b = 0.8\n",
      "Iteration 161, loss 465.69, W =0.53, b = 0.81\n",
      "Iteration 162, loss 464.72, W =0.53, b = 0.81\n",
      "Iteration 163, loss 463.75, W =0.54, b = 0.81\n",
      "Iteration 164, loss 462.79, W =0.54, b = 0.81\n",
      "Iteration 165, loss 461.82, W =0.55, b = 0.81\n",
      "Iteration 166, loss 460.87, W =0.55, b = 0.81\n",
      "Iteration 167, loss 459.91, W =0.56, b = 0.81\n",
      "Iteration 168, loss 458.96, W =0.56, b = 0.81\n",
      "Iteration 169, loss 458.01, W =0.57, b = 0.81\n",
      "Iteration 170, loss 457.06, W =0.57, b = 0.81\n",
      "Iteration 171, loss 456.12, W =0.58, b = 0.82\n",
      "Iteration 172, loss 455.18, W =0.58, b = 0.82\n",
      "Iteration 173, loss 454.25, W =0.59, b = 0.82\n",
      "Iteration 174, loss 453.31, W =0.59, b = 0.82\n",
      "Iteration 175, loss 452.38, W =0.6, b = 0.82\n",
      "Iteration 176, loss 451.46, W =0.6, b = 0.82\n",
      "Iteration 177, loss 450.53, W =0.61, b = 0.82\n",
      "Iteration 178, loss 449.61, W =0.61, b = 0.82\n",
      "Iteration 179, loss 448.7, W =0.61, b = 0.82\n",
      "Iteration 180, loss 447.78, W =0.62, b = 0.82\n",
      "Iteration 181, loss 446.87, W =0.62, b = 0.82\n",
      "Iteration 182, loss 445.96, W =0.63, b = 0.83\n",
      "Iteration 183, loss 445.06, W =0.63, b = 0.83\n",
      "Iteration 184, loss 444.16, W =0.64, b = 0.83\n",
      "Iteration 185, loss 443.26, W =0.64, b = 0.83\n",
      "Iteration 186, loss 442.36, W =0.65, b = 0.83\n",
      "Iteration 187, loss 441.47, W =0.65, b = 0.83\n",
      "Iteration 188, loss 440.58, W =0.66, b = 0.83\n",
      "Iteration 189, loss 439.69, W =0.66, b = 0.83\n",
      "Iteration 190, loss 438.81, W =0.67, b = 0.83\n",
      "Iteration 191, loss 437.93, W =0.67, b = 0.83\n",
      "Iteration 192, loss 437.05, W =0.67, b = 0.84\n",
      "Iteration 193, loss 436.17, W =0.68, b = 0.84\n",
      "Iteration 194, loss 435.3, W =0.68, b = 0.84\n",
      "Iteration 195, loss 434.43, W =0.69, b = 0.84\n",
      "Iteration 196, loss 433.56, W =0.69, b = 0.84\n",
      "Iteration 197, loss 432.7, W =0.7, b = 0.84\n",
      "Iteration 198, loss 431.84, W =0.7, b = 0.84\n",
      "Iteration 199, loss 430.98, W =0.71, b = 0.84\n",
      "Iteration 200, loss 430.13, W =0.71, b = 0.84\n",
      "Iteration 201, loss 429.28, W =0.72, b = 0.84\n",
      "Iteration 202, loss 428.43, W =0.72, b = 0.84\n",
      "Iteration 203, loss 427.58, W =0.72, b = 0.85\n",
      "Iteration 204, loss 426.74, W =0.73, b = 0.85\n",
      "Iteration 205, loss 425.9, W =0.73, b = 0.85\n",
      "Iteration 206, loss 425.06, W =0.74, b = 0.85\n",
      "Iteration 207, loss 424.23, W =0.74, b = 0.85\n",
      "Iteration 208, loss 423.39, W =0.75, b = 0.85\n",
      "Iteration 209, loss 422.56, W =0.75, b = 0.85\n",
      "Iteration 210, loss 421.74, W =0.76, b = 0.85\n",
      "Iteration 211, loss 420.91, W =0.76, b = 0.85\n",
      "Iteration 212, loss 420.09, W =0.77, b = 0.85\n",
      "Iteration 213, loss 419.28, W =0.77, b = 0.86\n",
      "Iteration 214, loss 418.46, W =0.77, b = 0.86\n",
      "Iteration 215, loss 417.65, W =0.78, b = 0.86\n",
      "Iteration 216, loss 416.84, W =0.78, b = 0.86\n",
      "Iteration 217, loss 416.03, W =0.79, b = 0.86\n",
      "Iteration 218, loss 415.23, W =0.79, b = 0.86\n",
      "Iteration 219, loss 414.42, W =0.8, b = 0.86\n",
      "Iteration 220, loss 413.63, W =0.8, b = 0.86\n",
      "Iteration 221, loss 412.83, W =0.8, b = 0.86\n",
      "Iteration 222, loss 412.04, W =0.81, b = 0.86\n",
      "Iteration 223, loss 411.24, W =0.81, b = 0.86\n",
      "Iteration 224, loss 410.46, W =0.82, b = 0.87\n",
      "Iteration 225, loss 409.67, W =0.82, b = 0.87\n",
      "Iteration 226, loss 408.89, W =0.83, b = 0.87\n",
      "Iteration 227, loss 408.11, W =0.83, b = 0.87\n",
      "Iteration 228, loss 407.33, W =0.84, b = 0.87\n",
      "Iteration 229, loss 406.55, W =0.84, b = 0.87\n",
      "Iteration 230, loss 405.78, W =0.84, b = 0.87\n",
      "Iteration 231, loss 405.01, W =0.85, b = 0.87\n",
      "Iteration 232, loss 404.24, W =0.85, b = 0.87\n",
      "Iteration 233, loss 403.48, W =0.86, b = 0.87\n",
      "Iteration 234, loss 402.72, W =0.86, b = 0.87\n",
      "Iteration 235, loss 401.96, W =0.87, b = 0.88\n",
      "Iteration 236, loss 401.2, W =0.87, b = 0.88\n",
      "Iteration 237, loss 400.45, W =0.87, b = 0.88\n",
      "Iteration 238, loss 399.69, W =0.88, b = 0.88\n",
      "Iteration 239, loss 398.95, W =0.88, b = 0.88\n",
      "Iteration 240, loss 398.2, W =0.89, b = 0.88\n",
      "Iteration 241, loss 397.45, W =0.89, b = 0.88\n",
      "Iteration 242, loss 396.71, W =0.9, b = 0.88\n",
      "Iteration 243, loss 395.97, W =0.9, b = 0.88\n",
      "Iteration 244, loss 395.24, W =0.9, b = 0.88\n",
      "Iteration 245, loss 394.5, W =0.91, b = 0.88\n",
      "Iteration 246, loss 393.77, W =0.91, b = 0.89\n",
      "Iteration 247, loss 393.04, W =0.92, b = 0.89\n",
      "Iteration 248, loss 392.31, W =0.92, b = 0.89\n",
      "Iteration 249, loss 391.59, W =0.92, b = 0.89\n",
      "Iteration 250, loss 390.87, W =0.93, b = 0.89\n",
      "Iteration 251, loss 390.15, W =0.93, b = 0.89\n",
      "Iteration 252, loss 389.43, W =0.94, b = 0.89\n",
      "Iteration 253, loss 388.71, W =0.94, b = 0.89\n",
      "Iteration 254, loss 388.0, W =0.95, b = 0.89\n",
      "Iteration 255, loss 387.29, W =0.95, b = 0.89\n",
      "Iteration 256, loss 386.58, W =0.95, b = 0.89\n",
      "Iteration 257, loss 385.88, W =0.96, b = 0.89\n",
      "Iteration 258, loss 385.18, W =0.96, b = 0.9\n",
      "Iteration 259, loss 384.47, W =0.97, b = 0.9\n",
      "Iteration 260, loss 383.78, W =0.97, b = 0.9\n",
      "Iteration 261, loss 383.08, W =0.97, b = 0.9\n",
      "Iteration 262, loss 382.39, W =0.98, b = 0.9\n",
      "Iteration 263, loss 381.7, W =0.98, b = 0.9\n",
      "Iteration 264, loss 381.01, W =0.99, b = 0.9\n",
      "Iteration 265, loss 380.32, W =0.99, b = 0.9\n",
      "Iteration 266, loss 379.64, W =0.99, b = 0.9\n",
      "Iteration 267, loss 378.95, W =1.0, b = 0.9\n",
      "Iteration 268, loss 378.27, W =1.0, b = 0.9\n",
      "Iteration 269, loss 377.6, W =1.01, b = 0.91\n",
      "Iteration 270, loss 376.92, W =1.01, b = 0.91\n",
      "Iteration 271, loss 376.25, W =1.01, b = 0.91\n",
      "Iteration 272, loss 375.58, W =1.02, b = 0.91\n",
      "Iteration 273, loss 374.91, W =1.02, b = 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 274, loss 374.24, W =1.03, b = 0.91\n",
      "Iteration 275, loss 373.58, W =1.03, b = 0.91\n",
      "Iteration 276, loss 372.92, W =1.03, b = 0.91\n",
      "Iteration 277, loss 372.26, W =1.04, b = 0.91\n",
      "Iteration 278, loss 371.6, W =1.04, b = 0.91\n",
      "Iteration 279, loss 370.95, W =1.05, b = 0.91\n",
      "Iteration 280, loss 370.29, W =1.05, b = 0.91\n",
      "Iteration 281, loss 369.64, W =1.05, b = 0.92\n",
      "Iteration 282, loss 369.0, W =1.06, b = 0.92\n",
      "Iteration 283, loss 368.35, W =1.06, b = 0.92\n",
      "Iteration 284, loss 367.71, W =1.07, b = 0.92\n",
      "Iteration 285, loss 367.06, W =1.07, b = 0.92\n",
      "Iteration 286, loss 366.42, W =1.07, b = 0.92\n",
      "Iteration 287, loss 365.79, W =1.08, b = 0.92\n",
      "Iteration 288, loss 365.15, W =1.08, b = 0.92\n",
      "Iteration 289, loss 364.52, W =1.09, b = 0.92\n",
      "Iteration 290, loss 363.89, W =1.09, b = 0.92\n",
      "Iteration 291, loss 363.26, W =1.09, b = 0.92\n",
      "Iteration 292, loss 362.63, W =1.1, b = 0.92\n",
      "Iteration 293, loss 362.01, W =1.1, b = 0.93\n",
      "Iteration 294, loss 361.38, W =1.11, b = 0.93\n",
      "Iteration 295, loss 360.76, W =1.11, b = 0.93\n",
      "Iteration 296, loss 360.14, W =1.11, b = 0.93\n",
      "Iteration 297, loss 359.53, W =1.12, b = 0.93\n",
      "Iteration 298, loss 358.91, W =1.12, b = 0.93\n",
      "Iteration 299, loss 358.3, W =1.12, b = 0.93\n",
      "Iteration 300, loss 357.69, W =1.13, b = 0.93\n",
      "Iteration 301, loss 357.08, W =1.13, b = 0.93\n",
      "Iteration 302, loss 356.48, W =1.14, b = 0.93\n",
      "Iteration 303, loss 355.87, W =1.14, b = 0.93\n",
      "Iteration 304, loss 355.27, W =1.14, b = 0.93\n",
      "Iteration 305, loss 354.67, W =1.15, b = 0.94\n",
      "Iteration 306, loss 354.07, W =1.15, b = 0.94\n",
      "Iteration 307, loss 353.48, W =1.16, b = 0.94\n",
      "Iteration 308, loss 352.88, W =1.16, b = 0.94\n",
      "Iteration 309, loss 352.29, W =1.16, b = 0.94\n",
      "Iteration 310, loss 351.7, W =1.17, b = 0.94\n",
      "Iteration 311, loss 351.11, W =1.17, b = 0.94\n",
      "Iteration 312, loss 350.53, W =1.17, b = 0.94\n",
      "Iteration 313, loss 349.94, W =1.18, b = 0.94\n",
      "Iteration 314, loss 349.36, W =1.18, b = 0.94\n",
      "Iteration 315, loss 348.78, W =1.19, b = 0.94\n",
      "Iteration 316, loss 348.2, W =1.19, b = 0.94\n",
      "Iteration 317, loss 347.62, W =1.19, b = 0.95\n",
      "Iteration 318, loss 347.05, W =1.2, b = 0.95\n",
      "Iteration 319, loss 346.48, W =1.2, b = 0.95\n",
      "Iteration 320, loss 345.91, W =1.2, b = 0.95\n",
      "Iteration 321, loss 345.34, W =1.21, b = 0.95\n",
      "Iteration 322, loss 344.77, W =1.21, b = 0.95\n",
      "Iteration 323, loss 344.21, W =1.21, b = 0.95\n",
      "Iteration 324, loss 343.64, W =1.22, b = 0.95\n",
      "Iteration 325, loss 343.08, W =1.22, b = 0.95\n",
      "Iteration 326, loss 342.52, W =1.23, b = 0.95\n",
      "Iteration 327, loss 341.97, W =1.23, b = 0.95\n",
      "Iteration 328, loss 341.41, W =1.23, b = 0.95\n",
      "Iteration 329, loss 340.86, W =1.24, b = 0.95\n",
      "Iteration 330, loss 340.31, W =1.24, b = 0.96\n",
      "Iteration 331, loss 339.76, W =1.24, b = 0.96\n",
      "Iteration 332, loss 339.21, W =1.25, b = 0.96\n",
      "Iteration 333, loss 338.66, W =1.25, b = 0.96\n",
      "Iteration 334, loss 338.12, W =1.25, b = 0.96\n",
      "Iteration 335, loss 337.58, W =1.26, b = 0.96\n",
      "Iteration 336, loss 337.04, W =1.26, b = 0.96\n",
      "Iteration 337, loss 336.5, W =1.27, b = 0.96\n",
      "Iteration 338, loss 335.96, W =1.27, b = 0.96\n",
      "Iteration 339, loss 335.43, W =1.27, b = 0.96\n",
      "Iteration 340, loss 334.89, W =1.28, b = 0.96\n",
      "Iteration 341, loss 334.36, W =1.28, b = 0.96\n",
      "Iteration 342, loss 333.83, W =1.28, b = 0.97\n",
      "Iteration 343, loss 333.3, W =1.29, b = 0.97\n",
      "Iteration 344, loss 332.78, W =1.29, b = 0.97\n",
      "Iteration 345, loss 332.25, W =1.29, b = 0.97\n",
      "Iteration 346, loss 331.73, W =1.3, b = 0.97\n",
      "Iteration 347, loss 331.21, W =1.3, b = 0.97\n",
      "Iteration 348, loss 330.69, W =1.3, b = 0.97\n",
      "Iteration 349, loss 330.17, W =1.31, b = 0.97\n",
      "Iteration 350, loss 329.66, W =1.31, b = 0.97\n",
      "Iteration 351, loss 329.14, W =1.32, b = 0.97\n",
      "Iteration 352, loss 328.63, W =1.32, b = 0.97\n",
      "Iteration 353, loss 328.12, W =1.32, b = 0.97\n",
      "Iteration 354, loss 327.61, W =1.33, b = 0.97\n",
      "Iteration 355, loss 327.1, W =1.33, b = 0.98\n",
      "Iteration 356, loss 326.6, W =1.33, b = 0.98\n",
      "Iteration 357, loss 326.09, W =1.34, b = 0.98\n",
      "Iteration 358, loss 325.59, W =1.34, b = 0.98\n",
      "Iteration 359, loss 325.09, W =1.34, b = 0.98\n",
      "Iteration 360, loss 324.59, W =1.35, b = 0.98\n",
      "Iteration 361, loss 324.1, W =1.35, b = 0.98\n",
      "Iteration 362, loss 323.6, W =1.35, b = 0.98\n",
      "Iteration 363, loss 323.11, W =1.36, b = 0.98\n",
      "Iteration 364, loss 322.62, W =1.36, b = 0.98\n",
      "Iteration 365, loss 322.13, W =1.36, b = 0.98\n",
      "Iteration 366, loss 321.64, W =1.37, b = 0.98\n",
      "Iteration 367, loss 321.15, W =1.37, b = 0.98\n",
      "Iteration 368, loss 320.67, W =1.37, b = 0.99\n",
      "Iteration 369, loss 320.18, W =1.38, b = 0.99\n",
      "Iteration 370, loss 319.7, W =1.38, b = 0.99\n",
      "Iteration 371, loss 319.22, W =1.38, b = 0.99\n",
      "Iteration 372, loss 318.74, W =1.39, b = 0.99\n",
      "Iteration 373, loss 318.26, W =1.39, b = 0.99\n",
      "Iteration 374, loss 317.79, W =1.39, b = 0.99\n",
      "Iteration 375, loss 317.31, W =1.4, b = 0.99\n",
      "Iteration 376, loss 316.84, W =1.4, b = 0.99\n",
      "Iteration 377, loss 316.37, W =1.4, b = 0.99\n",
      "Iteration 378, loss 315.9, W =1.41, b = 0.99\n",
      "Iteration 379, loss 315.43, W =1.41, b = 0.99\n",
      "Iteration 380, loss 314.97, W =1.41, b = 0.99\n",
      "Iteration 381, loss 314.5, W =1.42, b = 0.99\n",
      "Iteration 382, loss 314.04, W =1.42, b = 1.0\n",
      "Iteration 383, loss 313.58, W =1.42, b = 1.0\n",
      "Iteration 384, loss 313.12, W =1.43, b = 1.0\n",
      "Iteration 385, loss 312.66, W =1.43, b = 1.0\n",
      "Iteration 386, loss 312.2, W =1.43, b = 1.0\n",
      "Iteration 387, loss 311.75, W =1.44, b = 1.0\n",
      "Iteration 388, loss 311.29, W =1.44, b = 1.0\n",
      "Iteration 389, loss 310.84, W =1.44, b = 1.0\n",
      "Iteration 390, loss 310.39, W =1.45, b = 1.0\n",
      "Iteration 391, loss 309.94, W =1.45, b = 1.0\n",
      "Iteration 392, loss 309.49, W =1.45, b = 1.0\n",
      "Iteration 393, loss 309.05, W =1.46, b = 1.0\n",
      "Iteration 394, loss 308.6, W =1.46, b = 1.0\n",
      "Iteration 395, loss 308.16, W =1.46, b = 1.01\n",
      "Iteration 396, loss 307.72, W =1.47, b = 1.01\n",
      "Iteration 397, loss 307.28, W =1.47, b = 1.01\n",
      "Iteration 398, loss 306.84, W =1.47, b = 1.01\n",
      "Iteration 399, loss 306.4, W =1.48, b = 1.01\n",
      "Iteration 400, loss 305.97, W =1.48, b = 1.01\n",
      "Iteration 401, loss 305.53, W =1.48, b = 1.01\n",
      "Iteration 402, loss 305.1, W =1.49, b = 1.01\n",
      "Iteration 403, loss 304.67, W =1.49, b = 1.01\n",
      "Iteration 404, loss 304.24, W =1.49, b = 1.01\n",
      "Iteration 405, loss 303.81, W =1.5, b = 1.01\n",
      "Iteration 406, loss 303.38, W =1.5, b = 1.01\n",
      "Iteration 407, loss 302.96, W =1.5, b = 1.01\n",
      "Iteration 408, loss 302.53, W =1.51, b = 1.01\n",
      "Iteration 409, loss 302.11, W =1.51, b = 1.02\n",
      "Iteration 410, loss 301.69, W =1.51, b = 1.02\n",
      "Iteration 411, loss 301.27, W =1.52, b = 1.02\n",
      "Iteration 412, loss 300.85, W =1.52, b = 1.02\n",
      "Iteration 413, loss 300.43, W =1.52, b = 1.02\n",
      "Iteration 414, loss 300.02, W =1.52, b = 1.02\n",
      "Iteration 415, loss 299.6, W =1.53, b = 1.02\n",
      "Iteration 416, loss 299.19, W =1.53, b = 1.02\n",
      "Iteration 417, loss 298.78, W =1.53, b = 1.02\n",
      "Iteration 418, loss 298.37, W =1.54, b = 1.02\n",
      "Iteration 419, loss 297.96, W =1.54, b = 1.02\n",
      "Iteration 420, loss 297.55, W =1.54, b = 1.02\n",
      "Iteration 421, loss 297.14, W =1.55, b = 1.02\n",
      "Iteration 422, loss 296.74, W =1.55, b = 1.02\n",
      "Iteration 423, loss 296.34, W =1.55, b = 1.03\n",
      "Iteration 424, loss 295.93, W =1.56, b = 1.03\n",
      "Iteration 425, loss 295.53, W =1.56, b = 1.03\n",
      "Iteration 426, loss 295.13, W =1.56, b = 1.03\n",
      "Iteration 427, loss 294.74, W =1.57, b = 1.03\n",
      "Iteration 428, loss 294.34, W =1.57, b = 1.03\n",
      "Iteration 429, loss 293.94, W =1.57, b = 1.03\n",
      "Iteration 430, loss 293.55, W =1.57, b = 1.03\n",
      "Iteration 431, loss 293.16, W =1.58, b = 1.03\n",
      "Iteration 432, loss 292.77, W =1.58, b = 1.03\n",
      "Iteration 433, loss 292.38, W =1.58, b = 1.03\n",
      "Iteration 434, loss 291.99, W =1.59, b = 1.03\n",
      "Iteration 435, loss 291.6, W =1.59, b = 1.03\n",
      "Iteration 436, loss 291.21, W =1.59, b = 1.03\n",
      "Iteration 437, loss 290.83, W =1.6, b = 1.04\n",
      "Iteration 438, loss 290.45, W =1.6, b = 1.04\n",
      "Iteration 439, loss 290.06, W =1.6, b = 1.04\n",
      "Iteration 440, loss 289.68, W =1.61, b = 1.04\n",
      "Iteration 441, loss 289.3, W =1.61, b = 1.04\n",
      "Iteration 442, loss 288.92, W =1.61, b = 1.04\n",
      "Iteration 443, loss 288.55, W =1.61, b = 1.04\n",
      "Iteration 444, loss 288.17, W =1.62, b = 1.04\n",
      "Iteration 445, loss 287.8, W =1.62, b = 1.04\n",
      "Iteration 446, loss 287.42, W =1.62, b = 1.04\n",
      "Iteration 447, loss 287.05, W =1.63, b = 1.04\n",
      "Iteration 448, loss 286.68, W =1.63, b = 1.04\n",
      "Iteration 449, loss 286.31, W =1.63, b = 1.04\n",
      "Iteration 450, loss 285.94, W =1.63, b = 1.04\n",
      "Iteration 451, loss 285.58, W =1.64, b = 1.04\n",
      "Iteration 452, loss 285.21, W =1.64, b = 1.05\n",
      "Iteration 453, loss 284.85, W =1.64, b = 1.05\n",
      "Iteration 454, loss 284.48, W =1.65, b = 1.05\n",
      "Iteration 455, loss 284.12, W =1.65, b = 1.05\n",
      "Iteration 456, loss 283.76, W =1.65, b = 1.05\n",
      "Iteration 457, loss 283.4, W =1.66, b = 1.05\n",
      "Iteration 458, loss 283.04, W =1.66, b = 1.05\n",
      "Iteration 459, loss 282.68, W =1.66, b = 1.05\n",
      "Iteration 460, loss 282.33, W =1.66, b = 1.05\n",
      "Iteration 461, loss 281.97, W =1.67, b = 1.05\n",
      "Iteration 462, loss 281.62, W =1.67, b = 1.05\n",
      "Iteration 463, loss 281.27, W =1.67, b = 1.05\n",
      "Iteration 464, loss 280.91, W =1.68, b = 1.05\n",
      "Iteration 465, loss 280.56, W =1.68, b = 1.05\n",
      "Iteration 466, loss 280.22, W =1.68, b = 1.05\n",
      "Iteration 467, loss 279.87, W =1.68, b = 1.06\n",
      "Iteration 468, loss 279.52, W =1.69, b = 1.06\n",
      "Iteration 469, loss 279.17, W =1.69, b = 1.06\n",
      "Iteration 470, loss 278.83, W =1.69, b = 1.06\n",
      "Iteration 471, loss 278.49, W =1.7, b = 1.06\n",
      "Iteration 472, loss 278.15, W =1.7, b = 1.06\n",
      "Iteration 473, loss 277.8, W =1.7, b = 1.06\n",
      "Iteration 474, loss 277.46, W =1.7, b = 1.06\n",
      "Iteration 475, loss 277.13, W =1.71, b = 1.06\n",
      "Iteration 476, loss 276.79, W =1.71, b = 1.06\n",
      "Iteration 477, loss 276.45, W =1.71, b = 1.06\n",
      "Iteration 478, loss 276.12, W =1.72, b = 1.06\n",
      "Iteration 479, loss 275.78, W =1.72, b = 1.06\n",
      "Iteration 480, loss 275.45, W =1.72, b = 1.06\n",
      "Iteration 481, loss 275.12, W =1.72, b = 1.06\n",
      "Iteration 482, loss 274.79, W =1.73, b = 1.07\n",
      "Iteration 483, loss 274.46, W =1.73, b = 1.07\n",
      "Iteration 484, loss 274.13, W =1.73, b = 1.07\n",
      "Iteration 485, loss 273.8, W =1.74, b = 1.07\n",
      "Iteration 486, loss 273.48, W =1.74, b = 1.07\n",
      "Iteration 487, loss 273.15, W =1.74, b = 1.07\n",
      "Iteration 488, loss 272.83, W =1.74, b = 1.07\n",
      "Iteration 489, loss 272.5, W =1.75, b = 1.07\n",
      "Iteration 490, loss 272.18, W =1.75, b = 1.07\n",
      "Iteration 491, loss 271.86, W =1.75, b = 1.07\n",
      "Iteration 492, loss 271.54, W =1.76, b = 1.07\n",
      "Iteration 493, loss 271.22, W =1.76, b = 1.07\n",
      "Iteration 494, loss 270.9, W =1.76, b = 1.07\n",
      "Iteration 495, loss 270.59, W =1.76, b = 1.07\n",
      "Iteration 496, loss 270.27, W =1.77, b = 1.07\n",
      "Iteration 497, loss 269.96, W =1.77, b = 1.08\n",
      "Iteration 498, loss 269.64, W =1.77, b = 1.08\n",
      "Iteration 499, loss 269.33, W =1.77, b = 1.08\n",
      "Iteration 500, loss 269.02, W =1.78, b = 1.08\n",
      "Iteration 501, loss 268.71, W =1.78, b = 1.08\n",
      "Iteration 502, loss 268.4, W =1.78, b = 1.08\n",
      "Iteration 503, loss 268.09, W =1.79, b = 1.08\n",
      "Iteration 504, loss 267.78, W =1.79, b = 1.08\n",
      "Iteration 505, loss 267.48, W =1.79, b = 1.08\n",
      "Iteration 506, loss 267.17, W =1.79, b = 1.08\n",
      "Iteration 507, loss 266.87, W =1.8, b = 1.08\n",
      "Iteration 508, loss 266.57, W =1.8, b = 1.08\n",
      "Iteration 509, loss 266.26, W =1.8, b = 1.08\n",
      "Iteration 510, loss 265.96, W =1.8, b = 1.08\n",
      "Iteration 511, loss 265.66, W =1.81, b = 1.08\n",
      "Iteration 512, loss 265.36, W =1.81, b = 1.08\n",
      "Iteration 513, loss 265.07, W =1.81, b = 1.09\n",
      "Iteration 514, loss 264.77, W =1.81, b = 1.09\n",
      "Iteration 515, loss 264.47, W =1.82, b = 1.09\n",
      "Iteration 516, loss 264.18, W =1.82, b = 1.09\n",
      "Iteration 517, loss 263.88, W =1.82, b = 1.09\n",
      "Iteration 518, loss 263.59, W =1.83, b = 1.09\n",
      "Iteration 519, loss 263.3, W =1.83, b = 1.09\n",
      "Iteration 520, loss 263.01, W =1.83, b = 1.09\n",
      "Iteration 521, loss 262.72, W =1.83, b = 1.09\n",
      "Iteration 522, loss 262.43, W =1.84, b = 1.09\n",
      "Iteration 523, loss 262.14, W =1.84, b = 1.09\n",
      "Iteration 524, loss 261.85, W =1.84, b = 1.09\n",
      "Iteration 525, loss 261.57, W =1.84, b = 1.09\n",
      "Iteration 526, loss 261.28, W =1.85, b = 1.09\n",
      "Iteration 527, loss 261.0, W =1.85, b = 1.09\n",
      "Iteration 528, loss 260.71, W =1.85, b = 1.09\n",
      "Iteration 529, loss 260.43, W =1.85, b = 1.1\n",
      "Iteration 530, loss 260.15, W =1.86, b = 1.1\n",
      "Iteration 531, loss 259.87, W =1.86, b = 1.1\n",
      "Iteration 532, loss 259.59, W =1.86, b = 1.1\n",
      "Iteration 533, loss 259.31, W =1.86, b = 1.1\n",
      "Iteration 534, loss 259.03, W =1.87, b = 1.1\n",
      "Iteration 535, loss 258.76, W =1.87, b = 1.1\n",
      "Iteration 536, loss 258.48, W =1.87, b = 1.1\n",
      "Iteration 537, loss 258.21, W =1.87, b = 1.1\n",
      "Iteration 538, loss 257.93, W =1.88, b = 1.1\n",
      "Iteration 539, loss 257.66, W =1.88, b = 1.1\n",
      "Iteration 540, loss 257.39, W =1.88, b = 1.1\n",
      "Iteration 541, loss 257.11, W =1.88, b = 1.1\n",
      "Iteration 542, loss 256.84, W =1.89, b = 1.1\n",
      "Iteration 543, loss 256.58, W =1.89, b = 1.1\n",
      "Iteration 544, loss 256.31, W =1.89, b = 1.1\n",
      "Iteration 545, loss 256.04, W =1.89, b = 1.11\n",
      "Iteration 546, loss 255.77, W =1.9, b = 1.11\n",
      "Iteration 547, loss 255.51, W =1.9, b = 1.11\n",
      "Iteration 548, loss 255.24, W =1.9, b = 1.11\n",
      "Iteration 549, loss 254.98, W =1.9, b = 1.11\n",
      "Iteration 550, loss 254.71, W =1.91, b = 1.11\n",
      "Iteration 551, loss 254.45, W =1.91, b = 1.11\n",
      "Iteration 552, loss 254.19, W =1.91, b = 1.11\n",
      "Iteration 553, loss 253.93, W =1.91, b = 1.11\n",
      "Iteration 554, loss 253.67, W =1.92, b = 1.11\n",
      "Iteration 555, loss 253.41, W =1.92, b = 1.11\n",
      "Iteration 556, loss 253.15, W =1.92, b = 1.11\n",
      "Iteration 557, loss 252.9, W =1.92, b = 1.11\n",
      "Iteration 558, loss 252.64, W =1.93, b = 1.11\n",
      "Iteration 559, loss 252.38, W =1.93, b = 1.11\n",
      "Iteration 560, loss 252.13, W =1.93, b = 1.11\n",
      "Iteration 561, loss 251.88, W =1.93, b = 1.11\n",
      "Iteration 562, loss 251.62, W =1.94, b = 1.12\n",
      "Iteration 563, loss 251.37, W =1.94, b = 1.12\n",
      "Iteration 564, loss 251.12, W =1.94, b = 1.12\n",
      "Iteration 565, loss 250.87, W =1.94, b = 1.12\n",
      "Iteration 566, loss 250.62, W =1.95, b = 1.12\n",
      "Iteration 567, loss 250.37, W =1.95, b = 1.12\n",
      "Iteration 568, loss 250.12, W =1.95, b = 1.12\n",
      "Iteration 569, loss 249.88, W =1.95, b = 1.12\n",
      "Iteration 570, loss 249.63, W =1.96, b = 1.12\n",
      "Iteration 571, loss 249.39, W =1.96, b = 1.12\n",
      "Iteration 572, loss 249.14, W =1.96, b = 1.12\n",
      "Iteration 573, loss 248.9, W =1.96, b = 1.12\n",
      "Iteration 574, loss 248.66, W =1.97, b = 1.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 575, loss 248.41, W =1.97, b = 1.12\n",
      "Iteration 576, loss 248.17, W =1.97, b = 1.12\n",
      "Iteration 577, loss 247.93, W =1.97, b = 1.12\n",
      "Iteration 578, loss 247.69, W =1.98, b = 1.12\n",
      "Iteration 579, loss 247.45, W =1.98, b = 1.13\n",
      "Iteration 580, loss 247.22, W =1.98, b = 1.13\n",
      "Iteration 581, loss 246.98, W =1.98, b = 1.13\n",
      "Iteration 582, loss 246.74, W =1.99, b = 1.13\n",
      "Iteration 583, loss 246.51, W =1.99, b = 1.13\n",
      "Iteration 584, loss 246.27, W =1.99, b = 1.13\n",
      "Iteration 585, loss 246.04, W =1.99, b = 1.13\n",
      "Iteration 586, loss 245.8, W =1.99, b = 1.13\n",
      "Iteration 587, loss 245.57, W =2.0, b = 1.13\n",
      "Iteration 588, loss 245.34, W =2.0, b = 1.13\n",
      "Iteration 589, loss 245.11, W =2.0, b = 1.13\n",
      "Iteration 590, loss 244.88, W =2.0, b = 1.13\n",
      "Iteration 591, loss 244.65, W =2.01, b = 1.13\n",
      "Iteration 592, loss 244.42, W =2.01, b = 1.13\n",
      "Iteration 593, loss 244.19, W =2.01, b = 1.13\n",
      "Iteration 594, loss 243.97, W =2.01, b = 1.13\n",
      "Iteration 595, loss 243.74, W =2.02, b = 1.13\n",
      "Iteration 596, loss 243.51, W =2.02, b = 1.14\n",
      "Iteration 597, loss 243.29, W =2.02, b = 1.14\n",
      "Iteration 598, loss 243.07, W =2.02, b = 1.14\n",
      "Iteration 599, loss 242.84, W =2.02, b = 1.14\n",
      "Iteration 600, loss 242.62, W =2.03, b = 1.14\n",
      "Iteration 601, loss 242.4, W =2.03, b = 1.14\n",
      "Iteration 602, loss 242.18, W =2.03, b = 1.14\n",
      "Iteration 603, loss 241.96, W =2.03, b = 1.14\n",
      "Iteration 604, loss 241.74, W =2.04, b = 1.14\n",
      "Iteration 605, loss 241.52, W =2.04, b = 1.14\n",
      "Iteration 606, loss 241.3, W =2.04, b = 1.14\n",
      "Iteration 607, loss 241.08, W =2.04, b = 1.14\n",
      "Iteration 608, loss 240.87, W =2.05, b = 1.14\n",
      "Iteration 609, loss 240.65, W =2.05, b = 1.14\n",
      "Iteration 610, loss 240.43, W =2.05, b = 1.14\n",
      "Iteration 611, loss 240.22, W =2.05, b = 1.14\n",
      "Iteration 612, loss 240.01, W =2.05, b = 1.14\n",
      "Iteration 613, loss 239.79, W =2.06, b = 1.14\n",
      "Iteration 614, loss 239.58, W =2.06, b = 1.15\n",
      "Iteration 615, loss 239.37, W =2.06, b = 1.15\n",
      "Iteration 616, loss 239.16, W =2.06, b = 1.15\n",
      "Iteration 617, loss 238.95, W =2.07, b = 1.15\n",
      "Iteration 618, loss 238.74, W =2.07, b = 1.15\n",
      "Iteration 619, loss 238.53, W =2.07, b = 1.15\n",
      "Iteration 620, loss 238.32, W =2.07, b = 1.15\n",
      "Iteration 621, loss 238.11, W =2.07, b = 1.15\n",
      "Iteration 622, loss 237.91, W =2.08, b = 1.15\n",
      "Iteration 623, loss 237.7, W =2.08, b = 1.15\n",
      "Iteration 624, loss 237.5, W =2.08, b = 1.15\n",
      "Iteration 625, loss 237.29, W =2.08, b = 1.15\n",
      "Iteration 626, loss 237.09, W =2.09, b = 1.15\n",
      "Iteration 627, loss 236.89, W =2.09, b = 1.15\n",
      "Iteration 628, loss 236.68, W =2.09, b = 1.15\n",
      "Iteration 629, loss 236.48, W =2.09, b = 1.15\n",
      "Iteration 630, loss 236.28, W =2.09, b = 1.15\n",
      "Iteration 631, loss 236.08, W =2.1, b = 1.15\n",
      "Iteration 632, loss 235.88, W =2.1, b = 1.16\n",
      "Iteration 633, loss 235.68, W =2.1, b = 1.16\n",
      "Iteration 634, loss 235.48, W =2.1, b = 1.16\n",
      "Iteration 635, loss 235.28, W =2.11, b = 1.16\n",
      "Iteration 636, loss 235.09, W =2.11, b = 1.16\n",
      "Iteration 637, loss 234.89, W =2.11, b = 1.16\n",
      "Iteration 638, loss 234.69, W =2.11, b = 1.16\n",
      "Iteration 639, loss 234.5, W =2.11, b = 1.16\n",
      "Iteration 640, loss 234.3, W =2.12, b = 1.16\n",
      "Iteration 641, loss 234.11, W =2.12, b = 1.16\n",
      "Iteration 642, loss 233.92, W =2.12, b = 1.16\n",
      "Iteration 643, loss 233.72, W =2.12, b = 1.16\n",
      "Iteration 644, loss 233.53, W =2.12, b = 1.16\n",
      "Iteration 645, loss 233.34, W =2.13, b = 1.16\n",
      "Iteration 646, loss 233.15, W =2.13, b = 1.16\n",
      "Iteration 647, loss 232.96, W =2.13, b = 1.16\n",
      "Iteration 648, loss 232.77, W =2.13, b = 1.16\n",
      "Iteration 649, loss 232.58, W =2.13, b = 1.16\n",
      "Iteration 650, loss 232.39, W =2.14, b = 1.17\n",
      "Iteration 651, loss 232.21, W =2.14, b = 1.17\n",
      "Iteration 652, loss 232.02, W =2.14, b = 1.17\n",
      "Iteration 653, loss 231.83, W =2.14, b = 1.17\n",
      "Iteration 654, loss 231.65, W =2.15, b = 1.17\n",
      "Iteration 655, loss 231.46, W =2.15, b = 1.17\n",
      "Iteration 656, loss 231.28, W =2.15, b = 1.17\n",
      "Iteration 657, loss 231.09, W =2.15, b = 1.17\n",
      "Iteration 658, loss 230.91, W =2.15, b = 1.17\n",
      "Iteration 659, loss 230.73, W =2.16, b = 1.17\n",
      "Iteration 660, loss 230.55, W =2.16, b = 1.17\n",
      "Iteration 661, loss 230.36, W =2.16, b = 1.17\n",
      "Iteration 662, loss 230.18, W =2.16, b = 1.17\n",
      "Iteration 663, loss 230.0, W =2.16, b = 1.17\n",
      "Iteration 664, loss 229.82, W =2.17, b = 1.17\n",
      "Iteration 665, loss 229.64, W =2.17, b = 1.17\n",
      "Iteration 666, loss 229.47, W =2.17, b = 1.17\n",
      "Iteration 667, loss 229.29, W =2.17, b = 1.17\n",
      "Iteration 668, loss 229.11, W =2.17, b = 1.17\n",
      "Iteration 669, loss 228.94, W =2.18, b = 1.18\n",
      "Iteration 670, loss 228.76, W =2.18, b = 1.18\n",
      "Iteration 671, loss 228.58, W =2.18, b = 1.18\n",
      "Iteration 672, loss 228.41, W =2.18, b = 1.18\n",
      "Iteration 673, loss 228.23, W =2.18, b = 1.18\n",
      "Iteration 674, loss 228.06, W =2.19, b = 1.18\n",
      "Iteration 675, loss 227.89, W =2.19, b = 1.18\n",
      "Iteration 676, loss 227.72, W =2.19, b = 1.18\n",
      "Iteration 677, loss 227.54, W =2.19, b = 1.18\n",
      "Iteration 678, loss 227.37, W =2.19, b = 1.18\n",
      "Iteration 679, loss 227.2, W =2.2, b = 1.18\n",
      "Iteration 680, loss 227.03, W =2.2, b = 1.18\n",
      "Iteration 681, loss 226.86, W =2.2, b = 1.18\n",
      "Iteration 682, loss 226.69, W =2.2, b = 1.18\n",
      "Iteration 683, loss 226.52, W =2.2, b = 1.18\n",
      "Iteration 684, loss 226.36, W =2.21, b = 1.18\n",
      "Iteration 685, loss 226.19, W =2.21, b = 1.18\n",
      "Iteration 686, loss 226.02, W =2.21, b = 1.18\n",
      "Iteration 687, loss 225.86, W =2.21, b = 1.18\n",
      "Iteration 688, loss 225.69, W =2.21, b = 1.19\n",
      "Iteration 689, loss 225.52, W =2.22, b = 1.19\n",
      "Iteration 690, loss 225.36, W =2.22, b = 1.19\n",
      "Iteration 691, loss 225.2, W =2.22, b = 1.19\n",
      "Iteration 692, loss 225.03, W =2.22, b = 1.19\n",
      "Iteration 693, loss 224.87, W =2.22, b = 1.19\n",
      "Iteration 694, loss 224.71, W =2.23, b = 1.19\n",
      "Iteration 695, loss 224.55, W =2.23, b = 1.19\n",
      "Iteration 696, loss 224.38, W =2.23, b = 1.19\n",
      "Iteration 697, loss 224.22, W =2.23, b = 1.19\n",
      "Iteration 698, loss 224.06, W =2.23, b = 1.19\n",
      "Iteration 699, loss 223.9, W =2.24, b = 1.19\n",
      "Iteration 700, loss 223.74, W =2.24, b = 1.19\n",
      "Iteration 701, loss 223.59, W =2.24, b = 1.19\n",
      "Iteration 702, loss 223.43, W =2.24, b = 1.19\n",
      "Iteration 703, loss 223.27, W =2.24, b = 1.19\n",
      "Iteration 704, loss 223.11, W =2.25, b = 1.19\n",
      "Iteration 705, loss 222.96, W =2.25, b = 1.19\n",
      "Iteration 706, loss 222.8, W =2.25, b = 1.19\n",
      "Iteration 707, loss 222.65, W =2.25, b = 1.19\n",
      "Iteration 708, loss 222.49, W =2.25, b = 1.2\n",
      "Iteration 709, loss 222.34, W =2.26, b = 1.2\n",
      "Iteration 710, loss 222.18, W =2.26, b = 1.2\n",
      "Iteration 711, loss 222.03, W =2.26, b = 1.2\n",
      "Iteration 712, loss 221.88, W =2.26, b = 1.2\n",
      "Iteration 713, loss 221.72, W =2.26, b = 1.2\n",
      "Iteration 714, loss 221.57, W =2.26, b = 1.2\n",
      "Iteration 715, loss 221.42, W =2.27, b = 1.2\n",
      "Iteration 716, loss 221.27, W =2.27, b = 1.2\n",
      "Iteration 717, loss 221.12, W =2.27, b = 1.2\n",
      "Iteration 718, loss 220.97, W =2.27, b = 1.2\n",
      "Iteration 719, loss 220.82, W =2.27, b = 1.2\n",
      "Iteration 720, loss 220.67, W =2.28, b = 1.2\n",
      "Iteration 721, loss 220.52, W =2.28, b = 1.2\n",
      "Iteration 722, loss 220.37, W =2.28, b = 1.2\n",
      "Iteration 723, loss 220.23, W =2.28, b = 1.2\n",
      "Iteration 724, loss 220.08, W =2.28, b = 1.2\n",
      "Iteration 725, loss 219.93, W =2.29, b = 1.2\n",
      "Iteration 726, loss 219.79, W =2.29, b = 1.2\n",
      "Iteration 727, loss 219.64, W =2.29, b = 1.2\n",
      "Iteration 728, loss 219.5, W =2.29, b = 1.21\n",
      "Iteration 729, loss 219.35, W =2.29, b = 1.21\n",
      "Iteration 730, loss 219.21, W =2.29, b = 1.21\n",
      "Iteration 731, loss 219.07, W =2.3, b = 1.21\n",
      "Iteration 732, loss 218.92, W =2.3, b = 1.21\n",
      "Iteration 733, loss 218.78, W =2.3, b = 1.21\n",
      "Iteration 734, loss 218.64, W =2.3, b = 1.21\n",
      "Iteration 735, loss 218.5, W =2.3, b = 1.21\n",
      "Iteration 736, loss 218.36, W =2.31, b = 1.21\n",
      "Iteration 737, loss 218.21, W =2.31, b = 1.21\n",
      "Iteration 738, loss 218.07, W =2.31, b = 1.21\n",
      "Iteration 739, loss 217.93, W =2.31, b = 1.21\n",
      "Iteration 740, loss 217.8, W =2.31, b = 1.21\n",
      "Iteration 741, loss 217.66, W =2.31, b = 1.21\n",
      "Iteration 742, loss 217.52, W =2.32, b = 1.21\n",
      "Iteration 743, loss 217.38, W =2.32, b = 1.21\n",
      "Iteration 744, loss 217.24, W =2.32, b = 1.21\n",
      "Iteration 745, loss 217.11, W =2.32, b = 1.21\n",
      "Iteration 746, loss 216.97, W =2.32, b = 1.21\n",
      "Iteration 747, loss 216.83, W =2.33, b = 1.21\n",
      "Iteration 748, loss 216.7, W =2.33, b = 1.22\n",
      "Iteration 749, loss 216.56, W =2.33, b = 1.22\n",
      "Iteration 750, loss 216.43, W =2.33, b = 1.22\n",
      "Iteration 751, loss 216.29, W =2.33, b = 1.22\n",
      "Iteration 752, loss 216.16, W =2.33, b = 1.22\n",
      "Iteration 753, loss 216.03, W =2.34, b = 1.22\n",
      "Iteration 754, loss 215.89, W =2.34, b = 1.22\n",
      "Iteration 755, loss 215.76, W =2.34, b = 1.22\n",
      "Iteration 756, loss 215.63, W =2.34, b = 1.22\n",
      "Iteration 757, loss 215.5, W =2.34, b = 1.22\n",
      "Iteration 758, loss 215.37, W =2.34, b = 1.22\n",
      "Iteration 759, loss 215.24, W =2.35, b = 1.22\n",
      "Iteration 760, loss 215.11, W =2.35, b = 1.22\n",
      "Iteration 761, loss 214.98, W =2.35, b = 1.22\n",
      "Iteration 762, loss 214.85, W =2.35, b = 1.22\n",
      "Iteration 763, loss 214.72, W =2.35, b = 1.22\n",
      "Iteration 764, loss 214.59, W =2.36, b = 1.22\n",
      "Iteration 765, loss 214.46, W =2.36, b = 1.22\n",
      "Iteration 766, loss 214.33, W =2.36, b = 1.22\n",
      "Iteration 767, loss 214.21, W =2.36, b = 1.22\n",
      "Iteration 768, loss 214.08, W =2.36, b = 1.22\n",
      "Iteration 769, loss 213.95, W =2.36, b = 1.23\n",
      "Iteration 770, loss 213.83, W =2.37, b = 1.23\n",
      "Iteration 771, loss 213.7, W =2.37, b = 1.23\n",
      "Iteration 772, loss 213.58, W =2.37, b = 1.23\n",
      "Iteration 773, loss 213.45, W =2.37, b = 1.23\n",
      "Iteration 774, loss 213.33, W =2.37, b = 1.23\n",
      "Iteration 775, loss 213.2, W =2.37, b = 1.23\n",
      "Iteration 776, loss 213.08, W =2.38, b = 1.23\n",
      "Iteration 777, loss 212.96, W =2.38, b = 1.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 778, loss 212.84, W =2.38, b = 1.23\n",
      "Iteration 779, loss 212.71, W =2.38, b = 1.23\n",
      "Iteration 780, loss 212.59, W =2.38, b = 1.23\n",
      "Iteration 781, loss 212.47, W =2.38, b = 1.23\n",
      "Iteration 782, loss 212.35, W =2.39, b = 1.23\n",
      "Iteration 783, loss 212.23, W =2.39, b = 1.23\n",
      "Iteration 784, loss 212.11, W =2.39, b = 1.23\n",
      "Iteration 785, loss 211.99, W =2.39, b = 1.23\n",
      "Iteration 786, loss 211.87, W =2.39, b = 1.23\n",
      "Iteration 787, loss 211.75, W =2.39, b = 1.23\n",
      "Iteration 788, loss 211.63, W =2.4, b = 1.23\n",
      "Iteration 789, loss 211.51, W =2.4, b = 1.23\n",
      "Iteration 790, loss 211.4, W =2.4, b = 1.23\n",
      "Iteration 791, loss 211.28, W =2.4, b = 1.24\n",
      "Iteration 792, loss 211.16, W =2.4, b = 1.24\n",
      "Iteration 793, loss 211.04, W =2.4, b = 1.24\n",
      "Iteration 794, loss 210.93, W =2.41, b = 1.24\n",
      "Iteration 795, loss 210.81, W =2.41, b = 1.24\n",
      "Iteration 796, loss 210.7, W =2.41, b = 1.24\n",
      "Iteration 797, loss 210.58, W =2.41, b = 1.24\n",
      "Iteration 798, loss 210.47, W =2.41, b = 1.24\n",
      "Iteration 799, loss 210.35, W =2.41, b = 1.24\n",
      "Iteration 800, loss 210.24, W =2.42, b = 1.24\n",
      "Iteration 801, loss 210.13, W =2.42, b = 1.24\n",
      "Iteration 802, loss 210.01, W =2.42, b = 1.24\n",
      "Iteration 803, loss 209.9, W =2.42, b = 1.24\n",
      "Iteration 804, loss 209.79, W =2.42, b = 1.24\n",
      "Iteration 805, loss 209.67, W =2.42, b = 1.24\n",
      "Iteration 806, loss 209.56, W =2.43, b = 1.24\n",
      "Iteration 807, loss 209.45, W =2.43, b = 1.24\n",
      "Iteration 808, loss 209.34, W =2.43, b = 1.24\n",
      "Iteration 809, loss 209.23, W =2.43, b = 1.24\n",
      "Iteration 810, loss 209.12, W =2.43, b = 1.24\n",
      "Iteration 811, loss 209.01, W =2.43, b = 1.24\n",
      "Iteration 812, loss 208.9, W =2.43, b = 1.24\n",
      "Iteration 813, loss 208.79, W =2.44, b = 1.25\n",
      "Iteration 814, loss 208.68, W =2.44, b = 1.25\n",
      "Iteration 815, loss 208.57, W =2.44, b = 1.25\n",
      "Iteration 816, loss 208.47, W =2.44, b = 1.25\n",
      "Iteration 817, loss 208.36, W =2.44, b = 1.25\n",
      "Iteration 818, loss 208.25, W =2.44, b = 1.25\n",
      "Iteration 819, loss 208.14, W =2.45, b = 1.25\n",
      "Iteration 820, loss 208.04, W =2.45, b = 1.25\n",
      "Iteration 821, loss 207.93, W =2.45, b = 1.25\n",
      "Iteration 822, loss 207.83, W =2.45, b = 1.25\n",
      "Iteration 823, loss 207.72, W =2.45, b = 1.25\n",
      "Iteration 824, loss 207.61, W =2.45, b = 1.25\n",
      "Iteration 825, loss 207.51, W =2.46, b = 1.25\n",
      "Iteration 826, loss 207.41, W =2.46, b = 1.25\n",
      "Iteration 827, loss 207.3, W =2.46, b = 1.25\n",
      "Iteration 828, loss 207.2, W =2.46, b = 1.25\n",
      "Iteration 829, loss 207.09, W =2.46, b = 1.25\n",
      "Iteration 830, loss 206.99, W =2.46, b = 1.25\n",
      "Iteration 831, loss 206.89, W =2.46, b = 1.25\n",
      "Iteration 832, loss 206.79, W =2.47, b = 1.25\n",
      "Iteration 833, loss 206.68, W =2.47, b = 1.25\n",
      "Iteration 834, loss 206.58, W =2.47, b = 1.25\n",
      "Iteration 835, loss 206.48, W =2.47, b = 1.26\n",
      "Iteration 836, loss 206.38, W =2.47, b = 1.26\n",
      "Iteration 837, loss 206.28, W =2.47, b = 1.26\n",
      "Iteration 838, loss 206.18, W =2.48, b = 1.26\n",
      "Iteration 839, loss 206.08, W =2.48, b = 1.26\n",
      "Iteration 840, loss 205.98, W =2.48, b = 1.26\n",
      "Iteration 841, loss 205.88, W =2.48, b = 1.26\n",
      "Iteration 842, loss 205.78, W =2.48, b = 1.26\n",
      "Iteration 843, loss 205.68, W =2.48, b = 1.26\n",
      "Iteration 844, loss 205.58, W =2.48, b = 1.26\n",
      "Iteration 845, loss 205.49, W =2.49, b = 1.26\n",
      "Iteration 846, loss 205.39, W =2.49, b = 1.26\n",
      "Iteration 847, loss 205.29, W =2.49, b = 1.26\n",
      "Iteration 848, loss 205.19, W =2.49, b = 1.26\n",
      "Iteration 849, loss 205.1, W =2.49, b = 1.26\n",
      "Iteration 850, loss 205.0, W =2.49, b = 1.26\n",
      "Iteration 851, loss 204.9, W =2.5, b = 1.26\n",
      "Iteration 852, loss 204.81, W =2.5, b = 1.26\n",
      "Iteration 853, loss 204.71, W =2.5, b = 1.26\n",
      "Iteration 854, loss 204.62, W =2.5, b = 1.26\n",
      "Iteration 855, loss 204.52, W =2.5, b = 1.26\n",
      "Iteration 856, loss 204.43, W =2.5, b = 1.26\n",
      "Iteration 857, loss 204.33, W =2.5, b = 1.26\n",
      "Iteration 858, loss 204.24, W =2.51, b = 1.27\n",
      "Iteration 859, loss 204.15, W =2.51, b = 1.27\n",
      "Iteration 860, loss 204.05, W =2.51, b = 1.27\n",
      "Iteration 861, loss 203.96, W =2.51, b = 1.27\n",
      "Iteration 862, loss 203.87, W =2.51, b = 1.27\n",
      "Iteration 863, loss 203.77, W =2.51, b = 1.27\n",
      "Iteration 864, loss 203.68, W =2.51, b = 1.27\n",
      "Iteration 865, loss 203.59, W =2.52, b = 1.27\n",
      "Iteration 866, loss 203.5, W =2.52, b = 1.27\n",
      "Iteration 867, loss 203.41, W =2.52, b = 1.27\n",
      "Iteration 868, loss 203.32, W =2.52, b = 1.27\n",
      "Iteration 869, loss 203.23, W =2.52, b = 1.27\n",
      "Iteration 870, loss 203.14, W =2.52, b = 1.27\n",
      "Iteration 871, loss 203.05, W =2.52, b = 1.27\n",
      "Iteration 872, loss 202.96, W =2.53, b = 1.27\n",
      "Iteration 873, loss 202.87, W =2.53, b = 1.27\n",
      "Iteration 874, loss 202.78, W =2.53, b = 1.27\n",
      "Iteration 875, loss 202.69, W =2.53, b = 1.27\n",
      "Iteration 876, loss 202.6, W =2.53, b = 1.27\n",
      "Iteration 877, loss 202.51, W =2.53, b = 1.27\n",
      "Iteration 878, loss 202.43, W =2.53, b = 1.27\n",
      "Iteration 879, loss 202.34, W =2.54, b = 1.27\n",
      "Iteration 880, loss 202.25, W =2.54, b = 1.27\n",
      "Iteration 881, loss 202.16, W =2.54, b = 1.28\n",
      "Iteration 882, loss 202.08, W =2.54, b = 1.28\n",
      "Iteration 883, loss 201.99, W =2.54, b = 1.28\n",
      "Iteration 884, loss 201.9, W =2.54, b = 1.28\n",
      "Iteration 885, loss 201.82, W =2.54, b = 1.28\n",
      "Iteration 886, loss 201.73, W =2.55, b = 1.28\n",
      "Iteration 887, loss 201.65, W =2.55, b = 1.28\n",
      "Iteration 888, loss 201.56, W =2.55, b = 1.28\n",
      "Iteration 889, loss 201.48, W =2.55, b = 1.28\n",
      "Iteration 890, loss 201.39, W =2.55, b = 1.28\n",
      "Iteration 891, loss 201.31, W =2.55, b = 1.28\n",
      "Iteration 892, loss 201.22, W =2.55, b = 1.28\n",
      "Iteration 893, loss 201.14, W =2.56, b = 1.28\n",
      "Iteration 894, loss 201.06, W =2.56, b = 1.28\n",
      "Iteration 895, loss 200.97, W =2.56, b = 1.28\n",
      "Iteration 896, loss 200.89, W =2.56, b = 1.28\n",
      "Iteration 897, loss 200.81, W =2.56, b = 1.28\n",
      "Iteration 898, loss 200.73, W =2.56, b = 1.28\n",
      "Iteration 899, loss 200.65, W =2.56, b = 1.28\n",
      "Iteration 900, loss 200.56, W =2.57, b = 1.28\n",
      "Iteration 901, loss 200.48, W =2.57, b = 1.28\n",
      "Iteration 902, loss 200.4, W =2.57, b = 1.28\n",
      "Iteration 903, loss 200.32, W =2.57, b = 1.28\n",
      "Iteration 904, loss 200.24, W =2.57, b = 1.28\n",
      "Iteration 905, loss 200.16, W =2.57, b = 1.29\n",
      "Iteration 906, loss 200.08, W =2.57, b = 1.29\n",
      "Iteration 907, loss 200.0, W =2.57, b = 1.29\n",
      "Iteration 908, loss 199.92, W =2.58, b = 1.29\n",
      "Iteration 909, loss 199.84, W =2.58, b = 1.29\n",
      "Iteration 910, loss 199.76, W =2.58, b = 1.29\n",
      "Iteration 911, loss 199.68, W =2.58, b = 1.29\n",
      "Iteration 912, loss 199.6, W =2.58, b = 1.29\n",
      "Iteration 913, loss 199.53, W =2.58, b = 1.29\n",
      "Iteration 914, loss 199.45, W =2.58, b = 1.29\n",
      "Iteration 915, loss 199.37, W =2.59, b = 1.29\n",
      "Iteration 916, loss 199.29, W =2.59, b = 1.29\n",
      "Iteration 917, loss 199.22, W =2.59, b = 1.29\n",
      "Iteration 918, loss 199.14, W =2.59, b = 1.29\n",
      "Iteration 919, loss 199.06, W =2.59, b = 1.29\n",
      "Iteration 920, loss 198.99, W =2.59, b = 1.29\n",
      "Iteration 921, loss 198.91, W =2.59, b = 1.29\n",
      "Iteration 922, loss 198.83, W =2.59, b = 1.29\n",
      "Iteration 923, loss 198.76, W =2.6, b = 1.29\n",
      "Iteration 924, loss 198.68, W =2.6, b = 1.29\n",
      "Iteration 925, loss 198.61, W =2.6, b = 1.29\n",
      "Iteration 926, loss 198.53, W =2.6, b = 1.29\n",
      "Iteration 927, loss 198.46, W =2.6, b = 1.29\n",
      "Iteration 928, loss 198.38, W =2.6, b = 1.29\n",
      "Iteration 929, loss 198.31, W =2.6, b = 1.29\n",
      "Iteration 930, loss 198.24, W =2.61, b = 1.3\n",
      "Iteration 931, loss 198.16, W =2.61, b = 1.3\n",
      "Iteration 932, loss 198.09, W =2.61, b = 1.3\n",
      "Iteration 933, loss 198.01, W =2.61, b = 1.3\n",
      "Iteration 934, loss 197.94, W =2.61, b = 1.3\n",
      "Iteration 935, loss 197.87, W =2.61, b = 1.3\n",
      "Iteration 936, loss 197.8, W =2.61, b = 1.3\n",
      "Iteration 937, loss 197.72, W =2.61, b = 1.3\n",
      "Iteration 938, loss 197.65, W =2.62, b = 1.3\n",
      "Iteration 939, loss 197.58, W =2.62, b = 1.3\n",
      "Iteration 940, loss 197.51, W =2.62, b = 1.3\n",
      "Iteration 941, loss 197.44, W =2.62, b = 1.3\n",
      "Iteration 942, loss 197.37, W =2.62, b = 1.3\n",
      "Iteration 943, loss 197.3, W =2.62, b = 1.3\n",
      "Iteration 944, loss 197.23, W =2.62, b = 1.3\n",
      "Iteration 945, loss 197.16, W =2.62, b = 1.3\n",
      "Iteration 946, loss 197.08, W =2.63, b = 1.3\n",
      "Iteration 947, loss 197.02, W =2.63, b = 1.3\n",
      "Iteration 948, loss 196.95, W =2.63, b = 1.3\n",
      "Iteration 949, loss 196.88, W =2.63, b = 1.3\n",
      "Iteration 950, loss 196.81, W =2.63, b = 1.3\n",
      "Iteration 951, loss 196.74, W =2.63, b = 1.3\n",
      "Iteration 952, loss 196.67, W =2.63, b = 1.3\n",
      "Iteration 953, loss 196.6, W =2.63, b = 1.3\n",
      "Iteration 954, loss 196.53, W =2.64, b = 1.3\n",
      "Iteration 955, loss 196.46, W =2.64, b = 1.31\n",
      "Iteration 956, loss 196.4, W =2.64, b = 1.31\n",
      "Iteration 957, loss 196.33, W =2.64, b = 1.31\n",
      "Iteration 958, loss 196.26, W =2.64, b = 1.31\n",
      "Iteration 959, loss 196.19, W =2.64, b = 1.31\n",
      "Iteration 960, loss 196.13, W =2.64, b = 1.31\n",
      "Iteration 961, loss 196.06, W =2.64, b = 1.31\n",
      "Iteration 962, loss 195.99, W =2.65, b = 1.31\n",
      "Iteration 963, loss 195.93, W =2.65, b = 1.31\n",
      "Iteration 964, loss 195.86, W =2.65, b = 1.31\n",
      "Iteration 965, loss 195.8, W =2.65, b = 1.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 966, loss 195.73, W =2.65, b = 1.31\n",
      "Iteration 967, loss 195.66, W =2.65, b = 1.31\n",
      "Iteration 968, loss 195.6, W =2.65, b = 1.31\n",
      "Iteration 969, loss 195.53, W =2.65, b = 1.31\n",
      "Iteration 970, loss 195.47, W =2.66, b = 1.31\n",
      "Iteration 971, loss 195.41, W =2.66, b = 1.31\n",
      "Iteration 972, loss 195.34, W =2.66, b = 1.31\n",
      "Iteration 973, loss 195.28, W =2.66, b = 1.31\n",
      "Iteration 974, loss 195.21, W =2.66, b = 1.31\n",
      "Iteration 975, loss 195.15, W =2.66, b = 1.31\n",
      "Iteration 976, loss 195.09, W =2.66, b = 1.31\n",
      "Iteration 977, loss 195.02, W =2.66, b = 1.31\n",
      "Iteration 978, loss 194.96, W =2.67, b = 1.31\n",
      "Iteration 979, loss 194.9, W =2.67, b = 1.31\n",
      "Iteration 980, loss 194.83, W =2.67, b = 1.31\n",
      "Iteration 981, loss 194.77, W =2.67, b = 1.32\n",
      "Iteration 982, loss 194.71, W =2.67, b = 1.32\n",
      "Iteration 983, loss 194.65, W =2.67, b = 1.32\n",
      "Iteration 984, loss 194.59, W =2.67, b = 1.32\n",
      "Iteration 985, loss 194.52, W =2.67, b = 1.32\n",
      "Iteration 986, loss 194.46, W =2.67, b = 1.32\n",
      "Iteration 987, loss 194.4, W =2.68, b = 1.32\n",
      "Iteration 988, loss 194.34, W =2.68, b = 1.32\n",
      "Iteration 989, loss 194.28, W =2.68, b = 1.32\n",
      "Iteration 990, loss 194.22, W =2.68, b = 1.32\n",
      "Iteration 991, loss 194.16, W =2.68, b = 1.32\n",
      "Iteration 992, loss 194.1, W =2.68, b = 1.32\n",
      "Iteration 993, loss 194.04, W =2.68, b = 1.32\n",
      "Iteration 994, loss 193.98, W =2.68, b = 1.32\n",
      "Iteration 995, loss 193.92, W =2.69, b = 1.32\n",
      "Iteration 996, loss 193.86, W =2.69, b = 1.32\n",
      "Iteration 997, loss 193.8, W =2.69, b = 1.32\n",
      "Iteration 998, loss 193.74, W =2.69, b = 1.32\n",
      "Iteration 999, loss 193.68, W =2.69, b = 1.32\n",
      "Iteration 1000, loss 193.62, W =2.69, b = 1.32\n"
     ]
    }
   ],
   "source": [
    "####### Let's setup the linear regression model #####\n",
    "X=reg_d[['cylinders']].values\n",
    "y=reg_d['mpg'].values\n",
    "y=torch.tensor(y,dtype=torch.float)\n",
    "X=torch.tensor(X)\n",
    "W=torch.randn((1,1),requires_grad=True)\n",
    "b=torch.randn((1,),requires_grad=True)\n",
    "lr1=0.01\n",
    "lr2=0.01\n",
    "Losses=[]\n",
    "for i in range(1000):\n",
    "    pred=torch.matmul(X.float(),W)+b\n",
    "    diff=pred-y.reshape(398,1)\n",
    "    loss=torch.sum(diff*diff)/diff.shape[0]\n",
    "    loss.backward()\n",
    "    Losses.append(loss.item())\n",
    "    print(f\"Iteration {i+1}, loss {round(loss.item(),2)}, W ={round(W.item(),2)}, b = {round(b.item(),2)}\")\n",
    "    with torch.no_grad():\n",
    "        b-=(lr1/398)*b.grad\n",
    "        W-=(lr2/398)*W.grad\n",
    "        W.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x127c75dd0>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(Losses)),Losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_pregnant</th>\n",
       "      <th>Plasma_glucose</th>\n",
       "      <th>Blood_pres</th>\n",
       "      <th>Skin_thick</th>\n",
       "      <th>Serum_insu</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes_func</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No_pregnant  Plasma_glucose  Blood_pres  Skin_thick  Serum_insu   BMI  \\\n",
       "0            6             148          72          35           0  33.6   \n",
       "1            1              85          66          29           0  26.6   \n",
       "\n",
       "   Diabetes_func  Age  Class  \n",
       "0          0.627   50      1  \n",
       "1          0.351   31      0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Logistic Regressor #######\n",
    "log_d=pd.read_csv(\"data/classification.csv\")\n",
    "log_d.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We can start first by creating a sigmoid and then defining log_loss\n",
    "X=log_d[['No_pregnant']].values\n",
    "y=log_d['Class'].values\n",
    "X=torch.tensor(X,dtype=torch.float)\n",
    "y=torch.tensor(y,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=torch.randn((1,1),dtype=torch.float)\n",
    "b=torch.randn((1,),dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=torch.mm(X,W)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=1.0/(1+torch.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=-(y.reshape(768,1)*torch.log(p)+(1-y.reshape(768,1))*torch.log(1-p)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss 1.53, W =-0.89, b = -0.37\n",
      "Iteration 2, loss 1.47, W =-0.82, b = -0.36\n",
      "Iteration 3, loss 1.4, W =-0.73, b = -0.34\n",
      "Iteration 4, loss 1.31, W =-0.64, b = -0.33\n",
      "Iteration 5, loss 1.18, W =-0.53, b = -0.31\n",
      "Iteration 6, loss 1.03, W =-0.41, b = -0.3\n",
      "Iteration 7, loss 0.87, W =-0.29, b = -0.28\n",
      "Iteration 8, loss 0.74, W =-0.17, b = -0.27\n",
      "Iteration 9, loss 0.68, W =-0.08, b = -0.27\n",
      "Iteration 10, loss 0.66, W =-0.03, b = -0.27\n",
      "Iteration 11, loss 0.66, W =-0.01, b = -0.27\n",
      "Iteration 12, loss 0.66, W =0.0, b = -0.28\n",
      "Iteration 13, loss 0.66, W =0.0, b = -0.29\n",
      "Iteration 14, loss 0.66, W =0.01, b = -0.3\n",
      "Iteration 15, loss 0.66, W =0.01, b = -0.31\n",
      "Iteration 16, loss 0.66, W =0.01, b = -0.31\n",
      "Iteration 17, loss 0.65, W =0.01, b = -0.32\n",
      "Iteration 18, loss 0.65, W =0.01, b = -0.33\n",
      "Iteration 19, loss 0.65, W =0.01, b = -0.34\n",
      "Iteration 20, loss 0.65, W =0.01, b = -0.35\n",
      "Iteration 21, loss 0.65, W =0.02, b = -0.35\n",
      "Iteration 22, loss 0.65, W =0.02, b = -0.36\n",
      "Iteration 23, loss 0.65, W =0.02, b = -0.37\n",
      "Iteration 24, loss 0.65, W =0.02, b = -0.38\n",
      "Iteration 25, loss 0.65, W =0.02, b = -0.38\n",
      "Iteration 26, loss 0.65, W =0.02, b = -0.39\n",
      "Iteration 27, loss 0.65, W =0.02, b = -0.4\n",
      "Iteration 28, loss 0.65, W =0.02, b = -0.41\n",
      "Iteration 29, loss 0.65, W =0.02, b = -0.41\n",
      "Iteration 30, loss 0.65, W =0.03, b = -0.42\n",
      "Iteration 31, loss 0.65, W =0.03, b = -0.43\n",
      "Iteration 32, loss 0.65, W =0.03, b = -0.44\n",
      "Iteration 33, loss 0.65, W =0.03, b = -0.44\n",
      "Iteration 34, loss 0.65, W =0.03, b = -0.45\n",
      "Iteration 35, loss 0.64, W =0.03, b = -0.46\n",
      "Iteration 36, loss 0.64, W =0.03, b = -0.46\n",
      "Iteration 37, loss 0.64, W =0.03, b = -0.47\n",
      "Iteration 38, loss 0.64, W =0.03, b = -0.48\n",
      "Iteration 39, loss 0.64, W =0.03, b = -0.48\n",
      "Iteration 40, loss 0.64, W =0.04, b = -0.49\n",
      "Iteration 41, loss 0.64, W =0.04, b = -0.5\n",
      "Iteration 42, loss 0.64, W =0.04, b = -0.5\n",
      "Iteration 43, loss 0.64, W =0.04, b = -0.51\n",
      "Iteration 44, loss 0.64, W =0.04, b = -0.51\n",
      "Iteration 45, loss 0.64, W =0.04, b = -0.52\n",
      "Iteration 46, loss 0.64, W =0.04, b = -0.53\n",
      "Iteration 47, loss 0.64, W =0.04, b = -0.53\n",
      "Iteration 48, loss 0.64, W =0.04, b = -0.54\n",
      "Iteration 49, loss 0.64, W =0.04, b = -0.54\n",
      "Iteration 50, loss 0.64, W =0.05, b = -0.55\n",
      "Iteration 51, loss 0.64, W =0.05, b = -0.56\n",
      "Iteration 52, loss 0.64, W =0.05, b = -0.56\n",
      "Iteration 53, loss 0.64, W =0.05, b = -0.57\n",
      "Iteration 54, loss 0.64, W =0.05, b = -0.57\n",
      "Iteration 55, loss 0.64, W =0.05, b = -0.58\n",
      "Iteration 56, loss 0.64, W =0.05, b = -0.58\n",
      "Iteration 57, loss 0.64, W =0.05, b = -0.59\n",
      "Iteration 58, loss 0.64, W =0.05, b = -0.6\n",
      "Iteration 59, loss 0.64, W =0.05, b = -0.6\n",
      "Iteration 60, loss 0.64, W =0.05, b = -0.61\n",
      "Iteration 61, loss 0.64, W =0.05, b = -0.61\n",
      "Iteration 62, loss 0.63, W =0.05, b = -0.62\n",
      "Iteration 63, loss 0.63, W =0.06, b = -0.62\n",
      "Iteration 64, loss 0.63, W =0.06, b = -0.63\n",
      "Iteration 65, loss 0.63, W =0.06, b = -0.63\n",
      "Iteration 66, loss 0.63, W =0.06, b = -0.64\n",
      "Iteration 67, loss 0.63, W =0.06, b = -0.64\n",
      "Iteration 68, loss 0.63, W =0.06, b = -0.65\n",
      "Iteration 69, loss 0.63, W =0.06, b = -0.65\n",
      "Iteration 70, loss 0.63, W =0.06, b = -0.66\n",
      "Iteration 71, loss 0.63, W =0.06, b = -0.66\n",
      "Iteration 72, loss 0.63, W =0.06, b = -0.67\n",
      "Iteration 73, loss 0.63, W =0.06, b = -0.67\n",
      "Iteration 74, loss 0.63, W =0.06, b = -0.68\n",
      "Iteration 75, loss 0.63, W =0.06, b = -0.68\n",
      "Iteration 76, loss 0.63, W =0.06, b = -0.68\n",
      "Iteration 77, loss 0.63, W =0.07, b = -0.69\n",
      "Iteration 78, loss 0.63, W =0.07, b = -0.69\n",
      "Iteration 79, loss 0.63, W =0.07, b = -0.7\n",
      "Iteration 80, loss 0.63, W =0.07, b = -0.7\n",
      "Iteration 81, loss 0.63, W =0.07, b = -0.71\n",
      "Iteration 82, loss 0.63, W =0.07, b = -0.71\n",
      "Iteration 83, loss 0.63, W =0.07, b = -0.71\n",
      "Iteration 84, loss 0.63, W =0.07, b = -0.72\n",
      "Iteration 85, loss 0.63, W =0.07, b = -0.72\n",
      "Iteration 86, loss 0.63, W =0.07, b = -0.73\n",
      "Iteration 87, loss 0.63, W =0.07, b = -0.73\n",
      "Iteration 88, loss 0.63, W =0.07, b = -0.74\n",
      "Iteration 89, loss 0.63, W =0.07, b = -0.74\n",
      "Iteration 90, loss 0.63, W =0.07, b = -0.74\n",
      "Iteration 91, loss 0.63, W =0.07, b = -0.75\n",
      "Iteration 92, loss 0.63, W =0.07, b = -0.75\n",
      "Iteration 93, loss 0.63, W =0.08, b = -0.75\n",
      "Iteration 94, loss 0.63, W =0.08, b = -0.76\n",
      "Iteration 95, loss 0.63, W =0.08, b = -0.76\n",
      "Iteration 96, loss 0.63, W =0.08, b = -0.77\n",
      "Iteration 97, loss 0.63, W =0.08, b = -0.77\n",
      "Iteration 98, loss 0.63, W =0.08, b = -0.77\n",
      "Iteration 99, loss 0.63, W =0.08, b = -0.78\n",
      "Iteration 100, loss 0.63, W =0.08, b = -0.78\n"
     ]
    }
   ],
   "source": [
    "X=log_d[['No_pregnant']].values\n",
    "y=log_d['Class'].values\n",
    "X=torch.tensor(X,dtype=torch.float)\n",
    "y=torch.tensor(y,dtype=torch.float)\n",
    "W=torch.randn((1,1),dtype=torch.float,requires_grad=True)\n",
    "b=torch.randn((1,),dtype=torch.float,requires_grad=True)\n",
    "lr=0.1\n",
    "Loss=[]\n",
    "for i in range(100):\n",
    "    z=torch.mm(X,W)+b\n",
    "    p=1.0/(1+torch.exp(-z+0.001))\n",
    "    loss=-(y.reshape(768,1)*torch.log(p+0.001)+(1-y.reshape(768,1))*torch.log(1-p+0.001)).mean()\n",
    "    Loss.append(loss.item())\n",
    "    print(f\"Iteration {i+1}, loss {round(loss.item(),2)}, W ={round(W.item(),2)}, b = {round(b.item(),2)}\")\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        b-=lr*b.grad\n",
    "        W-=lr*W.grad\n",
    "        b.grad.zero_()\n",
    "        W.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x127db8950>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(Loss)),Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Now let's write a very simple MLP ######## \n",
    "# This time the ask will be straightforward as we will be not need to hand code complicated backward propagation##\n",
    "# Later on we will see how we can automate the process of batching the data, doing optimizations \n",
    "# (If your model has 100 parameters, then current approach may not be great)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train=pd.read_csv(\"data/mnist_train.csv\")\n",
    "mnist_test=pd.read_csv(\"data/mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=mnist_train.drop('label',axis=1).values\n",
    "y=mnist_train['label'].values\n",
    "X=torch.tensor(X,dtype=torch.float)\n",
    "y=torch.tensor(y,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=torch.randn((784,3),dtype=torch.float)\n",
    "b1=torch.randn((3,),dtype=torch.float)\n",
    "w2=torch.randn((3,10),dtype=torch.float)\n",
    "b2=torch.randn((10,),dtype=torch.float)\n",
    "def network(X,w1,b1,w2,b2):\n",
    "    z1=torch.matmul(X.float(),w1)+b1\n",
    "    res1=torch.sigmoid(z1)\n",
    "    z2=torch.matmul(res1,w2)+b2\n",
    "    probs=torch.softmax(z2,axis=1)\n",
    "    return probs\n",
    "def CE(probs,y):\n",
    "    return -torch.log(probs[range(y.shape[0]),y.long()]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=network(X,w1,b1,w2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4302, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CE(p,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1, loss 2.9748666286468506, acc 0.0974285677075386\n",
      "Iter 2, loss 2.9257547855377197, acc 0.0974285677075386\n",
      "Iter 3, loss 2.8819117546081543, acc 0.0974285677075386\n",
      "Iter 4, loss 2.8427894115448, acc 0.09747619181871414\n",
      "Iter 5, loss 2.807565212249756, acc 0.10457143187522888\n",
      "Iter 6, loss 2.7757558822631836, acc 0.10478571057319641\n",
      "Iter 7, loss 2.7470030784606934, acc 0.10473809391260147\n",
      "Iter 8, loss 2.720926523208618, acc 0.1057380959391594\n",
      "Iter 9, loss 2.6969566345214844, acc 0.10578571259975433\n",
      "Iter 10, loss 2.675022602081299, acc 0.10561905056238174\n"
     ]
    }
   ],
   "source": [
    "w1=torch.randn((784,3),dtype=torch.float,requires_grad=True)\n",
    "b1=torch.randn((3,),dtype=torch.float,requires_grad=True)\n",
    "w2=torch.randn((3,10),dtype=torch.float,requires_grad=True)\n",
    "b2=torch.randn((10,),dtype=torch.float,requires_grad=True)\n",
    "lr=0.1\n",
    "Loss=[]\n",
    "for i in range(10):\n",
    "    p=network(X,w1,b1,w2,b2)\n",
    "    #print(p)\n",
    "    loss=CE(p,y)\n",
    "    loss.backward()\n",
    "    Loss.append(loss.item())\n",
    "    acc=(p.argmax(axis=1)==y).float().mean().item()\n",
    "    print(f\"Iter {i+1}, loss {loss.item()}, acc {acc}\")\n",
    "    with torch.no_grad():\n",
    "        w1-=lr*w1.grad\n",
    "        b1-=lr*b1.grad\n",
    "        w2-=lr*w2.grad\n",
    "        b2-=lr*b2.grad\n",
    "        w1.grad.zero_()\n",
    "        b1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "        b2.grad.zero_()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x128c4ac10>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(Loss)),Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iter 1, loss 3.858506441116333, acc 0.14000000059604645\n",
      "Epoch 1, Iter 2, loss 3.9544589519500732, acc 0.07999999821186066\n",
      "Epoch 1, Iter 3, loss 3.721339702606201, acc 0.09000000357627869\n",
      "Epoch 1, Iter 4, loss 3.6383979320526123, acc 0.11999999731779099\n",
      "Epoch 1, Iter 5, loss 3.4573071002960205, acc 0.10000000149011612\n",
      "Epoch 1, Iter 6, loss 3.573138952255249, acc 0.09000000357627869\n",
      "Epoch 1, Iter 7, loss 3.429572820663452, acc 0.09000000357627869\n",
      "Epoch 1, Iter 8, loss 3.6817681789398193, acc 0.07999999821186066\n",
      "Epoch 1, Iter 9, loss 3.172441005706787, acc 0.07999999821186066\n",
      "Epoch 1, Iter 10, loss 3.152134418487549, acc 0.07999999821186066\n",
      "Epoch 1, Iter 11, loss 3.185713768005371, acc 0.09000000357627869\n",
      "Epoch 1, Iter 12, loss 3.075507164001465, acc 0.11999999731779099\n",
      "Epoch 1, Iter 13, loss 3.0589513778686523, acc 0.11999999731779099\n",
      "Epoch 1, Iter 14, loss 3.0442352294921875, acc 0.11999999731779099\n",
      "Epoch 1, Iter 15, loss 3.054908037185669, acc 0.07000000029802322\n",
      "Epoch 1, Iter 16, loss 2.84428334236145, acc 0.1599999964237213\n",
      "Epoch 1, Iter 17, loss 2.901285409927368, acc 0.15000000596046448\n",
      "Epoch 1, Iter 18, loss 2.9211490154266357, acc 0.11999999731779099\n",
      "Epoch 1, Iter 19, loss 2.9866137504577637, acc 0.12999999523162842\n",
      "Epoch 1, Iter 20, loss 3.041086435317993, acc 0.09000000357627869\n",
      "Epoch 1, Iter 21, loss 2.958822011947632, acc 0.07999999821186066\n",
      "Epoch 1, Iter 22, loss 2.734525442123413, acc 0.10000000149011612\n",
      "Epoch 1, Iter 23, loss 3.0309109687805176, acc 0.07000000029802322\n",
      "Epoch 1, Iter 24, loss 2.9217793941497803, acc 0.09000000357627869\n",
      "Epoch 1, Iter 25, loss 2.896963596343994, acc 0.10000000149011612\n",
      "Epoch 1, Iter 26, loss 2.8208205699920654, acc 0.07999999821186066\n",
      "Epoch 1, Iter 27, loss 2.6854114532470703, acc 0.05000000074505806\n",
      "Epoch 1, Iter 28, loss 2.848294973373413, acc 0.05999999865889549\n",
      "Epoch 1, Iter 29, loss 2.7693958282470703, acc 0.11999999731779099\n",
      "Epoch 1, Iter 30, loss 2.861382484436035, acc 0.05000000074505806\n",
      "Epoch 1, Iter 31, loss 2.6329901218414307, acc 0.10000000149011612\n",
      "Epoch 1, Iter 32, loss 2.686840772628784, acc 0.07000000029802322\n",
      "Epoch 1, Iter 33, loss 2.6619720458984375, acc 0.05000000074505806\n",
      "Epoch 1, Iter 34, loss 2.7815115451812744, acc 0.05000000074505806\n",
      "Epoch 1, Iter 35, loss 2.705263376235962, acc 0.09000000357627869\n",
      "Epoch 1, Iter 36, loss 2.8341739177703857, acc 0.05999999865889549\n",
      "Epoch 1, Iter 37, loss 2.612109661102295, acc 0.10999999940395355\n",
      "Epoch 1, Iter 38, loss 2.571519374847412, acc 0.05999999865889549\n",
      "Epoch 1, Iter 39, loss 2.532636880874634, acc 0.05000000074505806\n",
      "Epoch 1, Iter 40, loss 2.5524120330810547, acc 0.10999999940395355\n",
      "Epoch 1, Iter 41, loss 2.629457950592041, acc 0.05999999865889549\n",
      "Epoch 1, Iter 42, loss 2.485114812850952, acc 0.07000000029802322\n",
      "Epoch 1, Iter 43, loss 2.5163204669952393, acc 0.10000000149011612\n",
      "Epoch 1, Iter 44, loss 2.5508131980895996, acc 0.10000000149011612\n",
      "Epoch 1, Iter 45, loss 2.5531558990478516, acc 0.03999999910593033\n",
      "Epoch 1, Iter 46, loss 2.515115261077881, acc 0.07999999821186066\n",
      "Epoch 1, Iter 47, loss 2.612293004989624, acc 0.09000000357627869\n",
      "Epoch 1, Iter 48, loss 2.453773260116577, acc 0.07999999821186066\n",
      "Epoch 1, Iter 49, loss 2.681152105331421, acc 0.029999999329447746\n",
      "Epoch 1, Iter 50, loss 2.6047756671905518, acc 0.05000000074505806\n",
      "Epoch 1, Iter 51, loss 2.3998966217041016, acc 0.07000000029802322\n",
      "Epoch 1, Iter 52, loss 2.6122283935546875, acc 0.029999999329447746\n",
      "Epoch 1, Iter 53, loss 2.5780420303344727, acc 0.07999999821186066\n",
      "Epoch 1, Iter 54, loss 2.365089178085327, acc 0.10000000149011612\n",
      "Epoch 1, Iter 55, loss 2.4698047637939453, acc 0.07999999821186066\n",
      "Epoch 1, Iter 56, loss 2.489959955215454, acc 0.09000000357627869\n",
      "Epoch 1, Iter 57, loss 2.491457939147949, acc 0.07000000029802322\n",
      "Epoch 1, Iter 58, loss 2.3699028491973877, acc 0.07999999821186066\n",
      "Epoch 1, Iter 59, loss 2.484297752380371, acc 0.10999999940395355\n",
      "Epoch 1, Iter 60, loss 2.500070095062256, acc 0.03999999910593033\n",
      "Epoch 1, Iter 61, loss 2.5615921020507812, acc 0.10999999940395355\n",
      "Epoch 1, Iter 62, loss 2.453077554702759, acc 0.09000000357627869\n",
      "Epoch 1, Iter 63, loss 2.38179874420166, acc 0.10000000149011612\n",
      "Epoch 1, Iter 64, loss 2.442422866821289, acc 0.09000000357627869\n",
      "Epoch 1, Iter 65, loss 2.3659005165100098, acc 0.07999999821186066\n",
      "Epoch 1, Iter 66, loss 2.491732120513916, acc 0.15000000596046448\n",
      "Epoch 1, Iter 67, loss 2.5708534717559814, acc 0.07999999821186066\n",
      "Epoch 1, Iter 68, loss 2.4273488521575928, acc 0.07999999821186066\n",
      "Epoch 1, Iter 69, loss 2.44742751121521, acc 0.12999999523162842\n",
      "Epoch 1, Iter 70, loss 2.4925527572631836, acc 0.07999999821186066\n",
      "Epoch 1, Iter 71, loss 2.3914008140563965, acc 0.09000000357627869\n",
      "Epoch 1, Iter 72, loss 2.546647548675537, acc 0.09000000357627869\n",
      "Epoch 1, Iter 73, loss 2.352540969848633, acc 0.15000000596046448\n",
      "Epoch 1, Iter 74, loss 2.4024081230163574, acc 0.10999999940395355\n",
      "Epoch 1, Iter 75, loss 2.387896776199341, acc 0.10999999940395355\n",
      "Epoch 1, Iter 76, loss 2.4668478965759277, acc 0.05999999865889549\n",
      "Epoch 1, Iter 77, loss 2.47532320022583, acc 0.11999999731779099\n",
      "Epoch 1, Iter 78, loss 2.457853078842163, acc 0.1899999976158142\n",
      "Epoch 1, Iter 79, loss 2.410489320755005, acc 0.14000000059604645\n",
      "Epoch 1, Iter 80, loss 2.4138619899749756, acc 0.07999999821186066\n",
      "Epoch 1, Iter 81, loss 2.414573907852173, acc 0.09000000357627869\n",
      "Epoch 1, Iter 82, loss 2.4077277183532715, acc 0.10000000149011612\n",
      "Epoch 1, Iter 83, loss 2.3842310905456543, acc 0.09000000357627869\n",
      "Epoch 1, Iter 84, loss 2.4275567531585693, acc 0.10000000149011612\n",
      "Epoch 1, Iter 85, loss 2.345914363861084, acc 0.12999999523162842\n",
      "Epoch 1, Iter 86, loss 2.3317530155181885, acc 0.10000000149011612\n",
      "Epoch 1, Iter 87, loss 2.487123966217041, acc 0.10000000149011612\n",
      "Epoch 1, Iter 88, loss 2.4381532669067383, acc 0.14000000059604645\n",
      "Epoch 1, Iter 89, loss 2.3762712478637695, acc 0.11999999731779099\n",
      "Epoch 1, Iter 90, loss 2.429013967514038, acc 0.11999999731779099\n",
      "Epoch 1, Iter 91, loss 2.3173890113830566, acc 0.17000000178813934\n",
      "Epoch 1, Iter 92, loss 2.459237813949585, acc 0.11999999731779099\n",
      "Epoch 1, Iter 93, loss 2.3469583988189697, acc 0.18000000715255737\n",
      "Epoch 1, Iter 94, loss 2.354632616043091, acc 0.10000000149011612\n",
      "Epoch 1, Iter 95, loss 2.283005714416504, acc 0.14000000059604645\n",
      "Epoch 1, Iter 96, loss 2.3931970596313477, acc 0.11999999731779099\n",
      "Epoch 1, Iter 97, loss 2.3602449893951416, acc 0.07999999821186066\n",
      "Epoch 1, Iter 98, loss 2.396937370300293, acc 0.14000000059604645\n",
      "Epoch 1, Iter 99, loss 2.379476547241211, acc 0.12999999523162842\n",
      "Epoch 1, Iter 100, loss 2.4010114669799805, acc 0.1599999964237213\n",
      "Epoch 1, Iter 101, loss 2.408466339111328, acc 0.10000000149011612\n",
      "Epoch 1, Iter 102, loss 2.3794057369232178, acc 0.1599999964237213\n",
      "Epoch 1, Iter 103, loss 2.3165442943573, acc 0.17000000178813934\n",
      "Epoch 1, Iter 104, loss 2.460022211074829, acc 0.11999999731779099\n",
      "Epoch 1, Iter 105, loss 2.3888375759124756, acc 0.05999999865889549\n",
      "Epoch 1, Iter 106, loss 2.4295737743377686, acc 0.09000000357627869\n",
      "Epoch 1, Iter 107, loss 2.379317283630371, acc 0.09000000357627869\n",
      "Epoch 1, Iter 108, loss 2.3434877395629883, acc 0.11999999731779099\n",
      "Epoch 1, Iter 109, loss 2.337869882583618, acc 0.10000000149011612\n",
      "Epoch 1, Iter 110, loss 2.3553388118743896, acc 0.07999999821186066\n",
      "Epoch 1, Iter 111, loss 2.369076728820801, acc 0.11999999731779099\n",
      "Epoch 1, Iter 112, loss 2.359527349472046, acc 0.14000000059604645\n",
      "Epoch 1, Iter 113, loss 2.315469741821289, acc 0.12999999523162842\n",
      "Epoch 1, Iter 114, loss 2.399691581726074, acc 0.07999999821186066\n",
      "Epoch 1, Iter 115, loss 2.357954502105713, acc 0.07999999821186066\n",
      "Epoch 1, Iter 116, loss 2.3852005004882812, acc 0.07999999821186066\n",
      "Epoch 1, Iter 117, loss 2.3415451049804688, acc 0.15000000596046448\n",
      "Epoch 1, Iter 118, loss 2.3458492755889893, acc 0.07000000029802322\n",
      "Epoch 1, Iter 119, loss 2.3174548149108887, acc 0.15000000596046448\n",
      "Epoch 1, Iter 120, loss 2.3259987831115723, acc 0.11999999731779099\n",
      "Epoch 1, Iter 121, loss 2.3424501419067383, acc 0.12999999523162842\n",
      "Epoch 1, Iter 122, loss 2.2925002574920654, acc 0.1899999976158142\n",
      "Epoch 1, Iter 123, loss 2.401231527328491, acc 0.05999999865889549\n",
      "Epoch 1, Iter 124, loss 2.3108108043670654, acc 0.07999999821186066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iter 125, loss 2.378476142883301, acc 0.07000000029802322\n",
      "Epoch 1, Iter 126, loss 2.3318936824798584, acc 0.10000000149011612\n",
      "Epoch 1, Iter 127, loss 2.3821661472320557, acc 0.10000000149011612\n",
      "Epoch 1, Iter 128, loss 2.293911933898926, acc 0.10999999940395355\n",
      "Epoch 1, Iter 129, loss 2.350341558456421, acc 0.12999999523162842\n",
      "Epoch 1, Iter 130, loss 2.3369028568267822, acc 0.11999999731779099\n",
      "Epoch 1, Iter 131, loss 2.3269765377044678, acc 0.18000000715255737\n",
      "Epoch 1, Iter 132, loss 2.351130723953247, acc 0.12999999523162842\n",
      "Epoch 1, Iter 133, loss 2.3270630836486816, acc 0.11999999731779099\n",
      "Epoch 1, Iter 134, loss 2.323092222213745, acc 0.10999999940395355\n",
      "Epoch 1, Iter 135, loss 2.3328969478607178, acc 0.17000000178813934\n",
      "Epoch 1, Iter 136, loss 2.2460286617279053, acc 0.11999999731779099\n",
      "Epoch 1, Iter 137, loss 2.330556869506836, acc 0.07000000029802322\n",
      "Epoch 1, Iter 138, loss 2.29386305809021, acc 0.09000000357627869\n",
      "Epoch 1, Iter 139, loss 2.3857619762420654, acc 0.07000000029802322\n",
      "Epoch 1, Iter 140, loss 2.363673210144043, acc 0.05999999865889549\n",
      "Epoch 1, Iter 141, loss 2.348670721054077, acc 0.14000000059604645\n",
      "Epoch 1, Iter 142, loss 2.3234777450561523, acc 0.10999999940395355\n",
      "Epoch 1, Iter 143, loss 2.344104051589966, acc 0.10999999940395355\n",
      "Epoch 1, Iter 144, loss 2.304191827774048, acc 0.11999999731779099\n",
      "Epoch 1, Iter 145, loss 2.254894495010376, acc 0.10999999940395355\n",
      "Epoch 1, Iter 146, loss 2.266847848892212, acc 0.07999999821186066\n",
      "Epoch 1, Iter 147, loss 2.329421281814575, acc 0.17000000178813934\n",
      "Epoch 1, Iter 148, loss 2.3179752826690674, acc 0.10999999940395355\n",
      "Epoch 1, Iter 149, loss 2.3375022411346436, acc 0.09000000357627869\n",
      "Epoch 1, Iter 150, loss 2.3373334407806396, acc 0.1899999976158142\n",
      "Epoch 1, Iter 151, loss 2.274226188659668, acc 0.20999999344348907\n",
      "Epoch 1, Iter 152, loss 2.3562350273132324, acc 0.10999999940395355\n",
      "Epoch 1, Iter 153, loss 2.2940778732299805, acc 0.15000000596046448\n",
      "Epoch 1, Iter 154, loss 2.3213682174682617, acc 0.15000000596046448\n",
      "Epoch 1, Iter 155, loss 2.3582558631896973, acc 0.15000000596046448\n",
      "Epoch 1, Iter 156, loss 2.264341354370117, acc 0.18000000715255737\n",
      "Epoch 1, Iter 157, loss 2.2911558151245117, acc 0.10999999940395355\n",
      "Epoch 1, Iter 158, loss 2.251040458679199, acc 0.12999999523162842\n",
      "Epoch 1, Iter 159, loss 2.317099094390869, acc 0.12999999523162842\n",
      "Epoch 1, Iter 160, loss 2.293417453765869, acc 0.14000000059604645\n",
      "Epoch 1, Iter 161, loss 2.293163299560547, acc 0.17000000178813934\n",
      "Epoch 1, Iter 162, loss 2.2373363971710205, acc 0.27000001072883606\n",
      "Epoch 1, Iter 163, loss 2.282747745513916, acc 0.11999999731779099\n",
      "Epoch 1, Iter 164, loss 2.325998067855835, acc 0.10999999940395355\n",
      "Epoch 1, Iter 165, loss 2.308723211288452, acc 0.10999999940395355\n",
      "Epoch 1, Iter 166, loss 2.267343521118164, acc 0.1599999964237213\n",
      "Epoch 1, Iter 167, loss 2.322314500808716, acc 0.15000000596046448\n",
      "Epoch 1, Iter 168, loss 2.3139755725860596, acc 0.1599999964237213\n",
      "Epoch 1, Iter 169, loss 2.237286329269409, acc 0.1899999976158142\n",
      "Epoch 1, Iter 170, loss 2.29556941986084, acc 0.15000000596046448\n",
      "Epoch 1, Iter 171, loss 2.309377670288086, acc 0.09000000357627869\n",
      "Epoch 1, Iter 172, loss 2.2948086261749268, acc 0.11999999731779099\n",
      "Epoch 1, Iter 173, loss 2.2934579849243164, acc 0.15000000596046448\n",
      "Epoch 1, Iter 174, loss 2.2799177169799805, acc 0.15000000596046448\n",
      "Epoch 1, Iter 175, loss 2.2728071212768555, acc 0.1599999964237213\n",
      "Epoch 1, Iter 176, loss 2.3038299083709717, acc 0.12999999523162842\n",
      "Epoch 1, Iter 177, loss 2.3211748600006104, acc 0.20000000298023224\n",
      "Epoch 1, Iter 178, loss 2.3552663326263428, acc 0.18000000715255737\n",
      "Epoch 1, Iter 179, loss 2.3680312633514404, acc 0.14000000059604645\n",
      "Epoch 1, Iter 180, loss 2.3105127811431885, acc 0.18000000715255737\n",
      "Epoch 1, Iter 181, loss 2.278188705444336, acc 0.1899999976158142\n",
      "Epoch 1, Iter 182, loss 2.2363228797912598, acc 0.1599999964237213\n",
      "Epoch 1, Iter 183, loss 2.3280587196350098, acc 0.1599999964237213\n",
      "Epoch 1, Iter 184, loss 2.2653539180755615, acc 0.18000000715255737\n",
      "Epoch 1, Iter 185, loss 2.2708899974823, acc 0.20000000298023224\n",
      "Epoch 1, Iter 186, loss 2.292891502380371, acc 0.14000000059604645\n",
      "Epoch 1, Iter 187, loss 2.318157911300659, acc 0.1899999976158142\n",
      "Epoch 1, Iter 188, loss 2.3014447689056396, acc 0.14000000059604645\n",
      "Epoch 1, Iter 189, loss 2.34366512298584, acc 0.11999999731779099\n",
      "Epoch 1, Iter 190, loss 2.259962558746338, acc 0.14000000059604645\n",
      "Epoch 1, Iter 191, loss 2.285963773727417, acc 0.18000000715255737\n",
      "Epoch 1, Iter 192, loss 2.242746591567993, acc 0.1899999976158142\n",
      "Epoch 1, Iter 193, loss 2.2335453033447266, acc 0.1899999976158142\n",
      "Epoch 1, Iter 194, loss 2.2151830196380615, acc 0.20000000298023224\n",
      "Epoch 1, Iter 195, loss 2.256845474243164, acc 0.17000000178813934\n",
      "Epoch 1, Iter 196, loss 2.2877440452575684, acc 0.11999999731779099\n",
      "Epoch 1, Iter 197, loss 2.281080961227417, acc 0.15000000596046448\n",
      "Epoch 1, Iter 198, loss 2.197946548461914, acc 0.25999999046325684\n",
      "Epoch 1, Iter 199, loss 2.290870189666748, acc 0.18000000715255737\n",
      "Epoch 1, Iter 200, loss 2.263122320175171, acc 0.14000000059604645\n",
      "Epoch 1, Iter 201, loss 2.2108194828033447, acc 0.18000000715255737\n",
      "Epoch 1, Iter 202, loss 2.296682357788086, acc 0.14000000059604645\n",
      "Epoch 1, Iter 203, loss 2.3325202465057373, acc 0.14000000059604645\n",
      "Epoch 1, Iter 204, loss 2.2863259315490723, acc 0.17000000178813934\n",
      "Epoch 1, Iter 205, loss 2.240457773208618, acc 0.20999999344348907\n",
      "Epoch 1, Iter 206, loss 2.290266990661621, acc 0.20999999344348907\n",
      "Epoch 1, Iter 207, loss 2.323063373565674, acc 0.14000000059604645\n",
      "Epoch 1, Iter 208, loss 2.2799057960510254, acc 0.10999999940395355\n",
      "Epoch 1, Iter 209, loss 2.274017810821533, acc 0.11999999731779099\n",
      "Epoch 1, Iter 210, loss 2.3055014610290527, acc 0.10999999940395355\n",
      "Epoch 1, Iter 211, loss 2.2528111934661865, acc 0.2199999988079071\n",
      "Epoch 1, Iter 212, loss 2.3211510181427, acc 0.10000000149011612\n",
      "Epoch 1, Iter 213, loss 2.298717737197876, acc 0.10000000149011612\n",
      "Epoch 1, Iter 214, loss 2.301696300506592, acc 0.10999999940395355\n",
      "Epoch 1, Iter 215, loss 2.2709476947784424, acc 0.17000000178813934\n",
      "Epoch 1, Iter 216, loss 2.327080488204956, acc 0.10000000149011612\n",
      "Epoch 1, Iter 217, loss 2.2779455184936523, acc 0.17000000178813934\n",
      "Epoch 1, Iter 218, loss 2.309868335723877, acc 0.1599999964237213\n",
      "Epoch 1, Iter 219, loss 2.3082282543182373, acc 0.14000000059604645\n",
      "Epoch 1, Iter 220, loss 2.256129026412964, acc 0.12999999523162842\n",
      "Epoch 1, Iter 221, loss 2.2698850631713867, acc 0.15000000596046448\n",
      "Epoch 1, Iter 222, loss 2.2609219551086426, acc 0.18000000715255737\n",
      "Epoch 1, Iter 223, loss 2.2202823162078857, acc 0.1599999964237213\n",
      "Epoch 1, Iter 224, loss 2.279090642929077, acc 0.1599999964237213\n",
      "Epoch 1, Iter 225, loss 2.2369658946990967, acc 0.23000000417232513\n",
      "Epoch 1, Iter 226, loss 2.2428689002990723, acc 0.20999999344348907\n",
      "Epoch 1, Iter 227, loss 2.299968957901001, acc 0.18000000715255737\n",
      "Epoch 1, Iter 228, loss 2.236746311187744, acc 0.17000000178813934\n",
      "Epoch 1, Iter 229, loss 2.2688443660736084, acc 0.1599999964237213\n",
      "Epoch 1, Iter 230, loss 2.269894599914551, acc 0.17000000178813934\n",
      "Epoch 1, Iter 231, loss 2.2123610973358154, acc 0.20999999344348907\n",
      "Epoch 1, Iter 232, loss 2.2938039302825928, acc 0.15000000596046448\n",
      "Epoch 1, Iter 233, loss 2.232576847076416, acc 0.20999999344348907\n",
      "Epoch 1, Iter 234, loss 2.171302318572998, acc 0.2199999988079071\n",
      "Epoch 1, Iter 235, loss 2.2957723140716553, acc 0.14000000059604645\n",
      "Epoch 1, Iter 236, loss 2.268308639526367, acc 0.15000000596046448\n",
      "Epoch 1, Iter 237, loss 2.241063117980957, acc 0.1599999964237213\n",
      "Epoch 1, Iter 238, loss 2.2703330516815186, acc 0.15000000596046448\n",
      "Epoch 1, Iter 239, loss 2.1929540634155273, acc 0.12999999523162842\n",
      "Epoch 1, Iter 240, loss 2.3583385944366455, acc 0.14000000059604645\n",
      "Epoch 1, Iter 241, loss 2.2109732627868652, acc 0.20999999344348907\n",
      "Epoch 1, Iter 242, loss 2.328850746154785, acc 0.09000000357627869\n",
      "Epoch 1, Iter 243, loss 2.2361104488372803, acc 0.15000000596046448\n",
      "Epoch 1, Iter 244, loss 2.229208469390869, acc 0.23000000417232513\n",
      "Epoch 1, Iter 245, loss 2.2775208950042725, acc 0.17000000178813934\n",
      "Epoch 1, Iter 246, loss 2.2104218006134033, acc 0.17000000178813934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iter 247, loss 2.216445207595825, acc 0.1599999964237213\n",
      "Epoch 1, Iter 248, loss 2.245022773742676, acc 0.23000000417232513\n",
      "Epoch 1, Iter 249, loss 2.2295174598693848, acc 0.12999999523162842\n",
      "Epoch 1, Iter 250, loss 2.224292039871216, acc 0.2199999988079071\n",
      "Epoch 1, Iter 251, loss 2.226398468017578, acc 0.20999999344348907\n",
      "Epoch 1, Iter 252, loss 2.2896268367767334, acc 0.1599999964237213\n",
      "Epoch 1, Iter 253, loss 2.248734474182129, acc 0.18000000715255737\n",
      "Epoch 1, Iter 254, loss 2.278053045272827, acc 0.11999999731779099\n",
      "Epoch 1, Iter 255, loss 2.2248470783233643, acc 0.15000000596046448\n",
      "Epoch 1, Iter 256, loss 2.2435758113861084, acc 0.18000000715255737\n",
      "Epoch 1, Iter 257, loss 2.217998504638672, acc 0.20999999344348907\n",
      "Epoch 1, Iter 258, loss 2.2831223011016846, acc 0.18000000715255737\n",
      "Epoch 1, Iter 259, loss 2.2954022884368896, acc 0.10999999940395355\n",
      "Epoch 1, Iter 260, loss 2.2051494121551514, acc 0.1899999976158142\n",
      "Epoch 1, Iter 261, loss 2.2755913734436035, acc 0.1899999976158142\n",
      "Epoch 1, Iter 262, loss 2.3074872493743896, acc 0.11999999731779099\n",
      "Epoch 1, Iter 263, loss 2.207869291305542, acc 0.23999999463558197\n",
      "Epoch 1, Iter 264, loss 2.2122275829315186, acc 0.23999999463558197\n",
      "Epoch 1, Iter 265, loss 2.2889630794525146, acc 0.1899999976158142\n",
      "Epoch 1, Iter 266, loss 2.3014018535614014, acc 0.18000000715255737\n",
      "Epoch 1, Iter 267, loss 2.298243999481201, acc 0.18000000715255737\n",
      "Epoch 1, Iter 268, loss 2.167801856994629, acc 0.2199999988079071\n",
      "Epoch 1, Iter 269, loss 2.229893922805786, acc 0.18000000715255737\n",
      "Epoch 1, Iter 270, loss 2.2676541805267334, acc 0.18000000715255737\n",
      "Epoch 1, Iter 271, loss 2.2054619789123535, acc 0.17000000178813934\n",
      "Epoch 1, Iter 272, loss 2.2774546146392822, acc 0.15000000596046448\n",
      "Epoch 1, Iter 273, loss 2.1908626556396484, acc 0.17000000178813934\n",
      "Epoch 1, Iter 274, loss 2.1619575023651123, acc 0.23999999463558197\n",
      "Epoch 1, Iter 275, loss 2.2140119075775146, acc 0.17000000178813934\n",
      "Epoch 1, Iter 276, loss 2.191720485687256, acc 0.20000000298023224\n",
      "Epoch 1, Iter 277, loss 2.2811708450317383, acc 0.18000000715255737\n",
      "Epoch 1, Iter 278, loss 2.2015347480773926, acc 0.1899999976158142\n",
      "Epoch 1, Iter 279, loss 2.2617733478546143, acc 0.20000000298023224\n",
      "Epoch 1, Iter 280, loss 2.1963469982147217, acc 0.2199999988079071\n",
      "Epoch 1, Iter 281, loss 2.2284140586853027, acc 0.17000000178813934\n",
      "Epoch 1, Iter 282, loss 2.1992361545562744, acc 0.20000000298023224\n",
      "Epoch 1, Iter 283, loss 2.196920871734619, acc 0.1899999976158142\n",
      "Epoch 1, Iter 284, loss 2.260545492172241, acc 0.20000000298023224\n",
      "Epoch 1, Iter 285, loss 2.1985924243927, acc 0.25\n",
      "Epoch 1, Iter 286, loss 2.1862807273864746, acc 0.23000000417232513\n",
      "Epoch 1, Iter 287, loss 2.253542184829712, acc 0.20000000298023224\n",
      "Epoch 1, Iter 288, loss 2.2164790630340576, acc 0.20999999344348907\n",
      "Epoch 1, Iter 289, loss 2.2530412673950195, acc 0.18000000715255737\n",
      "Epoch 1, Iter 290, loss 2.2152647972106934, acc 0.20000000298023224\n",
      "Epoch 1, Iter 291, loss 2.2404592037200928, acc 0.20000000298023224\n",
      "Epoch 1, Iter 292, loss 2.1473400592803955, acc 0.23000000417232513\n",
      "Epoch 1, Iter 293, loss 2.2628231048583984, acc 0.1899999976158142\n",
      "Epoch 1, Iter 294, loss 2.2171993255615234, acc 0.20000000298023224\n",
      "Epoch 1, Iter 295, loss 2.19933819770813, acc 0.20999999344348907\n",
      "Epoch 1, Iter 296, loss 2.226206064224243, acc 0.18000000715255737\n",
      "Epoch 1, Iter 297, loss 2.2304494380950928, acc 0.20000000298023224\n",
      "Epoch 1, Iter 298, loss 2.192950487136841, acc 0.20000000298023224\n",
      "Epoch 1, Iter 299, loss 2.280876398086548, acc 0.09000000357627869\n",
      "Epoch 1, Iter 300, loss 2.2555925846099854, acc 0.1899999976158142\n",
      "Epoch 1, Iter 301, loss 2.277763843536377, acc 0.2199999988079071\n",
      "Epoch 1, Iter 302, loss 2.189746856689453, acc 0.20999999344348907\n",
      "Epoch 1, Iter 303, loss 2.213301181793213, acc 0.15000000596046448\n",
      "Epoch 1, Iter 304, loss 2.1861748695373535, acc 0.20999999344348907\n",
      "Epoch 1, Iter 305, loss 2.2358152866363525, acc 0.1899999976158142\n",
      "Epoch 1, Iter 306, loss 2.263418436050415, acc 0.17000000178813934\n",
      "Epoch 1, Iter 307, loss 2.2188010215759277, acc 0.18000000715255737\n",
      "Epoch 1, Iter 308, loss 2.2086150646209717, acc 0.1899999976158142\n",
      "Epoch 1, Iter 309, loss 2.2000701427459717, acc 0.20000000298023224\n",
      "Epoch 1, Iter 310, loss 2.2199878692626953, acc 0.18000000715255737\n",
      "Epoch 1, Iter 311, loss 2.218421697616577, acc 0.25\n",
      "Epoch 1, Iter 312, loss 2.2065200805664062, acc 0.2199999988079071\n",
      "Epoch 1, Iter 313, loss 2.2208049297332764, acc 0.1899999976158142\n",
      "Epoch 1, Iter 314, loss 2.2141005992889404, acc 0.23999999463558197\n",
      "Epoch 1, Iter 315, loss 2.122833013534546, acc 0.25999999046325684\n",
      "Epoch 1, Iter 316, loss 2.1710972785949707, acc 0.20999999344348907\n",
      "Epoch 1, Iter 317, loss 2.217050552368164, acc 0.18000000715255737\n",
      "Epoch 1, Iter 318, loss 2.156689405441284, acc 0.27000001072883606\n",
      "Epoch 1, Iter 319, loss 2.269202709197998, acc 0.1899999976158142\n",
      "Epoch 1, Iter 320, loss 2.147367000579834, acc 0.18000000715255737\n",
      "Epoch 1, Iter 321, loss 2.241748809814453, acc 0.15000000596046448\n",
      "Epoch 1, Iter 322, loss 2.22188401222229, acc 0.20000000298023224\n",
      "Epoch 1, Iter 323, loss 2.2520911693573, acc 0.17000000178813934\n",
      "Epoch 1, Iter 324, loss 2.1665701866149902, acc 0.25\n",
      "Epoch 1, Iter 325, loss 2.1930649280548096, acc 0.2199999988079071\n",
      "Epoch 1, Iter 326, loss 2.2212624549865723, acc 0.1899999976158142\n",
      "Epoch 1, Iter 327, loss 2.2487845420837402, acc 0.23000000417232513\n",
      "Epoch 1, Iter 328, loss 2.178556203842163, acc 0.2199999988079071\n",
      "Epoch 1, Iter 329, loss 2.1691880226135254, acc 0.23000000417232513\n",
      "Epoch 1, Iter 330, loss 2.21636700630188, acc 0.17000000178813934\n",
      "Epoch 1, Iter 331, loss 2.1668596267700195, acc 0.20999999344348907\n",
      "Epoch 1, Iter 332, loss 2.1858532428741455, acc 0.2199999988079071\n",
      "Epoch 1, Iter 333, loss 2.1434147357940674, acc 0.20000000298023224\n",
      "Epoch 1, Iter 334, loss 2.2108168601989746, acc 0.20000000298023224\n",
      "Epoch 1, Iter 335, loss 2.2390081882476807, acc 0.27000001072883606\n",
      "Epoch 1, Iter 336, loss 2.2004408836364746, acc 0.23999999463558197\n",
      "Epoch 1, Iter 337, loss 2.259147882461548, acc 0.1899999976158142\n",
      "Epoch 1, Iter 338, loss 2.2569360733032227, acc 0.17000000178813934\n",
      "Epoch 1, Iter 339, loss 2.232928514480591, acc 0.2199999988079071\n",
      "Epoch 1, Iter 340, loss 2.2231364250183105, acc 0.17000000178813934\n",
      "Epoch 1, Iter 341, loss 2.1177022457122803, acc 0.2800000011920929\n",
      "Epoch 1, Iter 342, loss 2.1917366981506348, acc 0.23000000417232513\n",
      "Epoch 1, Iter 343, loss 2.2227513790130615, acc 0.15000000596046448\n",
      "Epoch 1, Iter 344, loss 2.1779625415802, acc 0.23999999463558197\n",
      "Epoch 1, Iter 345, loss 2.258155107498169, acc 0.20999999344348907\n",
      "Epoch 1, Iter 346, loss 2.1600775718688965, acc 0.27000001072883606\n",
      "Epoch 1, Iter 347, loss 2.239640951156616, acc 0.2199999988079071\n",
      "Epoch 1, Iter 348, loss 2.1174352169036865, acc 0.3100000023841858\n",
      "Epoch 1, Iter 349, loss 2.1933701038360596, acc 0.20999999344348907\n",
      "Epoch 1, Iter 350, loss 2.1632909774780273, acc 0.25999999046325684\n",
      "Epoch 1, Iter 351, loss 2.2252023220062256, acc 0.1899999976158142\n",
      "Epoch 1, Iter 352, loss 2.1539313793182373, acc 0.25999999046325684\n",
      "Epoch 1, Iter 353, loss 2.256711959838867, acc 0.11999999731779099\n",
      "Epoch 1, Iter 354, loss 2.188746690750122, acc 0.20000000298023224\n",
      "Epoch 1, Iter 355, loss 2.2812371253967285, acc 0.15000000596046448\n",
      "Epoch 1, Iter 356, loss 2.146040439605713, acc 0.20999999344348907\n",
      "Epoch 1, Iter 357, loss 2.2066102027893066, acc 0.18000000715255737\n",
      "Epoch 1, Iter 358, loss 2.1995465755462646, acc 0.18000000715255737\n",
      "Epoch 1, Iter 359, loss 2.231957197189331, acc 0.12999999523162842\n",
      "Epoch 1, Iter 360, loss 2.1540098190307617, acc 0.25999999046325684\n",
      "Epoch 1, Iter 361, loss 2.143214702606201, acc 0.23000000417232513\n",
      "Epoch 1, Iter 362, loss 2.2521369457244873, acc 0.14000000059604645\n",
      "Epoch 1, Iter 363, loss 2.183095932006836, acc 0.20000000298023224\n",
      "Epoch 1, Iter 364, loss 2.282836675643921, acc 0.15000000596046448\n",
      "Epoch 1, Iter 365, loss 2.2254579067230225, acc 0.1599999964237213\n",
      "Epoch 1, Iter 366, loss 2.124850273132324, acc 0.27000001072883606\n",
      "Epoch 1, Iter 367, loss 2.18512225151062, acc 0.23000000417232513\n",
      "Epoch 1, Iter 368, loss 2.212475538253784, acc 0.1899999976158142\n",
      "Epoch 1, Iter 369, loss 2.1867499351501465, acc 0.1899999976158142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iter 370, loss 2.17336368560791, acc 0.2199999988079071\n",
      "Epoch 1, Iter 371, loss 2.203638792037964, acc 0.2199999988079071\n",
      "Epoch 1, Iter 372, loss 2.18243408203125, acc 0.20000000298023224\n",
      "Epoch 1, Iter 373, loss 2.16280198097229, acc 0.2199999988079071\n",
      "Epoch 1, Iter 374, loss 2.1851601600646973, acc 0.1899999976158142\n",
      "Epoch 1, Iter 375, loss 2.2262115478515625, acc 0.23000000417232513\n",
      "Epoch 1, Iter 376, loss 2.1926350593566895, acc 0.2199999988079071\n",
      "Epoch 1, Iter 377, loss 2.1726179122924805, acc 0.20000000298023224\n",
      "Epoch 1, Iter 378, loss 2.1834828853607178, acc 0.25999999046325684\n",
      "Epoch 1, Iter 379, loss 2.1640779972076416, acc 0.23000000417232513\n",
      "Epoch 1, Iter 380, loss 2.162644863128662, acc 0.23999999463558197\n",
      "Epoch 1, Iter 381, loss 2.1895172595977783, acc 0.15000000596046448\n",
      "Epoch 1, Iter 382, loss 2.150294303894043, acc 0.23000000417232513\n",
      "Epoch 1, Iter 383, loss 2.1411800384521484, acc 0.23999999463558197\n",
      "Epoch 1, Iter 384, loss 2.2112088203430176, acc 0.14000000059604645\n",
      "Epoch 1, Iter 385, loss 2.1713316440582275, acc 0.23999999463558197\n",
      "Epoch 1, Iter 386, loss 2.1761040687561035, acc 0.25\n",
      "Epoch 1, Iter 387, loss 2.207538604736328, acc 0.1899999976158142\n",
      "Epoch 1, Iter 388, loss 2.2414791584014893, acc 0.17000000178813934\n",
      "Epoch 1, Iter 389, loss 2.2130110263824463, acc 0.18000000715255737\n",
      "Epoch 1, Iter 390, loss 2.1668508052825928, acc 0.25999999046325684\n",
      "Epoch 1, Iter 391, loss 2.1846764087677, acc 0.2199999988079071\n",
      "Epoch 1, Iter 392, loss 2.149259328842163, acc 0.20999999344348907\n",
      "Epoch 1, Iter 393, loss 2.174137830734253, acc 0.20000000298023224\n",
      "Epoch 1, Iter 394, loss 2.1319940090179443, acc 0.28999999165534973\n",
      "Epoch 1, Iter 395, loss 2.123220443725586, acc 0.2800000011920929\n",
      "Epoch 1, Iter 396, loss 2.1643683910369873, acc 0.20999999344348907\n",
      "Epoch 1, Iter 397, loss 2.114304304122925, acc 0.2199999988079071\n",
      "Epoch 1, Iter 398, loss 2.2077219486236572, acc 0.18000000715255737\n",
      "Epoch 1, Iter 399, loss 2.1788365840911865, acc 0.2199999988079071\n",
      "Epoch 1, Iter 400, loss 2.1274476051330566, acc 0.23000000417232513\n",
      "Epoch 1, Iter 401, loss 2.142667770385742, acc 0.23999999463558197\n",
      "Epoch 1, Iter 402, loss 2.176888942718506, acc 0.23000000417232513\n",
      "Epoch 1, Iter 403, loss 2.1707985401153564, acc 0.25\n",
      "Epoch 1, Iter 404, loss 2.1896417140960693, acc 0.20000000298023224\n",
      "Epoch 1, Iter 405, loss 2.200835704803467, acc 0.18000000715255737\n",
      "Epoch 1, Iter 406, loss 2.2990126609802246, acc 0.10999999940395355\n",
      "Epoch 1, Iter 407, loss 2.227870464324951, acc 0.12999999523162842\n",
      "Epoch 1, Iter 408, loss 2.1997084617614746, acc 0.23000000417232513\n",
      "Epoch 1, Iter 409, loss 2.174391508102417, acc 0.20000000298023224\n",
      "Epoch 1, Iter 410, loss 2.139549493789673, acc 0.27000001072883606\n",
      "Epoch 1, Iter 411, loss 2.1120879650115967, acc 0.25\n",
      "Epoch 1, Iter 412, loss 2.1509358882904053, acc 0.23999999463558197\n",
      "Epoch 1, Iter 413, loss 2.2402634620666504, acc 0.1599999964237213\n",
      "Epoch 1, Iter 414, loss 2.220980167388916, acc 0.18000000715255737\n",
      "Epoch 1, Iter 415, loss 2.1768479347229004, acc 0.2199999988079071\n",
      "Epoch 1, Iter 416, loss 2.0930936336517334, acc 0.27000001072883606\n",
      "Epoch 1, Iter 417, loss 2.1286869049072266, acc 0.20999999344348907\n",
      "Epoch 1, Iter 418, loss 2.1313886642456055, acc 0.28999999165534973\n",
      "Epoch 1, Iter 419, loss 2.1830105781555176, acc 0.2800000011920929\n",
      "Epoch 1, Iter 420, loss 2.117227792739868, acc 0.28999999165534973\n",
      "Epoch 2, Iter 1, loss 2.0902771949768066, acc 0.28999999165534973\n",
      "Epoch 2, Iter 2, loss 2.1466422080993652, acc 0.23000000417232513\n",
      "Epoch 2, Iter 3, loss 2.169538974761963, acc 0.2199999988079071\n",
      "Epoch 2, Iter 4, loss 2.2183892726898193, acc 0.20999999344348907\n",
      "Epoch 2, Iter 5, loss 2.0789670944213867, acc 0.2800000011920929\n",
      "Epoch 2, Iter 6, loss 2.205217123031616, acc 0.20000000298023224\n",
      "Epoch 2, Iter 7, loss 2.2608954906463623, acc 0.18000000715255737\n",
      "Epoch 2, Iter 8, loss 2.150038242340088, acc 0.25\n",
      "Epoch 2, Iter 9, loss 2.175405263900757, acc 0.18000000715255737\n",
      "Epoch 2, Iter 10, loss 2.200875997543335, acc 0.1599999964237213\n",
      "Epoch 2, Iter 11, loss 2.1672844886779785, acc 0.18000000715255737\n",
      "Epoch 2, Iter 12, loss 2.153597831726074, acc 0.25\n",
      "Epoch 2, Iter 13, loss 2.1615586280822754, acc 0.20999999344348907\n",
      "Epoch 2, Iter 14, loss 2.1553750038146973, acc 0.1899999976158142\n",
      "Epoch 2, Iter 15, loss 2.131141185760498, acc 0.2800000011920929\n",
      "Epoch 2, Iter 16, loss 2.087432622909546, acc 0.1899999976158142\n",
      "Epoch 2, Iter 17, loss 2.170182228088379, acc 0.2199999988079071\n",
      "Epoch 2, Iter 18, loss 2.1320600509643555, acc 0.2199999988079071\n",
      "Epoch 2, Iter 19, loss 2.1691524982452393, acc 0.30000001192092896\n",
      "Epoch 2, Iter 20, loss 2.1095528602600098, acc 0.2800000011920929\n",
      "Epoch 2, Iter 21, loss 2.1343719959259033, acc 0.27000001072883606\n",
      "Epoch 2, Iter 22, loss 2.1746609210968018, acc 0.23000000417232513\n",
      "Epoch 2, Iter 23, loss 2.1791586875915527, acc 0.25999999046325684\n",
      "Epoch 2, Iter 24, loss 2.1961004734039307, acc 0.20000000298023224\n",
      "Epoch 2, Iter 25, loss 2.250633955001831, acc 0.18000000715255737\n",
      "Epoch 2, Iter 26, loss 2.149970054626465, acc 0.20000000298023224\n",
      "Epoch 2, Iter 27, loss 2.1387269496917725, acc 0.23000000417232513\n",
      "Epoch 2, Iter 28, loss 2.2484161853790283, acc 0.1599999964237213\n",
      "Epoch 2, Iter 29, loss 2.1406917572021484, acc 0.27000001072883606\n",
      "Epoch 2, Iter 30, loss 2.175530433654785, acc 0.20999999344348907\n",
      "Epoch 2, Iter 31, loss 2.222855567932129, acc 0.15000000596046448\n",
      "Epoch 2, Iter 32, loss 2.1211936473846436, acc 0.25\n",
      "Epoch 2, Iter 33, loss 2.1493215560913086, acc 0.1599999964237213\n",
      "Epoch 2, Iter 34, loss 2.1669540405273438, acc 0.25999999046325684\n",
      "Epoch 2, Iter 35, loss 2.193664789199829, acc 0.2199999988079071\n",
      "Epoch 2, Iter 36, loss 2.1834802627563477, acc 0.23000000417232513\n",
      "Epoch 2, Iter 37, loss 2.189406633377075, acc 0.18000000715255737\n",
      "Epoch 2, Iter 38, loss 2.1539719104766846, acc 0.2199999988079071\n",
      "Epoch 2, Iter 39, loss 2.1859350204467773, acc 0.20999999344348907\n",
      "Epoch 2, Iter 40, loss 2.0480849742889404, acc 0.25999999046325684\n",
      "Epoch 2, Iter 41, loss 2.1959171295166016, acc 0.1899999976158142\n",
      "Epoch 2, Iter 42, loss 2.1774349212646484, acc 0.20999999344348907\n",
      "Epoch 2, Iter 43, loss 2.108666181564331, acc 0.27000001072883606\n",
      "Epoch 2, Iter 44, loss 2.101816177368164, acc 0.25\n",
      "Epoch 2, Iter 45, loss 2.126422166824341, acc 0.23999999463558197\n",
      "Epoch 2, Iter 46, loss 2.134956121444702, acc 0.18000000715255737\n",
      "Epoch 2, Iter 47, loss 2.2237634658813477, acc 0.18000000715255737\n",
      "Epoch 2, Iter 48, loss 2.1689090728759766, acc 0.2199999988079071\n",
      "Epoch 2, Iter 49, loss 2.184675693511963, acc 0.23999999463558197\n",
      "Epoch 2, Iter 50, loss 2.1254453659057617, acc 0.20999999344348907\n",
      "Epoch 2, Iter 51, loss 2.09505558013916, acc 0.25999999046325684\n",
      "Epoch 2, Iter 52, loss 2.1471548080444336, acc 0.23000000417232513\n",
      "Epoch 2, Iter 53, loss 2.197538137435913, acc 0.2199999988079071\n",
      "Epoch 2, Iter 54, loss 2.1512913703918457, acc 0.20999999344348907\n",
      "Epoch 2, Iter 55, loss 2.2256155014038086, acc 0.1899999976158142\n",
      "Epoch 2, Iter 56, loss 2.211920976638794, acc 0.12999999523162842\n",
      "Epoch 2, Iter 57, loss 2.1820900440216064, acc 0.14000000059604645\n",
      "Epoch 2, Iter 58, loss 2.195359230041504, acc 0.17000000178813934\n",
      "Epoch 2, Iter 59, loss 2.2203376293182373, acc 0.1899999976158142\n",
      "Epoch 2, Iter 60, loss 2.20928955078125, acc 0.18000000715255737\n",
      "Epoch 2, Iter 61, loss 2.1644670963287354, acc 0.20999999344348907\n",
      "Epoch 2, Iter 62, loss 2.2161991596221924, acc 0.1899999976158142\n",
      "Epoch 2, Iter 63, loss 2.192725419998169, acc 0.17000000178813934\n",
      "Epoch 2, Iter 64, loss 2.10797381401062, acc 0.27000001072883606\n",
      "Epoch 2, Iter 65, loss 2.1724278926849365, acc 0.2199999988079071\n",
      "Epoch 2, Iter 66, loss 2.2460548877716064, acc 0.1899999976158142\n",
      "Epoch 2, Iter 67, loss 2.1942386627197266, acc 0.18000000715255737\n",
      "Epoch 2, Iter 68, loss 2.0675406455993652, acc 0.3199999928474426\n",
      "Epoch 2, Iter 69, loss 2.1726667881011963, acc 0.25\n",
      "Epoch 2, Iter 70, loss 2.2389304637908936, acc 0.2199999988079071\n",
      "Epoch 2, Iter 71, loss 2.1437389850616455, acc 0.1899999976158142\n",
      "Epoch 2, Iter 72, loss 2.228919744491577, acc 0.1899999976158142\n",
      "Epoch 2, Iter 73, loss 2.102614402770996, acc 0.30000001192092896\n",
      "Epoch 2, Iter 74, loss 2.121241807937622, acc 0.30000001192092896\n",
      "Epoch 2, Iter 75, loss 2.148130416870117, acc 0.20000000298023224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Iter 76, loss 2.143543004989624, acc 0.30000001192092896\n",
      "Epoch 2, Iter 77, loss 2.2204768657684326, acc 0.2199999988079071\n",
      "Epoch 2, Iter 78, loss 2.1562395095825195, acc 0.27000001072883606\n",
      "Epoch 2, Iter 79, loss 2.090224027633667, acc 0.28999999165534973\n",
      "Epoch 2, Iter 80, loss 2.1021578311920166, acc 0.25\n",
      "Epoch 2, Iter 81, loss 2.177950859069824, acc 0.1899999976158142\n",
      "Epoch 2, Iter 82, loss 2.1911635398864746, acc 0.20000000298023224\n",
      "Epoch 2, Iter 83, loss 2.1399567127227783, acc 0.25\n",
      "Epoch 2, Iter 84, loss 2.2666046619415283, acc 0.17000000178813934\n",
      "Epoch 2, Iter 85, loss 2.1298575401306152, acc 0.23999999463558197\n",
      "Epoch 2, Iter 86, loss 2.1872994899749756, acc 0.14000000059604645\n",
      "Epoch 2, Iter 87, loss 2.170240879058838, acc 0.27000001072883606\n",
      "Epoch 2, Iter 88, loss 2.1517629623413086, acc 0.23000000417232513\n",
      "Epoch 2, Iter 89, loss 2.160548686981201, acc 0.20999999344348907\n",
      "Epoch 2, Iter 90, loss 2.1854121685028076, acc 0.23999999463558197\n",
      "Epoch 2, Iter 91, loss 2.126190423965454, acc 0.23999999463558197\n",
      "Epoch 2, Iter 92, loss 2.225630521774292, acc 0.11999999731779099\n",
      "Epoch 2, Iter 93, loss 2.129225254058838, acc 0.2199999988079071\n",
      "Epoch 2, Iter 94, loss 2.120138645172119, acc 0.25\n",
      "Epoch 2, Iter 95, loss 2.0550594329833984, acc 0.25999999046325684\n",
      "Epoch 2, Iter 96, loss 2.1055123805999756, acc 0.23999999463558197\n",
      "Epoch 2, Iter 97, loss 2.1414406299591064, acc 0.20000000298023224\n",
      "Epoch 2, Iter 98, loss 2.1504578590393066, acc 0.27000001072883606\n",
      "Epoch 2, Iter 99, loss 2.172818899154663, acc 0.23000000417232513\n",
      "Epoch 2, Iter 100, loss 2.1844496726989746, acc 0.1899999976158142\n",
      "Epoch 2, Iter 101, loss 2.1560747623443604, acc 0.25\n",
      "Epoch 2, Iter 102, loss 2.22871994972229, acc 0.20000000298023224\n",
      "Epoch 2, Iter 103, loss 2.150655746459961, acc 0.1899999976158142\n",
      "Epoch 2, Iter 104, loss 2.2552387714385986, acc 0.18000000715255737\n",
      "Epoch 2, Iter 105, loss 2.192840814590454, acc 0.25\n",
      "Epoch 2, Iter 106, loss 2.2602293491363525, acc 0.1599999964237213\n",
      "Epoch 2, Iter 107, loss 2.1533162593841553, acc 0.23999999463558197\n",
      "Epoch 2, Iter 108, loss 2.1982545852661133, acc 0.25999999046325684\n",
      "Epoch 2, Iter 109, loss 2.105658531188965, acc 0.25\n",
      "Epoch 2, Iter 110, loss 2.193145513534546, acc 0.20999999344348907\n",
      "Epoch 2, Iter 111, loss 2.1622142791748047, acc 0.20999999344348907\n",
      "Epoch 2, Iter 112, loss 2.1172947883605957, acc 0.25\n",
      "Epoch 2, Iter 113, loss 2.125300884246826, acc 0.27000001072883606\n",
      "Epoch 2, Iter 114, loss 2.201199769973755, acc 0.23999999463558197\n",
      "Epoch 2, Iter 115, loss 2.1326334476470947, acc 0.25999999046325684\n",
      "Epoch 2, Iter 116, loss 2.15329647064209, acc 0.27000001072883606\n",
      "Epoch 2, Iter 117, loss 2.1718573570251465, acc 0.20999999344348907\n",
      "Epoch 2, Iter 118, loss 2.15181565284729, acc 0.23000000417232513\n",
      "Epoch 2, Iter 119, loss 2.172149896621704, acc 0.2199999988079071\n",
      "Epoch 2, Iter 120, loss 2.136646032333374, acc 0.25999999046325684\n",
      "Epoch 2, Iter 121, loss 2.106940507888794, acc 0.23000000417232513\n",
      "Epoch 2, Iter 122, loss 2.1320815086364746, acc 0.2199999988079071\n",
      "Epoch 2, Iter 123, loss 2.190255880355835, acc 0.20000000298023224\n",
      "Epoch 2, Iter 124, loss 2.1347436904907227, acc 0.20999999344348907\n",
      "Epoch 2, Iter 125, loss 2.185680627822876, acc 0.23999999463558197\n",
      "Epoch 2, Iter 126, loss 2.1158299446105957, acc 0.3100000023841858\n",
      "Epoch 2, Iter 127, loss 2.2184596061706543, acc 0.20999999344348907\n",
      "Epoch 2, Iter 128, loss 2.1798408031463623, acc 0.2199999988079071\n",
      "Epoch 2, Iter 129, loss 2.1717216968536377, acc 0.1599999964237213\n",
      "Epoch 2, Iter 130, loss 2.2214925289154053, acc 0.20999999344348907\n",
      "Epoch 2, Iter 131, loss 2.184907913208008, acc 0.18000000715255737\n",
      "Epoch 2, Iter 132, loss 2.1572351455688477, acc 0.25\n",
      "Epoch 2, Iter 133, loss 2.1474881172180176, acc 0.14000000059604645\n",
      "Epoch 2, Iter 134, loss 2.1764910221099854, acc 0.20999999344348907\n",
      "Epoch 2, Iter 135, loss 2.1396732330322266, acc 0.20999999344348907\n",
      "Epoch 2, Iter 136, loss 2.1194818019866943, acc 0.25\n",
      "Epoch 2, Iter 137, loss 2.145272731781006, acc 0.23000000417232513\n",
      "Epoch 2, Iter 138, loss 2.1296818256378174, acc 0.20999999344348907\n",
      "Epoch 2, Iter 139, loss 2.258547067642212, acc 0.1599999964237213\n",
      "Epoch 2, Iter 140, loss 2.2088239192962646, acc 0.2199999988079071\n",
      "Epoch 2, Iter 141, loss 2.181434154510498, acc 0.1899999976158142\n",
      "Epoch 2, Iter 142, loss 2.1606829166412354, acc 0.20000000298023224\n",
      "Epoch 2, Iter 143, loss 2.167189836502075, acc 0.27000001072883606\n",
      "Epoch 2, Iter 144, loss 2.2074575424194336, acc 0.2199999988079071\n",
      "Epoch 2, Iter 145, loss 2.1354403495788574, acc 0.25\n",
      "Epoch 2, Iter 146, loss 2.143843650817871, acc 0.25\n",
      "Epoch 2, Iter 147, loss 2.0989716053009033, acc 0.25\n",
      "Epoch 2, Iter 148, loss 2.1020913124084473, acc 0.28999999165534973\n",
      "Epoch 2, Iter 149, loss 2.1301276683807373, acc 0.28999999165534973\n",
      "Epoch 2, Iter 150, loss 2.177269220352173, acc 0.2800000011920929\n",
      "Epoch 2, Iter 151, loss 2.0763065814971924, acc 0.2800000011920929\n",
      "Epoch 2, Iter 152, loss 2.1599009037017822, acc 0.23999999463558197\n",
      "Epoch 2, Iter 153, loss 2.206012010574341, acc 0.20999999344348907\n",
      "Epoch 2, Iter 154, loss 2.129939079284668, acc 0.25999999046325684\n",
      "Epoch 2, Iter 155, loss 2.1904563903808594, acc 0.23999999463558197\n",
      "Epoch 2, Iter 156, loss 2.0967469215393066, acc 0.27000001072883606\n",
      "Epoch 2, Iter 157, loss 2.1926512718200684, acc 0.20000000298023224\n",
      "Epoch 2, Iter 158, loss 2.1581380367279053, acc 0.20000000298023224\n",
      "Epoch 2, Iter 159, loss 2.170234203338623, acc 0.20999999344348907\n",
      "Epoch 2, Iter 160, loss 2.1252830028533936, acc 0.25\n",
      "Epoch 2, Iter 161, loss 2.1140193939208984, acc 0.27000001072883606\n",
      "Epoch 2, Iter 162, loss 2.0384817123413086, acc 0.33000001311302185\n",
      "Epoch 2, Iter 163, loss 2.1913206577301025, acc 0.2199999988079071\n",
      "Epoch 2, Iter 164, loss 2.133873224258423, acc 0.27000001072883606\n",
      "Epoch 2, Iter 165, loss 2.1559414863586426, acc 0.20000000298023224\n",
      "Epoch 2, Iter 166, loss 2.070427179336548, acc 0.2199999988079071\n",
      "Epoch 2, Iter 167, loss 2.1783390045166016, acc 0.20000000298023224\n",
      "Epoch 2, Iter 168, loss 2.131592035293579, acc 0.2199999988079071\n",
      "Epoch 2, Iter 169, loss 2.059889793395996, acc 0.27000001072883606\n",
      "Epoch 2, Iter 170, loss 2.1621310710906982, acc 0.25\n",
      "Epoch 2, Iter 171, loss 2.1380577087402344, acc 0.20999999344348907\n",
      "Epoch 2, Iter 172, loss 2.1620309352874756, acc 0.2199999988079071\n",
      "Epoch 2, Iter 173, loss 2.1219866275787354, acc 0.23000000417232513\n",
      "Epoch 2, Iter 174, loss 2.075242042541504, acc 0.25999999046325684\n",
      "Epoch 2, Iter 175, loss 2.0849125385284424, acc 0.3100000023841858\n",
      "Epoch 2, Iter 176, loss 2.1612720489501953, acc 0.20000000298023224\n",
      "Epoch 2, Iter 177, loss 2.1780447959899902, acc 0.23000000417232513\n",
      "Epoch 2, Iter 178, loss 2.120603084564209, acc 0.23999999463558197\n",
      "Epoch 2, Iter 179, loss 2.160085916519165, acc 0.25999999046325684\n",
      "Epoch 2, Iter 180, loss 2.2020885944366455, acc 0.2199999988079071\n",
      "Epoch 2, Iter 181, loss 2.093463182449341, acc 0.25\n",
      "Epoch 2, Iter 182, loss 2.0901410579681396, acc 0.25\n",
      "Epoch 2, Iter 183, loss 2.18229341506958, acc 0.20999999344348907\n",
      "Epoch 2, Iter 184, loss 2.114597797393799, acc 0.25999999046325684\n",
      "Epoch 2, Iter 185, loss 2.0734293460845947, acc 0.25999999046325684\n",
      "Epoch 2, Iter 186, loss 2.162762403488159, acc 0.20999999344348907\n",
      "Epoch 2, Iter 187, loss 2.180283546447754, acc 0.27000001072883606\n",
      "Epoch 2, Iter 188, loss 2.1310317516326904, acc 0.2199999988079071\n",
      "Epoch 2, Iter 189, loss 2.2001030445098877, acc 0.17000000178813934\n",
      "Epoch 2, Iter 190, loss 2.1362452507019043, acc 0.20999999344348907\n",
      "Epoch 2, Iter 191, loss 2.2051215171813965, acc 0.25\n",
      "Epoch 2, Iter 192, loss 2.1556642055511475, acc 0.20999999344348907\n",
      "Epoch 2, Iter 193, loss 2.091966152191162, acc 0.27000001072883606\n",
      "Epoch 2, Iter 194, loss 2.1221330165863037, acc 0.25999999046325684\n",
      "Epoch 2, Iter 195, loss 2.1432366371154785, acc 0.23000000417232513\n",
      "Epoch 2, Iter 196, loss 2.1564974784851074, acc 0.20999999344348907\n",
      "Epoch 2, Iter 197, loss 2.1614513397216797, acc 0.20999999344348907\n",
      "Epoch 2, Iter 198, loss 2.0428354740142822, acc 0.28999999165534973\n",
      "Epoch 2, Iter 199, loss 2.2056925296783447, acc 0.2199999988079071\n",
      "Epoch 2, Iter 200, loss 2.158405065536499, acc 0.18000000715255737\n",
      "Epoch 2, Iter 201, loss 2.070957899093628, acc 0.25\n",
      "Epoch 2, Iter 202, loss 2.0856056213378906, acc 0.25999999046325684\n",
      "Epoch 2, Iter 203, loss 2.175011157989502, acc 0.23999999463558197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Iter 204, loss 2.1568644046783447, acc 0.23000000417232513\n",
      "Epoch 2, Iter 205, loss 2.0375967025756836, acc 0.25\n",
      "Epoch 2, Iter 206, loss 2.1434223651885986, acc 0.23999999463558197\n",
      "Epoch 2, Iter 207, loss 2.1673471927642822, acc 0.20999999344348907\n",
      "Epoch 2, Iter 208, loss 2.2245607376098633, acc 0.14000000059604645\n",
      "Epoch 2, Iter 209, loss 2.104931116104126, acc 0.23999999463558197\n",
      "Epoch 2, Iter 210, loss 2.1306235790252686, acc 0.25999999046325684\n",
      "Epoch 2, Iter 211, loss 2.0829520225524902, acc 0.2800000011920929\n",
      "Epoch 2, Iter 212, loss 2.18489933013916, acc 0.18000000715255737\n",
      "Epoch 2, Iter 213, loss 2.172408103942871, acc 0.18000000715255737\n",
      "Epoch 2, Iter 214, loss 2.1611902713775635, acc 0.1599999964237213\n",
      "Epoch 2, Iter 215, loss 2.1258771419525146, acc 0.20999999344348907\n",
      "Epoch 2, Iter 216, loss 2.180821180343628, acc 0.1899999976158142\n",
      "Epoch 2, Iter 217, loss 2.107332229614258, acc 0.2199999988079071\n",
      "Epoch 2, Iter 218, loss 2.1356709003448486, acc 0.23000000417232513\n",
      "Epoch 2, Iter 219, loss 2.213123083114624, acc 0.23999999463558197\n",
      "Epoch 2, Iter 220, loss 2.14979887008667, acc 0.17000000178813934\n",
      "Epoch 2, Iter 221, loss 2.0978667736053467, acc 0.25999999046325684\n",
      "Epoch 2, Iter 222, loss 2.084660530090332, acc 0.23999999463558197\n",
      "Epoch 2, Iter 223, loss 2.068981885910034, acc 0.2800000011920929\n",
      "Epoch 2, Iter 224, loss 2.1389544010162354, acc 0.25\n",
      "Epoch 2, Iter 225, loss 2.0508992671966553, acc 0.30000001192092896\n",
      "Epoch 2, Iter 226, loss 2.0889408588409424, acc 0.28999999165534973\n",
      "Epoch 2, Iter 227, loss 2.135693311691284, acc 0.20000000298023224\n",
      "Epoch 2, Iter 228, loss 2.0967330932617188, acc 0.28999999165534973\n",
      "Epoch 2, Iter 229, loss 2.156236410140991, acc 0.20000000298023224\n",
      "Epoch 2, Iter 230, loss 2.0790200233459473, acc 0.2199999988079071\n",
      "Epoch 2, Iter 231, loss 2.1125707626342773, acc 0.25999999046325684\n",
      "Epoch 2, Iter 232, loss 2.1285812854766846, acc 0.18000000715255737\n",
      "Epoch 2, Iter 233, loss 2.1284170150756836, acc 0.25\n",
      "Epoch 2, Iter 234, loss 2.051438093185425, acc 0.27000001072883606\n",
      "Epoch 2, Iter 235, loss 2.124950408935547, acc 0.23000000417232513\n",
      "Epoch 2, Iter 236, loss 2.1887149810791016, acc 0.1899999976158142\n",
      "Epoch 2, Iter 237, loss 2.1261744499206543, acc 0.23999999463558197\n",
      "Epoch 2, Iter 238, loss 2.120753526687622, acc 0.20999999344348907\n",
      "Epoch 2, Iter 239, loss 2.086228847503662, acc 0.18000000715255737\n",
      "Epoch 2, Iter 240, loss 2.2499399185180664, acc 0.1599999964237213\n",
      "Epoch 2, Iter 241, loss 2.143118143081665, acc 0.23000000417232513\n",
      "Epoch 2, Iter 242, loss 2.206043243408203, acc 0.12999999523162842\n",
      "Epoch 2, Iter 243, loss 2.1292412281036377, acc 0.20999999344348907\n",
      "Epoch 2, Iter 244, loss 2.0741169452667236, acc 0.25999999046325684\n",
      "Epoch 2, Iter 245, loss 2.1479785442352295, acc 0.23000000417232513\n",
      "Epoch 2, Iter 246, loss 2.1696465015411377, acc 0.20999999344348907\n",
      "Epoch 2, Iter 247, loss 2.062504291534424, acc 0.23000000417232513\n",
      "Epoch 2, Iter 248, loss 2.1218581199645996, acc 0.23999999463558197\n",
      "Epoch 2, Iter 249, loss 2.1614999771118164, acc 0.1599999964237213\n",
      "Epoch 2, Iter 250, loss 2.0832204818725586, acc 0.2800000011920929\n",
      "Epoch 2, Iter 251, loss 2.1271860599517822, acc 0.25999999046325684\n",
      "Epoch 2, Iter 252, loss 2.092294692993164, acc 0.27000001072883606\n",
      "Epoch 2, Iter 253, loss 2.178802251815796, acc 0.20000000298023224\n",
      "Epoch 2, Iter 254, loss 2.148024797439575, acc 0.23999999463558197\n",
      "Epoch 2, Iter 255, loss 2.093381881713867, acc 0.25999999046325684\n",
      "Epoch 2, Iter 256, loss 2.1485135555267334, acc 0.2199999988079071\n",
      "Epoch 2, Iter 257, loss 2.0388450622558594, acc 0.3400000035762787\n",
      "Epoch 2, Iter 258, loss 2.153892993927002, acc 0.2800000011920929\n",
      "Epoch 2, Iter 259, loss 2.1732730865478516, acc 0.1899999976158142\n",
      "Epoch 2, Iter 260, loss 2.103451728820801, acc 0.25\n",
      "Epoch 2, Iter 261, loss 2.1254568099975586, acc 0.23000000417232513\n",
      "Epoch 2, Iter 262, loss 2.1927971839904785, acc 0.15000000596046448\n",
      "Epoch 2, Iter 263, loss 2.0888161659240723, acc 0.25\n",
      "Epoch 2, Iter 264, loss 2.114928960800171, acc 0.27000001072883606\n",
      "Epoch 2, Iter 265, loss 2.1513679027557373, acc 0.2199999988079071\n",
      "Epoch 2, Iter 266, loss 2.1951699256896973, acc 0.20000000298023224\n",
      "Epoch 2, Iter 267, loss 2.1557633876800537, acc 0.2199999988079071\n",
      "Epoch 2, Iter 268, loss 2.0761899948120117, acc 0.25999999046325684\n",
      "Epoch 2, Iter 269, loss 2.092836856842041, acc 0.27000001072883606\n",
      "Epoch 2, Iter 270, loss 2.14392352104187, acc 0.25\n",
      "Epoch 2, Iter 271, loss 2.1411097049713135, acc 0.2199999988079071\n",
      "Epoch 2, Iter 272, loss 2.175144910812378, acc 0.1899999976158142\n",
      "Epoch 2, Iter 273, loss 2.09881854057312, acc 0.20000000298023224\n",
      "Epoch 2, Iter 274, loss 2.0754013061523438, acc 0.28999999165534973\n",
      "Epoch 2, Iter 275, loss 2.1571426391601562, acc 0.1899999976158142\n",
      "Epoch 2, Iter 276, loss 2.1108455657958984, acc 0.23000000417232513\n",
      "Epoch 2, Iter 277, loss 2.203472852706909, acc 0.17000000178813934\n",
      "Epoch 2, Iter 278, loss 2.1112313270568848, acc 0.23999999463558197\n",
      "Epoch 2, Iter 279, loss 2.0972933769226074, acc 0.2199999988079071\n",
      "Epoch 2, Iter 280, loss 2.0828847885131836, acc 0.25999999046325684\n",
      "Epoch 2, Iter 281, loss 2.132840633392334, acc 0.20999999344348907\n",
      "Epoch 2, Iter 282, loss 2.095081090927124, acc 0.28999999165534973\n",
      "Epoch 2, Iter 283, loss 2.117847204208374, acc 0.25\n",
      "Epoch 2, Iter 284, loss 2.108985424041748, acc 0.20999999344348907\n",
      "Epoch 2, Iter 285, loss 2.074591636657715, acc 0.2800000011920929\n",
      "Epoch 2, Iter 286, loss 2.062361001968384, acc 0.25999999046325684\n",
      "Epoch 2, Iter 287, loss 2.1344175338745117, acc 0.23000000417232513\n",
      "Epoch 2, Iter 288, loss 2.1515016555786133, acc 0.25\n",
      "Epoch 2, Iter 289, loss 2.156606674194336, acc 0.20999999344348907\n",
      "Epoch 2, Iter 290, loss 2.1253116130828857, acc 0.2199999988079071\n",
      "Epoch 2, Iter 291, loss 2.110055446624756, acc 0.23000000417232513\n",
      "Epoch 2, Iter 292, loss 2.0778040885925293, acc 0.23999999463558197\n",
      "Epoch 2, Iter 293, loss 2.1274170875549316, acc 0.20999999344348907\n",
      "Epoch 2, Iter 294, loss 2.104851007461548, acc 0.27000001072883606\n",
      "Epoch 2, Iter 295, loss 2.0912041664123535, acc 0.23999999463558197\n",
      "Epoch 2, Iter 296, loss 2.1794261932373047, acc 0.20000000298023224\n",
      "Epoch 2, Iter 297, loss 2.098073959350586, acc 0.2800000011920929\n",
      "Epoch 2, Iter 298, loss 2.142242193222046, acc 0.17000000178813934\n",
      "Epoch 2, Iter 299, loss 2.256929397583008, acc 0.10000000149011612\n",
      "Epoch 2, Iter 300, loss 2.1673226356506348, acc 0.20000000298023224\n",
      "Epoch 2, Iter 301, loss 2.134239435195923, acc 0.25999999046325684\n",
      "Epoch 2, Iter 302, loss 2.052957773208618, acc 0.27000001072883606\n",
      "Epoch 2, Iter 303, loss 2.1645288467407227, acc 0.17000000178813934\n",
      "Epoch 2, Iter 304, loss 2.0988543033599854, acc 0.25999999046325684\n",
      "Epoch 2, Iter 305, loss 2.189023017883301, acc 0.20999999344348907\n",
      "Epoch 2, Iter 306, loss 2.144932985305786, acc 0.23999999463558197\n",
      "Epoch 2, Iter 307, loss 2.0589568614959717, acc 0.30000001192092896\n",
      "Epoch 2, Iter 308, loss 2.1378097534179688, acc 0.2199999988079071\n",
      "Epoch 2, Iter 309, loss 2.0928406715393066, acc 0.23999999463558197\n",
      "Epoch 2, Iter 310, loss 2.125577449798584, acc 0.2199999988079071\n",
      "Epoch 2, Iter 311, loss 2.132138729095459, acc 0.2800000011920929\n",
      "Epoch 2, Iter 312, loss 2.109426259994507, acc 0.25999999046325684\n",
      "Epoch 2, Iter 313, loss 2.0963518619537354, acc 0.23999999463558197\n",
      "Epoch 2, Iter 314, loss 2.0358519554138184, acc 0.2800000011920929\n",
      "Epoch 2, Iter 315, loss 2.0936548709869385, acc 0.23999999463558197\n",
      "Epoch 2, Iter 316, loss 2.106095314025879, acc 0.23000000417232513\n",
      "Epoch 2, Iter 317, loss 2.144994020462036, acc 0.23999999463558197\n",
      "Epoch 2, Iter 318, loss 2.0811262130737305, acc 0.27000001072883606\n",
      "Epoch 2, Iter 319, loss 2.1622190475463867, acc 0.2199999988079071\n",
      "Epoch 2, Iter 320, loss 2.0585765838623047, acc 0.25999999046325684\n",
      "Epoch 2, Iter 321, loss 2.0825676918029785, acc 0.23000000417232513\n",
      "Epoch 2, Iter 322, loss 2.141166925430298, acc 0.2199999988079071\n",
      "Epoch 2, Iter 323, loss 2.1108405590057373, acc 0.23000000417232513\n",
      "Epoch 2, Iter 324, loss 2.0884125232696533, acc 0.27000001072883606\n",
      "Epoch 2, Iter 325, loss 2.1067638397216797, acc 0.2199999988079071\n",
      "Epoch 2, Iter 326, loss 2.1082849502563477, acc 0.20000000298023224\n",
      "Epoch 2, Iter 327, loss 2.128251552581787, acc 0.23999999463558197\n",
      "Epoch 2, Iter 328, loss 2.073688507080078, acc 0.25999999046325684\n",
      "Epoch 2, Iter 329, loss 2.0661497116088867, acc 0.2800000011920929\n",
      "Epoch 2, Iter 330, loss 2.0918986797332764, acc 0.20000000298023224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Iter 331, loss 2.1286063194274902, acc 0.2199999988079071\n",
      "Epoch 2, Iter 332, loss 2.0916597843170166, acc 0.2199999988079071\n",
      "Epoch 2, Iter 333, loss 2.057666540145874, acc 0.23999999463558197\n",
      "Epoch 2, Iter 334, loss 2.097505807876587, acc 0.23999999463558197\n",
      "Epoch 2, Iter 335, loss 2.106513500213623, acc 0.27000001072883606\n",
      "Epoch 2, Iter 336, loss 2.1462764739990234, acc 0.23999999463558197\n",
      "Epoch 2, Iter 337, loss 2.152691125869751, acc 0.25\n",
      "Epoch 2, Iter 338, loss 2.1929383277893066, acc 0.17000000178813934\n",
      "Epoch 2, Iter 339, loss 2.103379011154175, acc 0.23999999463558197\n",
      "Epoch 2, Iter 340, loss 2.212196111679077, acc 0.15000000596046448\n",
      "Epoch 2, Iter 341, loss 2.0289182662963867, acc 0.25\n",
      "Epoch 2, Iter 342, loss 2.15413761138916, acc 0.2199999988079071\n",
      "Epoch 2, Iter 343, loss 2.1399805545806885, acc 0.23000000417232513\n",
      "Epoch 2, Iter 344, loss 2.0412757396698, acc 0.27000001072883606\n",
      "Epoch 2, Iter 345, loss 2.110443592071533, acc 0.25999999046325684\n",
      "Epoch 2, Iter 346, loss 2.083763360977173, acc 0.28999999165534973\n",
      "Epoch 2, Iter 347, loss 2.1530187129974365, acc 0.25999999046325684\n",
      "Epoch 2, Iter 348, loss 2.0319464206695557, acc 0.30000001192092896\n",
      "Epoch 2, Iter 349, loss 2.0934340953826904, acc 0.23999999463558197\n",
      "Epoch 2, Iter 350, loss 2.061328649520874, acc 0.23000000417232513\n",
      "Epoch 2, Iter 351, loss 2.1787149906158447, acc 0.2199999988079071\n",
      "Epoch 2, Iter 352, loss 2.090986490249634, acc 0.25999999046325684\n",
      "Epoch 2, Iter 353, loss 2.1499600410461426, acc 0.14000000059604645\n",
      "Epoch 2, Iter 354, loss 2.09373140335083, acc 0.23000000417232513\n",
      "Epoch 2, Iter 355, loss 2.1675069332122803, acc 0.18000000715255737\n",
      "Epoch 2, Iter 356, loss 2.0849459171295166, acc 0.23999999463558197\n",
      "Epoch 2, Iter 357, loss 2.105764627456665, acc 0.2199999988079071\n",
      "Epoch 2, Iter 358, loss 2.167670965194702, acc 0.20999999344348907\n",
      "Epoch 2, Iter 359, loss 2.153968334197998, acc 0.17000000178813934\n",
      "Epoch 2, Iter 360, loss 2.0616860389709473, acc 0.23999999463558197\n",
      "Epoch 2, Iter 361, loss 2.0881259441375732, acc 0.25\n",
      "Epoch 2, Iter 362, loss 2.203343152999878, acc 0.17000000178813934\n",
      "Epoch 2, Iter 363, loss 2.093966484069824, acc 0.25\n",
      "Epoch 2, Iter 364, loss 2.1600818634033203, acc 0.15000000596046448\n",
      "Epoch 2, Iter 365, loss 2.1480724811553955, acc 0.1899999976158142\n",
      "Epoch 2, Iter 366, loss 2.043464422225952, acc 0.33000001311302185\n",
      "Epoch 2, Iter 367, loss 2.0782175064086914, acc 0.25999999046325684\n",
      "Epoch 2, Iter 368, loss 2.127877950668335, acc 0.20999999344348907\n",
      "Epoch 2, Iter 369, loss 2.1229536533355713, acc 0.23000000417232513\n",
      "Epoch 2, Iter 370, loss 2.1192643642425537, acc 0.25\n",
      "Epoch 2, Iter 371, loss 2.1172869205474854, acc 0.23999999463558197\n",
      "Epoch 2, Iter 372, loss 2.0918781757354736, acc 0.27000001072883606\n",
      "Epoch 2, Iter 373, loss 2.0500409603118896, acc 0.23999999463558197\n",
      "Epoch 2, Iter 374, loss 2.0932765007019043, acc 0.25\n",
      "Epoch 2, Iter 375, loss 2.1143038272857666, acc 0.23999999463558197\n",
      "Epoch 2, Iter 376, loss 2.1112821102142334, acc 0.2800000011920929\n",
      "Epoch 2, Iter 377, loss 2.072206974029541, acc 0.25\n",
      "Epoch 2, Iter 378, loss 2.051669120788574, acc 0.2800000011920929\n",
      "Epoch 2, Iter 379, loss 2.0754661560058594, acc 0.25\n",
      "Epoch 2, Iter 380, loss 2.1015233993530273, acc 0.2800000011920929\n",
      "Epoch 2, Iter 381, loss 2.1222689151763916, acc 0.18000000715255737\n",
      "Epoch 2, Iter 382, loss 2.052757501602173, acc 0.3100000023841858\n",
      "Epoch 2, Iter 383, loss 2.071563959121704, acc 0.25\n",
      "Epoch 2, Iter 384, loss 2.0927045345306396, acc 0.1899999976158142\n",
      "Epoch 2, Iter 385, loss 2.0119388103485107, acc 0.25999999046325684\n",
      "Epoch 2, Iter 386, loss 2.0703208446502686, acc 0.33000001311302185\n",
      "Epoch 2, Iter 387, loss 2.1318557262420654, acc 0.25999999046325684\n",
      "Epoch 2, Iter 388, loss 2.2110767364501953, acc 0.20999999344348907\n",
      "Epoch 2, Iter 389, loss 2.1273014545440674, acc 0.23999999463558197\n",
      "Epoch 2, Iter 390, loss 2.1504175662994385, acc 0.25\n",
      "Epoch 2, Iter 391, loss 2.0556259155273438, acc 0.2800000011920929\n",
      "Epoch 2, Iter 392, loss 2.087125062942505, acc 0.2199999988079071\n",
      "Epoch 2, Iter 393, loss 2.153515577316284, acc 0.20000000298023224\n",
      "Epoch 2, Iter 394, loss 2.0639402866363525, acc 0.3100000023841858\n",
      "Epoch 2, Iter 395, loss 2.0807416439056396, acc 0.27000001072883606\n",
      "Epoch 2, Iter 396, loss 2.1335983276367188, acc 0.1899999976158142\n",
      "Epoch 2, Iter 397, loss 2.001837968826294, acc 0.20999999344348907\n",
      "Epoch 2, Iter 398, loss 2.1134772300720215, acc 0.2199999988079071\n",
      "Epoch 2, Iter 399, loss 2.099034547805786, acc 0.23999999463558197\n",
      "Epoch 2, Iter 400, loss 2.071009635925293, acc 0.23999999463558197\n",
      "Epoch 2, Iter 401, loss 2.073566198348999, acc 0.25\n",
      "Epoch 2, Iter 402, loss 2.0678741931915283, acc 0.23999999463558197\n",
      "Epoch 2, Iter 403, loss 2.115896224975586, acc 0.25\n",
      "Epoch 2, Iter 404, loss 2.138446807861328, acc 0.25\n",
      "Epoch 2, Iter 405, loss 2.124777317047119, acc 0.1899999976158142\n",
      "Epoch 2, Iter 406, loss 2.262026309967041, acc 0.11999999731779099\n",
      "Epoch 2, Iter 407, loss 2.1488802433013916, acc 0.18000000715255737\n",
      "Epoch 2, Iter 408, loss 2.128352403640747, acc 0.25\n",
      "Epoch 2, Iter 409, loss 2.0730152130126953, acc 0.27000001072883606\n",
      "Epoch 2, Iter 410, loss 1.9884765148162842, acc 0.3799999952316284\n",
      "Epoch 2, Iter 411, loss 2.0387840270996094, acc 0.25\n",
      "Epoch 2, Iter 412, loss 2.0397651195526123, acc 0.27000001072883606\n",
      "Epoch 2, Iter 413, loss 2.090442419052124, acc 0.2199999988079071\n",
      "Epoch 2, Iter 414, loss 2.139129877090454, acc 0.1899999976158142\n",
      "Epoch 2, Iter 415, loss 2.051750659942627, acc 0.30000001192092896\n",
      "Epoch 2, Iter 416, loss 2.0406367778778076, acc 0.30000001192092896\n",
      "Epoch 2, Iter 417, loss 2.0222465991973877, acc 0.23999999463558197\n",
      "Epoch 2, Iter 418, loss 2.0537149906158447, acc 0.2800000011920929\n",
      "Epoch 2, Iter 419, loss 2.0157265663146973, acc 0.33000001311302185\n",
      "Epoch 2, Iter 420, loss 2.0589959621429443, acc 0.28999999165534973\n",
      "Epoch 3, Iter 1, loss 2.017399311065674, acc 0.30000001192092896\n",
      "Epoch 3, Iter 2, loss 2.0458009243011475, acc 0.2800000011920929\n",
      "Epoch 3, Iter 3, loss 2.0830342769622803, acc 0.25999999046325684\n",
      "Epoch 3, Iter 4, loss 2.192612409591675, acc 0.1899999976158142\n",
      "Epoch 3, Iter 5, loss 2.0535597801208496, acc 0.28999999165534973\n",
      "Epoch 3, Iter 6, loss 2.080256223678589, acc 0.25999999046325684\n",
      "Epoch 3, Iter 7, loss 2.1410820484161377, acc 0.2199999988079071\n",
      "Epoch 3, Iter 8, loss 2.01669979095459, acc 0.30000001192092896\n",
      "Epoch 3, Iter 9, loss 2.116689682006836, acc 0.20999999344348907\n",
      "Epoch 3, Iter 10, loss 2.159536123275757, acc 0.15000000596046448\n",
      "Epoch 3, Iter 11, loss 2.0477294921875, acc 0.27000001072883606\n",
      "Epoch 3, Iter 12, loss 2.1047120094299316, acc 0.2800000011920929\n",
      "Epoch 3, Iter 13, loss 2.1253550052642822, acc 0.20000000298023224\n",
      "Epoch 3, Iter 14, loss 2.0708069801330566, acc 0.2199999988079071\n",
      "Epoch 3, Iter 15, loss 2.060990333557129, acc 0.3100000023841858\n",
      "Epoch 3, Iter 16, loss 2.049556016921997, acc 0.20999999344348907\n",
      "Epoch 3, Iter 17, loss 2.089679479598999, acc 0.25\n",
      "Epoch 3, Iter 18, loss 2.047743320465088, acc 0.23999999463558197\n",
      "Epoch 3, Iter 19, loss 2.0729622840881348, acc 0.25999999046325684\n",
      "Epoch 3, Iter 20, loss 2.0841357707977295, acc 0.23999999463558197\n",
      "Epoch 3, Iter 21, loss 2.014084577560425, acc 0.33000001311302185\n",
      "Epoch 3, Iter 22, loss 2.0594265460968018, acc 0.20999999344348907\n",
      "Epoch 3, Iter 23, loss 2.0153627395629883, acc 0.3100000023841858\n",
      "Epoch 3, Iter 24, loss 2.100137948989868, acc 0.25999999046325684\n",
      "Epoch 3, Iter 25, loss 2.1461756229400635, acc 0.20000000298023224\n",
      "Epoch 3, Iter 26, loss 2.082360029220581, acc 0.23999999463558197\n",
      "Epoch 3, Iter 27, loss 1.9940887689590454, acc 0.27000001072883606\n",
      "Epoch 3, Iter 28, loss 2.0494277477264404, acc 0.23000000417232513\n",
      "Epoch 3, Iter 29, loss 2.0756750106811523, acc 0.27000001072883606\n",
      "Epoch 3, Iter 30, loss 2.142641544342041, acc 0.20000000298023224\n",
      "Epoch 3, Iter 31, loss 2.0858986377716064, acc 0.20000000298023224\n",
      "Epoch 3, Iter 32, loss 2.008652448654175, acc 0.30000001192092896\n",
      "Epoch 3, Iter 33, loss 2.062635898590088, acc 0.2199999988079071\n",
      "Epoch 3, Iter 34, loss 2.0533125400543213, acc 0.30000001192092896\n",
      "Epoch 3, Iter 35, loss 1.9852832555770874, acc 0.3400000035762787\n",
      "Epoch 3, Iter 36, loss 2.0549826622009277, acc 0.2800000011920929\n",
      "Epoch 3, Iter 37, loss 2.065732002258301, acc 0.2199999988079071\n",
      "Epoch 3, Iter 38, loss 2.086324453353882, acc 0.25\n",
      "Epoch 3, Iter 39, loss 2.03073787689209, acc 0.25\n",
      "Epoch 3, Iter 40, loss 2.007619857788086, acc 0.3400000035762787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Iter 41, loss 2.1238977909088135, acc 0.20999999344348907\n",
      "Epoch 3, Iter 42, loss 2.048126220703125, acc 0.25\n",
      "Epoch 3, Iter 43, loss 2.0341925621032715, acc 0.30000001192092896\n",
      "Epoch 3, Iter 44, loss 2.0531537532806396, acc 0.2800000011920929\n",
      "Epoch 3, Iter 45, loss 2.0518665313720703, acc 0.28999999165534973\n",
      "Epoch 3, Iter 46, loss 1.9871793985366821, acc 0.28999999165534973\n",
      "Epoch 3, Iter 47, loss 2.1615076065063477, acc 0.2199999988079071\n",
      "Epoch 3, Iter 48, loss 2.0897672176361084, acc 0.2199999988079071\n",
      "Epoch 3, Iter 49, loss 2.0594358444213867, acc 0.28999999165534973\n",
      "Epoch 3, Iter 50, loss 1.9866278171539307, acc 0.30000001192092896\n",
      "Epoch 3, Iter 51, loss 2.0314459800720215, acc 0.27000001072883606\n",
      "Epoch 3, Iter 52, loss 2.0347862243652344, acc 0.25\n",
      "Epoch 3, Iter 53, loss 2.0853590965270996, acc 0.23000000417232513\n",
      "Epoch 3, Iter 54, loss 2.1266679763793945, acc 0.2199999988079071\n",
      "Epoch 3, Iter 55, loss 2.100121259689331, acc 0.27000001072883606\n",
      "Epoch 3, Iter 56, loss 2.1752922534942627, acc 0.15000000596046448\n",
      "Epoch 3, Iter 57, loss 2.116162061691284, acc 0.25\n",
      "Epoch 3, Iter 58, loss 2.097846746444702, acc 0.1899999976158142\n",
      "Epoch 3, Iter 59, loss 2.057562828063965, acc 0.25\n",
      "Epoch 3, Iter 60, loss 2.0531725883483887, acc 0.2199999988079071\n",
      "Epoch 3, Iter 61, loss 2.1157114505767822, acc 0.23999999463558197\n",
      "Epoch 3, Iter 62, loss 2.1036157608032227, acc 0.20999999344348907\n",
      "Epoch 3, Iter 63, loss 2.0802388191223145, acc 0.23999999463558197\n",
      "Epoch 3, Iter 64, loss 2.0492031574249268, acc 0.30000001192092896\n",
      "Epoch 3, Iter 65, loss 2.090529680252075, acc 0.23999999463558197\n",
      "Epoch 3, Iter 66, loss 2.1812496185302734, acc 0.20000000298023224\n",
      "Epoch 3, Iter 67, loss 2.0989179611206055, acc 0.20000000298023224\n",
      "Epoch 3, Iter 68, loss 1.9553472995758057, acc 0.3400000035762787\n",
      "Epoch 3, Iter 69, loss 2.0546488761901855, acc 0.28999999165534973\n",
      "Epoch 3, Iter 70, loss 2.0747013092041016, acc 0.28999999165534973\n",
      "Epoch 3, Iter 71, loss 2.0970048904418945, acc 0.1899999976158142\n",
      "Epoch 3, Iter 72, loss 2.144176959991455, acc 0.25\n",
      "Epoch 3, Iter 73, loss 1.94929838180542, acc 0.3700000047683716\n",
      "Epoch 3, Iter 74, loss 2.0589427947998047, acc 0.3100000023841858\n",
      "Epoch 3, Iter 75, loss 2.026808977127075, acc 0.27000001072883606\n",
      "Epoch 3, Iter 76, loss 1.9875237941741943, acc 0.3700000047683716\n",
      "Epoch 3, Iter 77, loss 2.150804042816162, acc 0.1899999976158142\n",
      "Epoch 3, Iter 78, loss 2.032498836517334, acc 0.3199999928474426\n",
      "Epoch 3, Iter 79, loss 2.003568649291992, acc 0.30000001192092896\n",
      "Epoch 3, Iter 80, loss 2.004451036453247, acc 0.33000001311302185\n",
      "Epoch 3, Iter 81, loss 2.1204559803009033, acc 0.1899999976158142\n",
      "Epoch 3, Iter 82, loss 2.0974278450012207, acc 0.25\n",
      "Epoch 3, Iter 83, loss 2.0415821075439453, acc 0.30000001192092896\n",
      "Epoch 3, Iter 84, loss 2.132373809814453, acc 0.23000000417232513\n",
      "Epoch 3, Iter 85, loss 2.0828657150268555, acc 0.25\n",
      "Epoch 3, Iter 86, loss 2.012871742248535, acc 0.27000001072883606\n",
      "Epoch 3, Iter 87, loss 2.023239850997925, acc 0.30000001192092896\n",
      "Epoch 3, Iter 88, loss 2.021456480026245, acc 0.30000001192092896\n",
      "Epoch 3, Iter 89, loss 2.058427572250366, acc 0.25999999046325684\n",
      "Epoch 3, Iter 90, loss 2.096627712249756, acc 0.27000001072883606\n",
      "Epoch 3, Iter 91, loss 1.9909579753875732, acc 0.30000001192092896\n",
      "Epoch 3, Iter 92, loss 2.0779988765716553, acc 0.23999999463558197\n",
      "Epoch 3, Iter 93, loss 1.9716051816940308, acc 0.3100000023841858\n",
      "Epoch 3, Iter 94, loss 2.0930309295654297, acc 0.2199999988079071\n",
      "Epoch 3, Iter 95, loss 1.9746217727661133, acc 0.28999999165534973\n",
      "Epoch 3, Iter 96, loss 2.0402915477752686, acc 0.23000000417232513\n",
      "Epoch 3, Iter 97, loss 2.0058469772338867, acc 0.2800000011920929\n",
      "Epoch 3, Iter 98, loss 2.066115379333496, acc 0.23000000417232513\n",
      "Epoch 3, Iter 99, loss 2.0590505599975586, acc 0.23000000417232513\n",
      "Epoch 3, Iter 100, loss 2.1273276805877686, acc 0.23999999463558197\n",
      "Epoch 3, Iter 101, loss 1.9873740673065186, acc 0.3499999940395355\n",
      "Epoch 3, Iter 102, loss 2.107630729675293, acc 0.23999999463558197\n",
      "Epoch 3, Iter 103, loss 1.9695918560028076, acc 0.3199999928474426\n",
      "Epoch 3, Iter 104, loss 2.0914394855499268, acc 0.2199999988079071\n",
      "Epoch 3, Iter 105, loss 2.017703056335449, acc 0.3499999940395355\n",
      "Epoch 3, Iter 106, loss 2.1473965644836426, acc 0.23000000417232513\n",
      "Epoch 3, Iter 107, loss 2.062041759490967, acc 0.23999999463558197\n",
      "Epoch 3, Iter 108, loss 2.0153419971466064, acc 0.33000001311302185\n",
      "Epoch 3, Iter 109, loss 2.0254151821136475, acc 0.2800000011920929\n",
      "Epoch 3, Iter 110, loss 1.9861466884613037, acc 0.3400000035762787\n",
      "Epoch 3, Iter 111, loss 2.0899229049682617, acc 0.25999999046325684\n",
      "Epoch 3, Iter 112, loss 2.107588768005371, acc 0.25999999046325684\n",
      "Epoch 3, Iter 113, loss 1.92644464969635, acc 0.3799999952316284\n",
      "Epoch 3, Iter 114, loss 2.1275036334991455, acc 0.23999999463558197\n",
      "Epoch 3, Iter 115, loss 1.9900397062301636, acc 0.3100000023841858\n",
      "Epoch 3, Iter 116, loss 1.9728811979293823, acc 0.3700000047683716\n",
      "Epoch 3, Iter 117, loss 2.051130533218384, acc 0.25\n",
      "Epoch 3, Iter 118, loss 1.9572137594223022, acc 0.28999999165534973\n",
      "Epoch 3, Iter 119, loss 2.055961847305298, acc 0.27000001072883606\n",
      "Epoch 3, Iter 120, loss 2.0665900707244873, acc 0.23000000417232513\n",
      "Epoch 3, Iter 121, loss 2.0490119457244873, acc 0.25999999046325684\n",
      "Epoch 3, Iter 122, loss 2.099100351333618, acc 0.23999999463558197\n",
      "Epoch 3, Iter 123, loss 2.115013837814331, acc 0.25\n",
      "Epoch 3, Iter 124, loss 1.9653494358062744, acc 0.33000001311302185\n",
      "Epoch 3, Iter 125, loss 2.023979902267456, acc 0.3499999940395355\n",
      "Epoch 3, Iter 126, loss 2.029099464416504, acc 0.30000001192092896\n",
      "Epoch 3, Iter 127, loss 2.09902024269104, acc 0.28999999165534973\n",
      "Epoch 3, Iter 128, loss 2.1161904335021973, acc 0.2800000011920929\n",
      "Epoch 3, Iter 129, loss 2.1059248447418213, acc 0.20999999344348907\n",
      "Epoch 3, Iter 130, loss 2.041426181793213, acc 0.2800000011920929\n",
      "Epoch 3, Iter 131, loss 2.071087598800659, acc 0.23999999463558197\n",
      "Epoch 3, Iter 132, loss 2.0554332733154297, acc 0.25999999046325684\n",
      "Epoch 3, Iter 133, loss 2.1199018955230713, acc 0.18000000715255737\n",
      "Epoch 3, Iter 134, loss 2.0391979217529297, acc 0.28999999165534973\n",
      "Epoch 3, Iter 135, loss 2.0714192390441895, acc 0.28999999165534973\n",
      "Epoch 3, Iter 136, loss 1.9772454500198364, acc 0.33000001311302185\n",
      "Epoch 3, Iter 137, loss 2.029217481613159, acc 0.2800000011920929\n",
      "Epoch 3, Iter 138, loss 2.0003271102905273, acc 0.28999999165534973\n",
      "Epoch 3, Iter 139, loss 2.086230754852295, acc 0.2199999988079071\n",
      "Epoch 3, Iter 140, loss 2.047562837600708, acc 0.28999999165534973\n",
      "Epoch 3, Iter 141, loss 2.120002031326294, acc 0.1899999976158142\n",
      "Epoch 3, Iter 142, loss 2.0330283641815186, acc 0.25\n",
      "Epoch 3, Iter 143, loss 2.084777355194092, acc 0.30000001192092896\n",
      "Epoch 3, Iter 144, loss 2.0440728664398193, acc 0.2800000011920929\n",
      "Epoch 3, Iter 145, loss 1.9874653816223145, acc 0.3199999928474426\n",
      "Epoch 3, Iter 146, loss 2.034442186355591, acc 0.3199999928474426\n",
      "Epoch 3, Iter 147, loss 2.005986452102661, acc 0.30000001192092896\n",
      "Epoch 3, Iter 148, loss 1.9374979734420776, acc 0.3499999940395355\n",
      "Epoch 3, Iter 149, loss 1.989944577217102, acc 0.28999999165534973\n",
      "Epoch 3, Iter 150, loss 2.0068349838256836, acc 0.3199999928474426\n",
      "Epoch 3, Iter 151, loss 1.924659252166748, acc 0.3400000035762787\n",
      "Epoch 3, Iter 152, loss 1.9928183555603027, acc 0.30000001192092896\n",
      "Epoch 3, Iter 153, loss 2.032071828842163, acc 0.30000001192092896\n",
      "Epoch 3, Iter 154, loss 1.991816520690918, acc 0.3400000035762787\n",
      "Epoch 3, Iter 155, loss 2.096217393875122, acc 0.23000000417232513\n",
      "Epoch 3, Iter 156, loss 1.9183354377746582, acc 0.3199999928474426\n",
      "Epoch 3, Iter 157, loss 2.143235921859741, acc 0.23000000417232513\n",
      "Epoch 3, Iter 158, loss 2.0565197467803955, acc 0.28999999165534973\n",
      "Epoch 3, Iter 159, loss 2.063328266143799, acc 0.2800000011920929\n",
      "Epoch 3, Iter 160, loss 1.995153784751892, acc 0.3100000023841858\n",
      "Epoch 3, Iter 161, loss 2.054608106613159, acc 0.28999999165534973\n",
      "Epoch 3, Iter 162, loss 1.955348253250122, acc 0.3499999940395355\n",
      "Epoch 3, Iter 163, loss 2.043325901031494, acc 0.25\n",
      "Epoch 3, Iter 164, loss 1.9561564922332764, acc 0.3100000023841858\n",
      "Epoch 3, Iter 165, loss 2.0376334190368652, acc 0.23000000417232513\n",
      "Epoch 3, Iter 166, loss 1.9756191968917847, acc 0.2800000011920929\n",
      "Epoch 3, Iter 167, loss 2.0898027420043945, acc 0.27000001072883606\n",
      "Epoch 3, Iter 168, loss 2.0039639472961426, acc 0.25\n",
      "Epoch 3, Iter 169, loss 1.8906649351119995, acc 0.33000001311302185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Iter 170, loss 1.9974933862686157, acc 0.3400000035762787\n",
      "Epoch 3, Iter 171, loss 1.9840404987335205, acc 0.3100000023841858\n",
      "Epoch 3, Iter 172, loss 2.06077241897583, acc 0.23999999463558197\n",
      "Epoch 3, Iter 173, loss 2.0007126331329346, acc 0.27000001072883606\n",
      "Epoch 3, Iter 174, loss 1.9660859107971191, acc 0.3199999928474426\n",
      "Epoch 3, Iter 175, loss 1.938515067100525, acc 0.3199999928474426\n",
      "Epoch 3, Iter 176, loss 2.090269088745117, acc 0.25\n",
      "Epoch 3, Iter 177, loss 2.0820343494415283, acc 0.23999999463558197\n",
      "Epoch 3, Iter 178, loss 1.9841253757476807, acc 0.3100000023841858\n",
      "Epoch 3, Iter 179, loss 2.0423200130462646, acc 0.27000001072883606\n",
      "Epoch 3, Iter 180, loss 2.1190974712371826, acc 0.23000000417232513\n",
      "Epoch 3, Iter 181, loss 1.9321849346160889, acc 0.33000001311302185\n",
      "Epoch 3, Iter 182, loss 1.963266134262085, acc 0.3100000023841858\n",
      "Epoch 3, Iter 183, loss 2.0145974159240723, acc 0.3100000023841858\n",
      "Epoch 3, Iter 184, loss 1.9963603019714355, acc 0.3700000047683716\n",
      "Epoch 3, Iter 185, loss 1.9603142738342285, acc 0.33000001311302185\n",
      "Epoch 3, Iter 186, loss 2.0746729373931885, acc 0.2800000011920929\n",
      "Epoch 3, Iter 187, loss 2.0504584312438965, acc 0.3199999928474426\n",
      "Epoch 3, Iter 188, loss 2.067387342453003, acc 0.25\n",
      "Epoch 3, Iter 189, loss 2.1114208698272705, acc 0.20999999344348907\n",
      "Epoch 3, Iter 190, loss 2.0433874130249023, acc 0.28999999165534973\n",
      "Epoch 3, Iter 191, loss 2.0519092082977295, acc 0.3100000023841858\n",
      "Epoch 3, Iter 192, loss 1.9483507871627808, acc 0.3400000035762787\n",
      "Epoch 3, Iter 193, loss 2.014904260635376, acc 0.28999999165534973\n",
      "Epoch 3, Iter 194, loss 1.9803754091262817, acc 0.30000001192092896\n",
      "Epoch 3, Iter 195, loss 1.9628201723098755, acc 0.33000001311302185\n",
      "Epoch 3, Iter 196, loss 2.036761522293091, acc 0.25\n",
      "Epoch 3, Iter 197, loss 2.0003440380096436, acc 0.28999999165534973\n",
      "Epoch 3, Iter 198, loss 1.9367414712905884, acc 0.30000001192092896\n",
      "Epoch 3, Iter 199, loss 2.0284290313720703, acc 0.25999999046325684\n",
      "Epoch 3, Iter 200, loss 2.0888192653656006, acc 0.25\n",
      "Epoch 3, Iter 201, loss 1.9258440732955933, acc 0.38999998569488525\n",
      "Epoch 3, Iter 202, loss 1.9699146747589111, acc 0.38999998569488525\n",
      "Epoch 3, Iter 203, loss 2.0253612995147705, acc 0.2800000011920929\n",
      "Epoch 3, Iter 204, loss 1.9675915241241455, acc 0.2800000011920929\n",
      "Epoch 3, Iter 205, loss 1.9159023761749268, acc 0.3499999940395355\n",
      "Epoch 3, Iter 206, loss 2.008749008178711, acc 0.30000001192092896\n",
      "Epoch 3, Iter 207, loss 2.024827480316162, acc 0.3100000023841858\n",
      "Epoch 3, Iter 208, loss 2.0108628273010254, acc 0.25999999046325684\n",
      "Epoch 3, Iter 209, loss 2.078765630722046, acc 0.23000000417232513\n",
      "Epoch 3, Iter 210, loss 1.9972620010375977, acc 0.27000001072883606\n",
      "Epoch 3, Iter 211, loss 1.9374451637268066, acc 0.33000001311302185\n",
      "Epoch 3, Iter 212, loss 2.098104476928711, acc 0.23000000417232513\n",
      "Epoch 3, Iter 213, loss 2.041973352432251, acc 0.23000000417232513\n",
      "Epoch 3, Iter 214, loss 2.031740665435791, acc 0.2199999988079071\n",
      "Epoch 3, Iter 215, loss 2.0000290870666504, acc 0.27000001072883606\n",
      "Epoch 3, Iter 216, loss 2.129974603652954, acc 0.23000000417232513\n",
      "Epoch 3, Iter 217, loss 1.975683569908142, acc 0.28999999165534973\n",
      "Epoch 3, Iter 218, loss 2.0250444412231445, acc 0.25999999046325684\n",
      "Epoch 3, Iter 219, loss 2.0732173919677734, acc 0.25\n",
      "Epoch 3, Iter 220, loss 1.897803544998169, acc 0.27000001072883606\n",
      "Epoch 3, Iter 221, loss 1.9856016635894775, acc 0.30000001192092896\n",
      "Epoch 3, Iter 222, loss 1.9563887119293213, acc 0.23999999463558197\n",
      "Epoch 3, Iter 223, loss 1.8974876403808594, acc 0.3400000035762787\n",
      "Epoch 3, Iter 224, loss 1.9941788911819458, acc 0.30000001192092896\n",
      "Epoch 3, Iter 225, loss 1.928978681564331, acc 0.33000001311302185\n",
      "Epoch 3, Iter 226, loss 1.973912239074707, acc 0.33000001311302185\n",
      "Epoch 3, Iter 227, loss 1.9765795469284058, acc 0.27000001072883606\n",
      "Epoch 3, Iter 228, loss 1.9341658353805542, acc 0.3400000035762787\n",
      "Epoch 3, Iter 229, loss 2.055418014526367, acc 0.2199999988079071\n",
      "Epoch 3, Iter 230, loss 1.9591827392578125, acc 0.25\n",
      "Epoch 3, Iter 231, loss 2.041699171066284, acc 0.25\n",
      "Epoch 3, Iter 232, loss 2.0097146034240723, acc 0.23000000417232513\n",
      "Epoch 3, Iter 233, loss 1.965386986732483, acc 0.3400000035762787\n",
      "Epoch 3, Iter 234, loss 1.9145786762237549, acc 0.33000001311302185\n",
      "Epoch 3, Iter 235, loss 2.0650360584259033, acc 0.25999999046325684\n",
      "Epoch 3, Iter 236, loss 2.088688611984253, acc 0.25\n",
      "Epoch 3, Iter 237, loss 2.072056770324707, acc 0.27000001072883606\n",
      "Epoch 3, Iter 238, loss 2.011314868927002, acc 0.3199999928474426\n",
      "Epoch 3, Iter 239, loss 1.9621405601501465, acc 0.36000001430511475\n",
      "Epoch 3, Iter 240, loss 2.1078040599823, acc 0.23000000417232513\n",
      "Epoch 3, Iter 241, loss 2.0091304779052734, acc 0.2800000011920929\n",
      "Epoch 3, Iter 242, loss 2.0507943630218506, acc 0.23999999463558197\n",
      "Epoch 3, Iter 243, loss 2.014953851699829, acc 0.3199999928474426\n",
      "Epoch 3, Iter 244, loss 1.9905874729156494, acc 0.30000001192092896\n",
      "Epoch 3, Iter 245, loss 1.9965580701828003, acc 0.28999999165534973\n",
      "Epoch 3, Iter 246, loss 2.040008783340454, acc 0.28999999165534973\n",
      "Epoch 3, Iter 247, loss 1.9685755968093872, acc 0.30000001192092896\n",
      "Epoch 3, Iter 248, loss 1.992266058921814, acc 0.30000001192092896\n",
      "Epoch 3, Iter 249, loss 2.021428108215332, acc 0.30000001192092896\n",
      "Epoch 3, Iter 250, loss 1.9880610704421997, acc 0.30000001192092896\n",
      "Epoch 3, Iter 251, loss 2.0124711990356445, acc 0.3100000023841858\n",
      "Epoch 3, Iter 252, loss 1.9554377794265747, acc 0.33000001311302185\n",
      "Epoch 3, Iter 253, loss 2.03005051612854, acc 0.3400000035762787\n",
      "Epoch 3, Iter 254, loss 1.9810400009155273, acc 0.33000001311302185\n",
      "Epoch 3, Iter 255, loss 2.0312700271606445, acc 0.3100000023841858\n",
      "Epoch 3, Iter 256, loss 2.01676607131958, acc 0.30000001192092896\n",
      "Epoch 3, Iter 257, loss 1.9940998554229736, acc 0.3499999940395355\n",
      "Epoch 3, Iter 258, loss 2.100879430770874, acc 0.27000001072883606\n",
      "Epoch 3, Iter 259, loss 2.1152663230895996, acc 0.23000000417232513\n",
      "Epoch 3, Iter 260, loss 2.0224344730377197, acc 0.3100000023841858\n",
      "Epoch 3, Iter 261, loss 2.0528621673583984, acc 0.2199999988079071\n",
      "Epoch 3, Iter 262, loss 2.1195790767669678, acc 0.20000000298023224\n",
      "Epoch 3, Iter 263, loss 2.0106420516967773, acc 0.28999999165534973\n",
      "Epoch 3, Iter 264, loss 2.0009586811065674, acc 0.30000001192092896\n",
      "Epoch 3, Iter 265, loss 2.105489730834961, acc 0.2199999988079071\n",
      "Epoch 3, Iter 266, loss 2.0298354625701904, acc 0.2800000011920929\n",
      "Epoch 3, Iter 267, loss 2.0663440227508545, acc 0.23999999463558197\n",
      "Epoch 3, Iter 268, loss 1.9748600721359253, acc 0.3199999928474426\n",
      "Epoch 3, Iter 269, loss 1.9587191343307495, acc 0.30000001192092896\n",
      "Epoch 3, Iter 270, loss 2.07116961479187, acc 0.28999999165534973\n",
      "Epoch 3, Iter 271, loss 2.129025459289551, acc 0.23999999463558197\n",
      "Epoch 3, Iter 272, loss 2.0642664432525635, acc 0.2800000011920929\n",
      "Epoch 3, Iter 273, loss 2.021510601043701, acc 0.25\n",
      "Epoch 3, Iter 274, loss 2.0166444778442383, acc 0.30000001192092896\n",
      "Epoch 3, Iter 275, loss 2.0952374935150146, acc 0.23000000417232513\n",
      "Epoch 3, Iter 276, loss 2.018306016921997, acc 0.30000001192092896\n",
      "Epoch 3, Iter 277, loss 2.162125825881958, acc 0.1899999976158142\n",
      "Epoch 3, Iter 278, loss 1.9355255365371704, acc 0.3199999928474426\n",
      "Epoch 3, Iter 279, loss 2.0144896507263184, acc 0.23999999463558197\n",
      "Epoch 3, Iter 280, loss 1.969495415687561, acc 0.3700000047683716\n",
      "Epoch 3, Iter 281, loss 2.0742347240448, acc 0.2199999988079071\n",
      "Epoch 3, Iter 282, loss 2.0104143619537354, acc 0.30000001192092896\n",
      "Epoch 3, Iter 283, loss 2.009251356124878, acc 0.3199999928474426\n",
      "Epoch 3, Iter 284, loss 1.9485325813293457, acc 0.3400000035762787\n",
      "Epoch 3, Iter 285, loss 2.0917792320251465, acc 0.30000001192092896\n",
      "Epoch 3, Iter 286, loss 1.89463210105896, acc 0.4300000071525574\n",
      "Epoch 3, Iter 287, loss 1.9142346382141113, acc 0.36000001430511475\n",
      "Epoch 3, Iter 288, loss 2.03706431388855, acc 0.28999999165534973\n",
      "Epoch 3, Iter 289, loss 2.0112929344177246, acc 0.3400000035762787\n",
      "Epoch 3, Iter 290, loss 1.9828006029129028, acc 0.3199999928474426\n",
      "Epoch 3, Iter 291, loss 1.992590308189392, acc 0.3400000035762787\n",
      "Epoch 3, Iter 292, loss 1.9707850217819214, acc 0.3100000023841858\n",
      "Epoch 3, Iter 293, loss 2.0391714572906494, acc 0.25\n",
      "Epoch 3, Iter 294, loss 2.0365326404571533, acc 0.3100000023841858\n",
      "Epoch 3, Iter 295, loss 1.9898386001586914, acc 0.30000001192092896\n",
      "Epoch 3, Iter 296, loss 2.05000376701355, acc 0.23000000417232513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Iter 297, loss 1.9849400520324707, acc 0.3199999928474426\n",
      "Epoch 3, Iter 298, loss 1.9917731285095215, acc 0.27000001072883606\n",
      "Epoch 3, Iter 299, loss 2.14150333404541, acc 0.23000000417232513\n",
      "Epoch 3, Iter 300, loss 2.0667693614959717, acc 0.25999999046325684\n",
      "Epoch 3, Iter 301, loss 1.965146541595459, acc 0.36000001430511475\n",
      "Epoch 3, Iter 302, loss 1.9941606521606445, acc 0.3100000023841858\n",
      "Epoch 3, Iter 303, loss 2.0340473651885986, acc 0.23999999463558197\n",
      "Epoch 3, Iter 304, loss 1.9757860898971558, acc 0.3400000035762787\n",
      "Epoch 3, Iter 305, loss 2.079714059829712, acc 0.27000001072883606\n",
      "Epoch 3, Iter 306, loss 2.1322176456451416, acc 0.2800000011920929\n",
      "Epoch 3, Iter 307, loss 1.9920048713684082, acc 0.3400000035762787\n",
      "Epoch 3, Iter 308, loss 2.0542120933532715, acc 0.23000000417232513\n",
      "Epoch 3, Iter 309, loss 1.983964204788208, acc 0.3100000023841858\n",
      "Epoch 3, Iter 310, loss 2.028616189956665, acc 0.27000001072883606\n",
      "Epoch 3, Iter 311, loss 2.0550882816314697, acc 0.3100000023841858\n",
      "Epoch 3, Iter 312, loss 1.956950068473816, acc 0.30000001192092896\n",
      "Epoch 3, Iter 313, loss 2.0685930252075195, acc 0.2800000011920929\n",
      "Epoch 3, Iter 314, loss 1.8681988716125488, acc 0.33000001311302185\n",
      "Epoch 3, Iter 315, loss 1.9380336999893188, acc 0.3199999928474426\n",
      "Epoch 3, Iter 316, loss 1.9383007287979126, acc 0.3499999940395355\n",
      "Epoch 3, Iter 317, loss 2.003492593765259, acc 0.30000001192092896\n",
      "Epoch 3, Iter 318, loss 1.9761369228363037, acc 0.3199999928474426\n",
      "Epoch 3, Iter 319, loss 2.0980587005615234, acc 0.23999999463558197\n",
      "Epoch 3, Iter 320, loss 2.010915756225586, acc 0.3100000023841858\n",
      "Epoch 3, Iter 321, loss 1.988797903060913, acc 0.2800000011920929\n",
      "Epoch 3, Iter 322, loss 2.01821231842041, acc 0.2800000011920929\n",
      "Epoch 3, Iter 323, loss 1.98103928565979, acc 0.3100000023841858\n",
      "Epoch 3, Iter 324, loss 2.027339220046997, acc 0.2800000011920929\n",
      "Epoch 3, Iter 325, loss 1.9977030754089355, acc 0.28999999165534973\n",
      "Epoch 3, Iter 326, loss 1.9324383735656738, acc 0.28999999165534973\n",
      "Epoch 3, Iter 327, loss 1.977339506149292, acc 0.3700000047683716\n",
      "Epoch 3, Iter 328, loss 1.9626023769378662, acc 0.3100000023841858\n",
      "Epoch 3, Iter 329, loss 1.9658535718917847, acc 0.28999999165534973\n",
      "Epoch 3, Iter 330, loss 1.9312037229537964, acc 0.30000001192092896\n",
      "Epoch 3, Iter 331, loss 2.0401101112365723, acc 0.23000000417232513\n",
      "Epoch 3, Iter 332, loss 2.025110960006714, acc 0.25999999046325684\n",
      "Epoch 3, Iter 333, loss 1.9429309368133545, acc 0.3199999928474426\n",
      "Epoch 3, Iter 334, loss 1.9664779901504517, acc 0.3499999940395355\n",
      "Epoch 3, Iter 335, loss 1.9968249797821045, acc 0.33000001311302185\n",
      "Epoch 3, Iter 336, loss 2.019268274307251, acc 0.30000001192092896\n",
      "Epoch 3, Iter 337, loss 2.038754463195801, acc 0.2800000011920929\n",
      "Epoch 3, Iter 338, loss 2.1175763607025146, acc 0.1599999964237213\n",
      "Epoch 3, Iter 339, loss 2.053347110748291, acc 0.25\n",
      "Epoch 3, Iter 340, loss 2.060018539428711, acc 0.25999999046325684\n",
      "Epoch 3, Iter 341, loss 1.8817073106765747, acc 0.36000001430511475\n",
      "Epoch 3, Iter 342, loss 2.0022857189178467, acc 0.3100000023841858\n",
      "Epoch 3, Iter 343, loss 2.066521167755127, acc 0.23000000417232513\n",
      "Epoch 3, Iter 344, loss 1.9352902173995972, acc 0.33000001311302185\n",
      "Epoch 3, Iter 345, loss 1.9994425773620605, acc 0.30000001192092896\n",
      "Epoch 3, Iter 346, loss 1.9858825206756592, acc 0.3400000035762787\n",
      "Epoch 3, Iter 347, loss 1.998774528503418, acc 0.3400000035762787\n",
      "Epoch 3, Iter 348, loss 1.9103704690933228, acc 0.3799999952316284\n",
      "Epoch 3, Iter 349, loss 1.9656662940979004, acc 0.3100000023841858\n",
      "Epoch 3, Iter 350, loss 1.929867148399353, acc 0.30000001192092896\n",
      "Epoch 3, Iter 351, loss 2.051569938659668, acc 0.25999999046325684\n",
      "Epoch 3, Iter 352, loss 1.9950555562973022, acc 0.25999999046325684\n",
      "Epoch 3, Iter 353, loss 2.0477399826049805, acc 0.25999999046325684\n",
      "Epoch 3, Iter 354, loss 1.9493420124053955, acc 0.3400000035762787\n",
      "Epoch 3, Iter 355, loss 2.072610378265381, acc 0.25999999046325684\n",
      "Epoch 3, Iter 356, loss 1.9382954835891724, acc 0.3400000035762787\n",
      "Epoch 3, Iter 357, loss 2.0301406383514404, acc 0.2800000011920929\n",
      "Epoch 3, Iter 358, loss 2.092231512069702, acc 0.2800000011920929\n",
      "Epoch 3, Iter 359, loss 2.0117082595825195, acc 0.28999999165534973\n",
      "Epoch 3, Iter 360, loss 1.9384509325027466, acc 0.3199999928474426\n",
      "Epoch 3, Iter 361, loss 1.8994598388671875, acc 0.3499999940395355\n",
      "Epoch 3, Iter 362, loss 2.1076500415802, acc 0.23000000417232513\n",
      "Epoch 3, Iter 363, loss 1.979699730873108, acc 0.2800000011920929\n",
      "Epoch 3, Iter 364, loss 2.004080295562744, acc 0.25999999046325684\n",
      "Epoch 3, Iter 365, loss 2.0569870471954346, acc 0.27000001072883606\n",
      "Epoch 3, Iter 366, loss 1.9370166063308716, acc 0.38999998569488525\n",
      "Epoch 3, Iter 367, loss 1.8952178955078125, acc 0.36000001430511475\n",
      "Epoch 3, Iter 368, loss 2.0217854976654053, acc 0.2800000011920929\n",
      "Epoch 3, Iter 369, loss 2.008760929107666, acc 0.28999999165534973\n",
      "Epoch 3, Iter 370, loss 1.9943363666534424, acc 0.3499999940395355\n",
      "Epoch 3, Iter 371, loss 2.0732169151306152, acc 0.25999999046325684\n",
      "Epoch 3, Iter 372, loss 1.953864336013794, acc 0.3400000035762787\n",
      "Epoch 3, Iter 373, loss 1.967347264289856, acc 0.3400000035762787\n",
      "Epoch 3, Iter 374, loss 1.961637020111084, acc 0.3199999928474426\n",
      "Epoch 3, Iter 375, loss 2.0569450855255127, acc 0.2800000011920929\n",
      "Epoch 3, Iter 376, loss 1.9918020963668823, acc 0.3100000023841858\n",
      "Epoch 3, Iter 377, loss 1.985336422920227, acc 0.27000001072883606\n",
      "Epoch 3, Iter 378, loss 1.9626519680023193, acc 0.33000001311302185\n",
      "Epoch 3, Iter 379, loss 1.9948134422302246, acc 0.30000001192092896\n",
      "Epoch 3, Iter 380, loss 2.0279927253723145, acc 0.3400000035762787\n",
      "Epoch 3, Iter 381, loss 2.0281896591186523, acc 0.2199999988079071\n",
      "Epoch 3, Iter 382, loss 1.9180554151535034, acc 0.38999998569488525\n",
      "Epoch 3, Iter 383, loss 2.0023725032806396, acc 0.25999999046325684\n",
      "Epoch 3, Iter 384, loss 2.0331809520721436, acc 0.20999999344348907\n",
      "Epoch 3, Iter 385, loss 1.939041256904602, acc 0.3199999928474426\n",
      "Epoch 3, Iter 386, loss 1.924866795539856, acc 0.38999998569488525\n",
      "Epoch 3, Iter 387, loss 2.017664909362793, acc 0.28999999165534973\n",
      "Epoch 3, Iter 388, loss 2.047213554382324, acc 0.2800000011920929\n",
      "Epoch 3, Iter 389, loss 2.0711710453033447, acc 0.3199999928474426\n",
      "Epoch 3, Iter 390, loss 2.0169599056243896, acc 0.3700000047683716\n",
      "Epoch 3, Iter 391, loss 1.926740288734436, acc 0.3400000035762787\n",
      "Epoch 3, Iter 392, loss 1.928157925605774, acc 0.3400000035762787\n",
      "Epoch 3, Iter 393, loss 1.983353614807129, acc 0.3100000023841858\n",
      "Epoch 3, Iter 394, loss 1.9061294794082642, acc 0.3499999940395355\n",
      "Epoch 3, Iter 395, loss 1.9994311332702637, acc 0.28999999165534973\n",
      "Epoch 3, Iter 396, loss 2.0412073135375977, acc 0.28999999165534973\n",
      "Epoch 3, Iter 397, loss 1.8929762840270996, acc 0.3499999940395355\n",
      "Epoch 3, Iter 398, loss 1.9644787311553955, acc 0.3100000023841858\n",
      "Epoch 3, Iter 399, loss 1.9366793632507324, acc 0.3499999940395355\n",
      "Epoch 3, Iter 400, loss 1.9798626899719238, acc 0.27000001072883606\n",
      "Epoch 3, Iter 401, loss 1.9845024347305298, acc 0.30000001192092896\n",
      "Epoch 3, Iter 402, loss 1.906225562095642, acc 0.3199999928474426\n",
      "Epoch 3, Iter 403, loss 1.9662272930145264, acc 0.3400000035762787\n",
      "Epoch 3, Iter 404, loss 2.0263376235961914, acc 0.2800000011920929\n",
      "Epoch 3, Iter 405, loss 2.0051841735839844, acc 0.25999999046325684\n",
      "Epoch 3, Iter 406, loss 2.1764378547668457, acc 0.1899999976158142\n",
      "Epoch 3, Iter 407, loss 2.0615646839141846, acc 0.30000001192092896\n",
      "Epoch 3, Iter 408, loss 1.9866833686828613, acc 0.3199999928474426\n",
      "Epoch 3, Iter 409, loss 1.959505319595337, acc 0.3199999928474426\n",
      "Epoch 3, Iter 410, loss 1.9033335447311401, acc 0.4000000059604645\n",
      "Epoch 3, Iter 411, loss 1.9927985668182373, acc 0.27000001072883606\n",
      "Epoch 3, Iter 412, loss 1.969241738319397, acc 0.28999999165534973\n",
      "Epoch 3, Iter 413, loss 1.989128589630127, acc 0.25\n",
      "Epoch 3, Iter 414, loss 2.086554765701294, acc 0.20000000298023224\n",
      "Epoch 3, Iter 415, loss 2.006692409515381, acc 0.30000001192092896\n",
      "Epoch 3, Iter 416, loss 1.9400144815444946, acc 0.36000001430511475\n",
      "Epoch 3, Iter 417, loss 1.904952049255371, acc 0.2800000011920929\n",
      "Epoch 3, Iter 418, loss 1.9867470264434814, acc 0.3199999928474426\n",
      "Epoch 3, Iter 419, loss 1.9618501663208008, acc 0.36000001430511475\n",
      "Epoch 3, Iter 420, loss 1.9647512435913086, acc 0.3799999952316284\n"
     ]
    }
   ],
   "source": [
    "w1=torch.randn((784,3),dtype=torch.float,requires_grad=True)\n",
    "b1=torch.randn((3,),dtype=torch.float,requires_grad=True)\n",
    "w2=torch.randn((3,10),dtype=torch.float,requires_grad=True)\n",
    "b2=torch.randn((10,),dtype=torch.float,requires_grad=True)\n",
    "lr=0.1\n",
    "Loss=[]\n",
    "###### Mini Batch\n",
    "batch_size=100\n",
    "size=X.shape[0]\n",
    "steps=size//batch_size\n",
    "num_epoch=3\n",
    "for i in range(num_epoch):\n",
    "    for j in range(steps):\n",
    "        if j==0:\n",
    "            start=0\n",
    "            next_item=start+batch_size\n",
    "            x=X[start:next_item,]\n",
    "            Y=y[start:next_item,]\n",
    "            p=network(x,w1,b1,w2,b2)\n",
    "            loss=CE(p,Y)\n",
    "            loss.backward()\n",
    "            Loss.append(loss.item())\n",
    "            acc=(p.argmax(axis=1)==Y).float().mean().item()\n",
    "            print(f\"Epoch {i+1}, Iter {j+1}, loss {loss.item()}, acc {acc}\")\n",
    "            with torch.no_grad():\n",
    "                w1-=lr*w1.grad\n",
    "                b1-=lr*b1.grad\n",
    "                w2-=lr*w2.grad\n",
    "                b2-=lr*b2.grad\n",
    "                w1.grad.zero_()\n",
    "                b1.grad.zero_()\n",
    "                w2.grad.zero_()\n",
    "                b2.grad.zero_()   \n",
    "        else:\n",
    "            start+=batch_size\n",
    "            next_item+=batch_size\n",
    "            x=X[start:next_item,]\n",
    "            Y=y[start:next_item,]\n",
    "            p=network(x,w1,b1,w2,b2)\n",
    "            loss=CE(p,Y)\n",
    "            loss.backward()\n",
    "            Loss.append(loss.item())\n",
    "            acc=(p.argmax(axis=1)==Y).float().mean().item()\n",
    "            print(f\"Epoch {i+1}, Iter {j+1}, loss {loss.item()}, acc {acc}\")\n",
    "            with torch.no_grad():\n",
    "                w1-=lr*w1.grad\n",
    "                b1-=lr*b1.grad\n",
    "                w2-=lr*w2.grad\n",
    "                b2-=lr*b2.grad\n",
    "                w1.grad.zero_()\n",
    "                b1.grad.zero_()\n",
    "                w2.grad.zero_()\n",
    "                b2.grad.zero_()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12961e690>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3hUVfoH8O87k0oIEELogdAVkRqqIoKIFMWuqGsvq7uuDVfB1bUr6q5YfyrK2taCCmvDQlWKtNB7Dx0SWkKAhCRzfn/ceyd3Zu5kZpJJJnf4fp6HJ3funJk5kwnvnHvKe0QpBSIisj9HpCtAREThwYBORBQlGNCJiKIEAzoRUZRgQCciihIxkXrhBg0aqIyMjEi9PBGRLS1duvSgUirN6r6IBfSMjAxkZWVF6uWJiGxJRHb4u49dLkREUSLogC4iThFZLiI/WtwXLyKTRGSLiCwSkYxwVpKIiAILpYV+P4D1fu67HcARpVRbAOMBvFTZihERUWiCCugi0hzACAAf+ClyKYCP9eNvAFwgIlL56hERUbCCbaG/BuARAC4/9zcDsAsAlFIlAPIApHoXEpG7RCRLRLJyc3MrUF0iIvInYEAXkYsB5CillpZXzOKcT9YvpdQEpVSmUiozLc1y1g0REVVQMC30cwCMFJFsAF8CGCQi//UqsxtAOgCISAyAugAOh7GeREQUQMCArpQaq5RqrpTKADAKwCyl1J+8in0P4Gb9+Cq9TJXl5f1+5V7knSyuqqcnIrKlCs9DF5FnRGSkfnMigFQR2QLgIQBjwlE5K1tzC3DfF8sx+qsVVfUSRES2FNJKUaXUbwB+04//aTpfCODqcFbMn4LCEgDAgfyi6ng5IiLbsN1K0RKX1pPjdHBWJBGRme0Cukvvmo9hQCci8mC7gF5SyhY6EZEV2wX0Ur3LJcbJgE5EZGa7gF7s0harOh22qzoRUZWyXVQsLWUfOhGRFdsFdM5yISKyZruAXlyqdbmwhU5E5Ml2AX3IWY0AAC3q14pwTYiIahbbBfT4GCfiYhzW+R2JiE5jtgvoAOAQoOpSfxER2ZMtA7pTxD0fnYiINLYM6A4HAzoRkTdbBnSnQ9w5XYiISGPPgM4uFyIiH7YM6CICxnMiIk+2DOhOB+BiRCci8mDPgC6CUvahExF5sGVAdziELXQiIi+2DOhOB1voRETebBvQS9hCJyLyYMuAHh/jxKkSV6SrQURUo9gyoMfFOFDEgE5E5MGWAT0+xoE5m3LxzdLdka4KEVGNYduADgAPf70ywjUhIqo5bBrQnZGuAhFRjWPPgB5ry2oTEVUpW0ZGo8uFiIjK2DIyxjltWW0ioiply8jodHBDUSIib7YM6DEM6EREPmwZ0B0M6EREPmwZ0NlCJyLyZcuAzhY6EZEvWwb0bbnHI10FIqIax5YBPe9EcaSrQERU49gyoDtsWWsioqply9DoEPahExF5CxjQRSRBRBaLyEoRWSsiT1uUuUVEckVkhf7vjqqproYLi4iIfMUEUaYIwCClVIGIxAKYJyI/K6UWepWbpJS6N/xV9CVsoRMR+QgY0JVSCkCBfjNW/xfRDT2djOdERD6C6kMXEaeIrACQA2C6UmqRRbErRWSViHwjIul+nucuEckSkazc3NwKV5otdCIiX0EFdKVUqVKqK4DmAHqJSCevIj8AyFBKdQYwA8DHfp5nglIqUymVmZaWVuFKu1RELxCIiGqkkGa5KKWOAvgNwFCv84eUUkX6zfcB9AhL7fzWoyqfnYjInoKZ5ZImIvX040QAgwFs8CrTxHRzJID14aykN7bQiYh8BdNCbwJgtoisArAEWh/6jyLyjIiM1Mvcp09pXAngPgC3VE11NZd1bVaVT09EZEuiItTazczMVFlZWRV+fMaYqQCA7HEjwlUlIqIaT0SWKqUyre6z5UpRIiLyZduAXivOGekqEBHVKLYN6Led0wrMAEBEVMa2AV0kwstViYhqGPsGdHA+OhGRmX0Dur78P1KzdIiIahobB3TtJ+M5EZHGvgEdegs9wvUgIqopbBvQHe4WOkM6ERFg44BudLm4GM+JiADYOqAbXS6M6EREgI0DuoE9LkREGtsGdAd3LSIi8mDbgF7Wh84mOhERYOeArv9kPCci0tg3oBvTFiNbDSKiGsO2Ad3oQ2eXCxGRxrYB3cB4TkSksW1AF/a5EBF5sG1Ady/9Z0QnIgJg44BuzHLh0n8iIo19AzrzoRMRebBxQNd+MpwTEWlsHNC1iL5sx5EI14SIqGawb0DXf9716dKI1oOIqKawb0Bnbi4iIg+2Dei14pyRrgIRUY1i24Dep3UqAKBuYmyEa0JEVDPERLoCFdWkbiLObFIHzVMSI10VIqIawbYtdACIcwpKSl2RrgYRUY1g64Ae43SguJQz0YmIAJsH9Fin4BRb6EREAGwf0B0oZkAnIgJg84Aex4BORORm64CeEOvEiaLSSFeDiKhGsHVAb5FaC9sOHkd+YXGkq0JEFHG2DuitUpMAAJe/PT/CNSEiijxbB/QOjZMBAFtzj+POT7IiXBsiosiydUDvkl7PfTx93QF8MHdbBGtDRBRZAQO6iCSIyGIRWSkia0XkaYsy8SIySUS2iMgiEcmoispaSU2Kcx+/+POG6npZIqIaJ5gWehGAQUqpLgC6AhgqIn28ytwO4IhSqi2A8QBeCm81/XM4yvLolnKDUSI6jQUM6EpToN+M1f95R85LAXysH38D4AKR6slY7mRidCIiAEH2oYuIU0RWAMgBMF0ptcirSDMAuwBAKVUCIA9AqsXz3CUiWSKSlZubW7ma65wOBnQiIiDIgK6UKlVKdQXQHEAvEenkVcQqqvr0fyilJiilMpVSmWlpaaHX1oLD1sO6REThE1I4VEodBfAbgKFed+0GkA4AIhIDoC6Aw2GoX0AurvwnIgIQ3CyXNBGppx8nAhgMwHs6yfcAbtaPrwIwSylVLSOURSWM6EREQHA7FjUB8LGIOKF9AXyllPpRRJ4BkKWU+h7ARACfisgWaC3zUVVWYy9FJczlQkQEBBHQlVKrAHSzOP9P03EhgKvDW7XgsIVORKSx/ZDiKQZ0IiIAURDQiYhIw4BORBQlGNCJiKJE1AV0F/O5ENFpKuoCOme9ENHpKuoC+pn//AU5xwojXQ0iomoXdQEdABZuq5asA0RENYrtA3rD5HifczsPHcfBgqII1IaIKHJsH9DnPDIQN/dt6XHuX9M2of9LsyNUIyKiyLB9QE+IdSIhzulz/mQxc7wQ0enF9gEdAMQyHTsR0eklKgI6ERExoBMRRY2oCOjcJ5qIKFoCeqQrQERUA0RHQGdEJyKKkoDONjoRUXQE9NoJwWyNSkQU3aIioN92Tivc5LValIjodBMVAT0uxoG7B7SJdDWIiCIqKgI6wIFRIqLoCeheA6NnNa0ToZoQEUVG1AR074FRp0ML8OOnb8LzU9dFokpERNUqegJ6fAwm39PPfbtU31v09Zmb8f7c7ZGqFhFRtYmagA4ATeomuI9LuVk0EZ1moiqgO0wjo4rxnIhOM1EV0ItLXe7jUkZ0IjrNRFVArx1fNjC6JacAV73zRwRrQ0RUvaIqoKckxWHZExfiki5NAQBZO4647ztxqiRS1SIiqhZRFdABoH5SHOKcvm/r1g+XRKA2RETVJ+oCOgAkWyTrWrT9cARqQkRUfaIyoNdNjI10FYiIql1UBvQ65QT0wuJSzNt8sBprQ0RUPaIyoPtrof+x9SCue38h/jRxETbsz6/mWhERVa2o3Bmijp8NL65/f5H7+PDxU9VVHSKiahGVLfTyulwM17+/CD+u2lsNtSEiqh5RGdBdQeZx+XnN/iquCRFR9QkY0EUkXURmi8h6EVkrIvdblDlfRPJEZIX+759VU93g9GxVP6hy3BODiKJJMH3oJQBGK6WWiUgygKUiMl0p5Z1kfK5S6uLwVzF0sU4HhnVqHLAFLtzmiIiiSMAWulJqn1JqmX58DMB6AM2qumKVdaww8FJ/hnMiiiYh9aGLSAaAbgAWWdzdV0RWisjPInKWn8ffJSJZIpKVm5sbcmVDcaywOGAZo4G+P6+Qc9OJyPaCDugiUhvAZAAPKKW8J3EvA9BSKdUFwJsAvrV6DqXUBKVUplIqMy0traJ1Dkr/doGff/2+fBw9cQqXvj0Pf5po9R1FRGQfQQV0EYmFFsw/U0pN8b5fKZWvlCrQj38CECsiDcJa0xA9eGF7LPnH4HLLbDpQgHs/X44D+UUAgBJTPnUiIrsJZpaLAJgIYL1S6lU/ZRrr5SAivfTnPRTOiobK6RCkJccHLDdvS1lXy/A35uJYYTFmb8jBOeNmoaiktCqrSEQUVsHMcjkHwI0AVovICv3cYwBaAIBS6l0AVwG4R0RKAJwEMEop+2wZJKJtWbfpQAF+35SLf0/bhD1HT2Lf0UJkNEiKdPWIiIISMKArpeYhwIQQpdRbAN4KV6XC6fZzW2HivO3llolzOlBUonW3uJTWugeAEhe7YIjIPqJypaiZeVs6f4xgDgBKKcToAf2FnzZUWb2IiMIt6gN6RTj0+YyzNuREuCZERMGL+oAe6mLQ7QePY92+slmZeSeKUVLqwq7DJ3CwoCjMtSMiCp+oTJ9rdkbj5JDKvzZjs8ftLs9Mw6ie6fhyyS6IANtfHBHO6hERhU3Ut9CHdmpS6ef4cskuAMZMmGMAgDs+zsJ3K/ZU+rmJiMIl6gN6IK9d2zWk8kPGz4FSCjPWH8D9X64IWJ7dNERUXU6LgJ7sZwcjAOjXNjXk5yuxyLe+49Bxn5Wm3yzdjcznZmDd3tC3uztxqgT78k6G/DgiOn1FfR86APxw77nI2nEEl3ZtiqzsI0hLjsPgV+cAAOJjnCE/39RV+zxuZ4yZCgD426C2GD2kg/v8V1laV83+/JPo2LROSK9xwweLsHznUWSPY589EQXntAjoGQ2S3Cs++7bRWuT3DWqLHhn1kRAb+kXKA5PKulo+W7TDfZyVfcSjnJHCt7hU4e5Pl6J36/q49ZxWQb3G8p1HQ64XEZ3eTosuFysPDemAAe3TKtRCN/vH/9a4j2snxODoiVPuHDBFxdrPn1fvwy9r9+PpH7Q9QeZuzsV9XyyHUgqlLlVul0zeycBpgImIgNM4oJs9f3kny/PXZDYP6Xk27M9H12emo8Pjv2BLzjEU6gH92xWem1HfOHExvl+5Fx3/+SvaPPYThr8x129Qv/fzZSHVgYhOXwzoAG7o3RIXdy6b3tg8JRFAcDnVzXYdLhvEHPzqHBw8fqrc8ieLy7I5+ss3sy33uPvY5VKYumofSoPcBJuITi+nRR96MN68rht+1Ac7Zzw0AC6lUCsuBh0aJ6Oo2IVL3poX8nOeKgk+udfkZbsx8Iw0HDl+yt3PDwCnTDNnXvplA96bsw0AMO3B89C+UWiLpsJpz9GTmLJ0N+4d1JZ7sxLVEAzoOnNQSogt61dv3ygZuw6fCNvrXPveAr/33fv5cp9zxaUu/LJmP7bmFriDOQB8siAbz112dtjqZXC5FFxKIcZZ/sXbPf9dilW78zC8cxO0Sasd9noQUegY0E3qJsZaDkKm16+FiTdnol1DrUV83iuzAQBpyfHIPRbawqFF2w+HVP7oiWLc/d+lPueX7zyKa95dgLyTxfj1wfPc5zcdOIYh4+fg5Ss745qe6UG/zp2fZEEAxDodmLp6X8DpkidOad1F7P4hqjkY0E1mjR6AIyes+70vOLORz7lYR+S6GtaaBlGVUhARFBSV4KM/sgEAj0xehf7tG6BJ3UQs2nYIE+Zsw4SbMt253r1NX3cgpNd36lc0rirax2TRtkMocSmc0zaiOxnaTlFJKZwiAa+wKDrxUzdJrR2Ptg2D75c25pl/c3dfy/v/95d+YalXIK3G/oRB//4NnZ78FZ8v2uk+3/fFWQCAv3y2DDM35GD7wQIAQGFxKa55dwG+W7EHf/18GbIPHvd5zkAtb6OHqrikrNz0dQeQMWYq9ucVVvYt4doJC3HDB54bd4+dshoZY6bieFGJ5WNW7jqKuz7JqpF7w/66dj+mrd1f5a/T4fFffH5vdPpgQK+E+we3AwB0b5GC63r5dm90a5HiPn7hcv/93VPCEPjNs2G8GSF38KtzcNU7fyAnvwiLsw/j/i9XYOqqfTj/X7/5PMY8AwcACopKcOJUWSA1csYXlpTC2G3wvwu1RVbr92tXD0opZIyZiowxU5GT7z/IK6Xwf79tCZjq4IvF2peVv3IPTlqBaesOIPtQ+MY8zEpd2vv5T4AdsKz8+dOluOtT366zqhBqtx5FDwb0Cnh4SHvc1Lcl7ujfGtnjRsDhEDw18qxyH3OuRddBtxb1sOyJC9HdFPjDrdirtZq14wie/2ldwMeZgzcAdHryV/R+Yab7tkP/y7n63QXoN26Wx2vF6Zf75p2g/rfcf2bKbQeP4+VfNqLvi7Mwe2PgTUWcDus/21rxTsu6h4uxYOylX7iTFdVM7EOvgHsHtfM5Fx/jxNxHBuLzxTvRpXk993/+D2/piSXZh5FeP9HnMR/f1gt1EmKrtK5r9+b7BLhf1wbuLz9RVIrXF21Gtxb1cF57bT6+0cUElPWhA8A+vYvFCOixekA3d40syT6CPw/QjtftzUd+YTEOFZxC3slinN2srrvcrR8uQdbjg923pyzbjWSv35H3/uN5J4qRX1iMWnEx+ut6Xl2EYu7mXDhELPvujV4o+2x/TqcbBvQwSq9fC48OPcPj3MAzGmLgGQ0ty5uDeXyMw6NFGy6XvT2/Qo+bv/Ugxs/YBABYOPYCn/sT4zxTJuSdLMYSr1w2xkwYAJixvuxLZPgbc8t97cznZriPH/pqpXauZdlVTHFpWUSduzkXN05cDAAY2EH74inw08ceDOO5sseNwLfL92Bgh4aoW0v7nEr11y2twoi+dm8e6iTEIr1+raDKr96dh07N6nAtAAFgl0u1evWaLu7jS7o09bhv4dgL8MeYQUiK880tc12vdI9Wa3Uw56jp82JZV8vvm3KRMWYqCos9v3w2mLbt26j3oR8PY9eHeTbNoeNFWLFLS172ddZu93mjhX7nJ1lYsycPN05chIXbDvk8V05+IeZuzoXLpTBm8ipMX3cAT363Br+sKRu03JpbgAcmrcDor8sSsZW4tPccaMD4w/nbcaCcMYPyjHhjHvq/PNvj3PaDxzF56W6fsj+v3odL3pqH77xSS9DpiwG9Gl3RvSw3jDm4A0BKUhya1kv0mFMOAHMfGYgXLj8bDWrH443rumGwxfTJ6vTRfG1A0AiohlzTRh5PfLcWAHxmozz89UoMGf97hV7X3Cq//v1FuOzt+SgsLsV60xeJOeh/MHcb5m4+iFETFmL5ziMe9b307fm4ceJivDdnG75csgt3fpKFjxfs8Jjvb6zyNadzOGRK5WDu9lmSfRi3fbQEE+ZsxY5Dx/H0D+ss1w4AwN6j/gd+jxVaJ2K7+I25GP31Sp/zm3O0WUtbcwt86mTYfvA4d9Y6jTCgV7PfHj4f0x48z93P7M1oZQLA3QPaIL1+Lffl9MguTfHBzZlBv1bX9Hro3y6887hX7c6zPD/6K9+As+eoZyv1m6W7selAQYVed/Ue39d99/et7qAGeM7McZi6IC7/vz9w2dvz3YvGjD7/8gY37/tCW7VrfEkopTBk/Bz3/adKXcg5VoiCohJc/e4CzNqQgxd+2uD+4jl6oiw4nzR1PfUbNwtLd1jPQnn2R8/B6p2HTkApheP6411eVwbGlYLx92G18cpFr80JamctK3uOnsTvm3Ir9FiKDAb0apbRIKncHCyJetqBWKdgzLAz/JYzfHJbLyx9fDCevKSj+9ym54bhiYs74j+39PQIbOFwyE/CMe/+/2lr9+OFqevD+trevDf0/m1jWfCZYjGrpsvT0zBrQ3ALqIwvCqO/3HyFAGi573s9PxOdnvzV4/zgV32vQLwzZq71k1nTvOp4+c4jOO+V2R7vsdjl+Ts2WuTGJ1xS6hvQQ8knZBj86u/4dEE2hr8+Fzf/Z3HIjydP09buR8aYqdWyAxkDeg2TEOtAg9pxeO4y65S+3gqLS5FaOx6jerZwn4uLceD2c1uhflKcz7TFcEqM9Z9L/q5Pl2J/BfuRq9JtH2WFVN7l0nLWe3cfBVq8YwTZvJPFmLfloMd9Rfr4w4fzt3u01s3jEtv1xV6vzywL6Dn5nmkmjAa5w91C9/9Zz96YU+5gscul8NaszThy/BS25BTgie/Wuq9orLpy7Gb17jx8MHdb4IJVYJK+yfyaPaFvRRkqBvQaRkSQ9fiFuNYUoL1lPT4YU/7SD/3bNXBPr4uLsf4ozS201g2SMDGELpvreqWjd6v6AIAzm/huoXdZt6Y+56JNqVK45M156Pbs9JAfO3/LQXR5eprP1YsxpfXpH9bhynfKkrWZp5c+ZNGFdcU7f3jcNrqDxs/YhNkbcyxb6IZbP1yCsVNWa49zKZ/++oXbD+Ff0zZZ9tUXlyr8sHIv1lh0ewHaQq98P/3/NcUlb83Dc1V8xeiPQ0+3UR15jxjQbahB7Xh0b5GCT2/vjaR4rc/dyNEy/OzGHmXNLfSHhrRH24bBZUZs3SAJL17RGc/rK1ytltvXT4qrUP3N/u+G7pV+jqq06/BJrNsXesvKpRSmrt5ned+q3XmYtKQsRcMRvRvLapzAzDsRnDk+3P/Fco8W+OwNOdh9xHPF7E49a+jzP63H2U9Nw/DX57pX8BqNcKvZOe0f/xl/+2I5Ln7TOoV03xdnYcircyzvszJpyU5c5fXlFAknTpVg7JRVyDtRtV9GVZ33yIwBPYose+JCvHZtN49zRuvww1t74uLOTdEyNQnPXHoWxl/rOcvmp/v6Y/I9/TDibG2jjxin9kfYJi0J1/VKx7grz8a/r/Z8jL/t++67wHfhlT/DOjUOXAhA4zoJ5WaAfOnK8KcSrozsQyf8Jjybtu4AHp282n17+Btz8emCbATTgDNnAzV3heQXlnj01d/60RJc4hWAT+pXAN/oUyDX7cvHZ3ruH2OQ/mBB+dlDLxo/B9v0WTUlpS78sVXrTtqfX4hVu4/iUIDHA8Cjk1cja8eRgOW8HS8qwb+nbQx5XOCHldbTOr9asgtfLN6FYa/PwV2fhNYVFwonW+hUEfWT4ny6XtKS4wEArVKT3Odu6puBBrXjPcrVrRWLHi1TMHa4NhDbQ1/IIyJ48YrO6NemAVqmli12GdA+ze9MneT4spk6F3ZshD8PaO23zuUtiOlo6uZRKP8/g3mRVuM6CeWWrS7Bplbel1fonuoZyIBXZiO/sBjXvrfAHYwNK71mIB3xanluOlCAXYdPeHwRiGjTSa/R8/QfyC+/zhsPHMM7v20FALwxczOuf79sLGHkW/NxyZvzkF9YjL1HT2LhtkN44af12H7wOF7+ZYNPX7z37S8X73R/WVh5Y+ZmvDlri/sLqTw5+YV45od1OHz8FP72Rdk+A1bjAXvzCjGtnGyja/bkYUvOsYCv6Y/R5VIdLXSuFI1yr13bFbM35iKjQZLH+Q6NtZk2/dqk4o+th1C/ltZ90jylFn6491y0b+zbNdPDtFrzw1t6+v2PZf5SSU6IwT0D2qCo2IUVu476zF8vz0/398ekJTvx6OTVHtMAAeCWfhnuVMEAcG67BuiZkYIXrzgbT3y7NugB2VpxTo8VrTXd0RPF6PzUtAo//mBBkUfqAqUQVIA0M1qaG/b7Brm9eYU+9Zugb8xyRffmHl1+p0pd7qs8l0thzJTVqFcrFsM6NUbTuon4m9eVnvE5eQ/0788rxJLswx6L9XrpeYd+3+SZG8ilAP3i0yeVtJGG2pvR1eR9hfjLmv3okl4XTer6pvUwM16vOlroDOhRLrV2PK7q4bvZdcNk/10YZzeva3leRLD8iQtx+MQpOByCK7o3Q25BEV75daNHOXNAf+SiM1CvVhyeGnkWRk2w3q1pzLAzMO5n6znh6SnaVYFxNZBePxG7Dp/Ek5d0xKLth1E73okPbu6J5IRYfH23lrXSOy1BeewUzMOh1BXoWiew1XvysGr3URSG2PXhHStPlZQF9EJ9oDj/ZDG+WKzNCjEH9MLiUnyqZ/P0dv0HC7Et9ziGnNUI8TFOHDZNrd3qlYW01KXcgdzhFdBLXAp5J09h8tLduOu81gHTKdz936VoXCcBCx/zTY1hZiSTs1onEG7scqGQpCTFubeci3E6cPeANj5ljGyLl3VtisZ1fbs/RnZpikZ14mH8fzI/x/s3ec7CSdCDs9GnP/Oh87Hh2aEQEfx8f398fXc/1E30TN51R/9WQb+ferWsk6M1qB2PUSHs+GQXV727wGPw9FQFprVuzinAyLfmY06Ii46Onij2eO28k8UYNWEBNuzPx5/11MLmbrxTJS6MnbIa+/MK8cmCbPd5c5zduP+YO3W0McvH3yY1ADBmyip0fkpbO+D0CtglpQp//3olXvx5g98FdIaMMVMBIKgrQeMtHT5+Ct+Wk3U0HBjQqVKcDsHU+871GGQdeEZDNE9JxJ+9gr3os7NH9UzH738fiHXPDPV5vgs7NsKLV5yNH/92LoCyue4xeisnLsbhseerlX5tylbHbnpuWLllxww9Axd29E2n0LtVfbRIDS5BVjDGBrFILNzigti1yOgPrw5XvvOHx4Dmgq2HsHDbYTz74zrM3awNrpqneM7akIMvFu/EU9+vxQs/lV3Bmccm/moaCDaeu7y1F1OW7UG+njXUt4Xucn/hlJco76TXVd2hgqJyp20a6wTG/bwBD0xagR2H/O9dUFkM6FRpZzWti8u7NcfLV3XGR7f2RP2kOMx7dJDl3HVA23AjIdbpNzBf16sFOukpdRPcAT20Fa9PXtIRzeolItbp+7g/D2iNl6/s7K770LM8Z9p8fkdv/PuaLpabX894aID7+KEL27uPf3v4fPdrDT6zId67sYf7viu6N8Nl3ZqFVH/DdK/cPqGIsXjvkWbuRzYCq7+xQn+B+c1ZWyzLGFcb5l20yuPdQn/ux/XujKFWA5hGgrR+42Z6nO/x3Az0Me0V8M5vW5ExZqr7C8b7i8M7sV04MaBT2FyTmY7zO1inCg7kP7dkWk53NP4vxMaEFpxuPacV5o8Z5P2BxqMAAA7qSURBVNMPes/5bTB22Jm4OrM5Fj12Ac5uXhfe+2Wc2aQOEmKdHonQkhO04abUpDg8ps8EGqDniQe0lA6bnx+O7HEj8MHNPTFEb/VntkzBq9d0Lbe1/Nq1Xf3eV9dPl5A/5nQRFR0fqMqtcs0B2Mhd88dW34yYQFnwt0pXrJTCh/O3e0zjNFbgBtuN5D0oOilrl/vYKqCP/nolCotLfWYPAdrvevYGbQB2/HQt7bTR2vf+4qjK2S4M6FRtjKBo1doedEYjjxavoVGdBCTEOjB22JmVfv1XruqMB/RtA0UEjfTpjQLP+sTqg7pOhyBePz6vnRa8E2KduLN/a8z5+0B0Sa/n97VEBAvHXoCPbusFoGygtnWDJIzW36cI8M4N3XFZt2aY8pd+eHiI7/tvmJyAXx8ov5VuXBk0qZuAy7pW7ErArHer1Eo/hz+hpKLYrE8VtNojduG2w3j6h3Ues5/G/m8VlFJBv8YDk/wnLVNK+9IwVvUavFMbm9360RIAZV8oB/K15G3eXxxVOduFs1yo2oy7sjO6pO9ELz2dQDASYp3Y8Gz5/eDBujrTepCzUzPPWT3mL5x5jw5CQVEJmtRNwEND2rsDczD96+YB4YRYJ9Y9cxESYpxYoOdo79MqFcP0hVzdW6Sge4sU/GvaJp/n6dA42T1N8/t7z4HTIRCIe6OQ6Q8OcO8LG+8nBQQAPHtZJzzx7Rq/9xsyGtTCxFsy8dqMze4ph+Gy50jwCarenq3171vNDrFqhc/fcgjjZ2xGvcTAVzU9AqRyKHUpjJ+xGW/M9EwAF2htwVbTPPphr89FnNOBG/u29ChTWFx1M6sCBnQRSQfwCYDGAFwAJiilXvcqIwBeBzAcwAkAtyillnk/F53e6ifF4a8D21b7635yWy80sZhtY2jbsDY2Pz8Me4+exJxNuR59+2nJ8e7FWVZ96p/d0ds9tTIQIzVyz4z6uLxbM/fVglmMQ9wB7DxTl85TI8/y2LfWPLhotAAF/nP6AMCNfVrig7nbsCPAJtqtG9RGrbgYjOzStFIB/ea+LfHxAs+phtcHSGpmxRgwDYZ3APbHX9ZQw00VzDJ5wb89s22eKnVhotem4lXZhx5MC70EwGil1DIRSQawVESmK6XMyZuHAWin/+sN4B39J1HEmQOjP7FOB1qmJuHGvkkBy5pZ7T0aSFyMA+P99JvPeWQgco4V4YzGyeUOBFsN9opIuS10AEGlUzYGsys7qHpxl6Y+AT1c7JwBsipb6AH70JVS+4zWtlLqGID1ALw76i4F8InSLARQT0SahL22RFGuab1EdE2vh4RYJ2LKGUg1Bnu90yqYH/P6qK44p20qfrqvP14fpX2B/MsrH4+VWvGeU0XNjHGQYKTUqnzyNn+qYxl9VSksiWBANxORDADdAHhfNzUDsMt0ezd8gz5E5C4RyRKRrNxc7oRCVBnZ40Zg7LAz3Xl57vfqwrm0azN8dkcfdGxaB5fqg6U9WqZg+4vDfZ7LnH/HmJFjdYVgrA8IRq0QVuyG6oEgdmEyD0be0Nt/OurqViOmLYpIbQCTATyglPLOJ2p1bebzFaqUmqCUylRKZaalBb4MJqLAEuOcyB43AteYBn3Pamq9BgDQWvf3DWrrzo1/ZpM6uNiUB8VYeevd5XLP+W3QMjUJdwa5Etcc0L3n+leWMYe9POtNC9fCvHFXpTz89UqfxUnhEtT1k4jEQgvmnymlplgU2Q3APIWgOQBuRU4UAQvHXhCwa+ShIR0AaGmHB7RviJSkWAw+syEcDkF6fW2Q13sOvzGt9IHB7fH+XM+Bviu6NfPZ9i8xzomUWrE4cqIYr17bBb/8c3+l3lcoJtzYw2OA2HtqaqTtOXoy6L0JQhGwha7PYJkIYL1S6lU/xb4HcJNo+gDIU0pZZ/cnoirVuG6Ce+OTQK7t2QKN6yYgPsaJC85shIGmhWHeA49GnpXEWCdSk+JwSZemuFxfAdunje/c9TinAzNHn4/f/36+x+bnldEwOd7vfeYB4SFBXBEYC8QA4Is7+7iPB3ao+t6DJ78PPH20IoL5LZ8D4EYAq0XE6Lh6DEALAFBKvQvgJ2hTFrdAm7Z4a/irSkTVyV9qBodDsPSJC923x1/bFV+ZVll2Sa+HRy/qABFB/aS4kHe26pVRH4uzD1veN7hjI3zulQceAF64/Gxc2aMZMp+dgWOmBGD3DmyLt2Zv8Vnc85fz2+Cu89rg3LZpcCnlXmQGAL1bp2L2xqod43tseOUXylkJGNCVUvNg3UduLqMA/DVclSKiyGtQOx6T7uqDh79Zif7tym+1GgFiYIc0vHtjD7+7WZk9f3kn/ON/vi3V92/ORJenQ8v5fr0+6Dnr4fM9ttEbPaQ9Rg9pjye/99xAxJi+2dE01pCcEINjhSXlbn7uz7t/6oFYp+D2j4Pb+eisptYpqiuLS/+JyK/erVMx95FBeOHy4Lb4S60d7zeYN0/x3Ajiht4tLcvVTYxF9rgR6NTM/8CuP2nJ8R4rf0UEIuLe/cpYpeydMAsAjukDrd4plT/W0zeUZ2inxkFtIVjVGNCJqNKMTVEGlpOcbc7fB/q9L3vcCPz39t749Pay4DnlnnM8ymx/cbhHv/5fB/rm4vfn2p7pmPHQeeijB/Tyuhx6t0rF5Hv64bpeLfD6qK5o7bXb1zWZzXFdL99pkDVhbjwDOhFV2hmN62D9M0MxorP/9YQOh2Dm6AG4sGMj3NIvw+f+c9s18OjaiYtxYOWTQwAAF3duAhFxb2IBAH+/SBvU7NbCf5I0g4igbcNkFOvN6PJW4SbGOtGjpbad4aVdm/m05q/o3hy1432vQjJbpiDO6cBzl3Uqdx/dqsTkXEQUFsFs/dcmrbbPrlTlqZsYiw3PDnXPsPHOVLhw7AWokxh8GDP61xuVs5F4fKxnO9elv2asU3Bn/9bolVEfWRaDtqm147HpeS2R3LKdR/De72V5cAZ2SKvygVaAAZ2IajjzbJu/DmqLKcv3uDcst9risDx9WqViyrI9yMxI8VvGOx+O0ZPSqE4CHhmqXRXcdm4r5BwrwmeLdvp0yQBa9szMlinI2nEE2eNGoLjUhQ37jqFdo9pV2jXDgE5EEfPz/f1xsKD8lLRmbdJq+93cPBhXZzbHsLMbIznBf4pd7wVVxpVHZ9Pm6bXiYvDMpZ3w1CVn+V2F+tFtvZCjXxHEOh1+N18PJwZ0IooYf9sUVhURKTeYW0lLjsfke/rhzCbJPvdZzZYx1I6PQW2LlMtViQGdiAjA5Hv6YeP+Y5b3GV08NR0DOhERtKBtl8DtD6ctEhFFCQZ0IqIowYBORBQlGNCJiKIEAzoRUZRgQCciihIM6EREUYIBnYgoSoj3voHV9sIiuQB2VPDhDQAcDGN1IsHu74H1jzy7vwe71x+IzHtoqZSy3EIqYgG9MkQkSykVfA7OGsju74H1jzy7vwe71x+oee+BXS5ERFGCAZ2IKErYNaBPiHQFwsDu74H1jzy7vwe71x+oYe/Bln3oRETky64tdCIi8sKATkQUJWwX0EVkqIhsFJEtIjIm0vWxIiLpIjJbRNaLyFoRuV8/X19EpovIZv1nin5eROQN/T2tEpHukX0HGhFxishyEflRv91KRBbp9Z8kInH6+Xj99hb9/oxI1tsgIvVE5BsR2aB/Fn3t9BmIyIP6388aEflCRBJq+mcgIv8RkRwRWWM6F/LvXERu1stvFpGbI1z/V/S/oVUi8j8RqWe6b6xe/40icpHpfGTilFLKNv8AOAFsBdAaQByAlQA6RrpeFvVsAqC7fpwMYBOAjgBeBjBGPz8GwEv68XAAPwMQAH0ALIr0e9Dr9RCAzwH8qN/+CsAo/fhdAPfox38B8K5+PArApEjXXa/LxwDu0I/jANSzy2cAoBmA7QASTb/7W2r6ZwDgPADdAawxnQvpdw6gPoBt+s8U/TglgvUfAiBGP37JVP+OegyKB9BKj03OSMapiP3BVvCX3RfAr6bbYwGMjXS9gqj3dwAuBLARQBP9XBMAG/Xj9wBcZyrvLhfBOjcHMBPAIAA/6v/pDpr+sN2fBYBfAfTVj2P0chLh+tfRA6J4nbfFZ6AH9F16UIvRP4OL7PAZAMjwCogh/c4BXAfgPdN5j3LVXX+v+y4H8Jl+7BF/jM8gknHKbl0uxh+5Ybd+rsbSL327AVgEoJFSah8A6D8b6sVq4vt6DcAjAFz67VQAR5VSJfptcx3d9dfvz9PLR1JrALkAPtS7jT4QkSTY5DNQSu0B8C8AOwHsg/Y7XQp7fQaGUH/nNeqz8HIbtKsKoAbW324BXSzO1dh5lyJSG8BkAA8opfLLK2pxLmLvS0QuBpCjlFpqPm1RVAVxX6TEQLt0fkcp1Q3AcWiX+/7UqPeg9zNfCu1SvimAJADDLIrW5M8gEH91rpHvRUT+AaAEwGfGKYtiEa2/3QL6bgDpptvNAeyNUF3KJSKx0IL5Z0qpKfrpAyLSRL+/CYAc/XxNe1/nABgpItkAvoTW7fIagHoiEqOXMdfRXX/9/roADldnhS3sBrBbKbVIv/0NtABvl89gMIDtSqlcpVQxgCkA+sFen4Eh1N95TfssoA/MXgzgBqX3o6AG1t9uAX0JgHb6SH8ctMGf7yNcJx8iIgAmAlivlHrVdNf3AIwR+5uh9a0b52/SR/37AMgzLlEjQSk1VinVXCmVAe13PEspdQOA2QCu0ot51994X1fp5SPaolJK7QewS0Q66KcuALAONvkMoHW19BGRWvrfk1F/23wGJqH+zn8FMEREUvQrlSH6uYgQkaEAHgUwUil1wnTX9wBG6TOMWgFoB2AxIhmnqmugIYwDFsOhzRrZCuAfka6PnzqeC+0SaxWAFfq/4dD6NGcC2Kz/rK+XFwBv6+9pNYDMSL8H03s5H2WzXFpD+4PdAuBrAPH6+QT99hb9/taRrrder64AsvTP4VtoMyZs8xkAeBrABgBrAHwKbTZFjf4MAHwBrc+/GFpL9faK/M6h9VVv0f/dGuH6b4HWJ278X37XVP4fev03AhhmOh+ROMWl/0REUcJuXS5EROQHAzoRUZRgQCciihIM6EREUYIBnYgoSjCgExFFCQZ0IqIo8f8VXmsublR/MgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(Loss)),Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Is that all that a dl framework offers?\n",
    "###### Besides automatic gradient computation what else do we get?\n",
    "###### The first important issue that any dl framework will solve for us is the issue of data handling\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistData(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "    def __len__(self):\n",
    "        return X.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        X=self.X[idx,]\n",
    "        y=self.y[idx]\n",
    "        sample={'X':X,'y':y}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=mnist_train.drop('label',axis=1).values\n",
    "y=mnist_train['label'].values\n",
    "mnist=MnistData(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_batched=DataLoader(mnist,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 1, loss 3.4628796577453613, acc 0.05999999865889549\n",
      "Epoch 1, iter 2, loss 3.2974114418029785, acc 0.09000000357627869\n",
      "Epoch 1, iter 3, loss 3.3616178035736084, acc 0.07000000029802322\n",
      "Epoch 1, iter 4, loss 3.232241630554199, acc 0.09000000357627869\n",
      "Epoch 1, iter 5, loss 3.27498197555542, acc 0.14000000059604645\n",
      "Epoch 1, iter 6, loss 3.4163713455200195, acc 0.10000000149011612\n",
      "Epoch 1, iter 7, loss 2.786128282546997, acc 0.17000000178813934\n",
      "Epoch 1, iter 8, loss 3.210542678833008, acc 0.09000000357627869\n",
      "Epoch 1, iter 9, loss 3.106250047683716, acc 0.10999999940395355\n",
      "Epoch 1, iter 10, loss 3.352989435195923, acc 0.11999999731779099\n",
      "Epoch 1, iter 11, loss 3.0772292613983154, acc 0.10999999940395355\n",
      "Epoch 1, iter 12, loss 3.1429975032806396, acc 0.07999999821186066\n",
      "Epoch 1, iter 13, loss 3.2882068157196045, acc 0.10999999940395355\n",
      "Epoch 1, iter 14, loss 3.208022117614746, acc 0.05000000074505806\n",
      "Epoch 1, iter 15, loss 3.3429174423217773, acc 0.10000000149011612\n",
      "Epoch 1, iter 16, loss 3.252791166305542, acc 0.07999999821186066\n",
      "Epoch 1, iter 17, loss 3.3332483768463135, acc 0.09000000357627869\n",
      "Epoch 1, iter 18, loss 3.149055242538452, acc 0.14000000059604645\n",
      "Epoch 1, iter 19, loss 3.437401533126831, acc 0.09000000357627869\n",
      "Epoch 1, iter 20, loss 3.1039669513702393, acc 0.07999999821186066\n",
      "Epoch 1, iter 21, loss 3.1250860691070557, acc 0.09000000357627869\n",
      "Epoch 1, iter 22, loss 3.219649314880371, acc 0.15000000596046448\n",
      "Epoch 1, iter 23, loss 3.257779598236084, acc 0.11999999731779099\n",
      "Epoch 1, iter 24, loss 3.1186351776123047, acc 0.03999999910593033\n",
      "Epoch 1, iter 25, loss 3.314085006713867, acc 0.10000000149011612\n",
      "Epoch 1, iter 26, loss 3.189720392227173, acc 0.07000000029802322\n",
      "Epoch 1, iter 27, loss 3.162020206451416, acc 0.09000000357627869\n",
      "Epoch 1, iter 28, loss 3.293710231781006, acc 0.11999999731779099\n",
      "Epoch 1, iter 29, loss 3.1039464473724365, acc 0.10999999940395355\n",
      "Epoch 1, iter 30, loss 3.037038564682007, acc 0.10000000149011612\n",
      "Epoch 1, iter 31, loss 3.1088080406188965, acc 0.09000000357627869\n",
      "Epoch 1, iter 32, loss 2.996457815170288, acc 0.10999999940395355\n",
      "Epoch 1, iter 33, loss 2.985772132873535, acc 0.18000000715255737\n",
      "Epoch 1, iter 34, loss 2.9625563621520996, acc 0.12999999523162842\n",
      "Epoch 1, iter 35, loss 3.081876516342163, acc 0.10999999940395355\n",
      "Epoch 1, iter 36, loss 3.1575021743774414, acc 0.10000000149011612\n",
      "Epoch 1, iter 37, loss 2.9531056880950928, acc 0.10000000149011612\n",
      "Epoch 1, iter 38, loss 3.154930830001831, acc 0.10000000149011612\n",
      "Epoch 1, iter 39, loss 3.1388611793518066, acc 0.09000000357627869\n",
      "Epoch 1, iter 40, loss 3.0518784523010254, acc 0.05999999865889549\n",
      "Epoch 1, iter 41, loss 3.095360040664673, acc 0.10999999940395355\n",
      "Epoch 1, iter 42, loss 3.0749921798706055, acc 0.11999999731779099\n",
      "Epoch 1, iter 43, loss 3.3595457077026367, acc 0.03999999910593033\n",
      "Epoch 1, iter 44, loss 2.981973886489868, acc 0.09000000357627869\n",
      "Epoch 1, iter 45, loss 3.131716012954712, acc 0.05999999865889549\n",
      "Epoch 1, iter 46, loss 3.0627808570861816, acc 0.10000000149011612\n",
      "Epoch 1, iter 47, loss 2.9645888805389404, acc 0.15000000596046448\n",
      "Epoch 1, iter 48, loss 3.2102913856506348, acc 0.03999999910593033\n",
      "Epoch 1, iter 49, loss 2.969336748123169, acc 0.14000000059604645\n",
      "Epoch 1, iter 50, loss 2.9133689403533936, acc 0.10000000149011612\n",
      "Epoch 1, iter 51, loss 3.3085596561431885, acc 0.05999999865889549\n",
      "Epoch 1, iter 52, loss 2.9434814453125, acc 0.17000000178813934\n",
      "Epoch 1, iter 53, loss 3.210198402404785, acc 0.07999999821186066\n",
      "Epoch 1, iter 54, loss 3.1845197677612305, acc 0.03999999910593033\n",
      "Epoch 1, iter 55, loss 3.2216262817382812, acc 0.09000000357627869\n",
      "Epoch 1, iter 56, loss 3.104196786880493, acc 0.05999999865889549\n",
      "Epoch 1, iter 57, loss 2.854074478149414, acc 0.10999999940395355\n",
      "Epoch 1, iter 58, loss 2.9378530979156494, acc 0.07000000029802322\n",
      "Epoch 1, iter 59, loss 2.9452130794525146, acc 0.09000000357627869\n",
      "Epoch 1, iter 60, loss 2.9050955772399902, acc 0.05999999865889549\n",
      "Epoch 1, iter 61, loss 3.1008667945861816, acc 0.05999999865889549\n",
      "Epoch 1, iter 62, loss 3.0324063301086426, acc 0.05999999865889549\n",
      "Epoch 1, iter 63, loss 3.1101343631744385, acc 0.11999999731779099\n",
      "Epoch 1, iter 64, loss 3.1588571071624756, acc 0.05999999865889549\n",
      "Epoch 1, iter 65, loss 3.1653571128845215, acc 0.07999999821186066\n",
      "Epoch 1, iter 66, loss 2.904600143432617, acc 0.11999999731779099\n",
      "Epoch 1, iter 67, loss 3.133000135421753, acc 0.10999999940395355\n",
      "Epoch 1, iter 68, loss 2.909470558166504, acc 0.07999999821186066\n",
      "Epoch 1, iter 69, loss 3.1388721466064453, acc 0.09000000357627869\n",
      "Epoch 1, iter 70, loss 3.041215181350708, acc 0.07999999821186066\n",
      "Epoch 1, iter 71, loss 3.1158883571624756, acc 0.10000000149011612\n",
      "Epoch 1, iter 72, loss 3.185960054397583, acc 0.10999999940395355\n",
      "Epoch 1, iter 73, loss 2.942305088043213, acc 0.07000000029802322\n",
      "Epoch 1, iter 74, loss 2.9247968196868896, acc 0.05999999865889549\n",
      "Epoch 1, iter 75, loss 3.1287243366241455, acc 0.10999999940395355\n",
      "Epoch 1, iter 76, loss 2.9190094470977783, acc 0.03999999910593033\n",
      "Epoch 1, iter 77, loss 2.7690176963806152, acc 0.10000000149011612\n",
      "Epoch 1, iter 78, loss 3.092478036880493, acc 0.05999999865889549\n",
      "Epoch 1, iter 79, loss 2.960092544555664, acc 0.12999999523162842\n",
      "Epoch 1, iter 80, loss 3.1046395301818848, acc 0.07999999821186066\n",
      "Epoch 1, iter 81, loss 2.9394025802612305, acc 0.07999999821186066\n",
      "Epoch 1, iter 82, loss 3.105595111846924, acc 0.05999999865889549\n",
      "Epoch 1, iter 83, loss 2.8628554344177246, acc 0.07999999821186066\n",
      "Epoch 1, iter 84, loss 3.067345380783081, acc 0.07999999821186066\n",
      "Epoch 1, iter 85, loss 2.8881912231445312, acc 0.12999999523162842\n",
      "Epoch 1, iter 86, loss 2.968454599380493, acc 0.10000000149011612\n",
      "Epoch 1, iter 87, loss 2.837547540664673, acc 0.18000000715255737\n",
      "Epoch 1, iter 88, loss 2.8671557903289795, acc 0.10999999940395355\n",
      "Epoch 1, iter 89, loss 2.959822416305542, acc 0.09000000357627869\n",
      "Epoch 1, iter 90, loss 3.1018903255462646, acc 0.09000000357627869\n",
      "Epoch 1, iter 91, loss 2.9276294708251953, acc 0.07999999821186066\n",
      "Epoch 1, iter 92, loss 2.6755669116973877, acc 0.10999999940395355\n",
      "Epoch 1, iter 93, loss 2.972477912902832, acc 0.10000000149011612\n",
      "Epoch 1, iter 94, loss 2.7949700355529785, acc 0.10000000149011612\n",
      "Epoch 1, iter 95, loss 2.8155808448791504, acc 0.07999999821186066\n",
      "Epoch 1, iter 96, loss 2.7568061351776123, acc 0.12999999523162842\n",
      "Epoch 1, iter 97, loss 2.5736513137817383, acc 0.20000000298023224\n",
      "Epoch 1, iter 98, loss 2.916485071182251, acc 0.07000000029802322\n",
      "Epoch 1, iter 99, loss 2.7874927520751953, acc 0.15000000596046448\n",
      "Epoch 1, iter 100, loss 3.105776786804199, acc 0.10000000149011612\n",
      "Epoch 1, iter 101, loss 2.969027519226074, acc 0.07999999821186066\n",
      "Epoch 1, iter 102, loss 2.9495186805725098, acc 0.10999999940395355\n",
      "Epoch 1, iter 103, loss 2.7389004230499268, acc 0.09000000357627869\n",
      "Epoch 1, iter 104, loss 2.7717578411102295, acc 0.07000000029802322\n",
      "Epoch 1, iter 105, loss 2.992889642715454, acc 0.05000000074505806\n",
      "Epoch 1, iter 106, loss 2.8436310291290283, acc 0.11999999731779099\n",
      "Epoch 1, iter 107, loss 2.9302191734313965, acc 0.09000000357627869\n",
      "Epoch 1, iter 108, loss 3.007869005203247, acc 0.11999999731779099\n",
      "Epoch 1, iter 109, loss 2.7945477962493896, acc 0.12999999523162842\n",
      "Epoch 1, iter 110, loss 2.9318981170654297, acc 0.09000000357627869\n",
      "Epoch 1, iter 111, loss 3.1031458377838135, acc 0.07999999821186066\n",
      "Epoch 1, iter 112, loss 3.0935111045837402, acc 0.14000000059604645\n",
      "Epoch 1, iter 113, loss 2.937563180923462, acc 0.11999999731779099\n",
      "Epoch 1, iter 114, loss 2.8883070945739746, acc 0.1599999964237213\n",
      "Epoch 1, iter 115, loss 2.9231972694396973, acc 0.09000000357627869\n",
      "Epoch 1, iter 116, loss 2.8012945652008057, acc 0.10999999940395355\n",
      "Epoch 1, iter 117, loss 3.005793571472168, acc 0.10000000149011612\n",
      "Epoch 1, iter 118, loss 2.8720386028289795, acc 0.11999999731779099\n",
      "Epoch 1, iter 119, loss 2.8897454738616943, acc 0.05000000074505806\n",
      "Epoch 1, iter 120, loss 2.761300563812256, acc 0.12999999523162842\n",
      "Epoch 1, iter 121, loss 2.717005729675293, acc 0.10999999940395355\n",
      "Epoch 1, iter 122, loss 2.839529037475586, acc 0.10999999940395355\n",
      "Epoch 1, iter 123, loss 2.7956173419952393, acc 0.18000000715255737\n",
      "Epoch 1, iter 124, loss 3.01729154586792, acc 0.05000000074505806\n",
      "Epoch 1, iter 125, loss 3.1287221908569336, acc 0.09000000357627869\n",
      "Epoch 1, iter 126, loss 3.0052666664123535, acc 0.11999999731779099\n",
      "Epoch 1, iter 127, loss 2.846492290496826, acc 0.07000000029802322\n",
      "Epoch 1, iter 128, loss 2.846583366394043, acc 0.07000000029802322\n",
      "Epoch 1, iter 129, loss 2.8830034732818604, acc 0.07000000029802322\n",
      "Epoch 1, iter 130, loss 2.7237865924835205, acc 0.11999999731779099\n",
      "Epoch 1, iter 131, loss 2.738436698913574, acc 0.11999999731779099\n",
      "Epoch 1, iter 132, loss 2.8361403942108154, acc 0.10999999940395355\n",
      "Epoch 1, iter 133, loss 2.8201711177825928, acc 0.10000000149011612\n",
      "Epoch 1, iter 134, loss 2.834303855895996, acc 0.10000000149011612\n",
      "Epoch 1, iter 135, loss 2.918379306793213, acc 0.10999999940395355\n",
      "Epoch 1, iter 136, loss 2.9517812728881836, acc 0.07000000029802322\n",
      "Epoch 1, iter 137, loss 2.7500500679016113, acc 0.11999999731779099\n",
      "Epoch 1, iter 138, loss 2.7010338306427, acc 0.05999999865889549\n",
      "Epoch 1, iter 139, loss 2.718567132949829, acc 0.15000000596046448\n",
      "Epoch 1, iter 140, loss 2.734273672103882, acc 0.12999999523162842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 141, loss 2.782973527908325, acc 0.10999999940395355\n",
      "Epoch 1, iter 142, loss 2.952608346939087, acc 0.10000000149011612\n",
      "Epoch 1, iter 143, loss 2.9018068313598633, acc 0.03999999910593033\n",
      "Epoch 1, iter 144, loss 3.007448673248291, acc 0.05999999865889549\n",
      "Epoch 1, iter 145, loss 2.7799112796783447, acc 0.11999999731779099\n",
      "Epoch 1, iter 146, loss 2.84248685836792, acc 0.05000000074505806\n",
      "Epoch 1, iter 147, loss 2.8628857135772705, acc 0.07999999821186066\n",
      "Epoch 1, iter 148, loss 2.792958974838257, acc 0.09000000357627869\n",
      "Epoch 1, iter 149, loss 2.9257161617279053, acc 0.10999999940395355\n",
      "Epoch 1, iter 150, loss 2.6202399730682373, acc 0.10000000149011612\n",
      "Epoch 1, iter 151, loss 2.753852128982544, acc 0.10000000149011612\n",
      "Epoch 1, iter 152, loss 2.8701324462890625, acc 0.05000000074505806\n",
      "Epoch 1, iter 153, loss 2.967689275741577, acc 0.10999999940395355\n",
      "Epoch 1, iter 154, loss 2.9007132053375244, acc 0.10999999940395355\n",
      "Epoch 1, iter 155, loss 2.7764880657196045, acc 0.11999999731779099\n",
      "Epoch 1, iter 156, loss 2.5777597427368164, acc 0.15000000596046448\n",
      "Epoch 1, iter 157, loss 2.978628635406494, acc 0.05000000074505806\n",
      "Epoch 1, iter 158, loss 2.7740378379821777, acc 0.10999999940395355\n",
      "Epoch 1, iter 159, loss 2.8397183418273926, acc 0.03999999910593033\n",
      "Epoch 1, iter 160, loss 2.815476655960083, acc 0.09000000357627869\n",
      "Epoch 1, iter 161, loss 2.799626111984253, acc 0.11999999731779099\n",
      "Epoch 1, iter 162, loss 2.681056261062622, acc 0.05999999865889549\n",
      "Epoch 1, iter 163, loss 2.8005521297454834, acc 0.11999999731779099\n",
      "Epoch 1, iter 164, loss 2.8855013847351074, acc 0.11999999731779099\n",
      "Epoch 1, iter 165, loss 2.8341078758239746, acc 0.09000000357627869\n",
      "Epoch 1, iter 166, loss 2.901684522628784, acc 0.029999999329447746\n",
      "Epoch 1, iter 167, loss 2.720848321914673, acc 0.12999999523162842\n",
      "Epoch 1, iter 168, loss 2.6760387420654297, acc 0.12999999523162842\n",
      "Epoch 1, iter 169, loss 2.795180320739746, acc 0.09000000357627869\n",
      "Epoch 1, iter 170, loss 3.0308585166931152, acc 0.07999999821186066\n",
      "Epoch 1, iter 171, loss 2.8050808906555176, acc 0.10999999940395355\n",
      "Epoch 1, iter 172, loss 2.767289638519287, acc 0.07999999821186066\n",
      "Epoch 1, iter 173, loss 2.7354860305786133, acc 0.1599999964237213\n",
      "Epoch 1, iter 174, loss 2.658451557159424, acc 0.07000000029802322\n",
      "Epoch 1, iter 175, loss 2.913606882095337, acc 0.05999999865889549\n",
      "Epoch 1, iter 176, loss 2.872117042541504, acc 0.09000000357627869\n",
      "Epoch 1, iter 177, loss 2.6580324172973633, acc 0.07000000029802322\n",
      "Epoch 1, iter 178, loss 2.7830681800842285, acc 0.10000000149011612\n",
      "Epoch 1, iter 179, loss 2.739912748336792, acc 0.14000000059604645\n",
      "Epoch 1, iter 180, loss 2.832998275756836, acc 0.05000000074505806\n",
      "Epoch 1, iter 181, loss 2.5414810180664062, acc 0.12999999523162842\n",
      "Epoch 1, iter 182, loss 2.768819570541382, acc 0.12999999523162842\n",
      "Epoch 1, iter 183, loss 2.8224751949310303, acc 0.09000000357627869\n",
      "Epoch 1, iter 184, loss 2.718575954437256, acc 0.10000000149011612\n",
      "Epoch 1, iter 185, loss 2.6801881790161133, acc 0.09000000357627869\n",
      "Epoch 1, iter 186, loss 2.8364925384521484, acc 0.09000000357627869\n",
      "Epoch 1, iter 187, loss 2.835998296737671, acc 0.05000000074505806\n",
      "Epoch 1, iter 188, loss 2.7023022174835205, acc 0.07999999821186066\n",
      "Epoch 1, iter 189, loss 2.705012321472168, acc 0.05999999865889549\n",
      "Epoch 1, iter 190, loss 2.7083041667938232, acc 0.07999999821186066\n",
      "Epoch 1, iter 191, loss 2.637064218521118, acc 0.12999999523162842\n",
      "Epoch 1, iter 192, loss 2.8842053413391113, acc 0.05999999865889549\n",
      "Epoch 1, iter 193, loss 2.620779037475586, acc 0.09000000357627869\n",
      "Epoch 1, iter 194, loss 2.761626958847046, acc 0.07999999821186066\n",
      "Epoch 1, iter 195, loss 2.694493055343628, acc 0.07999999821186066\n",
      "Epoch 1, iter 196, loss 2.7451741695404053, acc 0.12999999523162842\n",
      "Epoch 1, iter 197, loss 2.7174196243286133, acc 0.07000000029802322\n",
      "Epoch 1, iter 198, loss 2.758151054382324, acc 0.05999999865889549\n",
      "Epoch 1, iter 199, loss 2.6707959175109863, acc 0.05999999865889549\n",
      "Epoch 1, iter 200, loss 2.722407817840576, acc 0.09000000357627869\n",
      "Epoch 1, iter 201, loss 2.834684133529663, acc 0.05000000074505806\n",
      "Epoch 1, iter 202, loss 2.6615400314331055, acc 0.07999999821186066\n",
      "Epoch 1, iter 203, loss 2.8775250911712646, acc 0.07999999821186066\n",
      "Epoch 1, iter 204, loss 2.8997790813446045, acc 0.07999999821186066\n",
      "Epoch 1, iter 205, loss 2.7140908241271973, acc 0.05999999865889549\n",
      "Epoch 1, iter 206, loss 2.639967679977417, acc 0.09000000357627869\n",
      "Epoch 1, iter 207, loss 2.627375602722168, acc 0.07999999821186066\n",
      "Epoch 1, iter 208, loss 2.6474902629852295, acc 0.12999999523162842\n",
      "Epoch 1, iter 209, loss 2.6164159774780273, acc 0.10999999940395355\n",
      "Epoch 1, iter 210, loss 2.762953758239746, acc 0.10000000149011612\n",
      "Epoch 1, iter 211, loss 2.8324661254882812, acc 0.07999999821186066\n",
      "Epoch 1, iter 212, loss 2.75972318649292, acc 0.05999999865889549\n",
      "Epoch 1, iter 213, loss 2.660550117492676, acc 0.07000000029802322\n",
      "Epoch 1, iter 214, loss 2.732908010482788, acc 0.10999999940395355\n",
      "Epoch 1, iter 215, loss 2.6836061477661133, acc 0.10999999940395355\n",
      "Epoch 1, iter 216, loss 2.703749418258667, acc 0.11999999731779099\n",
      "Epoch 1, iter 217, loss 2.747433662414551, acc 0.07000000029802322\n",
      "Epoch 1, iter 218, loss 2.626168727874756, acc 0.10000000149011612\n",
      "Epoch 1, iter 219, loss 2.6651549339294434, acc 0.15000000596046448\n",
      "Epoch 1, iter 220, loss 2.801676034927368, acc 0.03999999910593033\n",
      "Epoch 1, iter 221, loss 2.6880037784576416, acc 0.09000000357627869\n",
      "Epoch 1, iter 222, loss 2.5321996212005615, acc 0.10000000149011612\n",
      "Epoch 1, iter 223, loss 2.6721572875976562, acc 0.07000000029802322\n",
      "Epoch 1, iter 224, loss 2.598405361175537, acc 0.09000000357627869\n",
      "Epoch 1, iter 225, loss 2.784313678741455, acc 0.10000000149011612\n",
      "Epoch 1, iter 226, loss 2.808912754058838, acc 0.05999999865889549\n",
      "Epoch 1, iter 227, loss 2.6026995182037354, acc 0.07999999821186066\n",
      "Epoch 1, iter 228, loss 2.569669246673584, acc 0.11999999731779099\n",
      "Epoch 1, iter 229, loss 2.751472234725952, acc 0.07000000029802322\n",
      "Epoch 1, iter 230, loss 2.6902315616607666, acc 0.09000000357627869\n",
      "Epoch 1, iter 231, loss 2.8513991832733154, acc 0.07000000029802322\n",
      "Epoch 1, iter 232, loss 2.6806859970092773, acc 0.10000000149011612\n",
      "Epoch 1, iter 233, loss 2.583021879196167, acc 0.09000000357627869\n",
      "Epoch 1, iter 234, loss 2.7398879528045654, acc 0.03999999910593033\n",
      "Epoch 1, iter 235, loss 2.561499834060669, acc 0.07999999821186066\n",
      "Epoch 1, iter 236, loss 2.6910345554351807, acc 0.05999999865889549\n",
      "Epoch 1, iter 237, loss 2.616198778152466, acc 0.10999999940395355\n",
      "Epoch 1, iter 238, loss 2.6116528511047363, acc 0.07999999821186066\n",
      "Epoch 1, iter 239, loss 2.6227219104766846, acc 0.10000000149011612\n",
      "Epoch 1, iter 240, loss 2.6128342151641846, acc 0.12999999523162842\n",
      "Epoch 1, iter 241, loss 2.7104196548461914, acc 0.10000000149011612\n",
      "Epoch 1, iter 242, loss 2.663128137588501, acc 0.09000000357627869\n",
      "Epoch 1, iter 243, loss 2.577575922012329, acc 0.11999999731779099\n",
      "Epoch 1, iter 244, loss 2.6168668270111084, acc 0.09000000357627869\n",
      "Epoch 1, iter 245, loss 2.6210436820983887, acc 0.11999999731779099\n",
      "Epoch 1, iter 246, loss 2.7370848655700684, acc 0.07000000029802322\n",
      "Epoch 1, iter 247, loss 2.6636199951171875, acc 0.07000000029802322\n",
      "Epoch 1, iter 248, loss 2.6897194385528564, acc 0.10999999940395355\n",
      "Epoch 1, iter 249, loss 2.638270616531372, acc 0.10999999940395355\n",
      "Epoch 1, iter 250, loss 2.656543493270874, acc 0.10000000149011612\n",
      "Epoch 1, iter 251, loss 2.658111572265625, acc 0.05000000074505806\n",
      "Epoch 1, iter 252, loss 2.6483054161071777, acc 0.10000000149011612\n",
      "Epoch 1, iter 253, loss 2.5772249698638916, acc 0.11999999731779099\n",
      "Epoch 1, iter 254, loss 2.6734824180603027, acc 0.07999999821186066\n",
      "Epoch 1, iter 255, loss 2.8607287406921387, acc 0.05000000074505806\n",
      "Epoch 1, iter 256, loss 2.589150905609131, acc 0.11999999731779099\n",
      "Epoch 1, iter 257, loss 2.6576545238494873, acc 0.09000000357627869\n",
      "Epoch 1, iter 258, loss 2.670470952987671, acc 0.09000000357627869\n",
      "Epoch 1, iter 259, loss 2.6664414405822754, acc 0.10000000149011612\n",
      "Epoch 1, iter 260, loss 2.7432467937469482, acc 0.05999999865889549\n",
      "Epoch 1, iter 261, loss 2.67781138420105, acc 0.10000000149011612\n",
      "Epoch 1, iter 262, loss 2.737710952758789, acc 0.05999999865889549\n",
      "Epoch 1, iter 263, loss 2.711646795272827, acc 0.03999999910593033\n",
      "Epoch 1, iter 264, loss 2.622835397720337, acc 0.07000000029802322\n",
      "Epoch 1, iter 265, loss 2.6365714073181152, acc 0.14000000059604645\n",
      "Epoch 1, iter 266, loss 2.6260368824005127, acc 0.10000000149011612\n",
      "Epoch 1, iter 267, loss 2.6732234954833984, acc 0.10000000149011612\n",
      "Epoch 1, iter 268, loss 2.5926337242126465, acc 0.14000000059604645\n",
      "Epoch 1, iter 269, loss 2.5542380809783936, acc 0.10000000149011612\n",
      "Epoch 1, iter 270, loss 2.662381172180176, acc 0.07000000029802322\n",
      "Epoch 1, iter 271, loss 2.652186393737793, acc 0.07999999821186066\n",
      "Epoch 1, iter 272, loss 2.706869602203369, acc 0.03999999910593033\n",
      "Epoch 1, iter 273, loss 2.6327567100524902, acc 0.07000000029802322\n",
      "Epoch 1, iter 274, loss 2.592256546020508, acc 0.15000000596046448\n",
      "Epoch 1, iter 275, loss 2.709322929382324, acc 0.03999999910593033\n",
      "Epoch 1, iter 276, loss 2.648674964904785, acc 0.12999999523162842\n",
      "Epoch 1, iter 277, loss 2.462519884109497, acc 0.10000000149011612\n",
      "Epoch 1, iter 278, loss 2.534576892852783, acc 0.09000000357627869\n",
      "Epoch 1, iter 279, loss 2.7110838890075684, acc 0.09000000357627869\n",
      "Epoch 1, iter 280, loss 2.5129213333129883, acc 0.09000000357627869\n",
      "Epoch 1, iter 281, loss 2.707897424697876, acc 0.05000000074505806\n",
      "Epoch 1, iter 282, loss 2.8189196586608887, acc 0.05000000074505806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 283, loss 2.7210488319396973, acc 0.10000000149011612\n",
      "Epoch 1, iter 284, loss 2.5523858070373535, acc 0.07000000029802322\n",
      "Epoch 1, iter 285, loss 2.5406339168548584, acc 0.12999999523162842\n",
      "Epoch 1, iter 286, loss 2.5500071048736572, acc 0.03999999910593033\n",
      "Epoch 1, iter 287, loss 2.634793996810913, acc 0.09000000357627869\n",
      "Epoch 1, iter 288, loss 2.6051907539367676, acc 0.10000000149011612\n",
      "Epoch 1, iter 289, loss 2.5291757583618164, acc 0.14000000059604645\n",
      "Epoch 1, iter 290, loss 2.667059898376465, acc 0.07000000029802322\n",
      "Epoch 1, iter 291, loss 2.62869930267334, acc 0.07000000029802322\n",
      "Epoch 1, iter 292, loss 2.6922457218170166, acc 0.10000000149011612\n",
      "Epoch 1, iter 293, loss 2.631871223449707, acc 0.07999999821186066\n",
      "Epoch 1, iter 294, loss 2.539203643798828, acc 0.15000000596046448\n",
      "Epoch 1, iter 295, loss 2.5148513317108154, acc 0.09000000357627869\n",
      "Epoch 1, iter 296, loss 2.661358594894409, acc 0.10000000149011612\n",
      "Epoch 1, iter 297, loss 2.6222472190856934, acc 0.05000000074505806\n",
      "Epoch 1, iter 298, loss 2.4489247798919678, acc 0.07999999821186066\n",
      "Epoch 1, iter 299, loss 2.5284759998321533, acc 0.10999999940395355\n",
      "Epoch 1, iter 300, loss 2.714836359024048, acc 0.05999999865889549\n",
      "Epoch 1, iter 301, loss 2.62968111038208, acc 0.07999999821186066\n",
      "Epoch 1, iter 302, loss 2.5517563819885254, acc 0.07999999821186066\n",
      "Epoch 1, iter 303, loss 2.6069753170013428, acc 0.07999999821186066\n",
      "Epoch 1, iter 304, loss 2.678676128387451, acc 0.05000000074505806\n",
      "Epoch 1, iter 305, loss 2.6615915298461914, acc 0.10000000149011612\n",
      "Epoch 1, iter 306, loss 2.672638177871704, acc 0.05999999865889549\n",
      "Epoch 1, iter 307, loss 2.62247371673584, acc 0.10000000149011612\n",
      "Epoch 1, iter 308, loss 2.570168972015381, acc 0.10999999940395355\n",
      "Epoch 1, iter 309, loss 2.603053092956543, acc 0.07000000029802322\n",
      "Epoch 1, iter 310, loss 2.595755100250244, acc 0.11999999731779099\n",
      "Epoch 1, iter 311, loss 2.546304225921631, acc 0.05999999865889549\n",
      "Epoch 1, iter 312, loss 2.657818555831909, acc 0.07999999821186066\n",
      "Epoch 1, iter 313, loss 2.7977423667907715, acc 0.10999999940395355\n",
      "Epoch 1, iter 314, loss 2.549036979675293, acc 0.05000000074505806\n",
      "Epoch 1, iter 315, loss 2.66237211227417, acc 0.03999999910593033\n",
      "Epoch 1, iter 316, loss 2.522470474243164, acc 0.07000000029802322\n",
      "Epoch 1, iter 317, loss 2.7071783542633057, acc 0.07999999821186066\n",
      "Epoch 1, iter 318, loss 2.6078522205352783, acc 0.05000000074505806\n",
      "Epoch 1, iter 319, loss 2.4943675994873047, acc 0.10000000149011612\n",
      "Epoch 1, iter 320, loss 2.418968915939331, acc 0.14000000059604645\n",
      "Epoch 1, iter 321, loss 2.5584769248962402, acc 0.14000000059604645\n",
      "Epoch 1, iter 322, loss 2.518268585205078, acc 0.10000000149011612\n",
      "Epoch 1, iter 323, loss 2.569399118423462, acc 0.14000000059604645\n",
      "Epoch 1, iter 324, loss 2.640841484069824, acc 0.05999999865889549\n",
      "Epoch 1, iter 325, loss 2.601363182067871, acc 0.09000000357627869\n",
      "Epoch 1, iter 326, loss 2.5336647033691406, acc 0.07000000029802322\n",
      "Epoch 1, iter 327, loss 2.5218393802642822, acc 0.09000000357627869\n",
      "Epoch 1, iter 328, loss 2.606051445007324, acc 0.07999999821186066\n",
      "Epoch 1, iter 329, loss 2.5566976070404053, acc 0.14000000059604645\n",
      "Epoch 1, iter 330, loss 2.5209264755249023, acc 0.07999999821186066\n",
      "Epoch 1, iter 331, loss 2.5323526859283447, acc 0.05999999865889549\n",
      "Epoch 1, iter 332, loss 2.5551071166992188, acc 0.10000000149011612\n",
      "Epoch 1, iter 333, loss 2.556868076324463, acc 0.09000000357627869\n",
      "Epoch 1, iter 334, loss 2.708055019378662, acc 0.05000000074505806\n",
      "Epoch 1, iter 335, loss 2.50154447555542, acc 0.12999999523162842\n",
      "Epoch 1, iter 336, loss 2.6224870681762695, acc 0.10000000149011612\n",
      "Epoch 1, iter 337, loss 2.6129727363586426, acc 0.10999999940395355\n",
      "Epoch 1, iter 338, loss 2.506222724914551, acc 0.10000000149011612\n",
      "Epoch 1, iter 339, loss 2.527399778366089, acc 0.09000000357627869\n",
      "Epoch 1, iter 340, loss 2.7174150943756104, acc 0.05000000074505806\n",
      "Epoch 1, iter 341, loss 2.498257637023926, acc 0.07000000029802322\n",
      "Epoch 1, iter 342, loss 2.613093376159668, acc 0.07000000029802322\n",
      "Epoch 1, iter 343, loss 2.6109728813171387, acc 0.09000000357627869\n",
      "Epoch 1, iter 344, loss 2.634232759475708, acc 0.14000000059604645\n",
      "Epoch 1, iter 345, loss 2.5917086601257324, acc 0.11999999731779099\n",
      "Epoch 1, iter 346, loss 2.6638479232788086, acc 0.07000000029802322\n",
      "Epoch 1, iter 347, loss 2.580197811126709, acc 0.07999999821186066\n",
      "Epoch 1, iter 348, loss 2.625645637512207, acc 0.07000000029802322\n",
      "Epoch 1, iter 349, loss 2.485177516937256, acc 0.15000000596046448\n",
      "Epoch 1, iter 350, loss 2.4422264099121094, acc 0.10000000149011612\n",
      "Epoch 1, iter 351, loss 2.451219320297241, acc 0.07000000029802322\n",
      "Epoch 1, iter 352, loss 2.505232334136963, acc 0.10999999940395355\n",
      "Epoch 1, iter 353, loss 2.6770248413085938, acc 0.09000000357627869\n",
      "Epoch 1, iter 354, loss 2.6371068954467773, acc 0.03999999910593033\n",
      "Epoch 1, iter 355, loss 2.614069938659668, acc 0.10000000149011612\n",
      "Epoch 1, iter 356, loss 2.471104383468628, acc 0.1599999964237213\n",
      "Epoch 1, iter 357, loss 2.55351185798645, acc 0.07999999821186066\n",
      "Epoch 1, iter 358, loss 2.376849889755249, acc 0.10000000149011612\n",
      "Epoch 1, iter 359, loss 2.6578714847564697, acc 0.029999999329447746\n",
      "Epoch 1, iter 360, loss 2.576899528503418, acc 0.05999999865889549\n",
      "Epoch 1, iter 361, loss 2.5153610706329346, acc 0.07000000029802322\n",
      "Epoch 1, iter 362, loss 2.6070337295532227, acc 0.05999999865889549\n",
      "Epoch 1, iter 363, loss 2.5767905712127686, acc 0.14000000059604645\n",
      "Epoch 1, iter 364, loss 2.6710240840911865, acc 0.10000000149011612\n",
      "Epoch 1, iter 365, loss 2.569150924682617, acc 0.07000000029802322\n",
      "Epoch 1, iter 366, loss 2.626084804534912, acc 0.07999999821186066\n",
      "Epoch 1, iter 367, loss 2.471034526824951, acc 0.09000000357627869\n",
      "Epoch 1, iter 368, loss 2.551713705062866, acc 0.07999999821186066\n",
      "Epoch 1, iter 369, loss 2.505478620529175, acc 0.07999999821186066\n",
      "Epoch 1, iter 370, loss 2.5724706649780273, acc 0.10000000149011612\n",
      "Epoch 1, iter 371, loss 2.5715267658233643, acc 0.10999999940395355\n",
      "Epoch 1, iter 372, loss 2.399629831314087, acc 0.17000000178813934\n",
      "Epoch 1, iter 373, loss 2.5093834400177, acc 0.09000000357627869\n",
      "Epoch 1, iter 374, loss 2.5922744274139404, acc 0.09000000357627869\n",
      "Epoch 1, iter 375, loss 2.5846238136291504, acc 0.09000000357627869\n",
      "Epoch 1, iter 376, loss 2.5910937786102295, acc 0.05999999865889549\n",
      "Epoch 1, iter 377, loss 2.5674026012420654, acc 0.05999999865889549\n",
      "Epoch 1, iter 378, loss 2.5066041946411133, acc 0.10999999940395355\n",
      "Epoch 1, iter 379, loss 2.5682663917541504, acc 0.07999999821186066\n",
      "Epoch 1, iter 380, loss 2.6207685470581055, acc 0.09000000357627869\n",
      "Epoch 1, iter 381, loss 2.5381710529327393, acc 0.10000000149011612\n",
      "Epoch 1, iter 382, loss 2.554891586303711, acc 0.07999999821186066\n",
      "Epoch 1, iter 383, loss 2.454712390899658, acc 0.14000000059604645\n",
      "Epoch 1, iter 384, loss 2.512686252593994, acc 0.10999999940395355\n",
      "Epoch 1, iter 385, loss 2.5530288219451904, acc 0.07999999821186066\n",
      "Epoch 1, iter 386, loss 2.5543694496154785, acc 0.09000000357627869\n",
      "Epoch 1, iter 387, loss 2.681001663208008, acc 0.07000000029802322\n",
      "Epoch 1, iter 388, loss 2.544724225997925, acc 0.05999999865889549\n",
      "Epoch 1, iter 389, loss 2.4369611740112305, acc 0.10999999940395355\n",
      "Epoch 1, iter 390, loss 2.580842971801758, acc 0.05000000074505806\n",
      "Epoch 1, iter 391, loss 2.560530185699463, acc 0.10999999940395355\n",
      "Epoch 1, iter 392, loss 2.5049021244049072, acc 0.09000000357627869\n",
      "Epoch 1, iter 393, loss 2.515281915664673, acc 0.09000000357627869\n",
      "Epoch 1, iter 394, loss 2.7920775413513184, acc 0.07000000029802322\n",
      "Epoch 1, iter 395, loss 2.615055799484253, acc 0.03999999910593033\n",
      "Epoch 1, iter 396, loss 2.508300304412842, acc 0.05000000074505806\n",
      "Epoch 1, iter 397, loss 2.5590178966522217, acc 0.07000000029802322\n",
      "Epoch 1, iter 398, loss 2.4257259368896484, acc 0.11999999731779099\n",
      "Epoch 1, iter 399, loss 2.559627056121826, acc 0.03999999910593033\n",
      "Epoch 1, iter 400, loss 2.5122413635253906, acc 0.05999999865889549\n",
      "Epoch 1, iter 401, loss 2.5346665382385254, acc 0.15000000596046448\n",
      "Epoch 1, iter 402, loss 2.4663023948669434, acc 0.10000000149011612\n",
      "Epoch 1, iter 403, loss 2.4150333404541016, acc 0.029999999329447746\n",
      "Epoch 1, iter 404, loss 2.5760109424591064, acc 0.07000000029802322\n",
      "Epoch 1, iter 405, loss 2.5868899822235107, acc 0.10000000149011612\n",
      "Epoch 1, iter 406, loss 2.596665859222412, acc 0.10999999940395355\n",
      "Epoch 1, iter 407, loss 2.5750436782836914, acc 0.05999999865889549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 408, loss 2.5014216899871826, acc 0.12999999523162842\n",
      "Epoch 1, iter 409, loss 2.6293396949768066, acc 0.09000000357627869\n",
      "Epoch 1, iter 410, loss 2.598235845565796, acc 0.07999999821186066\n",
      "Epoch 1, iter 411, loss 2.5493361949920654, acc 0.07000000029802322\n",
      "Epoch 1, iter 412, loss 2.511396884918213, acc 0.09000000357627869\n",
      "Epoch 1, iter 413, loss 2.564298629760742, acc 0.07000000029802322\n",
      "Epoch 1, iter 414, loss 2.637518882751465, acc 0.07000000029802322\n",
      "Epoch 1, iter 415, loss 2.5690972805023193, acc 0.07999999821186066\n",
      "Epoch 1, iter 416, loss 2.522996664047241, acc 0.07999999821186066\n",
      "Epoch 1, iter 417, loss 2.5448532104492188, acc 0.10000000149011612\n",
      "Epoch 1, iter 418, loss 2.583062171936035, acc 0.05999999865889549\n",
      "Epoch 1, iter 419, loss 2.5512473583221436, acc 0.07999999821186066\n",
      "Epoch 1, iter 420, loss 2.512557029724121, acc 0.10999999940395355\n",
      "Epoch 2, iter 1, loss 2.601569890975952, acc 0.07999999821186066\n",
      "Epoch 2, iter 2, loss 2.478358268737793, acc 0.11999999731779099\n",
      "Epoch 2, iter 3, loss 2.552988052368164, acc 0.03999999910593033\n",
      "Epoch 2, iter 4, loss 2.497767925262451, acc 0.10999999940395355\n",
      "Epoch 2, iter 5, loss 2.5155179500579834, acc 0.10000000149011612\n",
      "Epoch 2, iter 6, loss 2.533640146255493, acc 0.09000000357627869\n",
      "Epoch 2, iter 7, loss 2.421809196472168, acc 0.10000000149011612\n",
      "Epoch 2, iter 8, loss 2.4267194271087646, acc 0.09000000357627869\n",
      "Epoch 2, iter 9, loss 2.5269107818603516, acc 0.07000000029802322\n",
      "Epoch 2, iter 10, loss 2.543274164199829, acc 0.07999999821186066\n",
      "Epoch 2, iter 11, loss 2.4911837577819824, acc 0.09000000357627869\n",
      "Epoch 2, iter 12, loss 2.4628915786743164, acc 0.10000000149011612\n",
      "Epoch 2, iter 13, loss 2.5151185989379883, acc 0.10000000149011612\n",
      "Epoch 2, iter 14, loss 2.5937671661376953, acc 0.05999999865889549\n",
      "Epoch 2, iter 15, loss 2.571195125579834, acc 0.05000000074505806\n",
      "Epoch 2, iter 16, loss 2.5790600776672363, acc 0.07000000029802322\n",
      "Epoch 2, iter 17, loss 2.5418384075164795, acc 0.10000000149011612\n",
      "Epoch 2, iter 18, loss 2.5499019622802734, acc 0.10999999940395355\n",
      "Epoch 2, iter 19, loss 2.6229331493377686, acc 0.10000000149011612\n",
      "Epoch 2, iter 20, loss 2.3999648094177246, acc 0.15000000596046448\n",
      "Epoch 2, iter 21, loss 2.6008224487304688, acc 0.07999999821186066\n",
      "Epoch 2, iter 22, loss 2.63249135017395, acc 0.07999999821186066\n",
      "Epoch 2, iter 23, loss 2.5601611137390137, acc 0.10999999940395355\n",
      "Epoch 2, iter 24, loss 2.4454140663146973, acc 0.11999999731779099\n",
      "Epoch 2, iter 25, loss 2.557387113571167, acc 0.12999999523162842\n",
      "Epoch 2, iter 26, loss 2.491198778152466, acc 0.12999999523162842\n",
      "Epoch 2, iter 27, loss 2.5158698558807373, acc 0.09000000357627869\n",
      "Epoch 2, iter 28, loss 2.6686172485351562, acc 0.07000000029802322\n",
      "Epoch 2, iter 29, loss 2.513612985610962, acc 0.09000000357627869\n",
      "Epoch 2, iter 30, loss 2.4914426803588867, acc 0.11999999731779099\n",
      "Epoch 2, iter 31, loss 2.5635666847229004, acc 0.09000000357627869\n",
      "Epoch 2, iter 32, loss 2.4622039794921875, acc 0.14000000059604645\n",
      "Epoch 2, iter 33, loss 2.5014617443084717, acc 0.09000000357627869\n",
      "Epoch 2, iter 34, loss 2.523472309112549, acc 0.11999999731779099\n",
      "Epoch 2, iter 35, loss 2.4922804832458496, acc 0.09000000357627869\n",
      "Epoch 2, iter 36, loss 2.5364584922790527, acc 0.11999999731779099\n",
      "Epoch 2, iter 37, loss 2.4507761001586914, acc 0.11999999731779099\n",
      "Epoch 2, iter 38, loss 2.5137243270874023, acc 0.09000000357627869\n",
      "Epoch 2, iter 39, loss 2.514543294906616, acc 0.07999999821186066\n",
      "Epoch 2, iter 40, loss 2.5227911472320557, acc 0.10000000149011612\n",
      "Epoch 2, iter 41, loss 2.53417706489563, acc 0.07999999821186066\n",
      "Epoch 2, iter 42, loss 2.5183115005493164, acc 0.07999999821186066\n",
      "Epoch 2, iter 43, loss 2.582047700881958, acc 0.10000000149011612\n",
      "Epoch 2, iter 44, loss 2.466240167617798, acc 0.07999999821186066\n",
      "Epoch 2, iter 45, loss 2.5816292762756348, acc 0.07000000029802322\n",
      "Epoch 2, iter 46, loss 2.511579990386963, acc 0.07999999821186066\n",
      "Epoch 2, iter 47, loss 2.4710896015167236, acc 0.07999999821186066\n",
      "Epoch 2, iter 48, loss 2.5516269207000732, acc 0.07000000029802322\n",
      "Epoch 2, iter 49, loss 2.517488956451416, acc 0.15000000596046448\n",
      "Epoch 2, iter 50, loss 2.390306234359741, acc 0.11999999731779099\n",
      "Epoch 2, iter 51, loss 2.57511043548584, acc 0.05999999865889549\n",
      "Epoch 2, iter 52, loss 2.5171196460723877, acc 0.14000000059604645\n",
      "Epoch 2, iter 53, loss 2.539125919342041, acc 0.10999999940395355\n",
      "Epoch 2, iter 54, loss 2.4702417850494385, acc 0.05999999865889549\n",
      "Epoch 2, iter 55, loss 2.573897361755371, acc 0.09000000357627869\n",
      "Epoch 2, iter 56, loss 2.4937593936920166, acc 0.11999999731779099\n",
      "Epoch 2, iter 57, loss 2.397719144821167, acc 0.11999999731779099\n",
      "Epoch 2, iter 58, loss 2.4662177562713623, acc 0.05999999865889549\n",
      "Epoch 2, iter 59, loss 2.484825372695923, acc 0.10000000149011612\n",
      "Epoch 2, iter 60, loss 2.5037851333618164, acc 0.09000000357627869\n",
      "Epoch 2, iter 61, loss 2.513759136199951, acc 0.11999999731779099\n",
      "Epoch 2, iter 62, loss 2.4477524757385254, acc 0.07000000029802322\n",
      "Epoch 2, iter 63, loss 2.5217320919036865, acc 0.07999999821186066\n",
      "Epoch 2, iter 64, loss 2.5525903701782227, acc 0.07000000029802322\n",
      "Epoch 2, iter 65, loss 2.535737991333008, acc 0.05000000074505806\n",
      "Epoch 2, iter 66, loss 2.5327200889587402, acc 0.05999999865889549\n",
      "Epoch 2, iter 67, loss 2.5260539054870605, acc 0.1599999964237213\n",
      "Epoch 2, iter 68, loss 2.4648890495300293, acc 0.05999999865889549\n",
      "Epoch 2, iter 69, loss 2.5318543910980225, acc 0.10000000149011612\n",
      "Epoch 2, iter 70, loss 2.5003528594970703, acc 0.10999999940395355\n",
      "Epoch 2, iter 71, loss 2.5484955310821533, acc 0.09000000357627869\n",
      "Epoch 2, iter 72, loss 2.6198225021362305, acc 0.07999999821186066\n",
      "Epoch 2, iter 73, loss 2.46401309967041, acc 0.07999999821186066\n",
      "Epoch 2, iter 74, loss 2.4362497329711914, acc 0.10999999940395355\n",
      "Epoch 2, iter 75, loss 2.5684781074523926, acc 0.10000000149011612\n",
      "Epoch 2, iter 76, loss 2.4602742195129395, acc 0.11999999731779099\n",
      "Epoch 2, iter 77, loss 2.408113956451416, acc 0.10000000149011612\n",
      "Epoch 2, iter 78, loss 2.4844725131988525, acc 0.11999999731779099\n",
      "Epoch 2, iter 79, loss 2.430189609527588, acc 0.11999999731779099\n",
      "Epoch 2, iter 80, loss 2.5551085472106934, acc 0.05000000074505806\n",
      "Epoch 2, iter 81, loss 2.455460548400879, acc 0.07999999821186066\n",
      "Epoch 2, iter 82, loss 2.498774766921997, acc 0.10999999940395355\n",
      "Epoch 2, iter 83, loss 2.5123651027679443, acc 0.10999999940395355\n",
      "Epoch 2, iter 84, loss 2.5753817558288574, acc 0.07999999821186066\n",
      "Epoch 2, iter 85, loss 2.4505786895751953, acc 0.14000000059604645\n",
      "Epoch 2, iter 86, loss 2.478856086730957, acc 0.07000000029802322\n",
      "Epoch 2, iter 87, loss 2.346501588821411, acc 0.1899999976158142\n",
      "Epoch 2, iter 88, loss 2.426234245300293, acc 0.10000000149011612\n",
      "Epoch 2, iter 89, loss 2.5510904788970947, acc 0.07000000029802322\n",
      "Epoch 2, iter 90, loss 2.551889419555664, acc 0.07000000029802322\n",
      "Epoch 2, iter 91, loss 2.4413387775421143, acc 0.10999999940395355\n",
      "Epoch 2, iter 92, loss 2.3234150409698486, acc 0.09000000357627869\n",
      "Epoch 2, iter 93, loss 2.5488998889923096, acc 0.05999999865889549\n",
      "Epoch 2, iter 94, loss 2.456570625305176, acc 0.09000000357627869\n",
      "Epoch 2, iter 95, loss 2.4843688011169434, acc 0.07999999821186066\n",
      "Epoch 2, iter 96, loss 2.4013309478759766, acc 0.11999999731779099\n",
      "Epoch 2, iter 97, loss 2.396172285079956, acc 0.10999999940395355\n",
      "Epoch 2, iter 98, loss 2.5086536407470703, acc 0.07000000029802322\n",
      "Epoch 2, iter 99, loss 2.4275143146514893, acc 0.14000000059604645\n",
      "Epoch 2, iter 100, loss 2.625622272491455, acc 0.05000000074505806\n",
      "Epoch 2, iter 101, loss 2.5861258506774902, acc 0.07999999821186066\n",
      "Epoch 2, iter 102, loss 2.5370371341705322, acc 0.10000000149011612\n",
      "Epoch 2, iter 103, loss 2.4520256519317627, acc 0.10999999940395355\n",
      "Epoch 2, iter 104, loss 2.3895318508148193, acc 0.12999999523162842\n",
      "Epoch 2, iter 105, loss 2.5309646129608154, acc 0.07000000029802322\n",
      "Epoch 2, iter 106, loss 2.4633560180664062, acc 0.10000000149011612\n",
      "Epoch 2, iter 107, loss 2.4588091373443604, acc 0.10000000149011612\n",
      "Epoch 2, iter 108, loss 2.5277178287506104, acc 0.10999999940395355\n",
      "Epoch 2, iter 109, loss 2.4906647205352783, acc 0.09000000357627869\n",
      "Epoch 2, iter 110, loss 2.5223731994628906, acc 0.07000000029802322\n",
      "Epoch 2, iter 111, loss 2.5873513221740723, acc 0.07000000029802322\n",
      "Epoch 2, iter 112, loss 2.5704824924468994, acc 0.10000000149011612\n",
      "Epoch 2, iter 113, loss 2.4095664024353027, acc 0.10000000149011612\n",
      "Epoch 2, iter 114, loss 2.5889639854431152, acc 0.09000000357627869\n",
      "Epoch 2, iter 115, loss 2.519792079925537, acc 0.10000000149011612\n",
      "Epoch 2, iter 116, loss 2.417231559753418, acc 0.11999999731779099\n",
      "Epoch 2, iter 117, loss 2.5183935165405273, acc 0.05999999865889549\n",
      "Epoch 2, iter 118, loss 2.5469977855682373, acc 0.07999999821186066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, iter 119, loss 2.515331506729126, acc 0.07999999821186066\n",
      "Epoch 2, iter 120, loss 2.4447147846221924, acc 0.14000000059604645\n",
      "Epoch 2, iter 121, loss 2.369691848754883, acc 0.14000000059604645\n",
      "Epoch 2, iter 122, loss 2.436418056488037, acc 0.09000000357627869\n",
      "Epoch 2, iter 123, loss 2.4372315406799316, acc 0.12999999523162842\n",
      "Epoch 2, iter 124, loss 2.60191011428833, acc 0.07000000029802322\n",
      "Epoch 2, iter 125, loss 2.524622678756714, acc 0.11999999731779099\n",
      "Epoch 2, iter 126, loss 2.6032605171203613, acc 0.07000000029802322\n",
      "Epoch 2, iter 127, loss 2.4947266578674316, acc 0.05000000074505806\n",
      "Epoch 2, iter 128, loss 2.510179042816162, acc 0.05000000074505806\n",
      "Epoch 2, iter 129, loss 2.540217638015747, acc 0.10999999940395355\n",
      "Epoch 2, iter 130, loss 2.508297920227051, acc 0.05999999865889549\n",
      "Epoch 2, iter 131, loss 2.4719057083129883, acc 0.11999999731779099\n",
      "Epoch 2, iter 132, loss 2.4311981201171875, acc 0.10999999940395355\n",
      "Epoch 2, iter 133, loss 2.445671796798706, acc 0.10000000149011612\n",
      "Epoch 2, iter 134, loss 2.4623677730560303, acc 0.07999999821186066\n",
      "Epoch 2, iter 135, loss 2.5022876262664795, acc 0.10000000149011612\n",
      "Epoch 2, iter 136, loss 2.4720025062561035, acc 0.09000000357627869\n",
      "Epoch 2, iter 137, loss 2.3596057891845703, acc 0.14000000059604645\n",
      "Epoch 2, iter 138, loss 2.4164679050445557, acc 0.07000000029802322\n",
      "Epoch 2, iter 139, loss 2.4726667404174805, acc 0.11999999731779099\n",
      "Epoch 2, iter 140, loss 2.4112071990966797, acc 0.07999999821186066\n",
      "Epoch 2, iter 141, loss 2.422403335571289, acc 0.10000000149011612\n",
      "Epoch 2, iter 142, loss 2.6263909339904785, acc 0.07000000029802322\n",
      "Epoch 2, iter 143, loss 2.447432279586792, acc 0.07000000029802322\n",
      "Epoch 2, iter 144, loss 2.5415587425231934, acc 0.09000000357627869\n",
      "Epoch 2, iter 145, loss 2.4653327465057373, acc 0.12999999523162842\n",
      "Epoch 2, iter 146, loss 2.4705162048339844, acc 0.07000000029802322\n",
      "Epoch 2, iter 147, loss 2.50783109664917, acc 0.07000000029802322\n",
      "Epoch 2, iter 148, loss 2.4391307830810547, acc 0.09000000357627869\n",
      "Epoch 2, iter 149, loss 2.524365186691284, acc 0.10999999940395355\n",
      "Epoch 2, iter 150, loss 2.397097110748291, acc 0.11999999731779099\n",
      "Epoch 2, iter 151, loss 2.475959300994873, acc 0.07999999821186066\n",
      "Epoch 2, iter 152, loss 2.5239098072052, acc 0.03999999910593033\n",
      "Epoch 2, iter 153, loss 2.5478382110595703, acc 0.12999999523162842\n",
      "Epoch 2, iter 154, loss 2.5129899978637695, acc 0.11999999731779099\n",
      "Epoch 2, iter 155, loss 2.4485230445861816, acc 0.14000000059604645\n",
      "Epoch 2, iter 156, loss 2.3791394233703613, acc 0.11999999731779099\n",
      "Epoch 2, iter 157, loss 2.6127126216888428, acc 0.03999999910593033\n",
      "Epoch 2, iter 158, loss 2.4614572525024414, acc 0.11999999731779099\n",
      "Epoch 2, iter 159, loss 2.5114896297454834, acc 0.07000000029802322\n",
      "Epoch 2, iter 160, loss 2.4589240550994873, acc 0.12999999523162842\n",
      "Epoch 2, iter 161, loss 2.411097526550293, acc 0.10000000149011612\n",
      "Epoch 2, iter 162, loss 2.403470039367676, acc 0.03999999910593033\n",
      "Epoch 2, iter 163, loss 2.4357128143310547, acc 0.12999999523162842\n",
      "Epoch 2, iter 164, loss 2.4725656509399414, acc 0.11999999731779099\n",
      "Epoch 2, iter 165, loss 2.5052995681762695, acc 0.10000000149011612\n",
      "Epoch 2, iter 166, loss 2.536816358566284, acc 0.05000000074505806\n",
      "Epoch 2, iter 167, loss 2.3882431983947754, acc 0.10000000149011612\n",
      "Epoch 2, iter 168, loss 2.448049783706665, acc 0.12999999523162842\n",
      "Epoch 2, iter 169, loss 2.5327839851379395, acc 0.07999999821186066\n",
      "Epoch 2, iter 170, loss 2.6031334400177, acc 0.07000000029802322\n",
      "Epoch 2, iter 171, loss 2.4793925285339355, acc 0.10999999940395355\n",
      "Epoch 2, iter 172, loss 2.4710135459899902, acc 0.10999999940395355\n",
      "Epoch 2, iter 173, loss 2.4566214084625244, acc 0.14000000059604645\n",
      "Epoch 2, iter 174, loss 2.3829946517944336, acc 0.07000000029802322\n",
      "Epoch 2, iter 175, loss 2.4927239418029785, acc 0.09000000357627869\n",
      "Epoch 2, iter 176, loss 2.512421131134033, acc 0.09000000357627869\n",
      "Epoch 2, iter 177, loss 2.443570137023926, acc 0.07999999821186066\n",
      "Epoch 2, iter 178, loss 2.4950802326202393, acc 0.11999999731779099\n",
      "Epoch 2, iter 179, loss 2.4524660110473633, acc 0.10000000149011612\n",
      "Epoch 2, iter 180, loss 2.385688304901123, acc 0.10000000149011612\n",
      "Epoch 2, iter 181, loss 2.300882577896118, acc 0.1599999964237213\n",
      "Epoch 2, iter 182, loss 2.4316840171813965, acc 0.12999999523162842\n",
      "Epoch 2, iter 183, loss 2.4670047760009766, acc 0.12999999523162842\n",
      "Epoch 2, iter 184, loss 2.533313751220703, acc 0.029999999329447746\n",
      "Epoch 2, iter 185, loss 2.4674718379974365, acc 0.07999999821186066\n",
      "Epoch 2, iter 186, loss 2.4993345737457275, acc 0.07000000029802322\n",
      "Epoch 2, iter 187, loss 2.4357948303222656, acc 0.07000000029802322\n",
      "Epoch 2, iter 188, loss 2.418858289718628, acc 0.10999999940395355\n",
      "Epoch 2, iter 189, loss 2.4884696006774902, acc 0.05999999865889549\n",
      "Epoch 2, iter 190, loss 2.407567024230957, acc 0.05999999865889549\n",
      "Epoch 2, iter 191, loss 2.388425827026367, acc 0.15000000596046448\n",
      "Epoch 2, iter 192, loss 2.507906913757324, acc 0.05999999865889549\n",
      "Epoch 2, iter 193, loss 2.423704147338867, acc 0.03999999910593033\n",
      "Epoch 2, iter 194, loss 2.3913729190826416, acc 0.07999999821186066\n",
      "Epoch 2, iter 195, loss 2.4474592208862305, acc 0.07999999821186066\n",
      "Epoch 2, iter 196, loss 2.445594072341919, acc 0.12999999523162842\n",
      "Epoch 2, iter 197, loss 2.405769109725952, acc 0.10000000149011612\n",
      "Epoch 2, iter 198, loss 2.4872589111328125, acc 0.07000000029802322\n",
      "Epoch 2, iter 199, loss 2.44075608253479, acc 0.07000000029802322\n",
      "Epoch 2, iter 200, loss 2.4927148818969727, acc 0.05000000074505806\n",
      "Epoch 2, iter 201, loss 2.5719003677368164, acc 0.029999999329447746\n",
      "Epoch 2, iter 202, loss 2.4102349281311035, acc 0.07999999821186066\n",
      "Epoch 2, iter 203, loss 2.5213470458984375, acc 0.09000000357627869\n",
      "Epoch 2, iter 204, loss 2.5567877292633057, acc 0.09000000357627869\n",
      "Epoch 2, iter 205, loss 2.4811556339263916, acc 0.05999999865889549\n",
      "Epoch 2, iter 206, loss 2.4443092346191406, acc 0.09000000357627869\n",
      "Epoch 2, iter 207, loss 2.444740056991577, acc 0.07000000029802322\n",
      "Epoch 2, iter 208, loss 2.4615752696990967, acc 0.10000000149011612\n",
      "Epoch 2, iter 209, loss 2.405686855316162, acc 0.11999999731779099\n",
      "Epoch 2, iter 210, loss 2.4224631786346436, acc 0.14000000059604645\n",
      "Epoch 2, iter 211, loss 2.5706472396850586, acc 0.07999999821186066\n",
      "Epoch 2, iter 212, loss 2.4930970668792725, acc 0.07999999821186066\n",
      "Epoch 2, iter 213, loss 2.401991844177246, acc 0.07000000029802322\n",
      "Epoch 2, iter 214, loss 2.459218978881836, acc 0.10000000149011612\n",
      "Epoch 2, iter 215, loss 2.4655230045318604, acc 0.09000000357627869\n",
      "Epoch 2, iter 216, loss 2.381787061691284, acc 0.10999999940395355\n",
      "Epoch 2, iter 217, loss 2.455021619796753, acc 0.10000000149011612\n",
      "Epoch 2, iter 218, loss 2.436631441116333, acc 0.10999999940395355\n",
      "Epoch 2, iter 219, loss 2.392702341079712, acc 0.11999999731779099\n",
      "Epoch 2, iter 220, loss 2.553250312805176, acc 0.03999999910593033\n",
      "Epoch 2, iter 221, loss 2.481926202774048, acc 0.09000000357627869\n",
      "Epoch 2, iter 222, loss 2.3861606121063232, acc 0.07999999821186066\n",
      "Epoch 2, iter 223, loss 2.3979461193084717, acc 0.09000000357627869\n",
      "Epoch 2, iter 224, loss 2.37760591506958, acc 0.07999999821186066\n",
      "Epoch 2, iter 225, loss 2.489780902862549, acc 0.09000000357627869\n",
      "Epoch 2, iter 226, loss 2.4818413257598877, acc 0.10000000149011612\n",
      "Epoch 2, iter 227, loss 2.4110822677612305, acc 0.11999999731779099\n",
      "Epoch 2, iter 228, loss 2.376059055328369, acc 0.10999999940395355\n",
      "Epoch 2, iter 229, loss 2.473345994949341, acc 0.10000000149011612\n",
      "Epoch 2, iter 230, loss 2.4323346614837646, acc 0.10999999940395355\n",
      "Epoch 2, iter 231, loss 2.5357465744018555, acc 0.05999999865889549\n",
      "Epoch 2, iter 232, loss 2.490931510925293, acc 0.07999999821186066\n",
      "Epoch 2, iter 233, loss 2.4203310012817383, acc 0.07999999821186066\n",
      "Epoch 2, iter 234, loss 2.4736156463623047, acc 0.07000000029802322\n",
      "Epoch 2, iter 235, loss 2.4020133018493652, acc 0.10000000149011612\n",
      "Epoch 2, iter 236, loss 2.430635452270508, acc 0.07999999821186066\n",
      "Epoch 2, iter 237, loss 2.4533252716064453, acc 0.07999999821186066\n",
      "Epoch 2, iter 238, loss 2.4317634105682373, acc 0.10000000149011612\n",
      "Epoch 2, iter 239, loss 2.4293954372406006, acc 0.10000000149011612\n",
      "Epoch 2, iter 240, loss 2.462998151779175, acc 0.11999999731779099\n",
      "Epoch 2, iter 241, loss 2.4579501152038574, acc 0.10000000149011612\n",
      "Epoch 2, iter 242, loss 2.3948895931243896, acc 0.10999999940395355\n",
      "Epoch 2, iter 243, loss 2.32045841217041, acc 0.18000000715255737\n",
      "Epoch 2, iter 244, loss 2.4367258548736572, acc 0.07999999821186066\n",
      "Epoch 2, iter 245, loss 2.4412806034088135, acc 0.14000000059604645\n",
      "Epoch 2, iter 246, loss 2.4955735206604004, acc 0.07999999821186066\n",
      "Epoch 2, iter 247, loss 2.3738865852355957, acc 0.10000000149011612\n",
      "Epoch 2, iter 248, loss 2.3947484493255615, acc 0.15000000596046448\n",
      "Epoch 2, iter 249, loss 2.3958539962768555, acc 0.10000000149011612\n",
      "Epoch 2, iter 250, loss 2.4104835987091064, acc 0.10999999940395355\n",
      "Epoch 2, iter 251, loss 2.3779475688934326, acc 0.11999999731779099\n",
      "Epoch 2, iter 252, loss 2.3402040004730225, acc 0.15000000596046448\n",
      "Epoch 2, iter 253, loss 2.439340114593506, acc 0.15000000596046448\n",
      "Epoch 2, iter 254, loss 2.437030553817749, acc 0.07999999821186066\n",
      "Epoch 2, iter 255, loss 2.5842459201812744, acc 0.05999999865889549\n",
      "Epoch 2, iter 256, loss 2.4414100646972656, acc 0.07999999821186066\n",
      "Epoch 2, iter 257, loss 2.428947925567627, acc 0.07999999821186066\n",
      "Epoch 2, iter 258, loss 2.3513808250427246, acc 0.15000000596046448\n",
      "Epoch 2, iter 259, loss 2.4017417430877686, acc 0.07999999821186066\n",
      "Epoch 2, iter 260, loss 2.4524731636047363, acc 0.03999999910593033\n",
      "Epoch 2, iter 261, loss 2.435572385787964, acc 0.09000000357627869\n",
      "Epoch 2, iter 262, loss 2.490060329437256, acc 0.07000000029802322\n",
      "Epoch 2, iter 263, loss 2.446828842163086, acc 0.05000000074505806\n",
      "Epoch 2, iter 264, loss 2.399925708770752, acc 0.09000000357627869\n",
      "Epoch 2, iter 265, loss 2.415275812149048, acc 0.1599999964237213\n",
      "Epoch 2, iter 266, loss 2.4272267818450928, acc 0.10999999940395355\n",
      "Epoch 2, iter 267, loss 2.43188214302063, acc 0.14000000059604645\n",
      "Epoch 2, iter 268, loss 2.4063892364501953, acc 0.1599999964237213\n",
      "Epoch 2, iter 269, loss 2.3764970302581787, acc 0.07999999821186066\n",
      "Epoch 2, iter 270, loss 2.452927350997925, acc 0.09000000357627869\n",
      "Epoch 2, iter 271, loss 2.46516752243042, acc 0.10000000149011612\n",
      "Epoch 2, iter 272, loss 2.43332576751709, acc 0.05000000074505806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, iter 273, loss 2.4190709590911865, acc 0.10000000149011612\n",
      "Epoch 2, iter 274, loss 2.360344886779785, acc 0.09000000357627869\n",
      "Epoch 2, iter 275, loss 2.469632148742676, acc 0.07000000029802322\n",
      "Epoch 2, iter 276, loss 2.4747567176818848, acc 0.11999999731779099\n",
      "Epoch 2, iter 277, loss 2.334923505783081, acc 0.15000000596046448\n",
      "Epoch 2, iter 278, loss 2.3585939407348633, acc 0.12999999523162842\n",
      "Epoch 2, iter 279, loss 2.4013283252716064, acc 0.10999999940395355\n",
      "Epoch 2, iter 280, loss 2.327058792114258, acc 0.10000000149011612\n",
      "Epoch 2, iter 281, loss 2.4097847938537598, acc 0.07000000029802322\n",
      "Epoch 2, iter 282, loss 2.5276620388031006, acc 0.14000000059604645\n",
      "Epoch 2, iter 283, loss 2.46806263923645, acc 0.07999999821186066\n",
      "Epoch 2, iter 284, loss 2.439537763595581, acc 0.05999999865889549\n",
      "Epoch 2, iter 285, loss 2.405940055847168, acc 0.07999999821186066\n",
      "Epoch 2, iter 286, loss 2.4192910194396973, acc 0.07999999821186066\n",
      "Epoch 2, iter 287, loss 2.4517292976379395, acc 0.10999999940395355\n",
      "Epoch 2, iter 288, loss 2.441497325897217, acc 0.07000000029802322\n",
      "Epoch 2, iter 289, loss 2.381538152694702, acc 0.10999999940395355\n",
      "Epoch 2, iter 290, loss 2.4672021865844727, acc 0.05999999865889549\n",
      "Epoch 2, iter 291, loss 2.382495641708374, acc 0.11999999731779099\n",
      "Epoch 2, iter 292, loss 2.4289968013763428, acc 0.09000000357627869\n",
      "Epoch 2, iter 293, loss 2.404355525970459, acc 0.09000000357627869\n",
      "Epoch 2, iter 294, loss 2.4156227111816406, acc 0.12999999523162842\n",
      "Epoch 2, iter 295, loss 2.3945531845092773, acc 0.11999999731779099\n",
      "Epoch 2, iter 296, loss 2.453948736190796, acc 0.09000000357627869\n",
      "Epoch 2, iter 297, loss 2.426703453063965, acc 0.09000000357627869\n",
      "Epoch 2, iter 298, loss 2.331854820251465, acc 0.12999999523162842\n",
      "Epoch 2, iter 299, loss 2.3530683517456055, acc 0.11999999731779099\n",
      "Epoch 2, iter 300, loss 2.4485349655151367, acc 0.09000000357627869\n",
      "Epoch 2, iter 301, loss 2.401937246322632, acc 0.05999999865889549\n",
      "Epoch 2, iter 302, loss 2.39656138420105, acc 0.12999999523162842\n",
      "Epoch 2, iter 303, loss 2.446547031402588, acc 0.10999999940395355\n",
      "Epoch 2, iter 304, loss 2.4678096771240234, acc 0.05000000074505806\n",
      "Epoch 2, iter 305, loss 2.4272730350494385, acc 0.09000000357627869\n",
      "Epoch 2, iter 306, loss 2.4734504222869873, acc 0.05999999865889549\n",
      "Epoch 2, iter 307, loss 2.382047653198242, acc 0.09000000357627869\n",
      "Epoch 2, iter 308, loss 2.399679183959961, acc 0.15000000596046448\n",
      "Epoch 2, iter 309, loss 2.351536512374878, acc 0.11999999731779099\n",
      "Epoch 2, iter 310, loss 2.4324562549591064, acc 0.05000000074505806\n",
      "Epoch 2, iter 311, loss 2.3886642456054688, acc 0.10000000149011612\n",
      "Epoch 2, iter 312, loss 2.464885950088501, acc 0.05000000074505806\n",
      "Epoch 2, iter 313, loss 2.4692816734313965, acc 0.11999999731779099\n",
      "Epoch 2, iter 314, loss 2.381736993789673, acc 0.18000000715255737\n",
      "Epoch 2, iter 315, loss 2.498129367828369, acc 0.10999999940395355\n",
      "Epoch 2, iter 316, loss 2.430722236633301, acc 0.07999999821186066\n",
      "Epoch 2, iter 317, loss 2.4755730628967285, acc 0.029999999329447746\n",
      "Epoch 2, iter 318, loss 2.4276161193847656, acc 0.05999999865889549\n",
      "Epoch 2, iter 319, loss 2.3519721031188965, acc 0.14000000059604645\n",
      "Epoch 2, iter 320, loss 2.324908494949341, acc 0.07000000029802322\n",
      "Epoch 2, iter 321, loss 2.428907632827759, acc 0.07999999821186066\n",
      "Epoch 2, iter 322, loss 2.4111359119415283, acc 0.10000000149011612\n",
      "Epoch 2, iter 323, loss 2.415861129760742, acc 0.09000000357627869\n",
      "Epoch 2, iter 324, loss 2.4184648990631104, acc 0.10000000149011612\n",
      "Epoch 2, iter 325, loss 2.4364371299743652, acc 0.05999999865889549\n",
      "Epoch 2, iter 326, loss 2.341440439224243, acc 0.11999999731779099\n",
      "Epoch 2, iter 327, loss 2.361694574356079, acc 0.11999999731779099\n",
      "Epoch 2, iter 328, loss 2.4719996452331543, acc 0.07000000029802322\n",
      "Epoch 2, iter 329, loss 2.412916660308838, acc 0.07000000029802322\n",
      "Epoch 2, iter 330, loss 2.3377504348754883, acc 0.10999999940395355\n",
      "Epoch 2, iter 331, loss 2.3729186058044434, acc 0.09000000357627869\n",
      "Epoch 2, iter 332, loss 2.3763234615325928, acc 0.11999999731779099\n",
      "Epoch 2, iter 333, loss 2.41782808303833, acc 0.07999999821186066\n",
      "Epoch 2, iter 334, loss 2.4966471195220947, acc 0.05999999865889549\n",
      "Epoch 2, iter 335, loss 2.3673462867736816, acc 0.09000000357627869\n",
      "Epoch 2, iter 336, loss 2.4394302368164062, acc 0.10999999940395355\n",
      "Epoch 2, iter 337, loss 2.424384117126465, acc 0.05000000074505806\n",
      "Epoch 2, iter 338, loss 2.3838818073272705, acc 0.07000000029802322\n",
      "Epoch 2, iter 339, loss 2.3476784229278564, acc 0.14000000059604645\n",
      "Epoch 2, iter 340, loss 2.475506544113159, acc 0.10999999940395355\n",
      "Epoch 2, iter 341, loss 2.3596320152282715, acc 0.07000000029802322\n",
      "Epoch 2, iter 342, loss 2.4652936458587646, acc 0.05000000074505806\n",
      "Epoch 2, iter 343, loss 2.345541477203369, acc 0.14000000059604645\n",
      "Epoch 2, iter 344, loss 2.4585258960723877, acc 0.10999999940395355\n",
      "Epoch 2, iter 345, loss 2.414668560028076, acc 0.07999999821186066\n",
      "Epoch 2, iter 346, loss 2.534616470336914, acc 0.05999999865889549\n",
      "Epoch 2, iter 347, loss 2.425374984741211, acc 0.10000000149011612\n",
      "Epoch 2, iter 348, loss 2.440321683883667, acc 0.07999999821186066\n",
      "Epoch 2, iter 349, loss 2.405402898788452, acc 0.029999999329447746\n",
      "Epoch 2, iter 350, loss 2.3380749225616455, acc 0.1599999964237213\n",
      "Epoch 2, iter 351, loss 2.305293083190918, acc 0.14000000059604645\n",
      "Epoch 2, iter 352, loss 2.4238953590393066, acc 0.10000000149011612\n",
      "Epoch 2, iter 353, loss 2.414607286453247, acc 0.10000000149011612\n",
      "Epoch 2, iter 354, loss 2.4698870182037354, acc 0.07999999821186066\n",
      "Epoch 2, iter 355, loss 2.3917911052703857, acc 0.07999999821186066\n",
      "Epoch 2, iter 356, loss 2.3540754318237305, acc 0.12999999523162842\n",
      "Epoch 2, iter 357, loss 2.3825347423553467, acc 0.07999999821186066\n",
      "Epoch 2, iter 358, loss 2.343139171600342, acc 0.07999999821186066\n",
      "Epoch 2, iter 359, loss 2.446829319000244, acc 0.05999999865889549\n",
      "Epoch 2, iter 360, loss 2.4634804725646973, acc 0.07000000029802322\n",
      "Epoch 2, iter 361, loss 2.3715922832489014, acc 0.11999999731779099\n",
      "Epoch 2, iter 362, loss 2.4125583171844482, acc 0.07000000029802322\n",
      "Epoch 2, iter 363, loss 2.3627119064331055, acc 0.12999999523162842\n",
      "Epoch 2, iter 364, loss 2.480990409851074, acc 0.09000000357627869\n",
      "Epoch 2, iter 365, loss 2.4035189151763916, acc 0.09000000357627869\n",
      "Epoch 2, iter 366, loss 2.4665591716766357, acc 0.07000000029802322\n",
      "Epoch 2, iter 367, loss 2.3795247077941895, acc 0.07000000029802322\n",
      "Epoch 2, iter 368, loss 2.441457748413086, acc 0.07999999821186066\n",
      "Epoch 2, iter 369, loss 2.3415310382843018, acc 0.12999999523162842\n",
      "Epoch 2, iter 370, loss 2.3691658973693848, acc 0.05999999865889549\n",
      "Epoch 2, iter 371, loss 2.4465487003326416, acc 0.05000000074505806\n",
      "Epoch 2, iter 372, loss 2.318052291870117, acc 0.15000000596046448\n",
      "Epoch 2, iter 373, loss 2.431140184402466, acc 0.07000000029802322\n",
      "Epoch 2, iter 374, loss 2.394127130508423, acc 0.07999999821186066\n",
      "Epoch 2, iter 375, loss 2.463139533996582, acc 0.07000000029802322\n",
      "Epoch 2, iter 376, loss 2.4118528366088867, acc 0.09000000357627869\n",
      "Epoch 2, iter 377, loss 2.4591825008392334, acc 0.07000000029802322\n",
      "Epoch 2, iter 378, loss 2.3927342891693115, acc 0.14000000059604645\n",
      "Epoch 2, iter 379, loss 2.4048643112182617, acc 0.10999999940395355\n",
      "Epoch 2, iter 380, loss 2.4182755947113037, acc 0.07000000029802322\n",
      "Epoch 2, iter 381, loss 2.4456655979156494, acc 0.07000000029802322\n",
      "Epoch 2, iter 382, loss 2.416032075881958, acc 0.07000000029802322\n",
      "Epoch 2, iter 383, loss 2.3379998207092285, acc 0.11999999731779099\n",
      "Epoch 2, iter 384, loss 2.4089319705963135, acc 0.10000000149011612\n",
      "Epoch 2, iter 385, loss 2.3791449069976807, acc 0.07999999821186066\n",
      "Epoch 2, iter 386, loss 2.3911678791046143, acc 0.05999999865889549\n",
      "Epoch 2, iter 387, loss 2.420145273208618, acc 0.05000000074505806\n",
      "Epoch 2, iter 388, loss 2.3971991539001465, acc 0.11999999731779099\n",
      "Epoch 2, iter 389, loss 2.371563196182251, acc 0.10000000149011612\n",
      "Epoch 2, iter 390, loss 2.4072725772857666, acc 0.07999999821186066\n",
      "Epoch 2, iter 391, loss 2.411417007446289, acc 0.07999999821186066\n",
      "Epoch 2, iter 392, loss 2.4190659523010254, acc 0.11999999731779099\n",
      "Epoch 2, iter 393, loss 2.3919687271118164, acc 0.14000000059604645\n",
      "Epoch 2, iter 394, loss 2.491250991821289, acc 0.05999999865889549\n",
      "Epoch 2, iter 395, loss 2.442042589187622, acc 0.07999999821186066\n",
      "Epoch 2, iter 396, loss 2.4055111408233643, acc 0.10999999940395355\n",
      "Epoch 2, iter 397, loss 2.470280170440674, acc 0.09000000357627869\n",
      "Epoch 2, iter 398, loss 2.353579044342041, acc 0.10000000149011612\n",
      "Epoch 2, iter 399, loss 2.4610395431518555, acc 0.10999999940395355\n",
      "Epoch 2, iter 400, loss 2.3793911933898926, acc 0.05999999865889549\n",
      "Epoch 2, iter 401, loss 2.3815300464630127, acc 0.12999999523162842\n",
      "Epoch 2, iter 402, loss 2.3577048778533936, acc 0.07000000029802322\n",
      "Epoch 2, iter 403, loss 2.3335440158843994, acc 0.09000000357627869\n",
      "Epoch 2, iter 404, loss 2.3972647190093994, acc 0.09000000357627869\n",
      "Epoch 2, iter 405, loss 2.4062161445617676, acc 0.11999999731779099\n",
      "Epoch 2, iter 406, loss 2.4525809288024902, acc 0.07999999821186066\n",
      "Epoch 2, iter 407, loss 2.461575984954834, acc 0.11999999731779099\n",
      "Epoch 2, iter 408, loss 2.3818702697753906, acc 0.10999999940395355\n",
      "Epoch 2, iter 409, loss 2.4336862564086914, acc 0.10000000149011612\n",
      "Epoch 2, iter 410, loss 2.4245290756225586, acc 0.09000000357627869\n",
      "Epoch 2, iter 411, loss 2.4040873050689697, acc 0.03999999910593033\n",
      "Epoch 2, iter 412, loss 2.3862152099609375, acc 0.10999999940395355\n",
      "Epoch 2, iter 413, loss 2.4460532665252686, acc 0.07999999821186066\n",
      "Epoch 2, iter 414, loss 2.4167885780334473, acc 0.12999999523162842\n",
      "Epoch 2, iter 415, loss 2.3750951290130615, acc 0.07000000029802322\n",
      "Epoch 2, iter 416, loss 2.360440969467163, acc 0.10999999940395355\n",
      "Epoch 2, iter 417, loss 2.4495956897735596, acc 0.07999999821186066\n",
      "Epoch 2, iter 418, loss 2.437988042831421, acc 0.05999999865889549\n",
      "Epoch 2, iter 419, loss 2.4150874614715576, acc 0.07999999821186066\n",
      "Epoch 2, iter 420, loss 2.3895108699798584, acc 0.10000000149011612\n",
      "Epoch 3, iter 1, loss 2.457326889038086, acc 0.10999999940395355\n",
      "Epoch 3, iter 2, loss 2.372352361679077, acc 0.07999999821186066\n",
      "Epoch 3, iter 3, loss 2.398481845855713, acc 0.11999999731779099\n",
      "Epoch 3, iter 4, loss 2.372840404510498, acc 0.12999999523162842\n",
      "Epoch 3, iter 5, loss 2.372201919555664, acc 0.10000000149011612\n",
      "Epoch 3, iter 6, loss 2.371936082839966, acc 0.09000000357627869\n",
      "Epoch 3, iter 7, loss 2.3719635009765625, acc 0.10999999940395355\n",
      "Epoch 3, iter 8, loss 2.3836138248443604, acc 0.07000000029802322\n",
      "Epoch 3, iter 9, loss 2.3678112030029297, acc 0.11999999731779099\n",
      "Epoch 3, iter 10, loss 2.3749642372131348, acc 0.14000000059604645\n",
      "Epoch 3, iter 11, loss 2.3388359546661377, acc 0.09000000357627869\n",
      "Epoch 3, iter 12, loss 2.3550145626068115, acc 0.09000000357627869\n",
      "Epoch 3, iter 13, loss 2.3376071453094482, acc 0.14000000059604645\n",
      "Epoch 3, iter 14, loss 2.4844369888305664, acc 0.05000000074505806\n",
      "Epoch 3, iter 15, loss 2.4386658668518066, acc 0.09000000357627869\n",
      "Epoch 3, iter 16, loss 2.4130303859710693, acc 0.10000000149011612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 17, loss 2.36478853225708, acc 0.10999999940395355\n",
      "Epoch 3, iter 18, loss 2.449943780899048, acc 0.07000000029802322\n",
      "Epoch 3, iter 19, loss 2.3917417526245117, acc 0.10000000149011612\n",
      "Epoch 3, iter 20, loss 2.3061208724975586, acc 0.15000000596046448\n",
      "Epoch 3, iter 21, loss 2.425468921661377, acc 0.029999999329447746\n",
      "Epoch 3, iter 22, loss 2.477083444595337, acc 0.05999999865889549\n",
      "Epoch 3, iter 23, loss 2.4145383834838867, acc 0.09000000357627869\n",
      "Epoch 3, iter 24, loss 2.3305160999298096, acc 0.15000000596046448\n",
      "Epoch 3, iter 25, loss 2.432816982269287, acc 0.05999999865889549\n",
      "Epoch 3, iter 26, loss 2.4085533618927, acc 0.05999999865889549\n",
      "Epoch 3, iter 27, loss 2.3827157020568848, acc 0.10000000149011612\n",
      "Epoch 3, iter 28, loss 2.422559976577759, acc 0.07999999821186066\n",
      "Epoch 3, iter 29, loss 2.3666696548461914, acc 0.10000000149011612\n",
      "Epoch 3, iter 30, loss 2.4532651901245117, acc 0.10000000149011612\n",
      "Epoch 3, iter 31, loss 2.4402153491973877, acc 0.10000000149011612\n",
      "Epoch 3, iter 32, loss 2.348724603652954, acc 0.12999999523162842\n",
      "Epoch 3, iter 33, loss 2.3658483028411865, acc 0.07999999821186066\n",
      "Epoch 3, iter 34, loss 2.4551546573638916, acc 0.05999999865889549\n",
      "Epoch 3, iter 35, loss 2.372177839279175, acc 0.07999999821186066\n",
      "Epoch 3, iter 36, loss 2.3880016803741455, acc 0.07999999821186066\n",
      "Epoch 3, iter 37, loss 2.3677780628204346, acc 0.10999999940395355\n",
      "Epoch 3, iter 38, loss 2.358734130859375, acc 0.12999999523162842\n",
      "Epoch 3, iter 39, loss 2.3641111850738525, acc 0.10000000149011612\n",
      "Epoch 3, iter 40, loss 2.4161951541900635, acc 0.14000000059604645\n",
      "Epoch 3, iter 41, loss 2.4262819290161133, acc 0.07000000029802322\n",
      "Epoch 3, iter 42, loss 2.3650496006011963, acc 0.07999999821186066\n",
      "Epoch 3, iter 43, loss 2.4284441471099854, acc 0.10000000149011612\n",
      "Epoch 3, iter 44, loss 2.379868268966675, acc 0.11999999731779099\n",
      "Epoch 3, iter 45, loss 2.4316537380218506, acc 0.11999999731779099\n",
      "Epoch 3, iter 46, loss 2.4491608142852783, acc 0.05999999865889549\n",
      "Epoch 3, iter 47, loss 2.3662939071655273, acc 0.09000000357627869\n",
      "Epoch 3, iter 48, loss 2.414977788925171, acc 0.10999999940395355\n",
      "Epoch 3, iter 49, loss 2.406364917755127, acc 0.11999999731779099\n",
      "Epoch 3, iter 50, loss 2.3717551231384277, acc 0.10000000149011612\n",
      "Epoch 3, iter 51, loss 2.424978256225586, acc 0.10000000149011612\n",
      "Epoch 3, iter 52, loss 2.385913610458374, acc 0.10999999940395355\n",
      "Epoch 3, iter 53, loss 2.4052748680114746, acc 0.11999999731779099\n",
      "Epoch 3, iter 54, loss 2.370429277420044, acc 0.07999999821186066\n",
      "Epoch 3, iter 55, loss 2.390582323074341, acc 0.09000000357627869\n",
      "Epoch 3, iter 56, loss 2.3842225074768066, acc 0.10000000149011612\n",
      "Epoch 3, iter 57, loss 2.303978204727173, acc 0.11999999731779099\n",
      "Epoch 3, iter 58, loss 2.405996799468994, acc 0.07000000029802322\n",
      "Epoch 3, iter 59, loss 2.4114937782287598, acc 0.09000000357627869\n",
      "Epoch 3, iter 60, loss 2.4133620262145996, acc 0.07000000029802322\n",
      "Epoch 3, iter 61, loss 2.398406744003296, acc 0.05999999865889549\n",
      "Epoch 3, iter 62, loss 2.311441659927368, acc 0.14000000059604645\n",
      "Epoch 3, iter 63, loss 2.3884294033050537, acc 0.10999999940395355\n",
      "Epoch 3, iter 64, loss 2.375781297683716, acc 0.07000000029802322\n",
      "Epoch 3, iter 65, loss 2.4227118492126465, acc 0.07999999821186066\n",
      "Epoch 3, iter 66, loss 2.3903069496154785, acc 0.07000000029802322\n",
      "Epoch 3, iter 67, loss 2.4207217693328857, acc 0.11999999731779099\n",
      "Epoch 3, iter 68, loss 2.3367345333099365, acc 0.09000000357627869\n",
      "Epoch 3, iter 69, loss 2.366729974746704, acc 0.09000000357627869\n",
      "Epoch 3, iter 70, loss 2.3843908309936523, acc 0.10999999940395355\n",
      "Epoch 3, iter 71, loss 2.412330150604248, acc 0.10000000149011612\n",
      "Epoch 3, iter 72, loss 2.4576947689056396, acc 0.03999999910593033\n",
      "Epoch 3, iter 73, loss 2.3824591636657715, acc 0.10000000149011612\n",
      "Epoch 3, iter 74, loss 2.3223249912261963, acc 0.11999999731779099\n",
      "Epoch 3, iter 75, loss 2.4210917949676514, acc 0.09000000357627869\n",
      "Epoch 3, iter 76, loss 2.363008737564087, acc 0.15000000596046448\n",
      "Epoch 3, iter 77, loss 2.3339431285858154, acc 0.11999999731779099\n",
      "Epoch 3, iter 78, loss 2.3908193111419678, acc 0.09000000357627869\n",
      "Epoch 3, iter 79, loss 2.3398680686950684, acc 0.07999999821186066\n",
      "Epoch 3, iter 80, loss 2.433769941329956, acc 0.07999999821186066\n",
      "Epoch 3, iter 81, loss 2.3543519973754883, acc 0.11999999731779099\n",
      "Epoch 3, iter 82, loss 2.3733348846435547, acc 0.11999999731779099\n",
      "Epoch 3, iter 83, loss 2.394570827484131, acc 0.10000000149011612\n",
      "Epoch 3, iter 84, loss 2.3756613731384277, acc 0.09000000357627869\n",
      "Epoch 3, iter 85, loss 2.3447742462158203, acc 0.10999999940395355\n",
      "Epoch 3, iter 86, loss 2.382326364517212, acc 0.10000000149011612\n",
      "Epoch 3, iter 87, loss 2.2730863094329834, acc 0.14000000059604645\n",
      "Epoch 3, iter 88, loss 2.322556257247925, acc 0.10999999940395355\n",
      "Epoch 3, iter 89, loss 2.45149302482605, acc 0.07000000029802322\n",
      "Epoch 3, iter 90, loss 2.4450833797454834, acc 0.07999999821186066\n",
      "Epoch 3, iter 91, loss 2.385854959487915, acc 0.10999999940395355\n",
      "Epoch 3, iter 92, loss 2.2619335651397705, acc 0.11999999731779099\n",
      "Epoch 3, iter 93, loss 2.4122154712677, acc 0.05000000074505806\n",
      "Epoch 3, iter 94, loss 2.3814780712127686, acc 0.11999999731779099\n",
      "Epoch 3, iter 95, loss 2.4032485485076904, acc 0.11999999731779099\n",
      "Epoch 3, iter 96, loss 2.3426947593688965, acc 0.15000000596046448\n",
      "Epoch 3, iter 97, loss 2.348085880279541, acc 0.10999999940395355\n",
      "Epoch 3, iter 98, loss 2.4022719860076904, acc 0.09000000357627869\n",
      "Epoch 3, iter 99, loss 2.2857494354248047, acc 0.1599999964237213\n",
      "Epoch 3, iter 100, loss 2.5050108432769775, acc 0.05000000074505806\n",
      "Epoch 3, iter 101, loss 2.432406425476074, acc 0.07999999821186066\n",
      "Epoch 3, iter 102, loss 2.361628293991089, acc 0.10999999940395355\n",
      "Epoch 3, iter 103, loss 2.4067821502685547, acc 0.07000000029802322\n",
      "Epoch 3, iter 104, loss 2.3091771602630615, acc 0.10999999940395355\n",
      "Epoch 3, iter 105, loss 2.4422495365142822, acc 0.09000000357627869\n",
      "Epoch 3, iter 106, loss 2.3411567211151123, acc 0.14000000059604645\n",
      "Epoch 3, iter 107, loss 2.351727247238159, acc 0.09000000357627869\n",
      "Epoch 3, iter 108, loss 2.3763113021850586, acc 0.07999999821186066\n",
      "Epoch 3, iter 109, loss 2.403571367263794, acc 0.10000000149011612\n",
      "Epoch 3, iter 110, loss 2.424023389816284, acc 0.07999999821186066\n",
      "Epoch 3, iter 111, loss 2.490259885787964, acc 0.07000000029802322\n",
      "Epoch 3, iter 112, loss 2.421424627304077, acc 0.05999999865889549\n",
      "Epoch 3, iter 113, loss 2.314065456390381, acc 0.10999999940395355\n",
      "Epoch 3, iter 114, loss 2.4722418785095215, acc 0.11999999731779099\n",
      "Epoch 3, iter 115, loss 2.385791063308716, acc 0.10000000149011612\n",
      "Epoch 3, iter 116, loss 2.3317325115203857, acc 0.07000000029802322\n",
      "Epoch 3, iter 117, loss 2.4074509143829346, acc 0.07999999821186066\n",
      "Epoch 3, iter 118, loss 2.4356582164764404, acc 0.05999999865889549\n",
      "Epoch 3, iter 119, loss 2.419625997543335, acc 0.09000000357627869\n",
      "Epoch 3, iter 120, loss 2.3479766845703125, acc 0.12999999523162842\n",
      "Epoch 3, iter 121, loss 2.329313039779663, acc 0.14000000059604645\n",
      "Epoch 3, iter 122, loss 2.3498334884643555, acc 0.05999999865889549\n",
      "Epoch 3, iter 123, loss 2.3510849475860596, acc 0.03999999910593033\n",
      "Epoch 3, iter 124, loss 2.4499354362487793, acc 0.07000000029802322\n",
      "Epoch 3, iter 125, loss 2.390263080596924, acc 0.11999999731779099\n",
      "Epoch 3, iter 126, loss 2.4677281379699707, acc 0.07000000029802322\n",
      "Epoch 3, iter 127, loss 2.3574254512786865, acc 0.03999999910593033\n",
      "Epoch 3, iter 128, loss 2.3629612922668457, acc 0.11999999731779099\n",
      "Epoch 3, iter 129, loss 2.4122190475463867, acc 0.07999999821186066\n",
      "Epoch 3, iter 130, loss 2.39140248298645, acc 0.05000000074505806\n",
      "Epoch 3, iter 131, loss 2.3696823120117188, acc 0.10000000149011612\n",
      "Epoch 3, iter 132, loss 2.347562313079834, acc 0.12999999523162842\n",
      "Epoch 3, iter 133, loss 2.3524787425994873, acc 0.10999999940395355\n",
      "Epoch 3, iter 134, loss 2.368673086166382, acc 0.10000000149011612\n",
      "Epoch 3, iter 135, loss 2.41229510307312, acc 0.07999999821186066\n",
      "Epoch 3, iter 136, loss 2.390869379043579, acc 0.09000000357627869\n",
      "Epoch 3, iter 137, loss 2.320713996887207, acc 0.12999999523162842\n",
      "Epoch 3, iter 138, loss 2.3177411556243896, acc 0.14000000059604645\n",
      "Epoch 3, iter 139, loss 2.3609633445739746, acc 0.10000000149011612\n",
      "Epoch 3, iter 140, loss 2.3488454818725586, acc 0.09000000357627869\n",
      "Epoch 3, iter 141, loss 2.322443962097168, acc 0.14000000059604645\n",
      "Epoch 3, iter 142, loss 2.4999310970306396, acc 0.09000000357627869\n",
      "Epoch 3, iter 143, loss 2.3081955909729004, acc 0.09000000357627869\n",
      "Epoch 3, iter 144, loss 2.435838222503662, acc 0.07000000029802322\n",
      "Epoch 3, iter 145, loss 2.3801984786987305, acc 0.07999999821186066\n",
      "Epoch 3, iter 146, loss 2.35791015625, acc 0.10999999940395355\n",
      "Epoch 3, iter 147, loss 2.4230263233184814, acc 0.07000000029802322\n",
      "Epoch 3, iter 148, loss 2.3727402687072754, acc 0.05000000074505806\n",
      "Epoch 3, iter 149, loss 2.443136215209961, acc 0.05000000074505806\n",
      "Epoch 3, iter 150, loss 2.3183364868164062, acc 0.14000000059604645\n",
      "Epoch 3, iter 151, loss 2.4231977462768555, acc 0.03999999910593033\n",
      "Epoch 3, iter 152, loss 2.4169070720672607, acc 0.05999999865889549\n",
      "Epoch 3, iter 153, loss 2.412368059158325, acc 0.10000000149011612\n",
      "Epoch 3, iter 154, loss 2.3807172775268555, acc 0.10999999940395355\n",
      "Epoch 3, iter 155, loss 2.3621559143066406, acc 0.15000000596046448\n",
      "Epoch 3, iter 156, loss 2.306281566619873, acc 0.10000000149011612\n",
      "Epoch 3, iter 157, loss 2.4884941577911377, acc 0.10999999940395355\n",
      "Epoch 3, iter 158, loss 2.34761381149292, acc 0.10000000149011612\n",
      "Epoch 3, iter 159, loss 2.4093644618988037, acc 0.05999999865889549\n",
      "Epoch 3, iter 160, loss 2.3835902214050293, acc 0.10999999940395355\n",
      "Epoch 3, iter 161, loss 2.3240435123443604, acc 0.10999999940395355\n",
      "Epoch 3, iter 162, loss 2.3368449211120605, acc 0.09000000357627869\n",
      "Epoch 3, iter 163, loss 2.3561742305755615, acc 0.10000000149011612\n",
      "Epoch 3, iter 164, loss 2.4127566814422607, acc 0.14000000059604645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 165, loss 2.3980727195739746, acc 0.07999999821186066\n",
      "Epoch 3, iter 166, loss 2.391594648361206, acc 0.10000000149011612\n",
      "Epoch 3, iter 167, loss 2.333547353744507, acc 0.09000000357627869\n",
      "Epoch 3, iter 168, loss 2.3973495960235596, acc 0.10000000149011612\n",
      "Epoch 3, iter 169, loss 2.4267051219940186, acc 0.10000000149011612\n",
      "Epoch 3, iter 170, loss 2.4645028114318848, acc 0.07000000029802322\n",
      "Epoch 3, iter 171, loss 2.378955364227295, acc 0.10999999940395355\n",
      "Epoch 3, iter 172, loss 2.386709690093994, acc 0.10000000149011612\n",
      "Epoch 3, iter 173, loss 2.396078586578369, acc 0.09000000357627869\n",
      "Epoch 3, iter 174, loss 2.3262548446655273, acc 0.07999999821186066\n",
      "Epoch 3, iter 175, loss 2.37505841255188, acc 0.07999999821186066\n",
      "Epoch 3, iter 176, loss 2.424989700317383, acc 0.10999999940395355\n",
      "Epoch 3, iter 177, loss 2.356804132461548, acc 0.05999999865889549\n",
      "Epoch 3, iter 178, loss 2.350721836090088, acc 0.09000000357627869\n",
      "Epoch 3, iter 179, loss 2.366633653640747, acc 0.07999999821186066\n",
      "Epoch 3, iter 180, loss 2.317793130874634, acc 0.14000000059604645\n",
      "Epoch 3, iter 181, loss 2.2575554847717285, acc 0.10999999940395355\n",
      "Epoch 3, iter 182, loss 2.3267998695373535, acc 0.09000000357627869\n",
      "Epoch 3, iter 183, loss 2.338616371154785, acc 0.10000000149011612\n",
      "Epoch 3, iter 184, loss 2.44010066986084, acc 0.03999999910593033\n",
      "Epoch 3, iter 185, loss 2.4083518981933594, acc 0.10999999940395355\n",
      "Epoch 3, iter 186, loss 2.395504951477051, acc 0.07000000029802322\n",
      "Epoch 3, iter 187, loss 2.3212578296661377, acc 0.07000000029802322\n",
      "Epoch 3, iter 188, loss 2.3770010471343994, acc 0.09000000357627869\n",
      "Epoch 3, iter 189, loss 2.3964388370513916, acc 0.10000000149011612\n",
      "Epoch 3, iter 190, loss 2.3568010330200195, acc 0.10000000149011612\n",
      "Epoch 3, iter 191, loss 2.3086538314819336, acc 0.12999999523162842\n",
      "Epoch 3, iter 192, loss 2.397158145904541, acc 0.09000000357627869\n",
      "Epoch 3, iter 193, loss 2.3587942123413086, acc 0.07999999821186066\n",
      "Epoch 3, iter 194, loss 2.313828468322754, acc 0.15000000596046448\n",
      "Epoch 3, iter 195, loss 2.3724026679992676, acc 0.09000000357627869\n",
      "Epoch 3, iter 196, loss 2.359511375427246, acc 0.11999999731779099\n",
      "Epoch 3, iter 197, loss 2.3472859859466553, acc 0.09000000357627869\n",
      "Epoch 3, iter 198, loss 2.3834171295166016, acc 0.09000000357627869\n",
      "Epoch 3, iter 199, loss 2.3696160316467285, acc 0.14000000059604645\n",
      "Epoch 3, iter 200, loss 2.3945274353027344, acc 0.1599999964237213\n",
      "Epoch 3, iter 201, loss 2.4455318450927734, acc 0.07000000029802322\n",
      "Epoch 3, iter 202, loss 2.3336431980133057, acc 0.10000000149011612\n",
      "Epoch 3, iter 203, loss 2.409379243850708, acc 0.10999999940395355\n",
      "Epoch 3, iter 204, loss 2.436163902282715, acc 0.05999999865889549\n",
      "Epoch 3, iter 205, loss 2.410325527191162, acc 0.07000000029802322\n",
      "Epoch 3, iter 206, loss 2.3405137062072754, acc 0.10000000149011612\n",
      "Epoch 3, iter 207, loss 2.408405065536499, acc 0.03999999910593033\n",
      "Epoch 3, iter 208, loss 2.375060558319092, acc 0.10000000149011612\n",
      "Epoch 3, iter 209, loss 2.339184045791626, acc 0.10999999940395355\n",
      "Epoch 3, iter 210, loss 2.32372784614563, acc 0.07999999821186066\n",
      "Epoch 3, iter 211, loss 2.4655163288116455, acc 0.05999999865889549\n",
      "Epoch 3, iter 212, loss 2.386831521987915, acc 0.12999999523162842\n",
      "Epoch 3, iter 213, loss 2.3149545192718506, acc 0.12999999523162842\n",
      "Epoch 3, iter 214, loss 2.4338717460632324, acc 0.05999999865889549\n",
      "Epoch 3, iter 215, loss 2.4046523571014404, acc 0.05999999865889549\n",
      "Epoch 3, iter 216, loss 2.325737953186035, acc 0.07999999821186066\n",
      "Epoch 3, iter 217, loss 2.3986005783081055, acc 0.11999999731779099\n",
      "Epoch 3, iter 218, loss 2.4076576232910156, acc 0.11999999731779099\n",
      "Epoch 3, iter 219, loss 2.3016281127929688, acc 0.11999999731779099\n",
      "Epoch 3, iter 220, loss 2.4777801036834717, acc 0.05000000074505806\n",
      "Epoch 3, iter 221, loss 2.349889039993286, acc 0.07999999821186066\n",
      "Epoch 3, iter 222, loss 2.330901861190796, acc 0.07999999821186066\n",
      "Epoch 3, iter 223, loss 2.297330856323242, acc 0.11999999731779099\n",
      "Epoch 3, iter 224, loss 2.3401176929473877, acc 0.10000000149011612\n",
      "Epoch 3, iter 225, loss 2.4157745838165283, acc 0.07000000029802322\n",
      "Epoch 3, iter 226, loss 2.3810975551605225, acc 0.07999999821186066\n",
      "Epoch 3, iter 227, loss 2.3637871742248535, acc 0.09000000357627869\n",
      "Epoch 3, iter 228, loss 2.285165786743164, acc 0.14000000059604645\n",
      "Epoch 3, iter 229, loss 2.386540412902832, acc 0.12999999523162842\n",
      "Epoch 3, iter 230, loss 2.3718104362487793, acc 0.09000000357627869\n",
      "Epoch 3, iter 231, loss 2.433413028717041, acc 0.07999999821186066\n",
      "Epoch 3, iter 232, loss 2.4248409271240234, acc 0.07999999821186066\n",
      "Epoch 3, iter 233, loss 2.347598075866699, acc 0.09000000357627869\n",
      "Epoch 3, iter 234, loss 2.3711037635803223, acc 0.07000000029802322\n",
      "Epoch 3, iter 235, loss 2.332979202270508, acc 0.09000000357627869\n",
      "Epoch 3, iter 236, loss 2.371612310409546, acc 0.07000000029802322\n",
      "Epoch 3, iter 237, loss 2.3822381496429443, acc 0.10999999940395355\n",
      "Epoch 3, iter 238, loss 2.333474636077881, acc 0.07000000029802322\n",
      "Epoch 3, iter 239, loss 2.3802783489227295, acc 0.09000000357627869\n",
      "Epoch 3, iter 240, loss 2.4061076641082764, acc 0.12999999523162842\n",
      "Epoch 3, iter 241, loss 2.399467945098877, acc 0.07999999821186066\n",
      "Epoch 3, iter 242, loss 2.3286266326904297, acc 0.11999999731779099\n",
      "Epoch 3, iter 243, loss 2.2924108505249023, acc 0.15000000596046448\n",
      "Epoch 3, iter 244, loss 2.380248546600342, acc 0.05000000074505806\n",
      "Epoch 3, iter 245, loss 2.3435850143432617, acc 0.05000000074505806\n",
      "Epoch 3, iter 246, loss 2.395612955093384, acc 0.05999999865889549\n",
      "Epoch 3, iter 247, loss 2.3014426231384277, acc 0.07000000029802322\n",
      "Epoch 3, iter 248, loss 2.343341827392578, acc 0.11999999731779099\n",
      "Epoch 3, iter 249, loss 2.3372650146484375, acc 0.17000000178813934\n",
      "Epoch 3, iter 250, loss 2.3030478954315186, acc 0.05999999865889549\n",
      "Epoch 3, iter 251, loss 2.317542314529419, acc 0.09000000357627869\n",
      "Epoch 3, iter 252, loss 2.272772789001465, acc 0.1599999964237213\n",
      "Epoch 3, iter 253, loss 2.4005494117736816, acc 0.12999999523162842\n",
      "Epoch 3, iter 254, loss 2.371295213699341, acc 0.10999999940395355\n",
      "Epoch 3, iter 255, loss 2.4672298431396484, acc 0.05000000074505806\n",
      "Epoch 3, iter 256, loss 2.3768699169158936, acc 0.05999999865889549\n",
      "Epoch 3, iter 257, loss 2.3658833503723145, acc 0.09000000357627869\n",
      "Epoch 3, iter 258, loss 2.2940616607666016, acc 0.10999999940395355\n",
      "Epoch 3, iter 259, loss 2.310852289199829, acc 0.09000000357627869\n",
      "Epoch 3, iter 260, loss 2.366119623184204, acc 0.07000000029802322\n",
      "Epoch 3, iter 261, loss 2.3121607303619385, acc 0.05999999865889549\n",
      "Epoch 3, iter 262, loss 2.409064292907715, acc 0.07999999821186066\n",
      "Epoch 3, iter 263, loss 2.3440091609954834, acc 0.05999999865889549\n",
      "Epoch 3, iter 264, loss 2.338303804397583, acc 0.09000000357627869\n",
      "Epoch 3, iter 265, loss 2.3631505966186523, acc 0.11999999731779099\n",
      "Epoch 3, iter 266, loss 2.338674306869507, acc 0.10999999940395355\n",
      "Epoch 3, iter 267, loss 2.3639321327209473, acc 0.18000000715255737\n",
      "Epoch 3, iter 268, loss 2.3614721298217773, acc 0.1599999964237213\n",
      "Epoch 3, iter 269, loss 2.3124194145202637, acc 0.09000000357627869\n",
      "Epoch 3, iter 270, loss 2.3895561695098877, acc 0.10000000149011612\n",
      "Epoch 3, iter 271, loss 2.382290840148926, acc 0.10999999940395355\n",
      "Epoch 3, iter 272, loss 2.352938652038574, acc 0.05999999865889549\n",
      "Epoch 3, iter 273, loss 2.3714280128479004, acc 0.09000000357627869\n",
      "Epoch 3, iter 274, loss 2.2649292945861816, acc 0.11999999731779099\n",
      "Epoch 3, iter 275, loss 2.3825180530548096, acc 0.07000000029802322\n",
      "Epoch 3, iter 276, loss 2.3910305500030518, acc 0.12999999523162842\n",
      "Epoch 3, iter 277, loss 2.299159049987793, acc 0.15000000596046448\n",
      "Epoch 3, iter 278, loss 2.293246030807495, acc 0.12999999523162842\n",
      "Epoch 3, iter 279, loss 2.342909812927246, acc 0.10000000149011612\n",
      "Epoch 3, iter 280, loss 2.3120663166046143, acc 0.09000000357627869\n",
      "Epoch 3, iter 281, loss 2.328608274459839, acc 0.07999999821186066\n",
      "Epoch 3, iter 282, loss 2.414304733276367, acc 0.1599999964237213\n",
      "Epoch 3, iter 283, loss 2.376176357269287, acc 0.07999999821186066\n",
      "Epoch 3, iter 284, loss 2.3943915367126465, acc 0.07000000029802322\n",
      "Epoch 3, iter 285, loss 2.335106134414673, acc 0.07999999821186066\n",
      "Epoch 3, iter 286, loss 2.3519277572631836, acc 0.09000000357627869\n",
      "Epoch 3, iter 287, loss 2.380262851715088, acc 0.12999999523162842\n",
      "Epoch 3, iter 288, loss 2.3805558681488037, acc 0.07000000029802322\n",
      "Epoch 3, iter 289, loss 2.3420968055725098, acc 0.10000000149011612\n",
      "Epoch 3, iter 290, loss 2.4007418155670166, acc 0.05999999865889549\n",
      "Epoch 3, iter 291, loss 2.3425240516662598, acc 0.11999999731779099\n",
      "Epoch 3, iter 292, loss 2.365607261657715, acc 0.10000000149011612\n",
      "Epoch 3, iter 293, loss 2.308941125869751, acc 0.10999999940395355\n",
      "Epoch 3, iter 294, loss 2.3865654468536377, acc 0.14000000059604645\n",
      "Epoch 3, iter 295, loss 2.3407421112060547, acc 0.11999999731779099\n",
      "Epoch 3, iter 296, loss 2.3889577388763428, acc 0.09000000357627869\n",
      "Epoch 3, iter 297, loss 2.3861324787139893, acc 0.09000000357627869\n",
      "Epoch 3, iter 298, loss 2.3161869049072266, acc 0.10999999940395355\n",
      "Epoch 3, iter 299, loss 2.3308863639831543, acc 0.11999999731779099\n",
      "Epoch 3, iter 300, loss 2.3681817054748535, acc 0.09000000357627869\n",
      "Epoch 3, iter 301, loss 2.3665807247161865, acc 0.03999999910593033\n",
      "Epoch 3, iter 302, loss 2.331665515899658, acc 0.12999999523162842\n",
      "Epoch 3, iter 303, loss 2.3824968338012695, acc 0.10999999940395355\n",
      "Epoch 3, iter 304, loss 2.4276747703552246, acc 0.05000000074505806\n",
      "Epoch 3, iter 305, loss 2.355670928955078, acc 0.09000000357627869\n",
      "Epoch 3, iter 306, loss 2.3753414154052734, acc 0.05999999865889549\n",
      "Epoch 3, iter 307, loss 2.3146326541900635, acc 0.10000000149011612\n",
      "Epoch 3, iter 308, loss 2.3370614051818848, acc 0.15000000596046448\n",
      "Epoch 3, iter 309, loss 2.31355619430542, acc 0.12999999523162842\n",
      "Epoch 3, iter 310, loss 2.389228582382202, acc 0.05000000074505806\n",
      "Epoch 3, iter 311, loss 2.3507654666900635, acc 0.11999999731779099\n",
      "Epoch 3, iter 312, loss 2.404419422149658, acc 0.05000000074505806\n",
      "Epoch 3, iter 313, loss 2.410562753677368, acc 0.10000000149011612\n",
      "Epoch 3, iter 314, loss 2.3295676708221436, acc 0.1899999976158142\n",
      "Epoch 3, iter 315, loss 2.434166431427002, acc 0.10999999940395355\n",
      "Epoch 3, iter 316, loss 2.367110013961792, acc 0.07999999821186066\n",
      "Epoch 3, iter 317, loss 2.363806962966919, acc 0.05000000074505806\n",
      "Epoch 3, iter 318, loss 2.388230800628662, acc 0.07000000029802322\n",
      "Epoch 3, iter 319, loss 2.3065552711486816, acc 0.14000000059604645\n",
      "Epoch 3, iter 320, loss 2.2946159839630127, acc 0.07999999821186066\n",
      "Epoch 3, iter 321, loss 2.356846570968628, acc 0.09000000357627869\n",
      "Epoch 3, iter 322, loss 2.3793981075286865, acc 0.10000000149011612\n",
      "Epoch 3, iter 323, loss 2.3775811195373535, acc 0.09000000357627869\n",
      "Epoch 3, iter 324, loss 2.3158013820648193, acc 0.10000000149011612\n",
      "Epoch 3, iter 325, loss 2.382558822631836, acc 0.05999999865889549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 326, loss 2.291949510574341, acc 0.12999999523162842\n",
      "Epoch 3, iter 327, loss 2.3337604999542236, acc 0.12999999523162842\n",
      "Epoch 3, iter 328, loss 2.432403802871704, acc 0.07000000029802322\n",
      "Epoch 3, iter 329, loss 2.344999313354492, acc 0.07000000029802322\n",
      "Epoch 3, iter 330, loss 2.294689893722534, acc 0.11999999731779099\n",
      "Epoch 3, iter 331, loss 2.323601007461548, acc 0.10000000149011612\n",
      "Epoch 3, iter 332, loss 2.3348031044006348, acc 0.11999999731779099\n",
      "Epoch 3, iter 333, loss 2.370610237121582, acc 0.09000000357627869\n",
      "Epoch 3, iter 334, loss 2.389709234237671, acc 0.05999999865889549\n",
      "Epoch 3, iter 335, loss 2.311138153076172, acc 0.09000000357627869\n",
      "Epoch 3, iter 336, loss 2.3314309120178223, acc 0.14000000059604645\n",
      "Epoch 3, iter 337, loss 2.3343241214752197, acc 0.07000000029802322\n",
      "Epoch 3, iter 338, loss 2.331068992614746, acc 0.07000000029802322\n",
      "Epoch 3, iter 339, loss 2.3221590518951416, acc 0.15000000596046448\n",
      "Epoch 3, iter 340, loss 2.403096914291382, acc 0.10999999940395355\n",
      "Epoch 3, iter 341, loss 2.3103673458099365, acc 0.07999999821186066\n",
      "Epoch 3, iter 342, loss 2.3968207836151123, acc 0.05000000074505806\n",
      "Epoch 3, iter 343, loss 2.305509090423584, acc 0.12999999523162842\n",
      "Epoch 3, iter 344, loss 2.406092405319214, acc 0.11999999731779099\n",
      "Epoch 3, iter 345, loss 2.3457860946655273, acc 0.09000000357627869\n",
      "Epoch 3, iter 346, loss 2.442671298980713, acc 0.07000000029802322\n",
      "Epoch 3, iter 347, loss 2.375584125518799, acc 0.12999999523162842\n",
      "Epoch 3, iter 348, loss 2.376704454421997, acc 0.07999999821186066\n",
      "Epoch 3, iter 349, loss 2.3840742111206055, acc 0.029999999329447746\n",
      "Epoch 3, iter 350, loss 2.330359935760498, acc 0.15000000596046448\n",
      "Epoch 3, iter 351, loss 2.2582755088806152, acc 0.15000000596046448\n",
      "Epoch 3, iter 352, loss 2.3928277492523193, acc 0.10999999940395355\n",
      "Epoch 3, iter 353, loss 2.332970380783081, acc 0.10999999940395355\n",
      "Epoch 3, iter 354, loss 2.3891441822052, acc 0.07999999821186066\n",
      "Epoch 3, iter 355, loss 2.3519234657287598, acc 0.07999999821186066\n",
      "Epoch 3, iter 356, loss 2.317298412322998, acc 0.14000000059604645\n",
      "Epoch 3, iter 357, loss 2.321493625640869, acc 0.09000000357627869\n",
      "Epoch 3, iter 358, loss 2.3159360885620117, acc 0.09000000357627869\n",
      "Epoch 3, iter 359, loss 2.3806052207946777, acc 0.07000000029802322\n",
      "Epoch 3, iter 360, loss 2.440354347229004, acc 0.07000000029802322\n",
      "Epoch 3, iter 361, loss 2.3206799030303955, acc 0.14000000059604645\n",
      "Epoch 3, iter 362, loss 2.354710340499878, acc 0.07000000029802322\n",
      "Epoch 3, iter 363, loss 2.325681686401367, acc 0.11999999731779099\n",
      "Epoch 3, iter 364, loss 2.4040169715881348, acc 0.10999999940395355\n",
      "Epoch 3, iter 365, loss 2.3430535793304443, acc 0.10999999940395355\n",
      "Epoch 3, iter 366, loss 2.3924241065979004, acc 0.07000000029802322\n",
      "Epoch 3, iter 367, loss 2.329740524291992, acc 0.07999999821186066\n",
      "Epoch 3, iter 368, loss 2.3826780319213867, acc 0.09000000357627869\n",
      "Epoch 3, iter 369, loss 2.295901298522949, acc 0.12999999523162842\n",
      "Epoch 3, iter 370, loss 2.315150499343872, acc 0.05999999865889549\n",
      "Epoch 3, iter 371, loss 2.375487804412842, acc 0.07000000029802322\n",
      "Epoch 3, iter 372, loss 2.29899001121521, acc 0.15000000596046448\n",
      "Epoch 3, iter 373, loss 2.3708767890930176, acc 0.09000000357627869\n",
      "Epoch 3, iter 374, loss 2.3093504905700684, acc 0.09000000357627869\n",
      "Epoch 3, iter 375, loss 2.407942771911621, acc 0.07000000029802322\n",
      "Epoch 3, iter 376, loss 2.3268189430236816, acc 0.09000000357627869\n",
      "Epoch 3, iter 377, loss 2.391883134841919, acc 0.07000000029802322\n",
      "Epoch 3, iter 378, loss 2.3350446224212646, acc 0.14000000059604645\n",
      "Epoch 3, iter 379, loss 2.378230333328247, acc 0.12999999523162842\n",
      "Epoch 3, iter 380, loss 2.3376588821411133, acc 0.07000000029802322\n",
      "Epoch 3, iter 381, loss 2.3801627159118652, acc 0.07000000029802322\n",
      "Epoch 3, iter 382, loss 2.3653178215026855, acc 0.07000000029802322\n",
      "Epoch 3, iter 383, loss 2.3115596771240234, acc 0.10999999940395355\n",
      "Epoch 3, iter 384, loss 2.353546142578125, acc 0.10000000149011612\n",
      "Epoch 3, iter 385, loss 2.3206546306610107, acc 0.07999999821186066\n",
      "Epoch 3, iter 386, loss 2.3521971702575684, acc 0.07000000029802322\n",
      "Epoch 3, iter 387, loss 2.371792793273926, acc 0.03999999910593033\n",
      "Epoch 3, iter 388, loss 2.355032444000244, acc 0.11999999731779099\n",
      "Epoch 3, iter 389, loss 2.324399709701538, acc 0.10999999940395355\n",
      "Epoch 3, iter 390, loss 2.3431081771850586, acc 0.09000000357627869\n",
      "Epoch 3, iter 391, loss 2.3429465293884277, acc 0.09000000357627869\n",
      "Epoch 3, iter 392, loss 2.3767282962799072, acc 0.10999999940395355\n",
      "Epoch 3, iter 393, loss 2.353801965713501, acc 0.14000000059604645\n",
      "Epoch 3, iter 394, loss 2.4078481197357178, acc 0.05999999865889549\n",
      "Epoch 3, iter 395, loss 2.384549856185913, acc 0.07000000029802322\n",
      "Epoch 3, iter 396, loss 2.3813178539276123, acc 0.10000000149011612\n",
      "Epoch 3, iter 397, loss 2.4214529991149902, acc 0.10000000149011612\n",
      "Epoch 3, iter 398, loss 2.3165228366851807, acc 0.10999999940395355\n",
      "Epoch 3, iter 399, loss 2.3962464332580566, acc 0.10999999940395355\n",
      "Epoch 3, iter 400, loss 2.3145439624786377, acc 0.05999999865889549\n",
      "Epoch 3, iter 401, loss 2.3389480113983154, acc 0.10999999940395355\n",
      "Epoch 3, iter 402, loss 2.3078854084014893, acc 0.07999999821186066\n",
      "Epoch 3, iter 403, loss 2.307119607925415, acc 0.09000000357627869\n",
      "Epoch 3, iter 404, loss 2.3187508583068848, acc 0.09000000357627869\n",
      "Epoch 3, iter 405, loss 2.320863723754883, acc 0.11999999731779099\n",
      "Epoch 3, iter 406, loss 2.383100986480713, acc 0.09000000357627869\n",
      "Epoch 3, iter 407, loss 2.4111733436584473, acc 0.11999999731779099\n",
      "Epoch 3, iter 408, loss 2.3076086044311523, acc 0.10999999940395355\n",
      "Epoch 3, iter 409, loss 2.3534996509552, acc 0.10000000149011612\n",
      "Epoch 3, iter 410, loss 2.3826417922973633, acc 0.09000000357627869\n",
      "Epoch 3, iter 411, loss 2.329967737197876, acc 0.03999999910593033\n",
      "Epoch 3, iter 412, loss 2.329256296157837, acc 0.10999999940395355\n",
      "Epoch 3, iter 413, loss 2.3973565101623535, acc 0.07000000029802322\n",
      "Epoch 3, iter 414, loss 2.3262441158294678, acc 0.12999999523162842\n",
      "Epoch 3, iter 415, loss 2.3150086402893066, acc 0.07000000029802322\n",
      "Epoch 3, iter 416, loss 2.3209123611450195, acc 0.10999999940395355\n",
      "Epoch 3, iter 417, loss 2.3988773822784424, acc 0.07999999821186066\n",
      "Epoch 3, iter 418, loss 2.3794753551483154, acc 0.05000000074505806\n",
      "Epoch 3, iter 419, loss 2.349604845046997, acc 0.07999999821186066\n",
      "Epoch 3, iter 420, loss 2.3283934593200684, acc 0.10999999940395355\n",
      "Epoch 4, iter 1, loss 2.410167694091797, acc 0.10000000149011612\n",
      "Epoch 4, iter 2, loss 2.3264200687408447, acc 0.09000000357627869\n",
      "Epoch 4, iter 3, loss 2.326509475708008, acc 0.11999999731779099\n",
      "Epoch 4, iter 4, loss 2.305912494659424, acc 0.14000000059604645\n",
      "Epoch 4, iter 5, loss 2.310006618499756, acc 0.10000000149011612\n",
      "Epoch 4, iter 6, loss 2.3356926441192627, acc 0.09000000357627869\n",
      "Epoch 4, iter 7, loss 2.3362181186676025, acc 0.10999999940395355\n",
      "Epoch 4, iter 8, loss 2.306053876876831, acc 0.07999999821186066\n",
      "Epoch 4, iter 9, loss 2.306684732437134, acc 0.12999999523162842\n",
      "Epoch 4, iter 10, loss 2.316779136657715, acc 0.14000000059604645\n",
      "Epoch 4, iter 11, loss 2.3025569915771484, acc 0.10000000149011612\n",
      "Epoch 4, iter 12, loss 2.3015213012695312, acc 0.07999999821186066\n",
      "Epoch 4, iter 13, loss 2.2924177646636963, acc 0.1599999964237213\n",
      "Epoch 4, iter 14, loss 2.400174856185913, acc 0.05000000074505806\n",
      "Epoch 4, iter 15, loss 2.375140428543091, acc 0.09000000357627869\n",
      "Epoch 4, iter 16, loss 2.3561201095581055, acc 0.10999999940395355\n",
      "Epoch 4, iter 17, loss 2.3096628189086914, acc 0.10999999940395355\n",
      "Epoch 4, iter 18, loss 2.3843140602111816, acc 0.07999999821186066\n",
      "Epoch 4, iter 19, loss 2.2912373542785645, acc 0.10999999940395355\n",
      "Epoch 4, iter 20, loss 2.248806953430176, acc 0.1599999964237213\n",
      "Epoch 4, iter 21, loss 2.3668372631073, acc 0.03999999910593033\n",
      "Epoch 4, iter 22, loss 2.3802902698516846, acc 0.05999999865889549\n",
      "Epoch 4, iter 23, loss 2.3382856845855713, acc 0.09000000357627869\n",
      "Epoch 4, iter 24, loss 2.2981743812561035, acc 0.1599999964237213\n",
      "Epoch 4, iter 25, loss 2.349916458129883, acc 0.07000000029802322\n",
      "Epoch 4, iter 26, loss 2.3624024391174316, acc 0.05999999865889549\n",
      "Epoch 4, iter 27, loss 2.324789524078369, acc 0.10999999940395355\n",
      "Epoch 4, iter 28, loss 2.3654584884643555, acc 0.07999999821186066\n",
      "Epoch 4, iter 29, loss 2.3271067142486572, acc 0.10000000149011612\n",
      "Epoch 4, iter 30, loss 2.415921688079834, acc 0.10999999940395355\n",
      "Epoch 4, iter 31, loss 2.368992805480957, acc 0.10000000149011612\n",
      "Epoch 4, iter 32, loss 2.313447952270508, acc 0.14000000059604645\n",
      "Epoch 4, iter 33, loss 2.34476375579834, acc 0.07999999821186066\n",
      "Epoch 4, iter 34, loss 2.411846160888672, acc 0.05999999865889549\n",
      "Epoch 4, iter 35, loss 2.3273534774780273, acc 0.07999999821186066\n",
      "Epoch 4, iter 36, loss 2.323214054107666, acc 0.09000000357627869\n",
      "Epoch 4, iter 37, loss 2.3354575634002686, acc 0.10999999940395355\n",
      "Epoch 4, iter 38, loss 2.323744297027588, acc 0.12999999523162842\n",
      "Epoch 4, iter 39, loss 2.302549123764038, acc 0.10999999940395355\n",
      "Epoch 4, iter 40, loss 2.365783452987671, acc 0.14000000059604645\n",
      "Epoch 4, iter 41, loss 2.382211208343506, acc 0.07000000029802322\n",
      "Epoch 4, iter 42, loss 2.317866325378418, acc 0.07999999821186066\n",
      "Epoch 4, iter 43, loss 2.3662562370300293, acc 0.10000000149011612\n",
      "Epoch 4, iter 44, loss 2.3082520961761475, acc 0.14000000059604645\n",
      "Epoch 4, iter 45, loss 2.3854660987854004, acc 0.11999999731779099\n",
      "Epoch 4, iter 46, loss 2.3972978591918945, acc 0.05999999865889549\n",
      "Epoch 4, iter 47, loss 2.339839220046997, acc 0.09000000357627869\n",
      "Epoch 4, iter 48, loss 2.3741960525512695, acc 0.10999999940395355\n",
      "Epoch 4, iter 49, loss 2.3654520511627197, acc 0.10999999940395355\n",
      "Epoch 4, iter 50, loss 2.3290984630584717, acc 0.10000000149011612\n",
      "Epoch 4, iter 51, loss 2.3542308807373047, acc 0.10000000149011612\n",
      "Epoch 4, iter 52, loss 2.338993549346924, acc 0.10999999940395355\n",
      "Epoch 4, iter 53, loss 2.3674426078796387, acc 0.12999999523162842\n",
      "Epoch 4, iter 54, loss 2.309046983718872, acc 0.09000000357627869\n",
      "Epoch 4, iter 55, loss 2.346367120742798, acc 0.09000000357627869\n",
      "Epoch 4, iter 56, loss 2.3369879722595215, acc 0.10000000149011612\n",
      "Epoch 4, iter 57, loss 2.266900062561035, acc 0.15000000596046448\n",
      "Epoch 4, iter 58, loss 2.3813483715057373, acc 0.05999999865889549\n",
      "Epoch 4, iter 59, loss 2.361945867538452, acc 0.09000000357627869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 60, loss 2.3621714115142822, acc 0.07999999821186066\n",
      "Epoch 4, iter 61, loss 2.3375229835510254, acc 0.05999999865889549\n",
      "Epoch 4, iter 62, loss 2.292172431945801, acc 0.14000000059604645\n",
      "Epoch 4, iter 63, loss 2.335615873336792, acc 0.11999999731779099\n",
      "Epoch 4, iter 64, loss 2.305798292160034, acc 0.07999999821186066\n",
      "Epoch 4, iter 65, loss 2.3606181144714355, acc 0.07999999821186066\n",
      "Epoch 4, iter 66, loss 2.324903726577759, acc 0.07999999821186066\n",
      "Epoch 4, iter 67, loss 2.3541009426116943, acc 0.11999999731779099\n",
      "Epoch 4, iter 68, loss 2.309887170791626, acc 0.09000000357627869\n",
      "Epoch 4, iter 69, loss 2.306722640991211, acc 0.10000000149011612\n",
      "Epoch 4, iter 70, loss 2.3454713821411133, acc 0.10999999940395355\n",
      "Epoch 4, iter 71, loss 2.3633244037628174, acc 0.10000000149011612\n",
      "Epoch 4, iter 72, loss 2.4019601345062256, acc 0.05000000074505806\n",
      "Epoch 4, iter 73, loss 2.325450897216797, acc 0.10000000149011612\n",
      "Epoch 4, iter 74, loss 2.2912564277648926, acc 0.10999999940395355\n",
      "Epoch 4, iter 75, loss 2.3563289642333984, acc 0.09000000357627869\n",
      "Epoch 4, iter 76, loss 2.337355613708496, acc 0.14000000059604645\n",
      "Epoch 4, iter 77, loss 2.319579839706421, acc 0.11999999731779099\n",
      "Epoch 4, iter 78, loss 2.3439574241638184, acc 0.09000000357627869\n",
      "Epoch 4, iter 79, loss 2.315547227859497, acc 0.07999999821186066\n",
      "Epoch 4, iter 80, loss 2.361490249633789, acc 0.07999999821186066\n",
      "Epoch 4, iter 81, loss 2.297008752822876, acc 0.15000000596046448\n",
      "Epoch 4, iter 82, loss 2.319730520248413, acc 0.11999999731779099\n",
      "Epoch 4, iter 83, loss 2.345569372177124, acc 0.10999999940395355\n",
      "Epoch 4, iter 84, loss 2.3079733848571777, acc 0.10000000149011612\n",
      "Epoch 4, iter 85, loss 2.3066632747650146, acc 0.10999999940395355\n",
      "Epoch 4, iter 86, loss 2.312340259552002, acc 0.11999999731779099\n",
      "Epoch 4, iter 87, loss 2.257524013519287, acc 0.11999999731779099\n",
      "Epoch 4, iter 88, loss 2.2879867553710938, acc 0.10999999940395355\n",
      "Epoch 4, iter 89, loss 2.3575992584228516, acc 0.07000000029802322\n",
      "Epoch 4, iter 90, loss 2.377082586288452, acc 0.09000000357627869\n",
      "Epoch 4, iter 91, loss 2.339432716369629, acc 0.10999999940395355\n",
      "Epoch 4, iter 92, loss 2.228644609451294, acc 0.14000000059604645\n",
      "Epoch 4, iter 93, loss 2.359632968902588, acc 0.05000000074505806\n",
      "Epoch 4, iter 94, loss 2.3367760181427, acc 0.11999999731779099\n",
      "Epoch 4, iter 95, loss 2.3527603149414062, acc 0.12999999523162842\n",
      "Epoch 4, iter 96, loss 2.292025566101074, acc 0.15000000596046448\n",
      "Epoch 4, iter 97, loss 2.3422725200653076, acc 0.10999999940395355\n",
      "Epoch 4, iter 98, loss 2.3822367191314697, acc 0.07999999821186066\n",
      "Epoch 4, iter 99, loss 2.2561826705932617, acc 0.17000000178813934\n",
      "Epoch 4, iter 100, loss 2.4079012870788574, acc 0.05999999865889549\n",
      "Epoch 4, iter 101, loss 2.3758933544158936, acc 0.07999999821186066\n",
      "Epoch 4, iter 102, loss 2.327695369720459, acc 0.10000000149011612\n",
      "Epoch 4, iter 103, loss 2.3489675521850586, acc 0.07999999821186066\n",
      "Epoch 4, iter 104, loss 2.2757060527801514, acc 0.10999999940395355\n",
      "Epoch 4, iter 105, loss 2.360849142074585, acc 0.11999999731779099\n",
      "Epoch 4, iter 106, loss 2.2891931533813477, acc 0.14000000059604645\n",
      "Epoch 4, iter 107, loss 2.279385805130005, acc 0.09000000357627869\n",
      "Epoch 4, iter 108, loss 2.324913501739502, acc 0.07999999821186066\n",
      "Epoch 4, iter 109, loss 2.350465774536133, acc 0.10000000149011612\n",
      "Epoch 4, iter 110, loss 2.3792831897735596, acc 0.07999999821186066\n",
      "Epoch 4, iter 111, loss 2.4346282482147217, acc 0.05999999865889549\n",
      "Epoch 4, iter 112, loss 2.3801109790802, acc 0.05999999865889549\n",
      "Epoch 4, iter 113, loss 2.282747507095337, acc 0.10999999940395355\n",
      "Epoch 4, iter 114, loss 2.382683753967285, acc 0.12999999523162842\n",
      "Epoch 4, iter 115, loss 2.2848963737487793, acc 0.10999999940395355\n",
      "Epoch 4, iter 116, loss 2.3172762393951416, acc 0.07000000029802322\n",
      "Epoch 4, iter 117, loss 2.3714044094085693, acc 0.07999999821186066\n",
      "Epoch 4, iter 118, loss 2.37742018699646, acc 0.05999999865889549\n",
      "Epoch 4, iter 119, loss 2.322326421737671, acc 0.09000000357627869\n",
      "Epoch 4, iter 120, loss 2.3066186904907227, acc 0.14000000059604645\n",
      "Epoch 4, iter 121, loss 2.3007454872131348, acc 0.14000000059604645\n",
      "Epoch 4, iter 122, loss 2.327968120574951, acc 0.05999999865889549\n",
      "Epoch 4, iter 123, loss 2.316969394683838, acc 0.03999999910593033\n",
      "Epoch 4, iter 124, loss 2.3798227310180664, acc 0.07000000029802322\n",
      "Epoch 4, iter 125, loss 2.3161818981170654, acc 0.11999999731779099\n",
      "Epoch 4, iter 126, loss 2.3955764770507812, acc 0.07000000029802322\n",
      "Epoch 4, iter 127, loss 2.31365704536438, acc 0.05999999865889549\n",
      "Epoch 4, iter 128, loss 2.325821876525879, acc 0.12999999523162842\n",
      "Epoch 4, iter 129, loss 2.346014976501465, acc 0.07999999821186066\n",
      "Epoch 4, iter 130, loss 2.357161521911621, acc 0.05999999865889549\n",
      "Epoch 4, iter 131, loss 2.3418149948120117, acc 0.10999999940395355\n",
      "Epoch 4, iter 132, loss 2.2927236557006836, acc 0.12999999523162842\n",
      "Epoch 4, iter 133, loss 2.324469804763794, acc 0.10999999940395355\n",
      "Epoch 4, iter 134, loss 2.3202898502349854, acc 0.10000000149011612\n",
      "Epoch 4, iter 135, loss 2.3797671794891357, acc 0.07999999821186066\n",
      "Epoch 4, iter 136, loss 2.3396334648132324, acc 0.09000000357627869\n",
      "Epoch 4, iter 137, loss 2.3114798069000244, acc 0.14000000059604645\n",
      "Epoch 4, iter 138, loss 2.2732303142547607, acc 0.14000000059604645\n",
      "Epoch 4, iter 139, loss 2.311600685119629, acc 0.10000000149011612\n",
      "Epoch 4, iter 140, loss 2.3128488063812256, acc 0.09000000357627869\n",
      "Epoch 4, iter 141, loss 2.2999684810638428, acc 0.12999999523162842\n",
      "Epoch 4, iter 142, loss 2.4425601959228516, acc 0.09000000357627869\n",
      "Epoch 4, iter 143, loss 2.258538007736206, acc 0.09000000357627869\n",
      "Epoch 4, iter 144, loss 2.3877365589141846, acc 0.05999999865889549\n",
      "Epoch 4, iter 145, loss 2.343608856201172, acc 0.07999999821186066\n",
      "Epoch 4, iter 146, loss 2.3151798248291016, acc 0.10999999940395355\n",
      "Epoch 4, iter 147, loss 2.3696162700653076, acc 0.07000000029802322\n",
      "Epoch 4, iter 148, loss 2.36342716217041, acc 0.05000000074505806\n",
      "Epoch 4, iter 149, loss 2.3890738487243652, acc 0.03999999910593033\n",
      "Epoch 4, iter 150, loss 2.2805895805358887, acc 0.14000000059604645\n",
      "Epoch 4, iter 151, loss 2.369248390197754, acc 0.07000000029802322\n",
      "Epoch 4, iter 152, loss 2.360507011413574, acc 0.05999999865889549\n",
      "Epoch 4, iter 153, loss 2.347215175628662, acc 0.10999999940395355\n",
      "Epoch 4, iter 154, loss 2.3199546337127686, acc 0.10999999940395355\n",
      "Epoch 4, iter 155, loss 2.328465223312378, acc 0.14000000059604645\n",
      "Epoch 4, iter 156, loss 2.2885329723358154, acc 0.10000000149011612\n",
      "Epoch 4, iter 157, loss 2.416876792907715, acc 0.11999999731779099\n",
      "Epoch 4, iter 158, loss 2.319293737411499, acc 0.10000000149011612\n",
      "Epoch 4, iter 159, loss 2.3715286254882812, acc 0.07000000029802322\n",
      "Epoch 4, iter 160, loss 2.3217580318450928, acc 0.11999999731779099\n",
      "Epoch 4, iter 161, loss 2.289388656616211, acc 0.10999999940395355\n",
      "Epoch 4, iter 162, loss 2.3070778846740723, acc 0.09000000357627869\n",
      "Epoch 4, iter 163, loss 2.307440757751465, acc 0.10000000149011612\n",
      "Epoch 4, iter 164, loss 2.3706552982330322, acc 0.12999999523162842\n",
      "Epoch 4, iter 165, loss 2.326322555541992, acc 0.09000000357627869\n",
      "Epoch 4, iter 166, loss 2.3264737129211426, acc 0.10999999940395355\n",
      "Epoch 4, iter 167, loss 2.2888712882995605, acc 0.07999999821186066\n",
      "Epoch 4, iter 168, loss 2.365858793258667, acc 0.10999999940395355\n",
      "Epoch 4, iter 169, loss 2.3687713146209717, acc 0.10999999940395355\n",
      "Epoch 4, iter 170, loss 2.4189038276672363, acc 0.07000000029802322\n",
      "Epoch 4, iter 171, loss 2.3341917991638184, acc 0.10999999940395355\n",
      "Epoch 4, iter 172, loss 2.3476510047912598, acc 0.10999999940395355\n",
      "Epoch 4, iter 173, loss 2.3656980991363525, acc 0.09000000357627869\n",
      "Epoch 4, iter 174, loss 2.300739288330078, acc 0.07999999821186066\n",
      "Epoch 4, iter 175, loss 2.3281257152557373, acc 0.07999999821186066\n",
      "Epoch 4, iter 176, loss 2.373941421508789, acc 0.09000000357627869\n",
      "Epoch 4, iter 177, loss 2.3227860927581787, acc 0.05999999865889549\n",
      "Epoch 4, iter 178, loss 2.317919969558716, acc 0.07999999821186066\n",
      "Epoch 4, iter 179, loss 2.3193275928497314, acc 0.09000000357627869\n",
      "Epoch 4, iter 180, loss 2.281071901321411, acc 0.15000000596046448\n",
      "Epoch 4, iter 181, loss 2.2311348915100098, acc 0.10999999940395355\n",
      "Epoch 4, iter 182, loss 2.283188581466675, acc 0.09000000357627869\n",
      "Epoch 4, iter 183, loss 2.289437770843506, acc 0.09000000357627869\n",
      "Epoch 4, iter 184, loss 2.368497371673584, acc 0.03999999910593033\n",
      "Epoch 4, iter 185, loss 2.3296263217926025, acc 0.12999999523162842\n",
      "Epoch 4, iter 186, loss 2.3468308448791504, acc 0.07999999821186066\n",
      "Epoch 4, iter 187, loss 2.2644453048706055, acc 0.09000000357627869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 188, loss 2.3223350048065186, acc 0.10000000149011612\n",
      "Epoch 4, iter 189, loss 2.3436293601989746, acc 0.10000000149011612\n",
      "Epoch 4, iter 190, loss 2.3078348636627197, acc 0.10999999940395355\n",
      "Epoch 4, iter 191, loss 2.2709834575653076, acc 0.10999999940395355\n",
      "Epoch 4, iter 192, loss 2.357168674468994, acc 0.07999999821186066\n",
      "Epoch 4, iter 193, loss 2.3331902027130127, acc 0.07000000029802322\n",
      "Epoch 4, iter 194, loss 2.276759386062622, acc 0.15000000596046448\n",
      "Epoch 4, iter 195, loss 2.319261074066162, acc 0.10000000149011612\n",
      "Epoch 4, iter 196, loss 2.3019909858703613, acc 0.12999999523162842\n",
      "Epoch 4, iter 197, loss 2.2914676666259766, acc 0.09000000357627869\n",
      "Epoch 4, iter 198, loss 2.324298620223999, acc 0.10999999940395355\n",
      "Epoch 4, iter 199, loss 2.347490072250366, acc 0.15000000596046448\n",
      "Epoch 4, iter 200, loss 2.345308780670166, acc 0.1599999964237213\n",
      "Epoch 4, iter 201, loss 2.3907768726348877, acc 0.07000000029802322\n",
      "Epoch 4, iter 202, loss 2.293853521347046, acc 0.10000000149011612\n",
      "Epoch 4, iter 203, loss 2.3208701610565186, acc 0.11999999731779099\n",
      "Epoch 4, iter 204, loss 2.37717866897583, acc 0.05999999865889549\n",
      "Epoch 4, iter 205, loss 2.3420231342315674, acc 0.07999999821186066\n",
      "Epoch 4, iter 206, loss 2.2961504459381104, acc 0.10999999940395355\n",
      "Epoch 4, iter 207, loss 2.373042345046997, acc 0.05000000074505806\n",
      "Epoch 4, iter 208, loss 2.360224723815918, acc 0.09000000357627869\n",
      "Epoch 4, iter 209, loss 2.305175304412842, acc 0.11999999731779099\n",
      "Epoch 4, iter 210, loss 2.2982187271118164, acc 0.07000000029802322\n",
      "Epoch 4, iter 211, loss 2.4174158573150635, acc 0.05000000074505806\n",
      "Epoch 4, iter 212, loss 2.3512401580810547, acc 0.12999999523162842\n",
      "Epoch 4, iter 213, loss 2.253462314605713, acc 0.14000000059604645\n",
      "Epoch 4, iter 214, loss 2.3582913875579834, acc 0.07000000029802322\n",
      "Epoch 4, iter 215, loss 2.3775599002838135, acc 0.05999999865889549\n",
      "Epoch 4, iter 216, loss 2.299004554748535, acc 0.07999999821186066\n",
      "Epoch 4, iter 217, loss 2.3544249534606934, acc 0.11999999731779099\n",
      "Epoch 4, iter 218, loss 2.3789920806884766, acc 0.14000000059604645\n",
      "Epoch 4, iter 219, loss 2.275667667388916, acc 0.10999999940395355\n",
      "Epoch 4, iter 220, loss 2.402844190597534, acc 0.05999999865889549\n",
      "Epoch 4, iter 221, loss 2.3020436763763428, acc 0.07999999821186066\n",
      "Epoch 4, iter 222, loss 2.2784297466278076, acc 0.09000000357627869\n",
      "Epoch 4, iter 223, loss 2.2391185760498047, acc 0.12999999523162842\n",
      "Epoch 4, iter 224, loss 2.3038036823272705, acc 0.10999999940395355\n",
      "Epoch 4, iter 225, loss 2.3751800060272217, acc 0.05999999865889549\n",
      "Epoch 4, iter 226, loss 2.327846050262451, acc 0.07999999821186066\n",
      "Epoch 4, iter 227, loss 2.316601037979126, acc 0.07999999821186066\n",
      "Epoch 4, iter 228, loss 2.258929967880249, acc 0.14000000059604645\n",
      "Epoch 4, iter 229, loss 2.3299577236175537, acc 0.12999999523162842\n",
      "Epoch 4, iter 230, loss 2.3173255920410156, acc 0.10000000149011612\n",
      "Epoch 4, iter 231, loss 2.3568241596221924, acc 0.07999999821186066\n",
      "Epoch 4, iter 232, loss 2.3945093154907227, acc 0.09000000357627869\n",
      "Epoch 4, iter 233, loss 2.282787561416626, acc 0.09000000357627869\n",
      "Epoch 4, iter 234, loss 2.306216239929199, acc 0.07000000029802322\n",
      "Epoch 4, iter 235, loss 2.2812044620513916, acc 0.10000000149011612\n",
      "Epoch 4, iter 236, loss 2.34147047996521, acc 0.07000000029802322\n",
      "Epoch 4, iter 237, loss 2.3348028659820557, acc 0.10999999940395355\n",
      "Epoch 4, iter 238, loss 2.29587984085083, acc 0.07000000029802322\n",
      "Epoch 4, iter 239, loss 2.3221559524536133, acc 0.09000000357627869\n",
      "Epoch 4, iter 240, loss 2.348754644393921, acc 0.11999999731779099\n",
      "Epoch 4, iter 241, loss 2.347079277038574, acc 0.07999999821186066\n",
      "Epoch 4, iter 242, loss 2.2664923667907715, acc 0.14000000059604645\n",
      "Epoch 4, iter 243, loss 2.2586863040924072, acc 0.15000000596046448\n",
      "Epoch 4, iter 244, loss 2.319486141204834, acc 0.07000000029802322\n",
      "Epoch 4, iter 245, loss 2.2870540618896484, acc 0.05999999865889549\n",
      "Epoch 4, iter 246, loss 2.352588176727295, acc 0.05999999865889549\n",
      "Epoch 4, iter 247, loss 2.2541403770446777, acc 0.07999999821186066\n",
      "Epoch 4, iter 248, loss 2.284019708633423, acc 0.11999999731779099\n",
      "Epoch 4, iter 249, loss 2.299891471862793, acc 0.17000000178813934\n",
      "Epoch 4, iter 250, loss 2.2410378456115723, acc 0.07000000029802322\n",
      "Epoch 4, iter 251, loss 2.2875092029571533, acc 0.09000000357627869\n",
      "Epoch 4, iter 252, loss 2.2399702072143555, acc 0.1599999964237213\n",
      "Epoch 4, iter 253, loss 2.388629198074341, acc 0.11999999731779099\n",
      "Epoch 4, iter 254, loss 2.342221260070801, acc 0.11999999731779099\n",
      "Epoch 4, iter 255, loss 2.4176530838012695, acc 0.05000000074505806\n",
      "Epoch 4, iter 256, loss 2.346076250076294, acc 0.05999999865889549\n",
      "Epoch 4, iter 257, loss 2.3209683895111084, acc 0.10000000149011612\n",
      "Epoch 4, iter 258, loss 2.2562906742095947, acc 0.10999999940395355\n",
      "Epoch 4, iter 259, loss 2.2768163681030273, acc 0.10000000149011612\n",
      "Epoch 4, iter 260, loss 2.3252882957458496, acc 0.07999999821186066\n",
      "Epoch 4, iter 261, loss 2.279491901397705, acc 0.05999999865889549\n",
      "Epoch 4, iter 262, loss 2.3562262058258057, acc 0.07999999821186066\n",
      "Epoch 4, iter 263, loss 2.3067398071289062, acc 0.07000000029802322\n",
      "Epoch 4, iter 264, loss 2.2889597415924072, acc 0.09000000357627869\n",
      "Epoch 4, iter 265, loss 2.3326852321624756, acc 0.11999999731779099\n",
      "Epoch 4, iter 266, loss 2.294102430343628, acc 0.10999999940395355\n",
      "Epoch 4, iter 267, loss 2.3052756786346436, acc 0.1899999976158142\n",
      "Epoch 4, iter 268, loss 2.3275089263916016, acc 0.1599999964237213\n",
      "Epoch 4, iter 269, loss 2.2706024646759033, acc 0.09000000357627869\n",
      "Epoch 4, iter 270, loss 2.3557443618774414, acc 0.11999999731779099\n",
      "Epoch 4, iter 271, loss 2.337055206298828, acc 0.10999999940395355\n",
      "Epoch 4, iter 272, loss 2.289412260055542, acc 0.07000000029802322\n",
      "Epoch 4, iter 273, loss 2.3249728679656982, acc 0.10000000149011612\n",
      "Epoch 4, iter 274, loss 2.2377800941467285, acc 0.10999999940395355\n",
      "Epoch 4, iter 275, loss 2.3323745727539062, acc 0.07000000029802322\n",
      "Epoch 4, iter 276, loss 2.3686187267303467, acc 0.11999999731779099\n",
      "Epoch 4, iter 277, loss 2.2817485332489014, acc 0.1599999964237213\n",
      "Epoch 4, iter 278, loss 2.2672808170318604, acc 0.12999999523162842\n",
      "Epoch 4, iter 279, loss 2.3080480098724365, acc 0.09000000357627869\n",
      "Epoch 4, iter 280, loss 2.2784488201141357, acc 0.09000000357627869\n",
      "Epoch 4, iter 281, loss 2.2889370918273926, acc 0.07999999821186066\n",
      "Epoch 4, iter 282, loss 2.3565566539764404, acc 0.1599999964237213\n",
      "Epoch 4, iter 283, loss 2.3130340576171875, acc 0.07999999821186066\n",
      "Epoch 4, iter 284, loss 2.3575310707092285, acc 0.07000000029802322\n",
      "Epoch 4, iter 285, loss 2.299593210220337, acc 0.09000000357627869\n",
      "Epoch 4, iter 286, loss 2.3161678314208984, acc 0.09000000357627869\n",
      "Epoch 4, iter 287, loss 2.3382885456085205, acc 0.12999999523162842\n",
      "Epoch 4, iter 288, loss 2.3508212566375732, acc 0.07000000029802322\n",
      "Epoch 4, iter 289, loss 2.2970080375671387, acc 0.10999999940395355\n",
      "Epoch 4, iter 290, loss 2.3505148887634277, acc 0.05999999865889549\n",
      "Epoch 4, iter 291, loss 2.2973103523254395, acc 0.12999999523162842\n",
      "Epoch 4, iter 292, loss 2.33577823638916, acc 0.10999999940395355\n",
      "Epoch 4, iter 293, loss 2.2843985557556152, acc 0.10999999940395355\n",
      "Epoch 4, iter 294, loss 2.361518144607544, acc 0.14000000059604645\n",
      "Epoch 4, iter 295, loss 2.3170480728149414, acc 0.10999999940395355\n",
      "Epoch 4, iter 296, loss 2.355482578277588, acc 0.09000000357627869\n",
      "Epoch 4, iter 297, loss 2.3617396354675293, acc 0.07999999821186066\n",
      "Epoch 4, iter 298, loss 2.291069507598877, acc 0.11999999731779099\n",
      "Epoch 4, iter 299, loss 2.3181216716766357, acc 0.12999999523162842\n",
      "Epoch 4, iter 300, loss 2.3236119747161865, acc 0.09000000357627869\n",
      "Epoch 4, iter 301, loss 2.339536666870117, acc 0.03999999910593033\n",
      "Epoch 4, iter 302, loss 2.304933547973633, acc 0.11999999731779099\n",
      "Epoch 4, iter 303, loss 2.3451027870178223, acc 0.10999999940395355\n",
      "Epoch 4, iter 304, loss 2.353921413421631, acc 0.05000000074505806\n",
      "Epoch 4, iter 305, loss 2.304455280303955, acc 0.10000000149011612\n",
      "Epoch 4, iter 306, loss 2.3273983001708984, acc 0.05999999865889549\n",
      "Epoch 4, iter 307, loss 2.279359817504883, acc 0.10999999940395355\n",
      "Epoch 4, iter 308, loss 2.3069357872009277, acc 0.15000000596046448\n",
      "Epoch 4, iter 309, loss 2.2943315505981445, acc 0.14000000059604645\n",
      "Epoch 4, iter 310, loss 2.3539557456970215, acc 0.05000000074505806\n",
      "Epoch 4, iter 311, loss 2.3006021976470947, acc 0.12999999523162842\n",
      "Epoch 4, iter 312, loss 2.354945182800293, acc 0.05999999865889549\n",
      "Epoch 4, iter 313, loss 2.3687987327575684, acc 0.09000000357627869\n",
      "Epoch 4, iter 314, loss 2.294337272644043, acc 0.1899999976158142\n",
      "Epoch 4, iter 315, loss 2.3779327869415283, acc 0.12999999523162842\n",
      "Epoch 4, iter 316, loss 2.339008092880249, acc 0.07000000029802322\n",
      "Epoch 4, iter 317, loss 2.3065695762634277, acc 0.05000000074505806\n",
      "Epoch 4, iter 318, loss 2.3593530654907227, acc 0.07000000029802322\n",
      "Epoch 4, iter 319, loss 2.2716057300567627, acc 0.15000000596046448\n",
      "Epoch 4, iter 320, loss 2.266726493835449, acc 0.07999999821186066\n",
      "Epoch 4, iter 321, loss 2.3355910778045654, acc 0.09000000357627869\n",
      "Epoch 4, iter 322, loss 2.3438634872436523, acc 0.10999999940395355\n",
      "Epoch 4, iter 323, loss 2.3393774032592773, acc 0.09000000357627869\n",
      "Epoch 4, iter 324, loss 2.252714157104492, acc 0.11999999731779099\n",
      "Epoch 4, iter 325, loss 2.3489954471588135, acc 0.05999999865889549\n",
      "Epoch 4, iter 326, loss 2.2690281867980957, acc 0.12999999523162842\n",
      "Epoch 4, iter 327, loss 2.307853937149048, acc 0.12999999523162842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 328, loss 2.4043190479278564, acc 0.07000000029802322\n",
      "Epoch 4, iter 329, loss 2.31357479095459, acc 0.07000000029802322\n",
      "Epoch 4, iter 330, loss 2.2733871936798096, acc 0.11999999731779099\n",
      "Epoch 4, iter 331, loss 2.313851833343506, acc 0.09000000357627869\n",
      "Epoch 4, iter 332, loss 2.310142755508423, acc 0.11999999731779099\n",
      "Epoch 4, iter 333, loss 2.306069850921631, acc 0.10999999940395355\n",
      "Epoch 4, iter 334, loss 2.32881498336792, acc 0.05999999865889549\n",
      "Epoch 4, iter 335, loss 2.2862634658813477, acc 0.10000000149011612\n",
      "Epoch 4, iter 336, loss 2.3040037155151367, acc 0.14000000059604645\n",
      "Epoch 4, iter 337, loss 2.297577142715454, acc 0.07000000029802322\n",
      "Epoch 4, iter 338, loss 2.3159444332122803, acc 0.07000000029802322\n",
      "Epoch 4, iter 339, loss 2.313762664794922, acc 0.12999999523162842\n",
      "Epoch 4, iter 340, loss 2.367837905883789, acc 0.10999999940395355\n",
      "Epoch 4, iter 341, loss 2.278501272201538, acc 0.10000000149011612\n",
      "Epoch 4, iter 342, loss 2.3361728191375732, acc 0.05000000074505806\n",
      "Epoch 4, iter 343, loss 2.2550792694091797, acc 0.1599999964237213\n",
      "Epoch 4, iter 344, loss 2.359802007675171, acc 0.11999999731779099\n",
      "Epoch 4, iter 345, loss 2.3102834224700928, acc 0.09000000357627869\n",
      "Epoch 4, iter 346, loss 2.403505563735962, acc 0.07000000029802322\n",
      "Epoch 4, iter 347, loss 2.3411030769348145, acc 0.15000000596046448\n",
      "Epoch 4, iter 348, loss 2.341146230697632, acc 0.07999999821186066\n",
      "Epoch 4, iter 349, loss 2.3422696590423584, acc 0.03999999910593033\n",
      "Epoch 4, iter 350, loss 2.295046091079712, acc 0.1599999964237213\n",
      "Epoch 4, iter 351, loss 2.235593795776367, acc 0.15000000596046448\n",
      "Epoch 4, iter 352, loss 2.3425557613372803, acc 0.12999999523162842\n",
      "Epoch 4, iter 353, loss 2.2789864540100098, acc 0.10999999940395355\n",
      "Epoch 4, iter 354, loss 2.3571813106536865, acc 0.07999999821186066\n",
      "Epoch 4, iter 355, loss 2.331902503967285, acc 0.07999999821186066\n",
      "Epoch 4, iter 356, loss 2.302520751953125, acc 0.12999999523162842\n",
      "Epoch 4, iter 357, loss 2.2950594425201416, acc 0.10999999940395355\n",
      "Epoch 4, iter 358, loss 2.2907018661499023, acc 0.09000000357627869\n",
      "Epoch 4, iter 359, loss 2.3535428047180176, acc 0.05999999865889549\n",
      "Epoch 4, iter 360, loss 2.3769147396087646, acc 0.07000000029802322\n",
      "Epoch 4, iter 361, loss 2.2959141731262207, acc 0.14000000059604645\n",
      "Epoch 4, iter 362, loss 2.3274731636047363, acc 0.07000000029802322\n",
      "Epoch 4, iter 363, loss 2.2852139472961426, acc 0.12999999523162842\n",
      "Epoch 4, iter 364, loss 2.375873327255249, acc 0.10999999940395355\n",
      "Epoch 4, iter 365, loss 2.3175883293151855, acc 0.10999999940395355\n",
      "Epoch 4, iter 366, loss 2.3575594425201416, acc 0.07000000029802322\n",
      "Epoch 4, iter 367, loss 2.3058958053588867, acc 0.10000000149011612\n",
      "Epoch 4, iter 368, loss 2.3638527393341064, acc 0.10000000149011612\n",
      "Epoch 4, iter 369, loss 2.2696776390075684, acc 0.14000000059604645\n",
      "Epoch 4, iter 370, loss 2.2697336673736572, acc 0.05999999865889549\n",
      "Epoch 4, iter 371, loss 2.3335444927215576, acc 0.07000000029802322\n",
      "Epoch 4, iter 372, loss 2.2695024013519287, acc 0.1599999964237213\n",
      "Epoch 4, iter 373, loss 2.3426096439361572, acc 0.09000000357627869\n",
      "Epoch 4, iter 374, loss 2.2784292697906494, acc 0.09000000357627869\n",
      "Epoch 4, iter 375, loss 2.362377882003784, acc 0.07999999821186066\n",
      "Epoch 4, iter 376, loss 2.2832577228546143, acc 0.09000000357627869\n",
      "Epoch 4, iter 377, loss 2.348395347595215, acc 0.07999999821186066\n",
      "Epoch 4, iter 378, loss 2.3051106929779053, acc 0.14000000059604645\n",
      "Epoch 4, iter 379, loss 2.3593943119049072, acc 0.12999999523162842\n",
      "Epoch 4, iter 380, loss 2.297346353530884, acc 0.07000000029802322\n",
      "Epoch 4, iter 381, loss 2.356375217437744, acc 0.07000000029802322\n",
      "Epoch 4, iter 382, loss 2.329036235809326, acc 0.07000000029802322\n",
      "Epoch 4, iter 383, loss 2.311223030090332, acc 0.10000000149011612\n",
      "Epoch 4, iter 384, loss 2.3392674922943115, acc 0.10999999940395355\n",
      "Epoch 4, iter 385, loss 2.286003351211548, acc 0.07999999821186066\n",
      "Epoch 4, iter 386, loss 2.321398973464966, acc 0.03999999910593033\n",
      "Epoch 4, iter 387, loss 2.3351802825927734, acc 0.03999999910593033\n",
      "Epoch 4, iter 388, loss 2.3112802505493164, acc 0.11999999731779099\n",
      "Epoch 4, iter 389, loss 2.287978172302246, acc 0.10999999940395355\n",
      "Epoch 4, iter 390, loss 2.3090531826019287, acc 0.09000000357627869\n",
      "Epoch 4, iter 391, loss 2.2901930809020996, acc 0.10000000149011612\n",
      "Epoch 4, iter 392, loss 2.3496792316436768, acc 0.10999999940395355\n",
      "Epoch 4, iter 393, loss 2.315582513809204, acc 0.15000000596046448\n",
      "Epoch 4, iter 394, loss 2.3649299144744873, acc 0.05999999865889549\n",
      "Epoch 4, iter 395, loss 2.3319575786590576, acc 0.07000000029802322\n",
      "Epoch 4, iter 396, loss 2.338146448135376, acc 0.10999999940395355\n",
      "Epoch 4, iter 397, loss 2.3837289810180664, acc 0.10000000149011612\n",
      "Epoch 4, iter 398, loss 2.286190986633301, acc 0.10999999940395355\n",
      "Epoch 4, iter 399, loss 2.3778016567230225, acc 0.10999999940395355\n",
      "Epoch 4, iter 400, loss 2.2773241996765137, acc 0.05999999865889549\n",
      "Epoch 4, iter 401, loss 2.3083651065826416, acc 0.10999999940395355\n",
      "Epoch 4, iter 402, loss 2.286046028137207, acc 0.07999999821186066\n",
      "Epoch 4, iter 403, loss 2.2824039459228516, acc 0.09000000357627869\n",
      "Epoch 4, iter 404, loss 2.274521827697754, acc 0.10999999940395355\n",
      "Epoch 4, iter 405, loss 2.267756700515747, acc 0.12999999523162842\n",
      "Epoch 4, iter 406, loss 2.3443286418914795, acc 0.10000000149011612\n",
      "Epoch 4, iter 407, loss 2.3644607067108154, acc 0.11999999731779099\n",
      "Epoch 4, iter 408, loss 2.260765314102173, acc 0.12999999523162842\n",
      "Epoch 4, iter 409, loss 2.324162244796753, acc 0.10000000149011612\n",
      "Epoch 4, iter 410, loss 2.3434767723083496, acc 0.09000000357627869\n",
      "Epoch 4, iter 411, loss 2.296297550201416, acc 0.05000000074505806\n",
      "Epoch 4, iter 412, loss 2.2980926036834717, acc 0.10999999940395355\n",
      "Epoch 4, iter 413, loss 2.3631534576416016, acc 0.07999999821186066\n",
      "Epoch 4, iter 414, loss 2.290371894836426, acc 0.12999999523162842\n",
      "Epoch 4, iter 415, loss 2.273049831390381, acc 0.10000000149011612\n",
      "Epoch 4, iter 416, loss 2.277015447616577, acc 0.10999999940395355\n",
      "Epoch 4, iter 417, loss 2.365868091583252, acc 0.07999999821186066\n",
      "Epoch 4, iter 418, loss 2.350539207458496, acc 0.05000000074505806\n",
      "Epoch 4, iter 419, loss 2.3259565830230713, acc 0.07999999821186066\n",
      "Epoch 4, iter 420, loss 2.264554977416992, acc 0.11999999731779099\n",
      "Epoch 5, iter 1, loss 2.353396415710449, acc 0.10000000149011612\n",
      "Epoch 5, iter 2, loss 2.303027391433716, acc 0.10000000149011612\n",
      "Epoch 5, iter 3, loss 2.2902748584747314, acc 0.12999999523162842\n",
      "Epoch 5, iter 4, loss 2.275683879852295, acc 0.14000000059604645\n",
      "Epoch 5, iter 5, loss 2.268796920776367, acc 0.10000000149011612\n",
      "Epoch 5, iter 6, loss 2.314936399459839, acc 0.09000000357627869\n",
      "Epoch 5, iter 7, loss 2.311763048171997, acc 0.11999999731779099\n",
      "Epoch 5, iter 8, loss 2.277010202407837, acc 0.07999999821186066\n",
      "Epoch 5, iter 9, loss 2.269625425338745, acc 0.14000000059604645\n",
      "Epoch 5, iter 10, loss 2.2679800987243652, acc 0.1599999964237213\n",
      "Epoch 5, iter 11, loss 2.274538516998291, acc 0.10000000149011612\n",
      "Epoch 5, iter 12, loss 2.2789225578308105, acc 0.10000000149011612\n",
      "Epoch 5, iter 13, loss 2.2772138118743896, acc 0.15000000596046448\n",
      "Epoch 5, iter 14, loss 2.372286558151245, acc 0.05000000074505806\n",
      "Epoch 5, iter 15, loss 2.3199336528778076, acc 0.09000000357627869\n",
      "Epoch 5, iter 16, loss 2.3241612911224365, acc 0.10999999940395355\n",
      "Epoch 5, iter 17, loss 2.2723848819732666, acc 0.10999999940395355\n",
      "Epoch 5, iter 18, loss 2.33669376373291, acc 0.07999999821186066\n",
      "Epoch 5, iter 19, loss 2.2514123916625977, acc 0.10999999940395355\n",
      "Epoch 5, iter 20, loss 2.2177674770355225, acc 0.1599999964237213\n",
      "Epoch 5, iter 21, loss 2.313793420791626, acc 0.05000000074505806\n",
      "Epoch 5, iter 22, loss 2.3445088863372803, acc 0.05999999865889549\n",
      "Epoch 5, iter 23, loss 2.2994792461395264, acc 0.10000000149011612\n",
      "Epoch 5, iter 24, loss 2.2766597270965576, acc 0.1599999964237213\n",
      "Epoch 5, iter 25, loss 2.3370201587677, acc 0.07000000029802322\n",
      "Epoch 5, iter 26, loss 2.3486509323120117, acc 0.03999999910593033\n",
      "Epoch 5, iter 27, loss 2.2995870113372803, acc 0.10000000149011612\n",
      "Epoch 5, iter 28, loss 2.344024896621704, acc 0.07000000029802322\n",
      "Epoch 5, iter 29, loss 2.288968563079834, acc 0.10000000149011612\n",
      "Epoch 5, iter 30, loss 2.4113893508911133, acc 0.10000000149011612\n",
      "Epoch 5, iter 31, loss 2.3455922603607178, acc 0.10999999940395355\n",
      "Epoch 5, iter 32, loss 2.303140163421631, acc 0.12999999523162842\n",
      "Epoch 5, iter 33, loss 2.3083062171936035, acc 0.09000000357627869\n",
      "Epoch 5, iter 34, loss 2.366523027420044, acc 0.05999999865889549\n",
      "Epoch 5, iter 35, loss 2.304609537124634, acc 0.10999999940395355\n",
      "Epoch 5, iter 36, loss 2.2967214584350586, acc 0.09000000357627869\n",
      "Epoch 5, iter 37, loss 2.32405686378479, acc 0.10999999940395355\n",
      "Epoch 5, iter 38, loss 2.2949535846710205, acc 0.12999999523162842\n",
      "Epoch 5, iter 39, loss 2.2632858753204346, acc 0.12999999523162842\n",
      "Epoch 5, iter 40, loss 2.3414928913116455, acc 0.14000000059604645\n",
      "Epoch 5, iter 41, loss 2.35402250289917, acc 0.07000000029802322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 42, loss 2.28204607963562, acc 0.07999999821186066\n",
      "Epoch 5, iter 43, loss 2.306685447692871, acc 0.10999999940395355\n",
      "Epoch 5, iter 44, loss 2.2754578590393066, acc 0.15000000596046448\n",
      "Epoch 5, iter 45, loss 2.3491873741149902, acc 0.11999999731779099\n",
      "Epoch 5, iter 46, loss 2.373767137527466, acc 0.05999999865889549\n",
      "Epoch 5, iter 47, loss 2.313532590866089, acc 0.09000000357627869\n",
      "Epoch 5, iter 48, loss 2.322287082672119, acc 0.12999999523162842\n",
      "Epoch 5, iter 49, loss 2.3590645790100098, acc 0.10999999940395355\n",
      "Epoch 5, iter 50, loss 2.29264760017395, acc 0.10999999940395355\n",
      "Epoch 5, iter 51, loss 2.317260980606079, acc 0.10000000149011612\n",
      "Epoch 5, iter 52, loss 2.331326484680176, acc 0.10000000149011612\n",
      "Epoch 5, iter 53, loss 2.342548131942749, acc 0.14000000059604645\n",
      "Epoch 5, iter 54, loss 2.2642650604248047, acc 0.07999999821186066\n",
      "Epoch 5, iter 55, loss 2.3049700260162354, acc 0.09000000357627869\n",
      "Epoch 5, iter 56, loss 2.2915468215942383, acc 0.10999999940395355\n",
      "Epoch 5, iter 57, loss 2.237790107727051, acc 0.15000000596046448\n",
      "Epoch 5, iter 58, loss 2.3121628761291504, acc 0.07999999821186066\n",
      "Epoch 5, iter 59, loss 2.3531181812286377, acc 0.09000000357627869\n",
      "Epoch 5, iter 60, loss 2.302014112472534, acc 0.09000000357627869\n",
      "Epoch 5, iter 61, loss 2.2814977169036865, acc 0.05999999865889549\n",
      "Epoch 5, iter 62, loss 2.265740156173706, acc 0.15000000596046448\n",
      "Epoch 5, iter 63, loss 2.3145503997802734, acc 0.10999999940395355\n",
      "Epoch 5, iter 64, loss 2.2554502487182617, acc 0.09000000357627869\n",
      "Epoch 5, iter 65, loss 2.2930994033813477, acc 0.09000000357627869\n",
      "Epoch 5, iter 66, loss 2.30043888092041, acc 0.07999999821186066\n",
      "Epoch 5, iter 67, loss 2.3098082542419434, acc 0.11999999731779099\n",
      "Epoch 5, iter 68, loss 2.2842798233032227, acc 0.09000000357627869\n",
      "Epoch 5, iter 69, loss 2.2638375759124756, acc 0.10999999940395355\n",
      "Epoch 5, iter 70, loss 2.323843240737915, acc 0.10999999940395355\n",
      "Epoch 5, iter 71, loss 2.326000213623047, acc 0.10999999940395355\n",
      "Epoch 5, iter 72, loss 2.352229356765747, acc 0.05999999865889549\n",
      "Epoch 5, iter 73, loss 2.298550605773926, acc 0.09000000357627869\n",
      "Epoch 5, iter 74, loss 2.2612600326538086, acc 0.10999999940395355\n",
      "Epoch 5, iter 75, loss 2.3442304134368896, acc 0.09000000357627869\n",
      "Epoch 5, iter 76, loss 2.3156325817108154, acc 0.12999999523162842\n",
      "Epoch 5, iter 77, loss 2.304952621459961, acc 0.10999999940395355\n",
      "Epoch 5, iter 78, loss 2.3139781951904297, acc 0.10000000149011612\n",
      "Epoch 5, iter 79, loss 2.3060734272003174, acc 0.07000000029802322\n",
      "Epoch 5, iter 80, loss 2.334177255630493, acc 0.07000000029802322\n",
      "Epoch 5, iter 81, loss 2.257803201675415, acc 0.1599999964237213\n",
      "Epoch 5, iter 82, loss 2.288943290710449, acc 0.10999999940395355\n",
      "Epoch 5, iter 83, loss 2.315943956375122, acc 0.10000000149011612\n",
      "Epoch 5, iter 84, loss 2.2707178592681885, acc 0.09000000357627869\n",
      "Epoch 5, iter 85, loss 2.2772960662841797, acc 0.10999999940395355\n",
      "Epoch 5, iter 86, loss 2.2762460708618164, acc 0.11999999731779099\n",
      "Epoch 5, iter 87, loss 2.230053424835205, acc 0.12999999523162842\n",
      "Epoch 5, iter 88, loss 2.273784637451172, acc 0.10999999940395355\n",
      "Epoch 5, iter 89, loss 2.3255057334899902, acc 0.07000000029802322\n",
      "Epoch 5, iter 90, loss 2.3340566158294678, acc 0.07999999821186066\n",
      "Epoch 5, iter 91, loss 2.304645299911499, acc 0.10000000149011612\n",
      "Epoch 5, iter 92, loss 2.2211031913757324, acc 0.1599999964237213\n",
      "Epoch 5, iter 93, loss 2.312615394592285, acc 0.05999999865889549\n",
      "Epoch 5, iter 94, loss 2.305748701095581, acc 0.11999999731779099\n",
      "Epoch 5, iter 95, loss 2.32370662689209, acc 0.12999999523162842\n",
      "Epoch 5, iter 96, loss 2.2740378379821777, acc 0.15000000596046448\n",
      "Epoch 5, iter 97, loss 2.313347816467285, acc 0.11999999731779099\n",
      "Epoch 5, iter 98, loss 2.3266611099243164, acc 0.10000000149011612\n",
      "Epoch 5, iter 99, loss 2.248870611190796, acc 0.1599999964237213\n",
      "Epoch 5, iter 100, loss 2.380702257156372, acc 0.05999999865889549\n",
      "Epoch 5, iter 101, loss 2.3421213626861572, acc 0.09000000357627869\n",
      "Epoch 5, iter 102, loss 2.287429094314575, acc 0.10999999940395355\n",
      "Epoch 5, iter 103, loss 2.3372418880462646, acc 0.07000000029802322\n",
      "Epoch 5, iter 104, loss 2.2620606422424316, acc 0.10000000149011612\n",
      "Epoch 5, iter 105, loss 2.3196799755096436, acc 0.11999999731779099\n",
      "Epoch 5, iter 106, loss 2.255232334136963, acc 0.15000000596046448\n",
      "Epoch 5, iter 107, loss 2.2395904064178467, acc 0.09000000357627869\n",
      "Epoch 5, iter 108, loss 2.2738261222839355, acc 0.09000000357627869\n",
      "Epoch 5, iter 109, loss 2.313328742980957, acc 0.10999999940395355\n",
      "Epoch 5, iter 110, loss 2.3489770889282227, acc 0.10000000149011612\n",
      "Epoch 5, iter 111, loss 2.3909637928009033, acc 0.05999999865889549\n",
      "Epoch 5, iter 112, loss 2.3233020305633545, acc 0.07000000029802322\n",
      "Epoch 5, iter 113, loss 2.2280290126800537, acc 0.10999999940395355\n",
      "Epoch 5, iter 114, loss 2.3937129974365234, acc 0.14000000059604645\n",
      "Epoch 5, iter 115, loss 2.260974645614624, acc 0.11999999731779099\n",
      "Epoch 5, iter 116, loss 2.2902424335479736, acc 0.07000000029802322\n",
      "Epoch 5, iter 117, loss 2.316512107849121, acc 0.07999999821186066\n",
      "Epoch 5, iter 118, loss 2.3469650745391846, acc 0.05000000074505806\n",
      "Epoch 5, iter 119, loss 2.277279853820801, acc 0.10000000149011612\n",
      "Epoch 5, iter 120, loss 2.279444932937622, acc 0.1599999964237213\n",
      "Epoch 5, iter 121, loss 2.2619681358337402, acc 0.14000000059604645\n",
      "Epoch 5, iter 122, loss 2.3025548458099365, acc 0.05999999865889549\n",
      "Epoch 5, iter 123, loss 2.287309169769287, acc 0.05000000074505806\n",
      "Epoch 5, iter 124, loss 2.3304293155670166, acc 0.07000000029802322\n",
      "Epoch 5, iter 125, loss 2.2881929874420166, acc 0.11999999731779099\n",
      "Epoch 5, iter 126, loss 2.383734941482544, acc 0.07000000029802322\n",
      "Epoch 5, iter 127, loss 2.2918100357055664, acc 0.05999999865889549\n",
      "Epoch 5, iter 128, loss 2.292238712310791, acc 0.11999999731779099\n",
      "Epoch 5, iter 129, loss 2.322572708129883, acc 0.07999999821186066\n",
      "Epoch 5, iter 130, loss 2.330873727798462, acc 0.05999999865889549\n",
      "Epoch 5, iter 131, loss 2.3198838233947754, acc 0.10000000149011612\n",
      "Epoch 5, iter 132, loss 2.2699570655822754, acc 0.11999999731779099\n",
      "Epoch 5, iter 133, loss 2.3034560680389404, acc 0.10999999940395355\n",
      "Epoch 5, iter 134, loss 2.2926042079925537, acc 0.10000000149011612\n",
      "Epoch 5, iter 135, loss 2.3640365600585938, acc 0.07999999821186066\n",
      "Epoch 5, iter 136, loss 2.2858388423919678, acc 0.10000000149011612\n",
      "Epoch 5, iter 137, loss 2.2806217670440674, acc 0.11999999731779099\n",
      "Epoch 5, iter 138, loss 2.2471070289611816, acc 0.12999999523162842\n",
      "Epoch 5, iter 139, loss 2.3032915592193604, acc 0.14000000059604645\n",
      "Epoch 5, iter 140, loss 2.2831907272338867, acc 0.11999999731779099\n",
      "Epoch 5, iter 141, loss 2.2790520191192627, acc 0.15000000596046448\n",
      "Epoch 5, iter 142, loss 2.410264015197754, acc 0.12999999523162842\n",
      "Epoch 5, iter 143, loss 2.2230236530303955, acc 0.14000000059604645\n",
      "Epoch 5, iter 144, loss 2.3479130268096924, acc 0.11999999731779099\n",
      "Epoch 5, iter 145, loss 2.2746524810791016, acc 0.10999999940395355\n",
      "Epoch 5, iter 146, loss 2.2942190170288086, acc 0.15000000596046448\n",
      "Epoch 5, iter 147, loss 2.3428053855895996, acc 0.10999999940395355\n",
      "Epoch 5, iter 148, loss 2.3429853916168213, acc 0.07000000029802322\n",
      "Epoch 5, iter 149, loss 2.3378024101257324, acc 0.10000000149011612\n",
      "Epoch 5, iter 150, loss 2.273106336593628, acc 0.15000000596046448\n",
      "Epoch 5, iter 151, loss 2.324460983276367, acc 0.03999999910593033\n",
      "Epoch 5, iter 152, loss 2.332479953765869, acc 0.05999999865889549\n",
      "Epoch 5, iter 153, loss 2.2745912075042725, acc 0.12999999523162842\n",
      "Epoch 5, iter 154, loss 2.3159306049346924, acc 0.11999999731779099\n",
      "Epoch 5, iter 155, loss 2.2898917198181152, acc 0.10000000149011612\n",
      "Epoch 5, iter 156, loss 2.2697978019714355, acc 0.10999999940395355\n",
      "Epoch 5, iter 157, loss 2.3883817195892334, acc 0.1599999964237213\n",
      "Epoch 5, iter 158, loss 2.293466091156006, acc 0.14000000059604645\n",
      "Epoch 5, iter 159, loss 2.3342158794403076, acc 0.07999999821186066\n",
      "Epoch 5, iter 160, loss 2.2724263668060303, acc 0.1599999964237213\n",
      "Epoch 5, iter 161, loss 2.2639353275299072, acc 0.18000000715255737\n",
      "Epoch 5, iter 162, loss 2.2810823917388916, acc 0.10999999940395355\n",
      "Epoch 5, iter 163, loss 2.281641960144043, acc 0.10999999940395355\n",
      "Epoch 5, iter 164, loss 2.341348886489868, acc 0.11999999731779099\n",
      "Epoch 5, iter 165, loss 2.304004192352295, acc 0.12999999523162842\n",
      "Epoch 5, iter 166, loss 2.2855277061462402, acc 0.20000000298023224\n",
      "Epoch 5, iter 167, loss 2.2810661792755127, acc 0.14000000059604645\n",
      "Epoch 5, iter 168, loss 2.3495397567749023, acc 0.11999999731779099\n",
      "Epoch 5, iter 169, loss 2.3360178470611572, acc 0.09000000357627869\n",
      "Epoch 5, iter 170, loss 2.3690383434295654, acc 0.09000000357627869\n",
      "Epoch 5, iter 171, loss 2.27736759185791, acc 0.11999999731779099\n",
      "Epoch 5, iter 172, loss 2.3115105628967285, acc 0.12999999523162842\n",
      "Epoch 5, iter 173, loss 2.3501296043395996, acc 0.09000000357627869\n",
      "Epoch 5, iter 174, loss 2.2788004875183105, acc 0.10000000149011612\n",
      "Epoch 5, iter 175, loss 2.2999486923217773, acc 0.14000000059604645\n",
      "Epoch 5, iter 176, loss 2.3385274410247803, acc 0.12999999523162842\n",
      "Epoch 5, iter 177, loss 2.300929546356201, acc 0.10999999940395355\n",
      "Epoch 5, iter 178, loss 2.2898752689361572, acc 0.07999999821186066\n",
      "Epoch 5, iter 179, loss 2.2931838035583496, acc 0.12999999523162842\n",
      "Epoch 5, iter 180, loss 2.2526490688323975, acc 0.1599999964237213\n",
      "Epoch 5, iter 181, loss 2.2021737098693848, acc 0.12999999523162842\n",
      "Epoch 5, iter 182, loss 2.2457642555236816, acc 0.1599999964237213\n",
      "Epoch 5, iter 183, loss 2.264134645462036, acc 0.09000000357627869\n",
      "Epoch 5, iter 184, loss 2.351040840148926, acc 0.10000000149011612\n",
      "Epoch 5, iter 185, loss 2.3182754516601562, acc 0.15000000596046448\n",
      "Epoch 5, iter 186, loss 2.3227105140686035, acc 0.12999999523162842\n",
      "Epoch 5, iter 187, loss 2.2274091243743896, acc 0.1599999964237213\n",
      "Epoch 5, iter 188, loss 2.300239086151123, acc 0.10000000149011612\n",
      "Epoch 5, iter 189, loss 2.329646110534668, acc 0.17000000178813934\n",
      "Epoch 5, iter 190, loss 2.274484395980835, acc 0.14000000059604645\n",
      "Epoch 5, iter 191, loss 2.26824688911438, acc 0.12999999523162842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 192, loss 2.3208327293395996, acc 0.11999999731779099\n",
      "Epoch 5, iter 193, loss 2.3150711059570312, acc 0.14000000059604645\n",
      "Epoch 5, iter 194, loss 2.2478134632110596, acc 0.1599999964237213\n",
      "Epoch 5, iter 195, loss 2.2792441844940186, acc 0.18000000715255737\n",
      "Epoch 5, iter 196, loss 2.2745773792266846, acc 0.1899999976158142\n",
      "Epoch 5, iter 197, loss 2.277524948120117, acc 0.15000000596046448\n",
      "Epoch 5, iter 198, loss 2.2931885719299316, acc 0.11999999731779099\n",
      "Epoch 5, iter 199, loss 2.310328722000122, acc 0.17000000178813934\n",
      "Epoch 5, iter 200, loss 2.340404748916626, acc 0.14000000059604645\n",
      "Epoch 5, iter 201, loss 2.3459105491638184, acc 0.11999999731779099\n",
      "Epoch 5, iter 202, loss 2.264159917831421, acc 0.14000000059604645\n",
      "Epoch 5, iter 203, loss 2.2822279930114746, acc 0.09000000357627869\n",
      "Epoch 5, iter 204, loss 2.333988904953003, acc 0.11999999731779099\n",
      "Epoch 5, iter 205, loss 2.332733631134033, acc 0.07999999821186066\n",
      "Epoch 5, iter 206, loss 2.2702064514160156, acc 0.1899999976158142\n",
      "Epoch 5, iter 207, loss 2.3466479778289795, acc 0.09000000357627869\n",
      "Epoch 5, iter 208, loss 2.3308472633361816, acc 0.14000000059604645\n",
      "Epoch 5, iter 209, loss 2.283320426940918, acc 0.1599999964237213\n",
      "Epoch 5, iter 210, loss 2.2638983726501465, acc 0.1599999964237213\n",
      "Epoch 5, iter 211, loss 2.3681693077087402, acc 0.11999999731779099\n",
      "Epoch 5, iter 212, loss 2.3083832263946533, acc 0.2199999988079071\n",
      "Epoch 5, iter 213, loss 2.2225000858306885, acc 0.1599999964237213\n",
      "Epoch 5, iter 214, loss 2.3290209770202637, acc 0.10000000149011612\n",
      "Epoch 5, iter 215, loss 2.3404276371002197, acc 0.10000000149011612\n",
      "Epoch 5, iter 216, loss 2.285719394683838, acc 0.11999999731779099\n",
      "Epoch 5, iter 217, loss 2.3093247413635254, acc 0.12999999523162842\n",
      "Epoch 5, iter 218, loss 2.368124485015869, acc 0.12999999523162842\n",
      "Epoch 5, iter 219, loss 2.2532029151916504, acc 0.12999999523162842\n",
      "Epoch 5, iter 220, loss 2.3733370304107666, acc 0.09000000357627869\n",
      "Epoch 5, iter 221, loss 2.265406608581543, acc 0.10999999940395355\n",
      "Epoch 5, iter 222, loss 2.264101028442383, acc 0.07999999821186066\n",
      "Epoch 5, iter 223, loss 2.211949348449707, acc 0.18000000715255737\n",
      "Epoch 5, iter 224, loss 2.278519630432129, acc 0.10999999940395355\n",
      "Epoch 5, iter 225, loss 2.3548924922943115, acc 0.07999999821186066\n",
      "Epoch 5, iter 226, loss 2.2863175868988037, acc 0.12999999523162842\n",
      "Epoch 5, iter 227, loss 2.2928218841552734, acc 0.14000000059604645\n",
      "Epoch 5, iter 228, loss 2.2324774265289307, acc 0.23000000417232513\n",
      "Epoch 5, iter 229, loss 2.3173727989196777, acc 0.11999999731779099\n",
      "Epoch 5, iter 230, loss 2.303391695022583, acc 0.10999999940395355\n",
      "Epoch 5, iter 231, loss 2.306239366531372, acc 0.12999999523162842\n",
      "Epoch 5, iter 232, loss 2.371760368347168, acc 0.11999999731779099\n",
      "Epoch 5, iter 233, loss 2.259674072265625, acc 0.11999999731779099\n",
      "Epoch 5, iter 234, loss 2.267115354537964, acc 0.12999999523162842\n",
      "Epoch 5, iter 235, loss 2.268711566925049, acc 0.14000000059604645\n",
      "Epoch 5, iter 236, loss 2.3176963329315186, acc 0.10999999940395355\n",
      "Epoch 5, iter 237, loss 2.3108322620391846, acc 0.15000000596046448\n",
      "Epoch 5, iter 238, loss 2.2722134590148926, acc 0.14000000059604645\n",
      "Epoch 5, iter 239, loss 2.2909629344940186, acc 0.14000000059604645\n",
      "Epoch 5, iter 240, loss 2.332752227783203, acc 0.10000000149011612\n",
      "Epoch 5, iter 241, loss 2.318084478378296, acc 0.07999999821186066\n",
      "Epoch 5, iter 242, loss 2.2509942054748535, acc 0.1599999964237213\n",
      "Epoch 5, iter 243, loss 2.248854637145996, acc 0.1599999964237213\n",
      "Epoch 5, iter 244, loss 2.2979013919830322, acc 0.09000000357627869\n",
      "Epoch 5, iter 245, loss 2.2487642765045166, acc 0.09000000357627869\n",
      "Epoch 5, iter 246, loss 2.324571132659912, acc 0.10000000149011612\n",
      "Epoch 5, iter 247, loss 2.2260076999664307, acc 0.15000000596046448\n",
      "Epoch 5, iter 248, loss 2.265052318572998, acc 0.12999999523162842\n",
      "Epoch 5, iter 249, loss 2.279120445251465, acc 0.1899999976158142\n",
      "Epoch 5, iter 250, loss 2.2180209159851074, acc 0.11999999731779099\n",
      "Epoch 5, iter 251, loss 2.2709288597106934, acc 0.12999999523162842\n",
      "Epoch 5, iter 252, loss 2.201979398727417, acc 0.18000000715255737\n",
      "Epoch 5, iter 253, loss 2.3657352924346924, acc 0.12999999523162842\n",
      "Epoch 5, iter 254, loss 2.3216445446014404, acc 0.1599999964237213\n",
      "Epoch 5, iter 255, loss 2.366145133972168, acc 0.10000000149011612\n",
      "Epoch 5, iter 256, loss 2.3266751766204834, acc 0.11999999731779099\n",
      "Epoch 5, iter 257, loss 2.3089215755462646, acc 0.15000000596046448\n",
      "Epoch 5, iter 258, loss 2.2429897785186768, acc 0.15000000596046448\n",
      "Epoch 5, iter 259, loss 2.2551605701446533, acc 0.1599999964237213\n",
      "Epoch 5, iter 260, loss 2.2996559143066406, acc 0.11999999731779099\n",
      "Epoch 5, iter 261, loss 2.2499775886535645, acc 0.11999999731779099\n",
      "Epoch 5, iter 262, loss 2.311999559402466, acc 0.11999999731779099\n",
      "Epoch 5, iter 263, loss 2.278668165206909, acc 0.12999999523162842\n",
      "Epoch 5, iter 264, loss 2.26633882522583, acc 0.10000000149011612\n",
      "Epoch 5, iter 265, loss 2.3111393451690674, acc 0.15000000596046448\n",
      "Epoch 5, iter 266, loss 2.256185293197632, acc 0.15000000596046448\n",
      "Epoch 5, iter 267, loss 2.2735586166381836, acc 0.23000000417232513\n",
      "Epoch 5, iter 268, loss 2.309098958969116, acc 0.18000000715255737\n",
      "Epoch 5, iter 269, loss 2.2562599182128906, acc 0.12999999523162842\n",
      "Epoch 5, iter 270, loss 2.3018407821655273, acc 0.11999999731779099\n",
      "Epoch 5, iter 271, loss 2.313650608062744, acc 0.18000000715255737\n",
      "Epoch 5, iter 272, loss 2.266058921813965, acc 0.15000000596046448\n",
      "Epoch 5, iter 273, loss 2.307633399963379, acc 0.17000000178813934\n",
      "Epoch 5, iter 274, loss 2.221947431564331, acc 0.18000000715255737\n",
      "Epoch 5, iter 275, loss 2.2977077960968018, acc 0.17000000178813934\n",
      "Epoch 5, iter 276, loss 2.352574110031128, acc 0.14000000059604645\n",
      "Epoch 5, iter 277, loss 2.2659249305725098, acc 0.11999999731779099\n",
      "Epoch 5, iter 278, loss 2.2466750144958496, acc 0.15000000596046448\n",
      "Epoch 5, iter 279, loss 2.279453992843628, acc 0.09000000357627869\n",
      "Epoch 5, iter 280, loss 2.257359743118286, acc 0.17000000178813934\n",
      "Epoch 5, iter 281, loss 2.2594730854034424, acc 0.12999999523162842\n",
      "Epoch 5, iter 282, loss 2.329279661178589, acc 0.15000000596046448\n",
      "Epoch 5, iter 283, loss 2.279311418533325, acc 0.10999999940395355\n",
      "Epoch 5, iter 284, loss 2.334064245223999, acc 0.10999999940395355\n",
      "Epoch 5, iter 285, loss 2.2828121185302734, acc 0.09000000357627869\n",
      "Epoch 5, iter 286, loss 2.292551040649414, acc 0.11999999731779099\n",
      "Epoch 5, iter 287, loss 2.3165738582611084, acc 0.1599999964237213\n",
      "Epoch 5, iter 288, loss 2.303802251815796, acc 0.09000000357627869\n",
      "Epoch 5, iter 289, loss 2.2431468963623047, acc 0.17000000178813934\n",
      "Epoch 5, iter 290, loss 2.3126890659332275, acc 0.10000000149011612\n",
      "Epoch 5, iter 291, loss 2.2679283618927, acc 0.15000000596046448\n",
      "Epoch 5, iter 292, loss 2.2712628841400146, acc 0.12999999523162842\n",
      "Epoch 5, iter 293, loss 2.2591187953948975, acc 0.11999999731779099\n",
      "Epoch 5, iter 294, loss 2.3253002166748047, acc 0.1599999964237213\n",
      "Epoch 5, iter 295, loss 2.300935745239258, acc 0.15000000596046448\n",
      "Epoch 5, iter 296, loss 2.317376136779785, acc 0.10999999940395355\n",
      "Epoch 5, iter 297, loss 2.3480799198150635, acc 0.12999999523162842\n",
      "Epoch 5, iter 298, loss 2.267838478088379, acc 0.1599999964237213\n",
      "Epoch 5, iter 299, loss 2.322019100189209, acc 0.15000000596046448\n",
      "Epoch 5, iter 300, loss 2.2923853397369385, acc 0.10999999940395355\n",
      "Epoch 5, iter 301, loss 2.3102283477783203, acc 0.09000000357627869\n",
      "Epoch 5, iter 302, loss 2.2866525650024414, acc 0.1899999976158142\n",
      "Epoch 5, iter 303, loss 2.3084421157836914, acc 0.15000000596046448\n",
      "Epoch 5, iter 304, loss 2.3270719051361084, acc 0.12999999523162842\n",
      "Epoch 5, iter 305, loss 2.266615867614746, acc 0.1599999964237213\n",
      "Epoch 5, iter 306, loss 2.286576986312866, acc 0.12999999523162842\n",
      "Epoch 5, iter 307, loss 2.2510695457458496, acc 0.15000000596046448\n",
      "Epoch 5, iter 308, loss 2.2781362533569336, acc 0.20000000298023224\n",
      "Epoch 5, iter 309, loss 2.260437250137329, acc 0.15000000596046448\n",
      "Epoch 5, iter 310, loss 2.332446336746216, acc 0.05999999865889549\n",
      "Epoch 5, iter 311, loss 2.2834980487823486, acc 0.18000000715255737\n",
      "Epoch 5, iter 312, loss 2.3158316612243652, acc 0.09000000357627869\n",
      "Epoch 5, iter 313, loss 2.3298041820526123, acc 0.12999999523162842\n",
      "Epoch 5, iter 314, loss 2.2827980518341064, acc 0.18000000715255737\n",
      "Epoch 5, iter 315, loss 2.352576971054077, acc 0.15000000596046448\n",
      "Epoch 5, iter 316, loss 2.286813974380493, acc 0.14000000059604645\n",
      "Epoch 5, iter 317, loss 2.2651467323303223, acc 0.18000000715255737\n",
      "Epoch 5, iter 318, loss 2.3397464752197266, acc 0.07999999821186066\n",
      "Epoch 5, iter 319, loss 2.2460198402404785, acc 0.10999999940395355\n",
      "Epoch 5, iter 320, loss 2.2505478858947754, acc 0.12999999523162842\n",
      "Epoch 5, iter 321, loss 2.3356235027313232, acc 0.07999999821186066\n",
      "Epoch 5, iter 322, loss 2.311619758605957, acc 0.15000000596046448\n",
      "Epoch 5, iter 323, loss 2.3086066246032715, acc 0.11999999731779099\n",
      "Epoch 5, iter 324, loss 2.205847978591919, acc 0.15000000596046448\n",
      "Epoch 5, iter 325, loss 2.318694591522217, acc 0.14000000059604645\n",
      "Epoch 5, iter 326, loss 2.2545888423919678, acc 0.14000000059604645\n",
      "Epoch 5, iter 327, loss 2.2915151119232178, acc 0.15000000596046448\n",
      "Epoch 5, iter 328, loss 2.389747142791748, acc 0.09000000357627869\n",
      "Epoch 5, iter 329, loss 2.29451847076416, acc 0.10000000149011612\n",
      "Epoch 5, iter 330, loss 2.255981683731079, acc 0.11999999731779099\n",
      "Epoch 5, iter 331, loss 2.276559829711914, acc 0.14000000059604645\n",
      "Epoch 5, iter 332, loss 2.2950971126556396, acc 0.15000000596046448\n",
      "Epoch 5, iter 333, loss 2.2796905040740967, acc 0.10999999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 334, loss 2.276608943939209, acc 0.10000000149011612\n",
      "Epoch 5, iter 335, loss 2.2574355602264404, acc 0.10999999940395355\n",
      "Epoch 5, iter 336, loss 2.279939651489258, acc 0.07000000029802322\n",
      "Epoch 5, iter 337, loss 2.261301040649414, acc 0.10999999940395355\n",
      "Epoch 5, iter 338, loss 2.2921760082244873, acc 0.09000000357627869\n",
      "Epoch 5, iter 339, loss 2.3046915531158447, acc 0.11999999731779099\n",
      "Epoch 5, iter 340, loss 2.3244822025299072, acc 0.11999999731779099\n",
      "Epoch 5, iter 341, loss 2.258974313735962, acc 0.10000000149011612\n",
      "Epoch 5, iter 342, loss 2.301293134689331, acc 0.10999999940395355\n",
      "Epoch 5, iter 343, loss 2.2244913578033447, acc 0.17000000178813934\n",
      "Epoch 5, iter 344, loss 2.3268685340881348, acc 0.09000000357627869\n",
      "Epoch 5, iter 345, loss 2.285013198852539, acc 0.09000000357627869\n",
      "Epoch 5, iter 346, loss 2.3733956813812256, acc 0.07999999821186066\n",
      "Epoch 5, iter 347, loss 2.3113210201263428, acc 0.17000000178813934\n",
      "Epoch 5, iter 348, loss 2.307232141494751, acc 0.12999999523162842\n",
      "Epoch 5, iter 349, loss 2.3086299896240234, acc 0.09000000357627869\n",
      "Epoch 5, iter 350, loss 2.2868010997772217, acc 0.11999999731779099\n",
      "Epoch 5, iter 351, loss 2.221095085144043, acc 0.17000000178813934\n",
      "Epoch 5, iter 352, loss 2.3201417922973633, acc 0.12999999523162842\n",
      "Epoch 5, iter 353, loss 2.2434744834899902, acc 0.1899999976158142\n",
      "Epoch 5, iter 354, loss 2.306891679763794, acc 0.14000000059604645\n",
      "Epoch 5, iter 355, loss 2.3173646926879883, acc 0.09000000357627869\n",
      "Epoch 5, iter 356, loss 2.276395082473755, acc 0.10000000149011612\n",
      "Epoch 5, iter 357, loss 2.282785415649414, acc 0.14000000059604645\n",
      "Epoch 5, iter 358, loss 2.2670700550079346, acc 0.1599999964237213\n",
      "Epoch 5, iter 359, loss 2.3246424198150635, acc 0.10999999940395355\n",
      "Epoch 5, iter 360, loss 2.3515820503234863, acc 0.09000000357627869\n",
      "Epoch 5, iter 361, loss 2.2712395191192627, acc 0.1899999976158142\n",
      "Epoch 5, iter 362, loss 2.298426866531372, acc 0.09000000357627869\n",
      "Epoch 5, iter 363, loss 2.2639167308807373, acc 0.12999999523162842\n",
      "Epoch 5, iter 364, loss 2.3480165004730225, acc 0.12999999523162842\n",
      "Epoch 5, iter 365, loss 2.2974421977996826, acc 0.14000000059604645\n",
      "Epoch 5, iter 366, loss 2.3310155868530273, acc 0.10000000149011612\n",
      "Epoch 5, iter 367, loss 2.288050651550293, acc 0.09000000357627869\n",
      "Epoch 5, iter 368, loss 2.3362388610839844, acc 0.07999999821186066\n",
      "Epoch 5, iter 369, loss 2.249087333679199, acc 0.1899999976158142\n",
      "Epoch 5, iter 370, loss 2.2424182891845703, acc 0.14000000059604645\n",
      "Epoch 5, iter 371, loss 2.3127427101135254, acc 0.10999999940395355\n",
      "Epoch 5, iter 372, loss 2.2556612491607666, acc 0.15000000596046448\n",
      "Epoch 5, iter 373, loss 2.312753677368164, acc 0.12999999523162842\n",
      "Epoch 5, iter 374, loss 2.2497808933258057, acc 0.17000000178813934\n",
      "Epoch 5, iter 375, loss 2.324110984802246, acc 0.10999999940395355\n",
      "Epoch 5, iter 376, loss 2.250999689102173, acc 0.18000000715255737\n",
      "Epoch 5, iter 377, loss 2.3131885528564453, acc 0.14000000059604645\n",
      "Epoch 5, iter 378, loss 2.2845683097839355, acc 0.15000000596046448\n",
      "Epoch 5, iter 379, loss 2.346356153488159, acc 0.10999999940395355\n",
      "Epoch 5, iter 380, loss 2.2654197216033936, acc 0.10000000149011612\n",
      "Epoch 5, iter 381, loss 2.3381495475769043, acc 0.05999999865889549\n",
      "Epoch 5, iter 382, loss 2.3050358295440674, acc 0.11999999731779099\n",
      "Epoch 5, iter 383, loss 2.2912490367889404, acc 0.07999999821186066\n",
      "Epoch 5, iter 384, loss 2.3211419582366943, acc 0.15000000596046448\n",
      "Epoch 5, iter 385, loss 2.2600200176239014, acc 0.11999999731779099\n",
      "Epoch 5, iter 386, loss 2.2946863174438477, acc 0.07999999821186066\n",
      "Epoch 5, iter 387, loss 2.314471483230591, acc 0.10000000149011612\n",
      "Epoch 5, iter 388, loss 2.2867839336395264, acc 0.15000000596046448\n",
      "Epoch 5, iter 389, loss 2.276533842086792, acc 0.18000000715255737\n",
      "Epoch 5, iter 390, loss 2.287106513977051, acc 0.1599999964237213\n",
      "Epoch 5, iter 391, loss 2.2637295722961426, acc 0.18000000715255737\n",
      "Epoch 5, iter 392, loss 2.3083999156951904, acc 0.14000000059604645\n",
      "Epoch 5, iter 393, loss 2.31360125541687, acc 0.14000000059604645\n",
      "Epoch 5, iter 394, loss 2.321112632751465, acc 0.11999999731779099\n",
      "Epoch 5, iter 395, loss 2.285439968109131, acc 0.11999999731779099\n",
      "Epoch 5, iter 396, loss 2.3134469985961914, acc 0.10999999940395355\n",
      "Epoch 5, iter 397, loss 2.3604471683502197, acc 0.10999999940395355\n",
      "Epoch 5, iter 398, loss 2.268054246902466, acc 0.14000000059604645\n",
      "Epoch 5, iter 399, loss 2.3521840572357178, acc 0.15000000596046448\n",
      "Epoch 5, iter 400, loss 2.24906325340271, acc 0.14000000059604645\n",
      "Epoch 5, iter 401, loss 2.280287265777588, acc 0.11999999731779099\n",
      "Epoch 5, iter 402, loss 2.262939214706421, acc 0.09000000357627869\n",
      "Epoch 5, iter 403, loss 2.2572829723358154, acc 0.14000000059604645\n",
      "Epoch 5, iter 404, loss 2.2475533485412598, acc 0.14000000059604645\n",
      "Epoch 5, iter 405, loss 2.2414908409118652, acc 0.18000000715255737\n",
      "Epoch 5, iter 406, loss 2.318009376525879, acc 0.11999999731779099\n",
      "Epoch 5, iter 407, loss 2.3228049278259277, acc 0.15000000596046448\n",
      "Epoch 5, iter 408, loss 2.2404396533966064, acc 0.17000000178813934\n",
      "Epoch 5, iter 409, loss 2.310687780380249, acc 0.12999999523162842\n",
      "Epoch 5, iter 410, loss 2.3185088634490967, acc 0.15000000596046448\n",
      "Epoch 5, iter 411, loss 2.272951126098633, acc 0.09000000357627869\n",
      "Epoch 5, iter 412, loss 2.270551919937134, acc 0.17000000178813934\n",
      "Epoch 5, iter 413, loss 2.345628261566162, acc 0.09000000357627869\n",
      "Epoch 5, iter 414, loss 2.271329879760742, acc 0.17000000178813934\n",
      "Epoch 5, iter 415, loss 2.2534162998199463, acc 0.18000000715255737\n",
      "Epoch 5, iter 416, loss 2.254072666168213, acc 0.15000000596046448\n",
      "Epoch 5, iter 417, loss 2.3372855186462402, acc 0.10000000149011612\n",
      "Epoch 5, iter 418, loss 2.3286898136138916, acc 0.09000000357627869\n",
      "Epoch 5, iter 419, loss 2.287247657775879, acc 0.10999999940395355\n",
      "Epoch 5, iter 420, loss 2.2415220737457275, acc 0.17000000178813934\n",
      "Epoch 6, iter 1, loss 2.3101861476898193, acc 0.14000000059604645\n",
      "Epoch 6, iter 2, loss 2.280094861984253, acc 0.12999999523162842\n",
      "Epoch 6, iter 3, loss 2.2667627334594727, acc 0.1599999964237213\n",
      "Epoch 6, iter 4, loss 2.252032518386841, acc 0.14000000059604645\n",
      "Epoch 6, iter 5, loss 2.254371404647827, acc 0.17000000178813934\n",
      "Epoch 6, iter 6, loss 2.2989394664764404, acc 0.15000000596046448\n",
      "Epoch 6, iter 7, loss 2.292726516723633, acc 0.14000000059604645\n",
      "Epoch 6, iter 8, loss 2.263556957244873, acc 0.09000000357627869\n",
      "Epoch 6, iter 9, loss 2.2444543838500977, acc 0.20000000298023224\n",
      "Epoch 6, iter 10, loss 2.236424207687378, acc 0.1899999976158142\n",
      "Epoch 6, iter 11, loss 2.25051212310791, acc 0.1899999976158142\n",
      "Epoch 6, iter 12, loss 2.2613472938537598, acc 0.1599999964237213\n",
      "Epoch 6, iter 13, loss 2.252364158630371, acc 0.23000000417232513\n",
      "Epoch 6, iter 14, loss 2.3462073802948, acc 0.10000000149011612\n",
      "Epoch 6, iter 15, loss 2.2931454181671143, acc 0.18000000715255737\n",
      "Epoch 6, iter 16, loss 2.291712522506714, acc 0.14000000059604645\n",
      "Epoch 6, iter 17, loss 2.2408366203308105, acc 0.15000000596046448\n",
      "Epoch 6, iter 18, loss 2.311697483062744, acc 0.10000000149011612\n",
      "Epoch 6, iter 19, loss 2.2251298427581787, acc 0.1599999964237213\n",
      "Epoch 6, iter 20, loss 2.2009854316711426, acc 0.1899999976158142\n",
      "Epoch 6, iter 21, loss 2.2768218517303467, acc 0.10999999940395355\n",
      "Epoch 6, iter 22, loss 2.2980690002441406, acc 0.14000000059604645\n",
      "Epoch 6, iter 23, loss 2.2741811275482178, acc 0.14000000059604645\n",
      "Epoch 6, iter 24, loss 2.2588276863098145, acc 0.12999999523162842\n",
      "Epoch 6, iter 25, loss 2.2951626777648926, acc 0.10999999940395355\n",
      "Epoch 6, iter 26, loss 2.314441204071045, acc 0.07999999821186066\n",
      "Epoch 6, iter 27, loss 2.265052080154419, acc 0.15000000596046448\n",
      "Epoch 6, iter 28, loss 2.31294846534729, acc 0.09000000357627869\n",
      "Epoch 6, iter 29, loss 2.267591714859009, acc 0.1599999964237213\n",
      "Epoch 6, iter 30, loss 2.396450996398926, acc 0.05000000074505806\n",
      "Epoch 6, iter 31, loss 2.298955202102661, acc 0.1899999976158142\n",
      "Epoch 6, iter 32, loss 2.281837224960327, acc 0.12999999523162842\n",
      "Epoch 6, iter 33, loss 2.2866311073303223, acc 0.10999999940395355\n",
      "Epoch 6, iter 34, loss 2.333872079849243, acc 0.10999999940395355\n",
      "Epoch 6, iter 35, loss 2.277552366256714, acc 0.1899999976158142\n",
      "Epoch 6, iter 36, loss 2.2782840728759766, acc 0.14000000059604645\n",
      "Epoch 6, iter 37, loss 2.308473825454712, acc 0.11999999731779099\n",
      "Epoch 6, iter 38, loss 2.264357089996338, acc 0.15000000596046448\n",
      "Epoch 6, iter 39, loss 2.24137806892395, acc 0.15000000596046448\n",
      "Epoch 6, iter 40, loss 2.336599111557007, acc 0.10999999940395355\n",
      "Epoch 6, iter 41, loss 2.3284125328063965, acc 0.14000000059604645\n",
      "Epoch 6, iter 42, loss 2.2553751468658447, acc 0.1599999964237213\n",
      "Epoch 6, iter 43, loss 2.2628297805786133, acc 0.14000000059604645\n",
      "Epoch 6, iter 44, loss 2.25093674659729, acc 0.17000000178813934\n",
      "Epoch 6, iter 45, loss 2.3197131156921387, acc 0.10999999940395355\n",
      "Epoch 6, iter 46, loss 2.3342125415802, acc 0.11999999731779099\n",
      "Epoch 6, iter 47, loss 2.287684440612793, acc 0.12999999523162842\n",
      "Epoch 6, iter 48, loss 2.3042263984680176, acc 0.10999999940395355\n",
      "Epoch 6, iter 49, loss 2.3204965591430664, acc 0.12999999523162842\n",
      "Epoch 6, iter 50, loss 2.2673020362854004, acc 0.14000000059604645\n",
      "Epoch 6, iter 51, loss 2.2918739318847656, acc 0.15000000596046448\n",
      "Epoch 6, iter 52, loss 2.29599666595459, acc 0.12999999523162842\n",
      "Epoch 6, iter 53, loss 2.3160200119018555, acc 0.15000000596046448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 54, loss 2.241621255874634, acc 0.1599999964237213\n",
      "Epoch 6, iter 55, loss 2.2790114879608154, acc 0.15000000596046448\n",
      "Epoch 6, iter 56, loss 2.267408847808838, acc 0.11999999731779099\n",
      "Epoch 6, iter 57, loss 2.2334227561950684, acc 0.1599999964237213\n",
      "Epoch 6, iter 58, loss 2.310739517211914, acc 0.10999999940395355\n",
      "Epoch 6, iter 59, loss 2.3386008739471436, acc 0.10000000149011612\n",
      "Epoch 6, iter 60, loss 2.287837266921997, acc 0.10000000149011612\n",
      "Epoch 6, iter 61, loss 2.2469890117645264, acc 0.11999999731779099\n",
      "Epoch 6, iter 62, loss 2.239598512649536, acc 0.18000000715255737\n",
      "Epoch 6, iter 63, loss 2.272237777709961, acc 0.1599999964237213\n",
      "Epoch 6, iter 64, loss 2.2328851222991943, acc 0.12999999523162842\n",
      "Epoch 6, iter 65, loss 2.2637834548950195, acc 0.10999999940395355\n",
      "Epoch 6, iter 66, loss 2.2607626914978027, acc 0.12999999523162842\n",
      "Epoch 6, iter 67, loss 2.2786686420440674, acc 0.14000000059604645\n",
      "Epoch 6, iter 68, loss 2.2630131244659424, acc 0.11999999731779099\n",
      "Epoch 6, iter 69, loss 2.2330167293548584, acc 0.14000000059604645\n",
      "Epoch 6, iter 70, loss 2.298795700073242, acc 0.10999999940395355\n",
      "Epoch 6, iter 71, loss 2.2914836406707764, acc 0.1599999964237213\n",
      "Epoch 6, iter 72, loss 2.334230422973633, acc 0.07999999821186066\n",
      "Epoch 6, iter 73, loss 2.2649431228637695, acc 0.14000000059604645\n",
      "Epoch 6, iter 74, loss 2.240844964981079, acc 0.14000000059604645\n",
      "Epoch 6, iter 75, loss 2.293260097503662, acc 0.14000000059604645\n",
      "Epoch 6, iter 76, loss 2.2822976112365723, acc 0.1599999964237213\n",
      "Epoch 6, iter 77, loss 2.291606903076172, acc 0.11999999731779099\n",
      "Epoch 6, iter 78, loss 2.2908453941345215, acc 0.12999999523162842\n",
      "Epoch 6, iter 79, loss 2.2731857299804688, acc 0.11999999731779099\n",
      "Epoch 6, iter 80, loss 2.2989838123321533, acc 0.1899999976158142\n",
      "Epoch 6, iter 81, loss 2.2381069660186768, acc 0.20000000298023224\n",
      "Epoch 6, iter 82, loss 2.2514476776123047, acc 0.15000000596046448\n",
      "Epoch 6, iter 83, loss 2.285000801086426, acc 0.10999999940395355\n",
      "Epoch 6, iter 84, loss 2.246898889541626, acc 0.17000000178813934\n",
      "Epoch 6, iter 85, loss 2.2670509815216064, acc 0.10000000149011612\n",
      "Epoch 6, iter 86, loss 2.2484819889068604, acc 0.18000000715255737\n",
      "Epoch 6, iter 87, loss 2.2073686122894287, acc 0.14000000059604645\n",
      "Epoch 6, iter 88, loss 2.2537426948547363, acc 0.10999999940395355\n",
      "Epoch 6, iter 89, loss 2.277162790298462, acc 0.14000000059604645\n",
      "Epoch 6, iter 90, loss 2.3027849197387695, acc 0.1599999964237213\n",
      "Epoch 6, iter 91, loss 2.285191059112549, acc 0.12999999523162842\n",
      "Epoch 6, iter 92, loss 2.2113442420959473, acc 0.20000000298023224\n",
      "Epoch 6, iter 93, loss 2.2846693992614746, acc 0.07000000029802322\n",
      "Epoch 6, iter 94, loss 2.2717249393463135, acc 0.1599999964237213\n",
      "Epoch 6, iter 95, loss 2.2890498638153076, acc 0.17000000178813934\n",
      "Epoch 6, iter 96, loss 2.2630834579467773, acc 0.12999999523162842\n",
      "Epoch 6, iter 97, loss 2.2992055416107178, acc 0.10999999940395355\n",
      "Epoch 6, iter 98, loss 2.318291425704956, acc 0.07999999821186066\n",
      "Epoch 6, iter 99, loss 2.225520133972168, acc 0.12999999523162842\n",
      "Epoch 6, iter 100, loss 2.338168144226074, acc 0.15000000596046448\n",
      "Epoch 6, iter 101, loss 2.3117520809173584, acc 0.14000000059604645\n",
      "Epoch 6, iter 102, loss 2.2669382095336914, acc 0.11999999731779099\n",
      "Epoch 6, iter 103, loss 2.3014743328094482, acc 0.10000000149011612\n",
      "Epoch 6, iter 104, loss 2.2648770809173584, acc 0.14000000059604645\n",
      "Epoch 6, iter 105, loss 2.281519889831543, acc 0.1599999964237213\n",
      "Epoch 6, iter 106, loss 2.258274793624878, acc 0.15000000596046448\n",
      "Epoch 6, iter 107, loss 2.2233057022094727, acc 0.1599999964237213\n",
      "Epoch 6, iter 108, loss 2.230203628540039, acc 0.14000000059604645\n",
      "Epoch 6, iter 109, loss 2.2947351932525635, acc 0.14000000059604645\n",
      "Epoch 6, iter 110, loss 2.3197216987609863, acc 0.12999999523162842\n",
      "Epoch 6, iter 111, loss 2.349851369857788, acc 0.10000000149011612\n",
      "Epoch 6, iter 112, loss 2.283910036087036, acc 0.10000000149011612\n",
      "Epoch 6, iter 113, loss 2.213433265686035, acc 0.12999999523162842\n",
      "Epoch 6, iter 114, loss 2.33663272857666, acc 0.11999999731779099\n",
      "Epoch 6, iter 115, loss 2.217616558074951, acc 0.18000000715255737\n",
      "Epoch 6, iter 116, loss 2.2721500396728516, acc 0.05999999865889549\n",
      "Epoch 6, iter 117, loss 2.28084135055542, acc 0.11999999731779099\n",
      "Epoch 6, iter 118, loss 2.318850040435791, acc 0.07999999821186066\n",
      "Epoch 6, iter 119, loss 2.254141330718994, acc 0.20000000298023224\n",
      "Epoch 6, iter 120, loss 2.2559902667999268, acc 0.1599999964237213\n",
      "Epoch 6, iter 121, loss 2.2574615478515625, acc 0.14000000059604645\n",
      "Epoch 6, iter 122, loss 2.280146598815918, acc 0.10000000149011612\n",
      "Epoch 6, iter 123, loss 2.2650797367095947, acc 0.11999999731779099\n",
      "Epoch 6, iter 124, loss 2.2877674102783203, acc 0.14000000059604645\n",
      "Epoch 6, iter 125, loss 2.253370761871338, acc 0.17000000178813934\n",
      "Epoch 6, iter 126, loss 2.328294277191162, acc 0.07000000029802322\n",
      "Epoch 6, iter 127, loss 2.2697341442108154, acc 0.10999999940395355\n",
      "Epoch 6, iter 128, loss 2.259323835372925, acc 0.18000000715255737\n",
      "Epoch 6, iter 129, loss 2.2799882888793945, acc 0.12999999523162842\n",
      "Epoch 6, iter 130, loss 2.3034191131591797, acc 0.09000000357627869\n",
      "Epoch 6, iter 131, loss 2.27132511138916, acc 0.12999999523162842\n",
      "Epoch 6, iter 132, loss 2.2606918811798096, acc 0.17000000178813934\n",
      "Epoch 6, iter 133, loss 2.2830142974853516, acc 0.12999999523162842\n",
      "Epoch 6, iter 134, loss 2.2661609649658203, acc 0.11999999731779099\n",
      "Epoch 6, iter 135, loss 2.34011173248291, acc 0.10999999940395355\n",
      "Epoch 6, iter 136, loss 2.274996757507324, acc 0.14000000059604645\n",
      "Epoch 6, iter 137, loss 2.2604029178619385, acc 0.15000000596046448\n",
      "Epoch 6, iter 138, loss 2.2145447731018066, acc 0.17000000178813934\n",
      "Epoch 6, iter 139, loss 2.267704963684082, acc 0.14000000059604645\n",
      "Epoch 6, iter 140, loss 2.2506320476531982, acc 0.12999999523162842\n",
      "Epoch 6, iter 141, loss 2.2665836811065674, acc 0.15000000596046448\n",
      "Epoch 6, iter 142, loss 2.373375177383423, acc 0.14000000059604645\n",
      "Epoch 6, iter 143, loss 2.188649892807007, acc 0.1599999964237213\n",
      "Epoch 6, iter 144, loss 2.30151104927063, acc 0.12999999523162842\n",
      "Epoch 6, iter 145, loss 2.2658698558807373, acc 0.10000000149011612\n",
      "Epoch 6, iter 146, loss 2.2591238021850586, acc 0.15000000596046448\n",
      "Epoch 6, iter 147, loss 2.3106935024261475, acc 0.10999999940395355\n",
      "Epoch 6, iter 148, loss 2.3257639408111572, acc 0.07000000029802322\n",
      "Epoch 6, iter 149, loss 2.297250270843506, acc 0.10000000149011612\n",
      "Epoch 6, iter 150, loss 2.2541663646698, acc 0.15000000596046448\n",
      "Epoch 6, iter 151, loss 2.297232151031494, acc 0.03999999910593033\n",
      "Epoch 6, iter 152, loss 2.316904067993164, acc 0.05999999865889549\n",
      "Epoch 6, iter 153, loss 2.2731359004974365, acc 0.12999999523162842\n",
      "Epoch 6, iter 154, loss 2.25366473197937, acc 0.14000000059604645\n",
      "Epoch 6, iter 155, loss 2.2694525718688965, acc 0.10999999940395355\n",
      "Epoch 6, iter 156, loss 2.2474210262298584, acc 0.11999999731779099\n",
      "Epoch 6, iter 157, loss 2.345947742462158, acc 0.17000000178813934\n",
      "Epoch 6, iter 158, loss 2.2679014205932617, acc 0.14000000059604645\n",
      "Epoch 6, iter 159, loss 2.3116884231567383, acc 0.07999999821186066\n",
      "Epoch 6, iter 160, loss 2.268773078918457, acc 0.15000000596046448\n",
      "Epoch 6, iter 161, loss 2.234529495239258, acc 0.18000000715255737\n",
      "Epoch 6, iter 162, loss 2.262930393218994, acc 0.10999999940395355\n",
      "Epoch 6, iter 163, loss 2.2584667205810547, acc 0.10999999940395355\n",
      "Epoch 6, iter 164, loss 2.301180362701416, acc 0.12999999523162842\n",
      "Epoch 6, iter 165, loss 2.250795602798462, acc 0.15000000596046448\n",
      "Epoch 6, iter 166, loss 2.2506096363067627, acc 0.20000000298023224\n",
      "Epoch 6, iter 167, loss 2.2560441493988037, acc 0.12999999523162842\n",
      "Epoch 6, iter 168, loss 2.3240857124328613, acc 0.11999999731779099\n",
      "Epoch 6, iter 169, loss 2.3110640048980713, acc 0.07999999821186066\n",
      "Epoch 6, iter 170, loss 2.343759059906006, acc 0.09000000357627869\n",
      "Epoch 6, iter 171, loss 2.2460014820098877, acc 0.11999999731779099\n",
      "Epoch 6, iter 172, loss 2.3015594482421875, acc 0.12999999523162842\n",
      "Epoch 6, iter 173, loss 2.3339366912841797, acc 0.09000000357627869\n",
      "Epoch 6, iter 174, loss 2.2543561458587646, acc 0.10999999940395355\n",
      "Epoch 6, iter 175, loss 2.2614927291870117, acc 0.14000000059604645\n",
      "Epoch 6, iter 176, loss 2.317190647125244, acc 0.12999999523162842\n",
      "Epoch 6, iter 177, loss 2.2803947925567627, acc 0.10999999940395355\n",
      "Epoch 6, iter 178, loss 2.266848564147949, acc 0.07999999821186066\n",
      "Epoch 6, iter 179, loss 2.254599094390869, acc 0.14000000059604645\n",
      "Epoch 6, iter 180, loss 2.2339327335357666, acc 0.15000000596046448\n",
      "Epoch 6, iter 181, loss 2.1963276863098145, acc 0.12999999523162842\n",
      "Epoch 6, iter 182, loss 2.220884084701538, acc 0.1599999964237213\n",
      "Epoch 6, iter 183, loss 2.2415525913238525, acc 0.09000000357627869\n",
      "Epoch 6, iter 184, loss 2.3021421432495117, acc 0.11999999731779099\n",
      "Epoch 6, iter 185, loss 2.2779531478881836, acc 0.1599999964237213\n",
      "Epoch 6, iter 186, loss 2.3034238815307617, acc 0.12999999523162842\n",
      "Epoch 6, iter 187, loss 2.2206907272338867, acc 0.1599999964237213\n",
      "Epoch 6, iter 188, loss 2.2787115573883057, acc 0.10000000149011612\n",
      "Epoch 6, iter 189, loss 2.302736520767212, acc 0.17000000178813934\n",
      "Epoch 6, iter 190, loss 2.242363929748535, acc 0.14000000059604645\n",
      "Epoch 6, iter 191, loss 2.263256311416626, acc 0.11999999731779099\n",
      "Epoch 6, iter 192, loss 2.2870376110076904, acc 0.11999999731779099\n",
      "Epoch 6, iter 193, loss 2.2961843013763428, acc 0.1599999964237213\n",
      "Epoch 6, iter 194, loss 2.2373037338256836, acc 0.1599999964237213\n",
      "Epoch 6, iter 195, loss 2.249361991882324, acc 0.18000000715255737\n",
      "Epoch 6, iter 196, loss 2.2502291202545166, acc 0.1899999976158142\n",
      "Epoch 6, iter 197, loss 2.241988182067871, acc 0.18000000715255737\n",
      "Epoch 6, iter 198, loss 2.2693567276000977, acc 0.11999999731779099\n",
      "Epoch 6, iter 199, loss 2.29231333732605, acc 0.17000000178813934\n",
      "Epoch 6, iter 200, loss 2.3050127029418945, acc 0.17000000178813934\n",
      "Epoch 6, iter 201, loss 2.3078560829162598, acc 0.11999999731779099\n",
      "Epoch 6, iter 202, loss 2.2371044158935547, acc 0.14000000059604645\n",
      "Epoch 6, iter 203, loss 2.26214599609375, acc 0.09000000357627869\n",
      "Epoch 6, iter 204, loss 2.274303674697876, acc 0.11999999731779099\n",
      "Epoch 6, iter 205, loss 2.2940919399261475, acc 0.07999999821186066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 206, loss 2.2699010372161865, acc 0.1899999976158142\n",
      "Epoch 6, iter 207, loss 2.334663152694702, acc 0.09000000357627869\n",
      "Epoch 6, iter 208, loss 2.306666374206543, acc 0.15000000596046448\n",
      "Epoch 6, iter 209, loss 2.2745838165283203, acc 0.1599999964237213\n",
      "Epoch 6, iter 210, loss 2.248410224914551, acc 0.15000000596046448\n",
      "Epoch 6, iter 211, loss 2.3197555541992188, acc 0.12999999523162842\n",
      "Epoch 6, iter 212, loss 2.285594940185547, acc 0.2199999988079071\n",
      "Epoch 6, iter 213, loss 2.204944610595703, acc 0.1599999964237213\n",
      "Epoch 6, iter 214, loss 2.3267126083374023, acc 0.09000000357627869\n",
      "Epoch 6, iter 215, loss 2.3204309940338135, acc 0.10999999940395355\n",
      "Epoch 6, iter 216, loss 2.275038719177246, acc 0.12999999523162842\n",
      "Epoch 6, iter 217, loss 2.263859272003174, acc 0.12999999523162842\n",
      "Epoch 6, iter 218, loss 2.3512251377105713, acc 0.11999999731779099\n",
      "Epoch 6, iter 219, loss 2.227825403213501, acc 0.12999999523162842\n",
      "Epoch 6, iter 220, loss 2.346187114715576, acc 0.10999999940395355\n",
      "Epoch 6, iter 221, loss 2.2449324131011963, acc 0.10000000149011612\n",
      "Epoch 6, iter 222, loss 2.253998279571533, acc 0.09000000357627869\n",
      "Epoch 6, iter 223, loss 2.191863775253296, acc 0.18000000715255737\n",
      "Epoch 6, iter 224, loss 2.2655222415924072, acc 0.10000000149011612\n",
      "Epoch 6, iter 225, loss 2.317775249481201, acc 0.07999999821186066\n",
      "Epoch 6, iter 226, loss 2.244020700454712, acc 0.14000000059604645\n",
      "Epoch 6, iter 227, loss 2.2799737453460693, acc 0.14000000059604645\n",
      "Epoch 6, iter 228, loss 2.2142553329467773, acc 0.23000000417232513\n",
      "Epoch 6, iter 229, loss 2.2823946475982666, acc 0.12999999523162842\n",
      "Epoch 6, iter 230, loss 2.279432535171509, acc 0.12999999523162842\n",
      "Epoch 6, iter 231, loss 2.2723169326782227, acc 0.12999999523162842\n",
      "Epoch 6, iter 232, loss 2.336043119430542, acc 0.11999999731779099\n",
      "Epoch 6, iter 233, loss 2.242812395095825, acc 0.11999999731779099\n",
      "Epoch 6, iter 234, loss 2.232257604598999, acc 0.14000000059604645\n",
      "Epoch 6, iter 235, loss 2.24096417427063, acc 0.14000000059604645\n",
      "Epoch 6, iter 236, loss 2.258298397064209, acc 0.11999999731779099\n",
      "Epoch 6, iter 237, loss 2.2825498580932617, acc 0.15000000596046448\n",
      "Epoch 6, iter 238, loss 2.2284488677978516, acc 0.1599999964237213\n",
      "Epoch 6, iter 239, loss 2.2612295150756836, acc 0.14000000059604645\n",
      "Epoch 6, iter 240, loss 2.3197150230407715, acc 0.10000000149011612\n",
      "Epoch 6, iter 241, loss 2.2988545894622803, acc 0.07999999821186066\n",
      "Epoch 6, iter 242, loss 2.239799976348877, acc 0.18000000715255737\n",
      "Epoch 6, iter 243, loss 2.2464706897735596, acc 0.17000000178813934\n",
      "Epoch 6, iter 244, loss 2.279681444168091, acc 0.09000000357627869\n",
      "Epoch 6, iter 245, loss 2.22346568107605, acc 0.09000000357627869\n",
      "Epoch 6, iter 246, loss 2.284848213195801, acc 0.10000000149011612\n",
      "Epoch 6, iter 247, loss 2.2259328365325928, acc 0.14000000059604645\n",
      "Epoch 6, iter 248, loss 2.2466471195220947, acc 0.14000000059604645\n",
      "Epoch 6, iter 249, loss 2.268425941467285, acc 0.1899999976158142\n",
      "Epoch 6, iter 250, loss 2.1887454986572266, acc 0.12999999523162842\n",
      "Epoch 6, iter 251, loss 2.2426154613494873, acc 0.15000000596046448\n",
      "Epoch 6, iter 252, loss 2.1849396228790283, acc 0.18000000715255737\n",
      "Epoch 6, iter 253, loss 2.3500924110412598, acc 0.12999999523162842\n",
      "Epoch 6, iter 254, loss 2.292625665664673, acc 0.1599999964237213\n",
      "Epoch 6, iter 255, loss 2.332228660583496, acc 0.10000000149011612\n",
      "Epoch 6, iter 256, loss 2.3110055923461914, acc 0.11999999731779099\n",
      "Epoch 6, iter 257, loss 2.2961173057556152, acc 0.15000000596046448\n",
      "Epoch 6, iter 258, loss 2.2299084663391113, acc 0.1599999964237213\n",
      "Epoch 6, iter 259, loss 2.220545530319214, acc 0.18000000715255737\n",
      "Epoch 6, iter 260, loss 2.2690541744232178, acc 0.14000000059604645\n",
      "Epoch 6, iter 261, loss 2.2352168560028076, acc 0.12999999523162842\n",
      "Epoch 6, iter 262, loss 2.282867908477783, acc 0.11999999731779099\n",
      "Epoch 6, iter 263, loss 2.2551279067993164, acc 0.14000000059604645\n",
      "Epoch 6, iter 264, loss 2.246647596359253, acc 0.12999999523162842\n",
      "Epoch 6, iter 265, loss 2.291400671005249, acc 0.1599999964237213\n",
      "Epoch 6, iter 266, loss 2.2355871200561523, acc 0.15000000596046448\n",
      "Epoch 6, iter 267, loss 2.2564547061920166, acc 0.23000000417232513\n",
      "Epoch 6, iter 268, loss 2.292410373687744, acc 0.18000000715255737\n",
      "Epoch 6, iter 269, loss 2.232818365097046, acc 0.14000000059604645\n",
      "Epoch 6, iter 270, loss 2.2722063064575195, acc 0.11999999731779099\n",
      "Epoch 6, iter 271, loss 2.2803335189819336, acc 0.1899999976158142\n",
      "Epoch 6, iter 272, loss 2.2510175704956055, acc 0.15000000596046448\n",
      "Epoch 6, iter 273, loss 2.263424873352051, acc 0.17000000178813934\n",
      "Epoch 6, iter 274, loss 2.209195137023926, acc 0.18000000715255737\n",
      "Epoch 6, iter 275, loss 2.278205156326294, acc 0.17000000178813934\n",
      "Epoch 6, iter 276, loss 2.3201656341552734, acc 0.14000000059604645\n",
      "Epoch 6, iter 277, loss 2.2482168674468994, acc 0.11999999731779099\n",
      "Epoch 6, iter 278, loss 2.2316668033599854, acc 0.15000000596046448\n",
      "Epoch 6, iter 279, loss 2.257399797439575, acc 0.09000000357627869\n",
      "Epoch 6, iter 280, loss 2.237272262573242, acc 0.17000000178813934\n",
      "Epoch 6, iter 281, loss 2.2338900566101074, acc 0.12999999523162842\n",
      "Epoch 6, iter 282, loss 2.3063576221466064, acc 0.15000000596046448\n",
      "Epoch 6, iter 283, loss 2.260103940963745, acc 0.10999999940395355\n",
      "Epoch 6, iter 284, loss 2.3105950355529785, acc 0.10999999940395355\n",
      "Epoch 6, iter 285, loss 2.2611615657806396, acc 0.09000000357627869\n",
      "Epoch 6, iter 286, loss 2.254865884780884, acc 0.14000000059604645\n",
      "Epoch 6, iter 287, loss 2.286330223083496, acc 0.1599999964237213\n",
      "Epoch 6, iter 288, loss 2.2852976322174072, acc 0.09000000357627869\n",
      "Epoch 6, iter 289, loss 2.2146971225738525, acc 0.17000000178813934\n",
      "Epoch 6, iter 290, loss 2.3024539947509766, acc 0.10000000149011612\n",
      "Epoch 6, iter 291, loss 2.2493467330932617, acc 0.15000000596046448\n",
      "Epoch 6, iter 292, loss 2.2723515033721924, acc 0.12999999523162842\n",
      "Epoch 6, iter 293, loss 2.2401583194732666, acc 0.11999999731779099\n",
      "Epoch 6, iter 294, loss 2.291862964630127, acc 0.1599999964237213\n",
      "Epoch 6, iter 295, loss 2.2737579345703125, acc 0.15000000596046448\n",
      "Epoch 6, iter 296, loss 2.2877490520477295, acc 0.11999999731779099\n",
      "Epoch 6, iter 297, loss 2.3144822120666504, acc 0.14000000059604645\n",
      "Epoch 6, iter 298, loss 2.2498369216918945, acc 0.17000000178813934\n",
      "Epoch 6, iter 299, loss 2.3013815879821777, acc 0.17000000178813934\n",
      "Epoch 6, iter 300, loss 2.2711806297302246, acc 0.11999999731779099\n",
      "Epoch 6, iter 301, loss 2.284940242767334, acc 0.09000000357627869\n",
      "Epoch 6, iter 302, loss 2.25089168548584, acc 0.1899999976158142\n",
      "Epoch 6, iter 303, loss 2.282432794570923, acc 0.15000000596046448\n",
      "Epoch 6, iter 304, loss 2.3080289363861084, acc 0.12999999523162842\n",
      "Epoch 6, iter 305, loss 2.2461562156677246, acc 0.1599999964237213\n",
      "Epoch 6, iter 306, loss 2.2659456729888916, acc 0.14000000059604645\n",
      "Epoch 6, iter 307, loss 2.234917402267456, acc 0.15000000596046448\n",
      "Epoch 6, iter 308, loss 2.259122371673584, acc 0.20000000298023224\n",
      "Epoch 6, iter 309, loss 2.251208543777466, acc 0.14000000059604645\n",
      "Epoch 6, iter 310, loss 2.3107802867889404, acc 0.05999999865889549\n",
      "Epoch 6, iter 311, loss 2.261770248413086, acc 0.18000000715255737\n",
      "Epoch 6, iter 312, loss 2.3022654056549072, acc 0.09000000357627869\n",
      "Epoch 6, iter 313, loss 2.3003110885620117, acc 0.12999999523162842\n",
      "Epoch 6, iter 314, loss 2.2666800022125244, acc 0.1899999976158142\n",
      "Epoch 6, iter 315, loss 2.3318793773651123, acc 0.15000000596046448\n",
      "Epoch 6, iter 316, loss 2.2657630443573, acc 0.14000000059604645\n",
      "Epoch 6, iter 317, loss 2.2370879650115967, acc 0.18000000715255737\n",
      "Epoch 6, iter 318, loss 2.322608709335327, acc 0.07999999821186066\n",
      "Epoch 6, iter 319, loss 2.248432159423828, acc 0.10999999940395355\n",
      "Epoch 6, iter 320, loss 2.213251829147339, acc 0.14000000059604645\n",
      "Epoch 6, iter 321, loss 2.2982451915740967, acc 0.10999999940395355\n",
      "Epoch 6, iter 322, loss 2.279733657836914, acc 0.15000000596046448\n",
      "Epoch 6, iter 323, loss 2.3011248111724854, acc 0.11999999731779099\n",
      "Epoch 6, iter 324, loss 2.1915934085845947, acc 0.14000000059604645\n",
      "Epoch 6, iter 325, loss 2.2904863357543945, acc 0.15000000596046448\n",
      "Epoch 6, iter 326, loss 2.2326297760009766, acc 0.14000000059604645\n",
      "Epoch 6, iter 327, loss 2.2773430347442627, acc 0.15000000596046448\n",
      "Epoch 6, iter 328, loss 2.3736493587493896, acc 0.09000000357627869\n",
      "Epoch 6, iter 329, loss 2.264577627182007, acc 0.10000000149011612\n",
      "Epoch 6, iter 330, loss 2.250967264175415, acc 0.11999999731779099\n",
      "Epoch 6, iter 331, loss 2.2785253524780273, acc 0.12999999523162842\n",
      "Epoch 6, iter 332, loss 2.282379627227783, acc 0.15000000596046448\n",
      "Epoch 6, iter 333, loss 2.2635648250579834, acc 0.10999999940395355\n",
      "Epoch 6, iter 334, loss 2.2213857173919678, acc 0.12999999523162842\n",
      "Epoch 6, iter 335, loss 2.2379446029663086, acc 0.12999999523162842\n",
      "Epoch 6, iter 336, loss 2.261359453201294, acc 0.07000000029802322\n",
      "Epoch 6, iter 337, loss 2.234158992767334, acc 0.10999999940395355\n",
      "Epoch 6, iter 338, loss 2.2737839221954346, acc 0.09000000357627869\n",
      "Epoch 6, iter 339, loss 2.2697293758392334, acc 0.14000000059604645\n",
      "Epoch 6, iter 340, loss 2.3087525367736816, acc 0.11999999731779099\n",
      "Epoch 6, iter 341, loss 2.238809108734131, acc 0.10000000149011612\n",
      "Epoch 6, iter 342, loss 2.2824296951293945, acc 0.10999999940395355\n",
      "Epoch 6, iter 343, loss 2.2116804122924805, acc 0.17000000178813934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 344, loss 2.2838447093963623, acc 0.10000000149011612\n",
      "Epoch 6, iter 345, loss 2.261364698410034, acc 0.10000000149011612\n",
      "Epoch 6, iter 346, loss 2.3492496013641357, acc 0.07999999821186066\n",
      "Epoch 6, iter 347, loss 2.288677453994751, acc 0.18000000715255737\n",
      "Epoch 6, iter 348, loss 2.27620792388916, acc 0.12999999523162842\n",
      "Epoch 6, iter 349, loss 2.2965309619903564, acc 0.09000000357627869\n",
      "Epoch 6, iter 350, loss 2.2875006198883057, acc 0.11999999731779099\n",
      "Epoch 6, iter 351, loss 2.2044496536254883, acc 0.18000000715255737\n",
      "Epoch 6, iter 352, loss 2.306654930114746, acc 0.12999999523162842\n",
      "Epoch 6, iter 353, loss 2.2053451538085938, acc 0.20999999344348907\n",
      "Epoch 6, iter 354, loss 2.304722547531128, acc 0.12999999523162842\n",
      "Epoch 6, iter 355, loss 2.2940943241119385, acc 0.10000000149011612\n",
      "Epoch 6, iter 356, loss 2.2667179107666016, acc 0.10000000149011612\n",
      "Epoch 6, iter 357, loss 2.2540621757507324, acc 0.14000000059604645\n",
      "Epoch 6, iter 358, loss 2.2458364963531494, acc 0.1599999964237213\n",
      "Epoch 6, iter 359, loss 2.3000619411468506, acc 0.10999999940395355\n",
      "Epoch 6, iter 360, loss 2.3241114616394043, acc 0.10000000149011612\n",
      "Epoch 6, iter 361, loss 2.2628238201141357, acc 0.1899999976158142\n",
      "Epoch 6, iter 362, loss 2.2725157737731934, acc 0.09000000357627869\n",
      "Epoch 6, iter 363, loss 2.2491676807403564, acc 0.10999999940395355\n",
      "Epoch 6, iter 364, loss 2.3380179405212402, acc 0.12999999523162842\n",
      "Epoch 6, iter 365, loss 2.284489870071411, acc 0.14000000059604645\n",
      "Epoch 6, iter 366, loss 2.311764717102051, acc 0.10999999940395355\n",
      "Epoch 6, iter 367, loss 2.2720844745635986, acc 0.09000000357627869\n",
      "Epoch 6, iter 368, loss 2.3201818466186523, acc 0.07999999821186066\n",
      "Epoch 6, iter 369, loss 2.217559337615967, acc 0.1899999976158142\n",
      "Epoch 6, iter 370, loss 2.2184691429138184, acc 0.14000000059604645\n",
      "Epoch 6, iter 371, loss 2.2974722385406494, acc 0.10999999940395355\n",
      "Epoch 6, iter 372, loss 2.2462351322174072, acc 0.1599999964237213\n",
      "Epoch 6, iter 373, loss 2.28291392326355, acc 0.12999999523162842\n",
      "Epoch 6, iter 374, loss 2.2322826385498047, acc 0.18000000715255737\n",
      "Epoch 6, iter 375, loss 2.2975544929504395, acc 0.10999999940395355\n",
      "Epoch 6, iter 376, loss 2.2268424034118652, acc 0.18000000715255737\n",
      "Epoch 6, iter 377, loss 2.276075601577759, acc 0.15000000596046448\n",
      "Epoch 6, iter 378, loss 2.2755141258239746, acc 0.15000000596046448\n",
      "Epoch 6, iter 379, loss 2.332740545272827, acc 0.10999999940395355\n",
      "Epoch 6, iter 380, loss 2.2427594661712646, acc 0.10000000149011612\n",
      "Epoch 6, iter 381, loss 2.317101240158081, acc 0.05999999865889549\n",
      "Epoch 6, iter 382, loss 2.281414270401001, acc 0.11999999731779099\n",
      "Epoch 6, iter 383, loss 2.2768869400024414, acc 0.10000000149011612\n",
      "Epoch 6, iter 384, loss 2.2711992263793945, acc 0.17000000178813934\n",
      "Epoch 6, iter 385, loss 2.2449939250946045, acc 0.11999999731779099\n",
      "Epoch 6, iter 386, loss 2.279374599456787, acc 0.09000000357627869\n",
      "Epoch 6, iter 387, loss 2.2952704429626465, acc 0.10000000149011612\n",
      "Epoch 6, iter 388, loss 2.274796962738037, acc 0.15000000596046448\n",
      "Epoch 6, iter 389, loss 2.256120204925537, acc 0.1899999976158142\n",
      "Epoch 6, iter 390, loss 2.2700231075286865, acc 0.1599999964237213\n",
      "Epoch 6, iter 391, loss 2.247401714324951, acc 0.18000000715255737\n",
      "Epoch 6, iter 392, loss 2.2778165340423584, acc 0.14000000059604645\n",
      "Epoch 6, iter 393, loss 2.299690008163452, acc 0.15000000596046448\n",
      "Epoch 6, iter 394, loss 2.293924331665039, acc 0.12999999523162842\n",
      "Epoch 6, iter 395, loss 2.2642931938171387, acc 0.11999999731779099\n",
      "Epoch 6, iter 396, loss 2.291607618331909, acc 0.10999999940395355\n",
      "Epoch 6, iter 397, loss 2.3391189575195312, acc 0.10999999940395355\n",
      "Epoch 6, iter 398, loss 2.2541260719299316, acc 0.14000000059604645\n",
      "Epoch 6, iter 399, loss 2.3142080307006836, acc 0.15000000596046448\n",
      "Epoch 6, iter 400, loss 2.2349846363067627, acc 0.14000000059604645\n",
      "Epoch 6, iter 401, loss 2.2522761821746826, acc 0.11999999731779099\n",
      "Epoch 6, iter 402, loss 2.239377498626709, acc 0.10000000149011612\n",
      "Epoch 6, iter 403, loss 2.2421350479125977, acc 0.14000000059604645\n",
      "Epoch 6, iter 404, loss 2.230384588241577, acc 0.14000000059604645\n",
      "Epoch 6, iter 405, loss 2.2140913009643555, acc 0.18000000715255737\n",
      "Epoch 6, iter 406, loss 2.296966791152954, acc 0.11999999731779099\n",
      "Epoch 6, iter 407, loss 2.317267656326294, acc 0.14000000059604645\n",
      "Epoch 6, iter 408, loss 2.2060282230377197, acc 0.18000000715255737\n",
      "Epoch 6, iter 409, loss 2.288590431213379, acc 0.14000000059604645\n",
      "Epoch 6, iter 410, loss 2.2980570793151855, acc 0.15000000596046448\n",
      "Epoch 6, iter 411, loss 2.257899761199951, acc 0.09000000357627869\n",
      "Epoch 6, iter 412, loss 2.232340097427368, acc 0.17000000178813934\n",
      "Epoch 6, iter 413, loss 2.305917739868164, acc 0.11999999731779099\n",
      "Epoch 6, iter 414, loss 2.2423095703125, acc 0.1599999964237213\n",
      "Epoch 6, iter 415, loss 2.219099521636963, acc 0.1899999976158142\n",
      "Epoch 6, iter 416, loss 2.2436609268188477, acc 0.15000000596046448\n",
      "Epoch 6, iter 417, loss 2.320556402206421, acc 0.10000000149011612\n",
      "Epoch 6, iter 418, loss 2.2990808486938477, acc 0.10000000149011612\n",
      "Epoch 6, iter 419, loss 2.2402355670928955, acc 0.11999999731779099\n",
      "Epoch 6, iter 420, loss 2.219374895095825, acc 0.17000000178813934\n",
      "Epoch 7, iter 1, loss 2.302825689315796, acc 0.12999999523162842\n",
      "Epoch 7, iter 2, loss 2.2781314849853516, acc 0.12999999523162842\n",
      "Epoch 7, iter 3, loss 2.253469467163086, acc 0.17000000178813934\n",
      "Epoch 7, iter 4, loss 2.2171430587768555, acc 0.1599999964237213\n",
      "Epoch 7, iter 5, loss 2.241718053817749, acc 0.18000000715255737\n",
      "Epoch 7, iter 6, loss 2.277212142944336, acc 0.15000000596046448\n",
      "Epoch 7, iter 7, loss 2.2784323692321777, acc 0.14000000059604645\n",
      "Epoch 7, iter 8, loss 2.2453196048736572, acc 0.09000000357627869\n",
      "Epoch 7, iter 9, loss 2.225806951522827, acc 0.20000000298023224\n",
      "Epoch 7, iter 10, loss 2.19792103767395, acc 0.20000000298023224\n",
      "Epoch 7, iter 11, loss 2.221444606781006, acc 0.1899999976158142\n",
      "Epoch 7, iter 12, loss 2.216499090194702, acc 0.17000000178813934\n",
      "Epoch 7, iter 13, loss 2.2309751510620117, acc 0.23000000417232513\n",
      "Epoch 7, iter 14, loss 2.3227412700653076, acc 0.10000000149011612\n",
      "Epoch 7, iter 15, loss 2.2781031131744385, acc 0.18000000715255737\n",
      "Epoch 7, iter 16, loss 2.2684519290924072, acc 0.14000000059604645\n",
      "Epoch 7, iter 17, loss 2.2124500274658203, acc 0.15000000596046448\n",
      "Epoch 7, iter 18, loss 2.276301383972168, acc 0.10000000149011612\n",
      "Epoch 7, iter 19, loss 2.1974692344665527, acc 0.17000000178813934\n",
      "Epoch 7, iter 20, loss 2.1845412254333496, acc 0.1899999976158142\n",
      "Epoch 7, iter 21, loss 2.2482216358184814, acc 0.10999999940395355\n",
      "Epoch 7, iter 22, loss 2.2577037811279297, acc 0.14000000059604645\n",
      "Epoch 7, iter 23, loss 2.2537081241607666, acc 0.15000000596046448\n",
      "Epoch 7, iter 24, loss 2.2455685138702393, acc 0.12999999523162842\n",
      "Epoch 7, iter 25, loss 2.271969795227051, acc 0.10999999940395355\n",
      "Epoch 7, iter 26, loss 2.2976508140563965, acc 0.09000000357627869\n",
      "Epoch 7, iter 27, loss 2.2446045875549316, acc 0.15000000596046448\n",
      "Epoch 7, iter 28, loss 2.299574136734009, acc 0.09000000357627869\n",
      "Epoch 7, iter 29, loss 2.2337539196014404, acc 0.17000000178813934\n",
      "Epoch 7, iter 30, loss 2.377453088760376, acc 0.05000000074505806\n",
      "Epoch 7, iter 31, loss 2.251868963241577, acc 0.1899999976158142\n",
      "Epoch 7, iter 32, loss 2.2608633041381836, acc 0.12999999523162842\n",
      "Epoch 7, iter 33, loss 2.273481845855713, acc 0.10999999940395355\n",
      "Epoch 7, iter 34, loss 2.312479019165039, acc 0.10999999940395355\n",
      "Epoch 7, iter 35, loss 2.2641170024871826, acc 0.1899999976158142\n",
      "Epoch 7, iter 36, loss 2.2495501041412354, acc 0.1599999964237213\n",
      "Epoch 7, iter 37, loss 2.3013815879821777, acc 0.11999999731779099\n",
      "Epoch 7, iter 38, loss 2.2454817295074463, acc 0.15000000596046448\n",
      "Epoch 7, iter 39, loss 2.2242166996002197, acc 0.15000000596046448\n",
      "Epoch 7, iter 40, loss 2.305718421936035, acc 0.11999999731779099\n",
      "Epoch 7, iter 41, loss 2.3009183406829834, acc 0.14000000059604645\n",
      "Epoch 7, iter 42, loss 2.2245421409606934, acc 0.1599999964237213\n",
      "Epoch 7, iter 43, loss 2.223710298538208, acc 0.14000000059604645\n",
      "Epoch 7, iter 44, loss 2.2269794940948486, acc 0.18000000715255737\n",
      "Epoch 7, iter 45, loss 2.2652316093444824, acc 0.10999999940395355\n",
      "Epoch 7, iter 46, loss 2.3007850646972656, acc 0.11999999731779099\n",
      "Epoch 7, iter 47, loss 2.2662415504455566, acc 0.12999999523162842\n",
      "Epoch 7, iter 48, loss 2.2861969470977783, acc 0.10999999940395355\n",
      "Epoch 7, iter 49, loss 2.2695882320404053, acc 0.12999999523162842\n",
      "Epoch 7, iter 50, loss 2.248870611190796, acc 0.14000000059604645\n",
      "Epoch 7, iter 51, loss 2.2649805545806885, acc 0.1599999964237213\n",
      "Epoch 7, iter 52, loss 2.2789504528045654, acc 0.12999999523162842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 53, loss 2.310170888900757, acc 0.15000000596046448\n",
      "Epoch 7, iter 54, loss 2.228506565093994, acc 0.14000000059604645\n",
      "Epoch 7, iter 55, loss 2.2597460746765137, acc 0.17000000178813934\n",
      "Epoch 7, iter 56, loss 2.2281720638275146, acc 0.12999999523162842\n",
      "Epoch 7, iter 57, loss 2.1992645263671875, acc 0.1599999964237213\n",
      "Epoch 7, iter 58, loss 2.2793219089508057, acc 0.10999999940395355\n",
      "Epoch 7, iter 59, loss 2.314406394958496, acc 0.10000000149011612\n",
      "Epoch 7, iter 60, loss 2.275378465652466, acc 0.10000000149011612\n",
      "Epoch 7, iter 61, loss 2.217125177383423, acc 0.14000000059604645\n",
      "Epoch 7, iter 62, loss 2.2263283729553223, acc 0.18000000715255737\n",
      "Epoch 7, iter 63, loss 2.2520525455474854, acc 0.1599999964237213\n",
      "Epoch 7, iter 64, loss 2.2247257232666016, acc 0.10999999940395355\n",
      "Epoch 7, iter 65, loss 2.2485697269439697, acc 0.10999999940395355\n",
      "Epoch 7, iter 66, loss 2.237531900405884, acc 0.14000000059604645\n",
      "Epoch 7, iter 67, loss 2.270357131958008, acc 0.14000000059604645\n",
      "Epoch 7, iter 68, loss 2.2396860122680664, acc 0.11999999731779099\n",
      "Epoch 7, iter 69, loss 2.2099008560180664, acc 0.14000000059604645\n",
      "Epoch 7, iter 70, loss 2.2957100868225098, acc 0.10999999940395355\n",
      "Epoch 7, iter 71, loss 2.270190715789795, acc 0.1599999964237213\n",
      "Epoch 7, iter 72, loss 2.3270435333251953, acc 0.07999999821186066\n",
      "Epoch 7, iter 73, loss 2.250108480453491, acc 0.14000000059604645\n",
      "Epoch 7, iter 74, loss 2.215653896331787, acc 0.15000000596046448\n",
      "Epoch 7, iter 75, loss 2.2755157947540283, acc 0.14000000059604645\n",
      "Epoch 7, iter 76, loss 2.258146286010742, acc 0.1599999964237213\n",
      "Epoch 7, iter 77, loss 2.2740731239318848, acc 0.11999999731779099\n",
      "Epoch 7, iter 78, loss 2.260054588317871, acc 0.15000000596046448\n",
      "Epoch 7, iter 79, loss 2.267873525619507, acc 0.11999999731779099\n",
      "Epoch 7, iter 80, loss 2.267934799194336, acc 0.1899999976158142\n",
      "Epoch 7, iter 81, loss 2.215492010116577, acc 0.2199999988079071\n",
      "Epoch 7, iter 82, loss 2.2298855781555176, acc 0.15000000596046448\n",
      "Epoch 7, iter 83, loss 2.264388084411621, acc 0.10999999940395355\n",
      "Epoch 7, iter 84, loss 2.2234511375427246, acc 0.17000000178813934\n",
      "Epoch 7, iter 85, loss 2.2546298503875732, acc 0.10000000149011612\n",
      "Epoch 7, iter 86, loss 2.1880266666412354, acc 0.18000000715255737\n",
      "Epoch 7, iter 87, loss 2.19307279586792, acc 0.14000000059604645\n",
      "Epoch 7, iter 88, loss 2.2367196083068848, acc 0.10999999940395355\n",
      "Epoch 7, iter 89, loss 2.2527880668640137, acc 0.14000000059604645\n",
      "Epoch 7, iter 90, loss 2.2721920013427734, acc 0.17000000178813934\n",
      "Epoch 7, iter 91, loss 2.2445709705352783, acc 0.12999999523162842\n",
      "Epoch 7, iter 92, loss 2.200882911682129, acc 0.20999999344348907\n",
      "Epoch 7, iter 93, loss 2.247361660003662, acc 0.07999999821186066\n",
      "Epoch 7, iter 94, loss 2.2413744926452637, acc 0.17000000178813934\n",
      "Epoch 7, iter 95, loss 2.27034068107605, acc 0.17000000178813934\n",
      "Epoch 7, iter 96, loss 2.2546591758728027, acc 0.12999999523162842\n",
      "Epoch 7, iter 97, loss 2.2986202239990234, acc 0.10000000149011612\n",
      "Epoch 7, iter 98, loss 2.2993407249450684, acc 0.07999999821186066\n",
      "Epoch 7, iter 99, loss 2.194370985031128, acc 0.14000000059604645\n",
      "Epoch 7, iter 100, loss 2.297651767730713, acc 0.1599999964237213\n",
      "Epoch 7, iter 101, loss 2.3025286197662354, acc 0.15000000596046448\n",
      "Epoch 7, iter 102, loss 2.2591214179992676, acc 0.11999999731779099\n",
      "Epoch 7, iter 103, loss 2.2867681980133057, acc 0.10000000149011612\n",
      "Epoch 7, iter 104, loss 2.229438543319702, acc 0.1599999964237213\n",
      "Epoch 7, iter 105, loss 2.239260196685791, acc 0.1599999964237213\n",
      "Epoch 7, iter 106, loss 2.236855983734131, acc 0.1599999964237213\n",
      "Epoch 7, iter 107, loss 2.2051055431365967, acc 0.1599999964237213\n",
      "Epoch 7, iter 108, loss 2.2106592655181885, acc 0.14000000059604645\n",
      "Epoch 7, iter 109, loss 2.2753641605377197, acc 0.15000000596046448\n",
      "Epoch 7, iter 110, loss 2.291656494140625, acc 0.14000000059604645\n",
      "Epoch 7, iter 111, loss 2.3137946128845215, acc 0.10000000149011612\n",
      "Epoch 7, iter 112, loss 2.2720754146575928, acc 0.10000000149011612\n",
      "Epoch 7, iter 113, loss 2.214921236038208, acc 0.12999999523162842\n",
      "Epoch 7, iter 114, loss 2.30515193939209, acc 0.11999999731779099\n",
      "Epoch 7, iter 115, loss 2.2031688690185547, acc 0.18000000715255737\n",
      "Epoch 7, iter 116, loss 2.258747100830078, acc 0.05999999865889549\n",
      "Epoch 7, iter 117, loss 2.2563135623931885, acc 0.12999999523162842\n",
      "Epoch 7, iter 118, loss 2.2893495559692383, acc 0.09000000357627869\n",
      "Epoch 7, iter 119, loss 2.209815263748169, acc 0.20000000298023224\n",
      "Epoch 7, iter 120, loss 2.2339670658111572, acc 0.1599999964237213\n",
      "Epoch 7, iter 121, loss 2.215595245361328, acc 0.15000000596046448\n",
      "Epoch 7, iter 122, loss 2.262377977371216, acc 0.10000000149011612\n",
      "Epoch 7, iter 123, loss 2.2549991607666016, acc 0.14000000059604645\n",
      "Epoch 7, iter 124, loss 2.276789903640747, acc 0.14000000059604645\n",
      "Epoch 7, iter 125, loss 2.2312042713165283, acc 0.17000000178813934\n",
      "Epoch 7, iter 126, loss 2.2959985733032227, acc 0.07000000029802322\n",
      "Epoch 7, iter 127, loss 2.2462916374206543, acc 0.11999999731779099\n",
      "Epoch 7, iter 128, loss 2.233671188354492, acc 0.1899999976158142\n",
      "Epoch 7, iter 129, loss 2.263368844985962, acc 0.14000000059604645\n",
      "Epoch 7, iter 130, loss 2.286806344985962, acc 0.09000000357627869\n",
      "Epoch 7, iter 131, loss 2.260882616043091, acc 0.12999999523162842\n",
      "Epoch 7, iter 132, loss 2.2483603954315186, acc 0.17000000178813934\n",
      "Epoch 7, iter 133, loss 2.245175361633301, acc 0.15000000596046448\n",
      "Epoch 7, iter 134, loss 2.2409472465515137, acc 0.12999999523162842\n",
      "Epoch 7, iter 135, loss 2.3120951652526855, acc 0.10000000149011612\n",
      "Epoch 7, iter 136, loss 2.2270021438598633, acc 0.1599999964237213\n",
      "Epoch 7, iter 137, loss 2.2507243156433105, acc 0.15000000596046448\n",
      "Epoch 7, iter 138, loss 2.1973111629486084, acc 0.17000000178813934\n",
      "Epoch 7, iter 139, loss 2.2385683059692383, acc 0.14000000059604645\n",
      "Epoch 7, iter 140, loss 2.2329018115997314, acc 0.12999999523162842\n",
      "Epoch 7, iter 141, loss 2.2568349838256836, acc 0.15000000596046448\n",
      "Epoch 7, iter 142, loss 2.345688581466675, acc 0.14000000059604645\n",
      "Epoch 7, iter 143, loss 2.1785459518432617, acc 0.1599999964237213\n",
      "Epoch 7, iter 144, loss 2.276045560836792, acc 0.14000000059604645\n",
      "Epoch 7, iter 145, loss 2.2461905479431152, acc 0.10999999940395355\n",
      "Epoch 7, iter 146, loss 2.2398977279663086, acc 0.15000000596046448\n",
      "Epoch 7, iter 147, loss 2.2890093326568604, acc 0.10000000149011612\n",
      "Epoch 7, iter 148, loss 2.31645131111145, acc 0.07000000029802322\n",
      "Epoch 7, iter 149, loss 2.277188777923584, acc 0.10000000149011612\n",
      "Epoch 7, iter 150, loss 2.239799737930298, acc 0.15000000596046448\n",
      "Epoch 7, iter 151, loss 2.277843475341797, acc 0.03999999910593033\n",
      "Epoch 7, iter 152, loss 2.3056235313415527, acc 0.05999999865889549\n",
      "Epoch 7, iter 153, loss 2.2566497325897217, acc 0.12999999523162842\n",
      "Epoch 7, iter 154, loss 2.242952585220337, acc 0.12999999523162842\n",
      "Epoch 7, iter 155, loss 2.2531681060791016, acc 0.11999999731779099\n",
      "Epoch 7, iter 156, loss 2.2360024452209473, acc 0.11999999731779099\n",
      "Epoch 7, iter 157, loss 2.3000717163085938, acc 0.17000000178813934\n",
      "Epoch 7, iter 158, loss 2.257145643234253, acc 0.14000000059604645\n",
      "Epoch 7, iter 159, loss 2.296278476715088, acc 0.07999999821186066\n",
      "Epoch 7, iter 160, loss 2.249194860458374, acc 0.1599999964237213\n",
      "Epoch 7, iter 161, loss 2.202812910079956, acc 0.18000000715255737\n",
      "Epoch 7, iter 162, loss 2.244006395339966, acc 0.10999999940395355\n",
      "Epoch 7, iter 163, loss 2.25223970413208, acc 0.10999999940395355\n",
      "Epoch 7, iter 164, loss 2.2853782176971436, acc 0.12999999523162842\n",
      "Epoch 7, iter 165, loss 2.233792304992676, acc 0.12999999523162842\n",
      "Epoch 7, iter 166, loss 2.2102184295654297, acc 0.2199999988079071\n",
      "Epoch 7, iter 167, loss 2.2413599491119385, acc 0.14000000059604645\n",
      "Epoch 7, iter 168, loss 2.3040456771850586, acc 0.12999999523162842\n",
      "Epoch 7, iter 169, loss 2.2909505367279053, acc 0.09000000357627869\n",
      "Epoch 7, iter 170, loss 2.3152456283569336, acc 0.09000000357627869\n",
      "Epoch 7, iter 171, loss 2.2173235416412354, acc 0.12999999523162842\n",
      "Epoch 7, iter 172, loss 2.279557704925537, acc 0.14000000059604645\n",
      "Epoch 7, iter 173, loss 2.2923085689544678, acc 0.10000000149011612\n",
      "Epoch 7, iter 174, loss 2.2566988468170166, acc 0.10000000149011612\n",
      "Epoch 7, iter 175, loss 2.212623357772827, acc 0.15000000596046448\n",
      "Epoch 7, iter 176, loss 2.299135684967041, acc 0.12999999523162842\n",
      "Epoch 7, iter 177, loss 2.265834093093872, acc 0.10999999940395355\n",
      "Epoch 7, iter 178, loss 2.2537689208984375, acc 0.09000000357627869\n",
      "Epoch 7, iter 179, loss 2.2411272525787354, acc 0.14000000059604645\n",
      "Epoch 7, iter 180, loss 2.2074668407440186, acc 0.1599999964237213\n",
      "Epoch 7, iter 181, loss 2.188424587249756, acc 0.12999999523162842\n",
      "Epoch 7, iter 182, loss 2.2064096927642822, acc 0.17000000178813934\n",
      "Epoch 7, iter 183, loss 2.2223825454711914, acc 0.10000000149011612\n",
      "Epoch 7, iter 184, loss 2.280740737915039, acc 0.11999999731779099\n",
      "Epoch 7, iter 185, loss 2.257413864135742, acc 0.1599999964237213\n",
      "Epoch 7, iter 186, loss 2.2592875957489014, acc 0.15000000596046448\n",
      "Epoch 7, iter 187, loss 2.2053935527801514, acc 0.1599999964237213\n",
      "Epoch 7, iter 188, loss 2.265120267868042, acc 0.10000000149011612\n",
      "Epoch 7, iter 189, loss 2.291415214538574, acc 0.17000000178813934\n",
      "Epoch 7, iter 190, loss 2.1997792720794678, acc 0.15000000596046448\n",
      "Epoch 7, iter 191, loss 2.2461435794830322, acc 0.11999999731779099\n",
      "Epoch 7, iter 192, loss 2.272547483444214, acc 0.11999999731779099\n",
      "Epoch 7, iter 193, loss 2.285413980484009, acc 0.1599999964237213\n",
      "Epoch 7, iter 194, loss 2.20969295501709, acc 0.18000000715255737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 195, loss 2.224217653274536, acc 0.18000000715255737\n",
      "Epoch 7, iter 196, loss 2.234705686569214, acc 0.1899999976158142\n",
      "Epoch 7, iter 197, loss 2.2357077598571777, acc 0.17000000178813934\n",
      "Epoch 7, iter 198, loss 2.249824285507202, acc 0.11999999731779099\n",
      "Epoch 7, iter 199, loss 2.2777037620544434, acc 0.17000000178813934\n",
      "Epoch 7, iter 200, loss 2.286104679107666, acc 0.17000000178813934\n",
      "Epoch 7, iter 201, loss 2.2674765586853027, acc 0.11999999731779099\n",
      "Epoch 7, iter 202, loss 2.2214136123657227, acc 0.14000000059604645\n",
      "Epoch 7, iter 203, loss 2.245736598968506, acc 0.09000000357627869\n",
      "Epoch 7, iter 204, loss 2.2480878829956055, acc 0.12999999523162842\n",
      "Epoch 7, iter 205, loss 2.271852493286133, acc 0.09000000357627869\n",
      "Epoch 7, iter 206, loss 2.246371269226074, acc 0.1899999976158142\n",
      "Epoch 7, iter 207, loss 2.320695400238037, acc 0.09000000357627869\n",
      "Epoch 7, iter 208, loss 2.293930768966675, acc 0.15000000596046448\n",
      "Epoch 7, iter 209, loss 2.261353015899658, acc 0.1599999964237213\n",
      "Epoch 7, iter 210, loss 2.229975700378418, acc 0.17000000178813934\n",
      "Epoch 7, iter 211, loss 2.2956666946411133, acc 0.12999999523162842\n",
      "Epoch 7, iter 212, loss 2.2589781284332275, acc 0.23000000417232513\n",
      "Epoch 7, iter 213, loss 2.187786340713501, acc 0.1599999964237213\n",
      "Epoch 7, iter 214, loss 2.2894344329833984, acc 0.10000000149011612\n",
      "Epoch 7, iter 215, loss 2.300645351409912, acc 0.10999999940395355\n",
      "Epoch 7, iter 216, loss 2.2428908348083496, acc 0.14000000059604645\n",
      "Epoch 7, iter 217, loss 2.237255573272705, acc 0.11999999731779099\n",
      "Epoch 7, iter 218, loss 2.3080825805664062, acc 0.15000000596046448\n",
      "Epoch 7, iter 219, loss 2.213153600692749, acc 0.12999999523162842\n",
      "Epoch 7, iter 220, loss 2.3229923248291016, acc 0.10999999940395355\n",
      "Epoch 7, iter 221, loss 2.221773147583008, acc 0.10999999940395355\n",
      "Epoch 7, iter 222, loss 2.2260913848876953, acc 0.10000000149011612\n",
      "Epoch 7, iter 223, loss 2.1635196208953857, acc 0.1899999976158142\n",
      "Epoch 7, iter 224, loss 2.2399353981018066, acc 0.11999999731779099\n",
      "Epoch 7, iter 225, loss 2.299393653869629, acc 0.09000000357627869\n",
      "Epoch 7, iter 226, loss 2.2257659435272217, acc 0.12999999523162842\n",
      "Epoch 7, iter 227, loss 2.2756540775299072, acc 0.14000000059604645\n",
      "Epoch 7, iter 228, loss 2.1917946338653564, acc 0.23000000417232513\n",
      "Epoch 7, iter 229, loss 2.2721800804138184, acc 0.12999999523162842\n",
      "Epoch 7, iter 230, loss 2.2893991470336914, acc 0.10999999940395355\n",
      "Epoch 7, iter 231, loss 2.245781183242798, acc 0.14000000059604645\n",
      "Epoch 7, iter 232, loss 2.3166379928588867, acc 0.12999999523162842\n",
      "Epoch 7, iter 233, loss 2.2209150791168213, acc 0.12999999523162842\n",
      "Epoch 7, iter 234, loss 2.205427646636963, acc 0.1599999964237213\n",
      "Epoch 7, iter 235, loss 2.20957088470459, acc 0.1599999964237213\n",
      "Epoch 7, iter 236, loss 2.256199359893799, acc 0.11999999731779099\n",
      "Epoch 7, iter 237, loss 2.26275897026062, acc 0.15000000596046448\n",
      "Epoch 7, iter 238, loss 2.202869176864624, acc 0.1599999964237213\n",
      "Epoch 7, iter 239, loss 2.240999221801758, acc 0.12999999523162842\n",
      "Epoch 7, iter 240, loss 2.3140206336975098, acc 0.10000000149011612\n",
      "Epoch 7, iter 241, loss 2.2968764305114746, acc 0.09000000357627869\n",
      "Epoch 7, iter 242, loss 2.2306854724884033, acc 0.1899999976158142\n",
      "Epoch 7, iter 243, loss 2.228107213973999, acc 0.18000000715255737\n",
      "Epoch 7, iter 244, loss 2.2609405517578125, acc 0.09000000357627869\n",
      "Epoch 7, iter 245, loss 2.207984209060669, acc 0.09000000357627869\n",
      "Epoch 7, iter 246, loss 2.2730135917663574, acc 0.10000000149011612\n",
      "Epoch 7, iter 247, loss 2.2011966705322266, acc 0.15000000596046448\n",
      "Epoch 7, iter 248, loss 2.226808547973633, acc 0.14000000059604645\n",
      "Epoch 7, iter 249, loss 2.2570650577545166, acc 0.18000000715255737\n",
      "Epoch 7, iter 250, loss 2.166886806488037, acc 0.15000000596046448\n",
      "Epoch 7, iter 251, loss 2.2477545738220215, acc 0.1599999964237213\n",
      "Epoch 7, iter 252, loss 2.1731488704681396, acc 0.17000000178813934\n",
      "Epoch 7, iter 253, loss 2.326218605041504, acc 0.15000000596046448\n",
      "Epoch 7, iter 254, loss 2.2704873085021973, acc 0.15000000596046448\n",
      "Epoch 7, iter 255, loss 2.3088083267211914, acc 0.10000000149011612\n",
      "Epoch 7, iter 256, loss 2.2905800342559814, acc 0.11999999731779099\n",
      "Epoch 7, iter 257, loss 2.2745463848114014, acc 0.1599999964237213\n",
      "Epoch 7, iter 258, loss 2.1872949600219727, acc 0.18000000715255737\n",
      "Epoch 7, iter 259, loss 2.186221122741699, acc 0.1899999976158142\n",
      "Epoch 7, iter 260, loss 2.2622714042663574, acc 0.12999999523162842\n",
      "Epoch 7, iter 261, loss 2.2288196086883545, acc 0.12999999523162842\n",
      "Epoch 7, iter 262, loss 2.257438898086548, acc 0.11999999731779099\n",
      "Epoch 7, iter 263, loss 2.241304397583008, acc 0.14000000059604645\n",
      "Epoch 7, iter 264, loss 2.2312426567077637, acc 0.11999999731779099\n",
      "Epoch 7, iter 265, loss 2.29025936126709, acc 0.15000000596046448\n",
      "Epoch 7, iter 266, loss 2.227335214614868, acc 0.14000000059604645\n",
      "Epoch 7, iter 267, loss 2.23191499710083, acc 0.23000000417232513\n",
      "Epoch 7, iter 268, loss 2.272709608078003, acc 0.18000000715255737\n",
      "Epoch 7, iter 269, loss 2.2258670330047607, acc 0.12999999523162842\n",
      "Epoch 7, iter 270, loss 2.2487070560455322, acc 0.11999999731779099\n",
      "Epoch 7, iter 271, loss 2.2631945610046387, acc 0.1899999976158142\n",
      "Epoch 7, iter 272, loss 2.245651960372925, acc 0.15000000596046448\n",
      "Epoch 7, iter 273, loss 2.251932144165039, acc 0.1599999964237213\n",
      "Epoch 7, iter 274, loss 2.190978527069092, acc 0.18000000715255737\n",
      "Epoch 7, iter 275, loss 2.2546467781066895, acc 0.17000000178813934\n",
      "Epoch 7, iter 276, loss 2.296271562576294, acc 0.15000000596046448\n",
      "Epoch 7, iter 277, loss 2.24849796295166, acc 0.12999999523162842\n",
      "Epoch 7, iter 278, loss 2.218991279602051, acc 0.15000000596046448\n",
      "Epoch 7, iter 279, loss 2.2395358085632324, acc 0.09000000357627869\n",
      "Epoch 7, iter 280, loss 2.221421718597412, acc 0.17000000178813934\n",
      "Epoch 7, iter 281, loss 2.2259740829467773, acc 0.11999999731779099\n",
      "Epoch 7, iter 282, loss 2.282210350036621, acc 0.1599999964237213\n",
      "Epoch 7, iter 283, loss 2.242889642715454, acc 0.10999999940395355\n",
      "Epoch 7, iter 284, loss 2.2876691818237305, acc 0.10999999940395355\n",
      "Epoch 7, iter 285, loss 2.2384631633758545, acc 0.09000000357627869\n",
      "Epoch 7, iter 286, loss 2.2332282066345215, acc 0.14000000059604645\n",
      "Epoch 7, iter 287, loss 2.2598867416381836, acc 0.1599999964237213\n",
      "Epoch 7, iter 288, loss 2.2630035877227783, acc 0.09000000357627869\n",
      "Epoch 7, iter 289, loss 2.201730251312256, acc 0.17000000178813934\n",
      "Epoch 7, iter 290, loss 2.2713584899902344, acc 0.10999999940395355\n",
      "Epoch 7, iter 291, loss 2.2337725162506104, acc 0.15000000596046448\n",
      "Epoch 7, iter 292, loss 2.2553257942199707, acc 0.12999999523162842\n",
      "Epoch 7, iter 293, loss 2.2175745964050293, acc 0.11999999731779099\n",
      "Epoch 7, iter 294, loss 2.28157901763916, acc 0.1599999964237213\n",
      "Epoch 7, iter 295, loss 2.2454891204833984, acc 0.1599999964237213\n",
      "Epoch 7, iter 296, loss 2.268847703933716, acc 0.11999999731779099\n",
      "Epoch 7, iter 297, loss 2.294276237487793, acc 0.14000000059604645\n",
      "Epoch 7, iter 298, loss 2.2505600452423096, acc 0.17000000178813934\n",
      "Epoch 7, iter 299, loss 2.303529977798462, acc 0.1599999964237213\n",
      "Epoch 7, iter 300, loss 2.224198341369629, acc 0.14000000059604645\n",
      "Epoch 7, iter 301, loss 2.2689249515533447, acc 0.09000000357627869\n",
      "Epoch 7, iter 302, loss 2.2315549850463867, acc 0.1899999976158142\n",
      "Epoch 7, iter 303, loss 2.2528445720672607, acc 0.15000000596046448\n",
      "Epoch 7, iter 304, loss 2.3000006675720215, acc 0.12999999523162842\n",
      "Epoch 7, iter 305, loss 2.2166898250579834, acc 0.1599999964237213\n",
      "Epoch 7, iter 306, loss 2.2530934810638428, acc 0.14000000059604645\n",
      "Epoch 7, iter 307, loss 2.2067043781280518, acc 0.1599999964237213\n",
      "Epoch 7, iter 308, loss 2.2379586696624756, acc 0.20000000298023224\n",
      "Epoch 7, iter 309, loss 2.257269859313965, acc 0.11999999731779099\n",
      "Epoch 7, iter 310, loss 2.289045572280884, acc 0.05999999865889549\n",
      "Epoch 7, iter 311, loss 2.2445449829101562, acc 0.18000000715255737\n",
      "Epoch 7, iter 312, loss 2.2735729217529297, acc 0.09000000357627869\n",
      "Epoch 7, iter 313, loss 2.282508134841919, acc 0.12999999523162842\n",
      "Epoch 7, iter 314, loss 2.257094621658325, acc 0.1899999976158142\n",
      "Epoch 7, iter 315, loss 2.2832283973693848, acc 0.15000000596046448\n",
      "Epoch 7, iter 316, loss 2.2420592308044434, acc 0.14000000059604645\n",
      "Epoch 7, iter 317, loss 2.2114713191986084, acc 0.18000000715255737\n",
      "Epoch 7, iter 318, loss 2.304536819458008, acc 0.07999999821186066\n",
      "Epoch 7, iter 319, loss 2.220841407775879, acc 0.10999999940395355\n",
      "Epoch 7, iter 320, loss 2.2088282108306885, acc 0.14000000059604645\n",
      "Epoch 7, iter 321, loss 2.279257297515869, acc 0.10999999940395355\n",
      "Epoch 7, iter 322, loss 2.2610623836517334, acc 0.15000000596046448\n",
      "Epoch 7, iter 323, loss 2.2883377075195312, acc 0.11999999731779099\n",
      "Epoch 7, iter 324, loss 2.1684741973876953, acc 0.14000000059604645\n",
      "Epoch 7, iter 325, loss 2.2718966007232666, acc 0.15000000596046448\n",
      "Epoch 7, iter 326, loss 2.2076942920684814, acc 0.14000000059604645\n",
      "Epoch 7, iter 327, loss 2.2668628692626953, acc 0.15000000596046448\n",
      "Epoch 7, iter 328, loss 2.3722939491271973, acc 0.09000000357627869\n",
      "Epoch 7, iter 329, loss 2.252923011779785, acc 0.10000000149011612\n",
      "Epoch 7, iter 330, loss 2.2394332885742188, acc 0.12999999523162842\n",
      "Epoch 7, iter 331, loss 2.255967140197754, acc 0.12999999523162842\n",
      "Epoch 7, iter 332, loss 2.2510149478912354, acc 0.15000000596046448\n",
      "Epoch 7, iter 333, loss 2.247079610824585, acc 0.11999999731779099\n",
      "Epoch 7, iter 334, loss 2.188204288482666, acc 0.12999999523162842\n",
      "Epoch 7, iter 335, loss 2.2223756313323975, acc 0.11999999731779099\n",
      "Epoch 7, iter 336, loss 2.243572235107422, acc 0.07000000029802322\n",
      "Epoch 7, iter 337, loss 2.220932960510254, acc 0.10999999940395355\n",
      "Epoch 7, iter 338, loss 2.2547788619995117, acc 0.09000000357627869\n",
      "Epoch 7, iter 339, loss 2.252622127532959, acc 0.14000000059604645\n",
      "Epoch 7, iter 340, loss 2.29119873046875, acc 0.11999999731779099\n",
      "Epoch 7, iter 341, loss 2.228944778442383, acc 0.10000000149011612\n",
      "Epoch 7, iter 342, loss 2.26334547996521, acc 0.10000000149011612\n",
      "Epoch 7, iter 343, loss 2.201080560684204, acc 0.17000000178813934\n",
      "Epoch 7, iter 344, loss 2.265097141265869, acc 0.10000000149011612\n",
      "Epoch 7, iter 345, loss 2.2453479766845703, acc 0.10000000149011612\n",
      "Epoch 7, iter 346, loss 2.3275067806243896, acc 0.07999999821186066\n",
      "Epoch 7, iter 347, loss 2.2778377532958984, acc 0.18000000715255737\n",
      "Epoch 7, iter 348, loss 2.2339510917663574, acc 0.14000000059604645\n",
      "Epoch 7, iter 349, loss 2.292985439300537, acc 0.09000000357627869\n",
      "Epoch 7, iter 350, loss 2.251547336578369, acc 0.12999999523162842\n",
      "Epoch 7, iter 351, loss 2.201054811477661, acc 0.1899999976158142\n",
      "Epoch 7, iter 352, loss 2.2843074798583984, acc 0.14000000059604645\n",
      "Epoch 7, iter 353, loss 2.183311700820923, acc 0.20999999344348907\n",
      "Epoch 7, iter 354, loss 2.264289140701294, acc 0.15000000596046448\n",
      "Epoch 7, iter 355, loss 2.274535894393921, acc 0.10000000149011612\n",
      "Epoch 7, iter 356, loss 2.2609081268310547, acc 0.10000000149011612\n",
      "Epoch 7, iter 357, loss 2.2319774627685547, acc 0.15000000596046448\n",
      "Epoch 7, iter 358, loss 2.2287960052490234, acc 0.1599999964237213\n",
      "Epoch 7, iter 359, loss 2.2757091522216797, acc 0.10999999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 360, loss 2.295745372772217, acc 0.10000000149011612\n",
      "Epoch 7, iter 361, loss 2.2221083641052246, acc 0.20000000298023224\n",
      "Epoch 7, iter 362, loss 2.245828628540039, acc 0.10000000149011612\n",
      "Epoch 7, iter 363, loss 2.237231492996216, acc 0.11999999731779099\n",
      "Epoch 7, iter 364, loss 2.317026138305664, acc 0.14000000059604645\n",
      "Epoch 7, iter 365, loss 2.274533271789551, acc 0.14000000059604645\n",
      "Epoch 7, iter 366, loss 2.291851758956909, acc 0.10999999940395355\n",
      "Epoch 7, iter 367, loss 2.2584142684936523, acc 0.09000000357627869\n",
      "Epoch 7, iter 368, loss 2.297563314437866, acc 0.09000000357627869\n",
      "Epoch 7, iter 369, loss 2.1949307918548584, acc 0.20000000298023224\n",
      "Epoch 7, iter 370, loss 2.2036991119384766, acc 0.14000000059604645\n",
      "Epoch 7, iter 371, loss 2.264979362487793, acc 0.11999999731779099\n",
      "Epoch 7, iter 372, loss 2.2180964946746826, acc 0.1599999964237213\n",
      "Epoch 7, iter 373, loss 2.25313401222229, acc 0.14000000059604645\n",
      "Epoch 7, iter 374, loss 2.2164690494537354, acc 0.18000000715255737\n",
      "Epoch 7, iter 375, loss 2.27398681640625, acc 0.10999999940395355\n",
      "Epoch 7, iter 376, loss 2.2013638019561768, acc 0.18000000715255737\n",
      "Epoch 7, iter 377, loss 2.2574613094329834, acc 0.15000000596046448\n",
      "Epoch 7, iter 378, loss 2.25402569770813, acc 0.15000000596046448\n",
      "Epoch 7, iter 379, loss 2.327326774597168, acc 0.10000000149011612\n",
      "Epoch 7, iter 380, loss 2.213270664215088, acc 0.10000000149011612\n",
      "Epoch 7, iter 381, loss 2.284925699234009, acc 0.07000000029802322\n",
      "Epoch 7, iter 382, loss 2.2650656700134277, acc 0.11999999731779099\n",
      "Epoch 7, iter 383, loss 2.2460579872131348, acc 0.10999999940395355\n",
      "Epoch 7, iter 384, loss 2.251404047012329, acc 0.17000000178813934\n",
      "Epoch 7, iter 385, loss 2.225679874420166, acc 0.11999999731779099\n",
      "Epoch 7, iter 386, loss 2.2474822998046875, acc 0.09000000357627869\n",
      "Epoch 7, iter 387, loss 2.2708353996276855, acc 0.11999999731779099\n",
      "Epoch 7, iter 388, loss 2.2573418617248535, acc 0.15000000596046448\n",
      "Epoch 7, iter 389, loss 2.251868486404419, acc 0.18000000715255737\n",
      "Epoch 7, iter 390, loss 2.2650270462036133, acc 0.15000000596046448\n",
      "Epoch 7, iter 391, loss 2.2225937843322754, acc 0.17000000178813934\n",
      "Epoch 7, iter 392, loss 2.2543647289276123, acc 0.14000000059604645\n",
      "Epoch 7, iter 393, loss 2.2772769927978516, acc 0.15000000596046448\n",
      "Epoch 7, iter 394, loss 2.273477554321289, acc 0.11999999731779099\n",
      "Epoch 7, iter 395, loss 2.2444238662719727, acc 0.11999999731779099\n",
      "Epoch 7, iter 396, loss 2.270004987716675, acc 0.10999999940395355\n",
      "Epoch 7, iter 397, loss 2.315147638320923, acc 0.10999999940395355\n",
      "Epoch 7, iter 398, loss 2.2409987449645996, acc 0.14000000059604645\n",
      "Epoch 7, iter 399, loss 2.288465738296509, acc 0.15000000596046448\n",
      "Epoch 7, iter 400, loss 2.2080087661743164, acc 0.14000000059604645\n",
      "Epoch 7, iter 401, loss 2.235468864440918, acc 0.11999999731779099\n",
      "Epoch 7, iter 402, loss 2.227477788925171, acc 0.10000000149011612\n",
      "Epoch 7, iter 403, loss 2.221513509750366, acc 0.14000000059604645\n",
      "Epoch 7, iter 404, loss 2.216756582260132, acc 0.14000000059604645\n",
      "Epoch 7, iter 405, loss 2.1975820064544678, acc 0.18000000715255737\n",
      "Epoch 7, iter 406, loss 2.274895668029785, acc 0.11999999731779099\n",
      "Epoch 7, iter 407, loss 2.285281181335449, acc 0.14000000059604645\n",
      "Epoch 7, iter 408, loss 2.190748691558838, acc 0.18000000715255737\n",
      "Epoch 7, iter 409, loss 2.265871047973633, acc 0.15000000596046448\n",
      "Epoch 7, iter 410, loss 2.2850606441497803, acc 0.15000000596046448\n",
      "Epoch 7, iter 411, loss 2.2311604022979736, acc 0.10000000149011612\n",
      "Epoch 7, iter 412, loss 2.214132308959961, acc 0.17000000178813934\n",
      "Epoch 7, iter 413, loss 2.2955591678619385, acc 0.10999999940395355\n",
      "Epoch 7, iter 414, loss 2.222882032394409, acc 0.17000000178813934\n",
      "Epoch 7, iter 415, loss 2.2041282653808594, acc 0.1899999976158142\n",
      "Epoch 7, iter 416, loss 2.2017998695373535, acc 0.17000000178813934\n",
      "Epoch 7, iter 417, loss 2.283750534057617, acc 0.11999999731779099\n",
      "Epoch 7, iter 418, loss 2.282158851623535, acc 0.10000000149011612\n",
      "Epoch 7, iter 419, loss 2.2247214317321777, acc 0.10999999940395355\n",
      "Epoch 7, iter 420, loss 2.1887640953063965, acc 0.18000000715255737\n",
      "Epoch 8, iter 1, loss 2.2702786922454834, acc 0.14000000059604645\n",
      "Epoch 8, iter 2, loss 2.246701240539551, acc 0.14000000059604645\n",
      "Epoch 8, iter 3, loss 2.218195915222168, acc 0.17000000178813934\n",
      "Epoch 8, iter 4, loss 2.1958816051483154, acc 0.15000000596046448\n",
      "Epoch 8, iter 5, loss 2.2099499702453613, acc 0.17000000178813934\n",
      "Epoch 8, iter 6, loss 2.2562365531921387, acc 0.15000000596046448\n",
      "Epoch 8, iter 7, loss 2.2552475929260254, acc 0.14000000059604645\n",
      "Epoch 8, iter 8, loss 2.2378463745117188, acc 0.10000000149011612\n",
      "Epoch 8, iter 9, loss 2.1996047496795654, acc 0.20999999344348907\n",
      "Epoch 8, iter 10, loss 2.175490617752075, acc 0.20000000298023224\n",
      "Epoch 8, iter 11, loss 2.207836866378784, acc 0.1899999976158142\n",
      "Epoch 8, iter 12, loss 2.208961009979248, acc 0.1599999964237213\n",
      "Epoch 8, iter 13, loss 2.220492124557495, acc 0.23999999463558197\n",
      "Epoch 8, iter 14, loss 2.297680139541626, acc 0.10000000149011612\n",
      "Epoch 8, iter 15, loss 2.239732265472412, acc 0.1899999976158142\n",
      "Epoch 8, iter 16, loss 2.255918502807617, acc 0.14000000059604645\n",
      "Epoch 8, iter 17, loss 2.184598445892334, acc 0.1599999964237213\n",
      "Epoch 8, iter 18, loss 2.246994733810425, acc 0.10999999940395355\n",
      "Epoch 8, iter 19, loss 2.177637815475464, acc 0.17000000178813934\n",
      "Epoch 8, iter 20, loss 2.1635446548461914, acc 0.20000000298023224\n",
      "Epoch 8, iter 21, loss 2.228665828704834, acc 0.10999999940395355\n",
      "Epoch 8, iter 22, loss 2.2341458797454834, acc 0.14000000059604645\n",
      "Epoch 8, iter 23, loss 2.2242980003356934, acc 0.14000000059604645\n",
      "Epoch 8, iter 24, loss 2.23337459564209, acc 0.12999999523162842\n",
      "Epoch 8, iter 25, loss 2.2587730884552, acc 0.10999999940395355\n",
      "Epoch 8, iter 26, loss 2.2621657848358154, acc 0.07999999821186066\n",
      "Epoch 8, iter 27, loss 2.2247426509857178, acc 0.15000000596046448\n",
      "Epoch 8, iter 28, loss 2.277203321456909, acc 0.10000000149011612\n",
      "Epoch 8, iter 29, loss 2.2193803787231445, acc 0.17000000178813934\n",
      "Epoch 8, iter 30, loss 2.370272159576416, acc 0.05000000074505806\n",
      "Epoch 8, iter 31, loss 2.2627291679382324, acc 0.18000000715255737\n",
      "Epoch 8, iter 32, loss 2.2470133304595947, acc 0.12999999523162842\n",
      "Epoch 8, iter 33, loss 2.2562501430511475, acc 0.11999999731779099\n",
      "Epoch 8, iter 34, loss 2.294309139251709, acc 0.10999999940395355\n",
      "Epoch 8, iter 35, loss 2.2530386447906494, acc 0.1899999976158142\n",
      "Epoch 8, iter 36, loss 2.235356092453003, acc 0.17000000178813934\n",
      "Epoch 8, iter 37, loss 2.278596878051758, acc 0.11999999731779099\n",
      "Epoch 8, iter 38, loss 2.227370500564575, acc 0.15000000596046448\n",
      "Epoch 8, iter 39, loss 2.208801746368408, acc 0.15000000596046448\n",
      "Epoch 8, iter 40, loss 2.280672073364258, acc 0.11999999731779099\n",
      "Epoch 8, iter 41, loss 2.284351110458374, acc 0.14000000059604645\n",
      "Epoch 8, iter 42, loss 2.207501173019409, acc 0.1599999964237213\n",
      "Epoch 8, iter 43, loss 2.2220115661621094, acc 0.14000000059604645\n",
      "Epoch 8, iter 44, loss 2.217963457107544, acc 0.1899999976158142\n",
      "Epoch 8, iter 45, loss 2.261164665222168, acc 0.10999999940395355\n",
      "Epoch 8, iter 46, loss 2.2835543155670166, acc 0.11999999731779099\n",
      "Epoch 8, iter 47, loss 2.247891664505005, acc 0.12999999523162842\n",
      "Epoch 8, iter 48, loss 2.2722134590148926, acc 0.10999999940395355\n",
      "Epoch 8, iter 49, loss 2.2791287899017334, acc 0.11999999731779099\n",
      "Epoch 8, iter 50, loss 2.2343955039978027, acc 0.15000000596046448\n",
      "Epoch 8, iter 51, loss 2.240398406982422, acc 0.1599999964237213\n",
      "Epoch 8, iter 52, loss 2.2560999393463135, acc 0.12999999523162842\n",
      "Epoch 8, iter 53, loss 2.297149181365967, acc 0.14000000059604645\n",
      "Epoch 8, iter 54, loss 2.1893136501312256, acc 0.18000000715255737\n",
      "Epoch 8, iter 55, loss 2.2316999435424805, acc 0.1599999964237213\n",
      "Epoch 8, iter 56, loss 2.215583562850952, acc 0.14000000059604645\n",
      "Epoch 8, iter 57, loss 2.195066452026367, acc 0.1599999964237213\n",
      "Epoch 8, iter 58, loss 2.2558507919311523, acc 0.10999999940395355\n",
      "Epoch 8, iter 59, loss 2.3041038513183594, acc 0.10000000149011612\n",
      "Epoch 8, iter 60, loss 2.2647998332977295, acc 0.10000000149011612\n",
      "Epoch 8, iter 61, loss 2.1963579654693604, acc 0.14000000059604645\n",
      "Epoch 8, iter 62, loss 2.2193117141723633, acc 0.18000000715255737\n",
      "Epoch 8, iter 63, loss 2.2330498695373535, acc 0.1599999964237213\n",
      "Epoch 8, iter 64, loss 2.1900413036346436, acc 0.10999999940395355\n",
      "Epoch 8, iter 65, loss 2.2185442447662354, acc 0.10999999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 66, loss 2.2317934036254883, acc 0.12999999523162842\n",
      "Epoch 8, iter 67, loss 2.2660884857177734, acc 0.12999999523162842\n",
      "Epoch 8, iter 68, loss 2.2238030433654785, acc 0.11999999731779099\n",
      "Epoch 8, iter 69, loss 2.1930627822875977, acc 0.12999999523162842\n",
      "Epoch 8, iter 70, loss 2.2758240699768066, acc 0.11999999731779099\n",
      "Epoch 8, iter 71, loss 2.2552642822265625, acc 0.1599999964237213\n",
      "Epoch 8, iter 72, loss 2.2961204051971436, acc 0.07999999821186066\n",
      "Epoch 8, iter 73, loss 2.238607883453369, acc 0.15000000596046448\n",
      "Epoch 8, iter 74, loss 2.1945862770080566, acc 0.14000000059604645\n",
      "Epoch 8, iter 75, loss 2.278005838394165, acc 0.14000000059604645\n",
      "Epoch 8, iter 76, loss 2.2495954036712646, acc 0.17000000178813934\n",
      "Epoch 8, iter 77, loss 2.2651045322418213, acc 0.11999999731779099\n",
      "Epoch 8, iter 78, loss 2.2422218322753906, acc 0.15000000596046448\n",
      "Epoch 8, iter 79, loss 2.2400128841400146, acc 0.12999999523162842\n",
      "Epoch 8, iter 80, loss 2.2494394779205322, acc 0.20000000298023224\n",
      "Epoch 8, iter 81, loss 2.205230236053467, acc 0.2199999988079071\n",
      "Epoch 8, iter 82, loss 2.211045980453491, acc 0.15000000596046448\n",
      "Epoch 8, iter 83, loss 2.242114305496216, acc 0.10999999940395355\n",
      "Epoch 8, iter 84, loss 2.20756459236145, acc 0.17000000178813934\n",
      "Epoch 8, iter 85, loss 2.2382493019104004, acc 0.10000000149011612\n",
      "Epoch 8, iter 86, loss 2.1806066036224365, acc 0.1899999976158142\n",
      "Epoch 8, iter 87, loss 2.180335283279419, acc 0.14000000059604645\n",
      "Epoch 8, iter 88, loss 2.2196640968322754, acc 0.11999999731779099\n",
      "Epoch 8, iter 89, loss 2.2405593395233154, acc 0.14000000059604645\n",
      "Epoch 8, iter 90, loss 2.2505693435668945, acc 0.1599999964237213\n",
      "Epoch 8, iter 91, loss 2.223623275756836, acc 0.12999999523162842\n",
      "Epoch 8, iter 92, loss 2.192671537399292, acc 0.20000000298023224\n",
      "Epoch 8, iter 93, loss 2.248828649520874, acc 0.07999999821186066\n",
      "Epoch 8, iter 94, loss 2.2363834381103516, acc 0.17000000178813934\n",
      "Epoch 8, iter 95, loss 2.238661289215088, acc 0.18000000715255737\n",
      "Epoch 8, iter 96, loss 2.242327928543091, acc 0.12999999523162842\n",
      "Epoch 8, iter 97, loss 2.2826650142669678, acc 0.10000000149011612\n",
      "Epoch 8, iter 98, loss 2.2675669193267822, acc 0.10000000149011612\n",
      "Epoch 8, iter 99, loss 2.2006442546844482, acc 0.12999999523162842\n",
      "Epoch 8, iter 100, loss 2.270974636077881, acc 0.15000000596046448\n",
      "Epoch 8, iter 101, loss 2.285583257675171, acc 0.14000000059604645\n",
      "Epoch 8, iter 102, loss 2.243921995162964, acc 0.11999999731779099\n",
      "Epoch 8, iter 103, loss 2.2728312015533447, acc 0.10000000149011612\n",
      "Epoch 8, iter 104, loss 2.215324640274048, acc 0.1599999964237213\n",
      "Epoch 8, iter 105, loss 2.2244672775268555, acc 0.1599999964237213\n",
      "Epoch 8, iter 106, loss 2.2268073558807373, acc 0.1599999964237213\n",
      "Epoch 8, iter 107, loss 2.1917314529418945, acc 0.1599999964237213\n",
      "Epoch 8, iter 108, loss 2.1966705322265625, acc 0.14000000059604645\n",
      "Epoch 8, iter 109, loss 2.268019676208496, acc 0.15000000596046448\n",
      "Epoch 8, iter 110, loss 2.2801620960235596, acc 0.14000000059604645\n",
      "Epoch 8, iter 111, loss 2.287691354751587, acc 0.10999999940395355\n",
      "Epoch 8, iter 112, loss 2.2598867416381836, acc 0.10000000149011612\n",
      "Epoch 8, iter 113, loss 2.1793503761291504, acc 0.14000000059604645\n",
      "Epoch 8, iter 114, loss 2.282005786895752, acc 0.12999999523162842\n",
      "Epoch 8, iter 115, loss 2.1881237030029297, acc 0.18000000715255737\n",
      "Epoch 8, iter 116, loss 2.2454090118408203, acc 0.05999999865889549\n",
      "Epoch 8, iter 117, loss 2.2261013984680176, acc 0.11999999731779099\n",
      "Epoch 8, iter 118, loss 2.2699193954467773, acc 0.09000000357627869\n",
      "Epoch 8, iter 119, loss 2.1927449703216553, acc 0.20000000298023224\n",
      "Epoch 8, iter 120, loss 2.2184746265411377, acc 0.15000000596046448\n",
      "Epoch 8, iter 121, loss 2.2070696353912354, acc 0.15000000596046448\n",
      "Epoch 8, iter 122, loss 2.2474019527435303, acc 0.10000000149011612\n",
      "Epoch 8, iter 123, loss 2.2387688159942627, acc 0.12999999523162842\n",
      "Epoch 8, iter 124, loss 2.2629477977752686, acc 0.12999999523162842\n",
      "Epoch 8, iter 125, loss 2.2068538665771484, acc 0.17000000178813934\n",
      "Epoch 8, iter 126, loss 2.2781496047973633, acc 0.07999999821186066\n",
      "Epoch 8, iter 127, loss 2.233071804046631, acc 0.11999999731779099\n",
      "Epoch 8, iter 128, loss 2.2232437133789062, acc 0.18000000715255737\n",
      "Epoch 8, iter 129, loss 2.2415637969970703, acc 0.14000000059604645\n",
      "Epoch 8, iter 130, loss 2.271618604660034, acc 0.09000000357627869\n",
      "Epoch 8, iter 131, loss 2.2348666191101074, acc 0.12999999523162842\n",
      "Epoch 8, iter 132, loss 2.236222267150879, acc 0.17000000178813934\n",
      "Epoch 8, iter 133, loss 2.2244231700897217, acc 0.15000000596046448\n",
      "Epoch 8, iter 134, loss 2.216618776321411, acc 0.12999999523162842\n",
      "Epoch 8, iter 135, loss 2.3072028160095215, acc 0.10000000149011612\n",
      "Epoch 8, iter 136, loss 2.197538375854492, acc 0.1599999964237213\n",
      "Epoch 8, iter 137, loss 2.239889144897461, acc 0.15000000596046448\n",
      "Epoch 8, iter 138, loss 2.184007167816162, acc 0.17000000178813934\n",
      "Epoch 8, iter 139, loss 2.2171030044555664, acc 0.14000000059604645\n",
      "Epoch 8, iter 140, loss 2.209109306335449, acc 0.14000000059604645\n",
      "Epoch 8, iter 141, loss 2.2418100833892822, acc 0.15000000596046448\n",
      "Epoch 8, iter 142, loss 2.3309946060180664, acc 0.14000000059604645\n",
      "Epoch 8, iter 143, loss 2.1613550186157227, acc 0.1599999964237213\n",
      "Epoch 8, iter 144, loss 2.255035161972046, acc 0.12999999523162842\n",
      "Epoch 8, iter 145, loss 2.2111597061157227, acc 0.10000000149011612\n",
      "Epoch 8, iter 146, loss 2.2235312461853027, acc 0.15000000596046448\n",
      "Epoch 8, iter 147, loss 2.2598607540130615, acc 0.10999999940395355\n",
      "Epoch 8, iter 148, loss 2.308818817138672, acc 0.07000000029802322\n",
      "Epoch 8, iter 149, loss 2.2500312328338623, acc 0.10000000149011612\n",
      "Epoch 8, iter 150, loss 2.226423978805542, acc 0.15000000596046448\n",
      "Epoch 8, iter 151, loss 2.2618439197540283, acc 0.03999999910593033\n",
      "Epoch 8, iter 152, loss 2.2932543754577637, acc 0.05999999865889549\n",
      "Epoch 8, iter 153, loss 2.225046396255493, acc 0.14000000059604645\n",
      "Epoch 8, iter 154, loss 2.2333147525787354, acc 0.12999999523162842\n",
      "Epoch 8, iter 155, loss 2.2374587059020996, acc 0.11999999731779099\n",
      "Epoch 8, iter 156, loss 2.2133021354675293, acc 0.12999999523162842\n",
      "Epoch 8, iter 157, loss 2.2883079051971436, acc 0.17000000178813934\n",
      "Epoch 8, iter 158, loss 2.237205743789673, acc 0.14000000059604645\n",
      "Epoch 8, iter 159, loss 2.269686222076416, acc 0.09000000357627869\n",
      "Epoch 8, iter 160, loss 2.2437736988067627, acc 0.15000000596046448\n",
      "Epoch 8, iter 161, loss 2.175262689590454, acc 0.1899999976158142\n",
      "Epoch 8, iter 162, loss 2.239793300628662, acc 0.10999999940395355\n",
      "Epoch 8, iter 163, loss 2.2383124828338623, acc 0.10999999940395355\n",
      "Epoch 8, iter 164, loss 2.2698519229888916, acc 0.12999999523162842\n",
      "Epoch 8, iter 165, loss 2.2520875930786133, acc 0.12999999523162842\n",
      "Epoch 8, iter 166, loss 2.21022629737854, acc 0.20000000298023224\n",
      "Epoch 8, iter 167, loss 2.2069661617279053, acc 0.14000000059604645\n",
      "Epoch 8, iter 168, loss 2.288058280944824, acc 0.12999999523162842\n",
      "Epoch 8, iter 169, loss 2.2653183937072754, acc 0.09000000357627869\n",
      "Epoch 8, iter 170, loss 2.2946722507476807, acc 0.09000000357627869\n",
      "Epoch 8, iter 171, loss 2.198188543319702, acc 0.12999999523162842\n",
      "Epoch 8, iter 172, loss 2.2679555416107178, acc 0.12999999523162842\n",
      "Epoch 8, iter 173, loss 2.287594795227051, acc 0.10000000149011612\n",
      "Epoch 8, iter 174, loss 2.2262094020843506, acc 0.10999999940395355\n",
      "Epoch 8, iter 175, loss 2.2292373180389404, acc 0.14000000059604645\n",
      "Epoch 8, iter 176, loss 2.2832231521606445, acc 0.12999999523162842\n",
      "Epoch 8, iter 177, loss 2.2523245811462402, acc 0.10999999940395355\n",
      "Epoch 8, iter 178, loss 2.228553533554077, acc 0.09000000357627869\n",
      "Epoch 8, iter 179, loss 2.212803602218628, acc 0.15000000596046448\n",
      "Epoch 8, iter 180, loss 2.183201313018799, acc 0.17000000178813934\n",
      "Epoch 8, iter 181, loss 2.175424575805664, acc 0.12999999523162842\n",
      "Epoch 8, iter 182, loss 2.1897835731506348, acc 0.17000000178813934\n",
      "Epoch 8, iter 183, loss 2.2144734859466553, acc 0.09000000357627869\n",
      "Epoch 8, iter 184, loss 2.27660870552063, acc 0.11999999731779099\n",
      "Epoch 8, iter 185, loss 2.246004581451416, acc 0.1599999964237213\n",
      "Epoch 8, iter 186, loss 2.2501261234283447, acc 0.14000000059604645\n",
      "Epoch 8, iter 187, loss 2.1876654624938965, acc 0.15000000596046448\n",
      "Epoch 8, iter 188, loss 2.2510745525360107, acc 0.10000000149011612\n",
      "Epoch 8, iter 189, loss 2.265883445739746, acc 0.18000000715255737\n",
      "Epoch 8, iter 190, loss 2.207932233810425, acc 0.14000000059604645\n",
      "Epoch 8, iter 191, loss 2.2359561920166016, acc 0.12999999523162842\n",
      "Epoch 8, iter 192, loss 2.247621774673462, acc 0.11999999731779099\n",
      "Epoch 8, iter 193, loss 2.2549266815185547, acc 0.15000000596046448\n",
      "Epoch 8, iter 194, loss 2.197488784790039, acc 0.17000000178813934\n",
      "Epoch 8, iter 195, loss 2.208878755569458, acc 0.18000000715255737\n",
      "Epoch 8, iter 196, loss 2.2124483585357666, acc 0.1899999976158142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 197, loss 2.1979103088378906, acc 0.1899999976158142\n",
      "Epoch 8, iter 198, loss 2.2267730236053467, acc 0.11999999731779099\n",
      "Epoch 8, iter 199, loss 2.261683702468872, acc 0.17000000178813934\n",
      "Epoch 8, iter 200, loss 2.2596852779388428, acc 0.1599999964237213\n",
      "Epoch 8, iter 201, loss 2.2522053718566895, acc 0.11999999731779099\n",
      "Epoch 8, iter 202, loss 2.2066380977630615, acc 0.14000000059604645\n",
      "Epoch 8, iter 203, loss 2.2315661907196045, acc 0.09000000357627869\n",
      "Epoch 8, iter 204, loss 2.256462812423706, acc 0.11999999731779099\n",
      "Epoch 8, iter 205, loss 2.256272315979004, acc 0.09000000357627869\n",
      "Epoch 8, iter 206, loss 2.209573745727539, acc 0.20000000298023224\n",
      "Epoch 8, iter 207, loss 2.2976622581481934, acc 0.10000000149011612\n",
      "Epoch 8, iter 208, loss 2.279933214187622, acc 0.15000000596046448\n",
      "Epoch 8, iter 209, loss 2.251288414001465, acc 0.1599999964237213\n",
      "Epoch 8, iter 210, loss 2.2120516300201416, acc 0.18000000715255737\n",
      "Epoch 8, iter 211, loss 2.268658399581909, acc 0.12999999523162842\n",
      "Epoch 8, iter 212, loss 2.2492775917053223, acc 0.23000000417232513\n",
      "Epoch 8, iter 213, loss 2.167064905166626, acc 0.17000000178813934\n",
      "Epoch 8, iter 214, loss 2.2814483642578125, acc 0.07999999821186066\n",
      "Epoch 8, iter 215, loss 2.261009931564331, acc 0.10999999940395355\n",
      "Epoch 8, iter 216, loss 2.263399600982666, acc 0.10999999940395355\n",
      "Epoch 8, iter 217, loss 2.173860549926758, acc 0.17000000178813934\n",
      "Epoch 8, iter 218, loss 2.328226089477539, acc 0.11999999731779099\n",
      "Epoch 8, iter 219, loss 2.212019205093384, acc 0.12999999523162842\n",
      "Epoch 8, iter 220, loss 2.2818715572357178, acc 0.11999999731779099\n",
      "Epoch 8, iter 221, loss 2.2162575721740723, acc 0.10000000149011612\n",
      "Epoch 8, iter 222, loss 2.2408483028411865, acc 0.07999999821186066\n",
      "Epoch 8, iter 223, loss 2.157365560531616, acc 0.1899999976158142\n",
      "Epoch 8, iter 224, loss 2.235722541809082, acc 0.10000000149011612\n",
      "Epoch 8, iter 225, loss 2.266716957092285, acc 0.09000000357627869\n",
      "Epoch 8, iter 226, loss 2.182140827178955, acc 0.1599999964237213\n",
      "Epoch 8, iter 227, loss 2.2377538681030273, acc 0.14000000059604645\n",
      "Epoch 8, iter 228, loss 2.1834044456481934, acc 0.23000000417232513\n",
      "Epoch 8, iter 229, loss 2.2547855377197266, acc 0.12999999523162842\n",
      "Epoch 8, iter 230, loss 2.2498767375946045, acc 0.14000000059604645\n",
      "Epoch 8, iter 231, loss 2.2218973636627197, acc 0.12999999523162842\n",
      "Epoch 8, iter 232, loss 2.3072831630706787, acc 0.10999999940395355\n",
      "Epoch 8, iter 233, loss 2.2076799869537354, acc 0.12999999523162842\n",
      "Epoch 8, iter 234, loss 2.195659637451172, acc 0.14000000059604645\n",
      "Epoch 8, iter 235, loss 2.209710121154785, acc 0.14000000059604645\n",
      "Epoch 8, iter 236, loss 2.2421669960021973, acc 0.11999999731779099\n",
      "Epoch 8, iter 237, loss 2.2544970512390137, acc 0.15000000596046448\n",
      "Epoch 8, iter 238, loss 2.188901901245117, acc 0.1599999964237213\n",
      "Epoch 8, iter 239, loss 2.2100629806518555, acc 0.14000000059604645\n",
      "Epoch 8, iter 240, loss 2.288576364517212, acc 0.10000000149011612\n",
      "Epoch 8, iter 241, loss 2.2771923542022705, acc 0.07999999821186066\n",
      "Epoch 8, iter 242, loss 2.209838390350342, acc 0.18000000715255737\n",
      "Epoch 8, iter 243, loss 2.2136192321777344, acc 0.17000000178813934\n",
      "Epoch 8, iter 244, loss 2.247652292251587, acc 0.09000000357627869\n",
      "Epoch 8, iter 245, loss 2.1752443313598633, acc 0.09000000357627869\n",
      "Epoch 8, iter 246, loss 2.243438959121704, acc 0.10000000149011612\n",
      "Epoch 8, iter 247, loss 2.1922121047973633, acc 0.15000000596046448\n",
      "Epoch 8, iter 248, loss 2.2090158462524414, acc 0.14000000059604645\n",
      "Epoch 8, iter 249, loss 2.241286039352417, acc 0.1899999976158142\n",
      "Epoch 8, iter 250, loss 2.1469883918762207, acc 0.14000000059604645\n",
      "Epoch 8, iter 251, loss 2.229952812194824, acc 0.15000000596046448\n",
      "Epoch 8, iter 252, loss 2.157733678817749, acc 0.18000000715255737\n",
      "Epoch 8, iter 253, loss 2.321868658065796, acc 0.14000000059604645\n",
      "Epoch 8, iter 254, loss 2.2486648559570312, acc 0.1599999964237213\n",
      "Epoch 8, iter 255, loss 2.289675712585449, acc 0.10000000149011612\n",
      "Epoch 8, iter 256, loss 2.280683755874634, acc 0.11999999731779099\n",
      "Epoch 8, iter 257, loss 2.2750983238220215, acc 0.1599999964237213\n",
      "Epoch 8, iter 258, loss 2.1657497882843018, acc 0.18000000715255737\n",
      "Epoch 8, iter 259, loss 2.17189884185791, acc 0.17000000178813934\n",
      "Epoch 8, iter 260, loss 2.2270469665527344, acc 0.14000000059604645\n",
      "Epoch 8, iter 261, loss 2.2094345092773438, acc 0.12999999523162842\n",
      "Epoch 8, iter 262, loss 2.237515926361084, acc 0.11999999731779099\n",
      "Epoch 8, iter 263, loss 2.2251029014587402, acc 0.14000000059604645\n",
      "Epoch 8, iter 264, loss 2.2149152755737305, acc 0.11999999731779099\n",
      "Epoch 8, iter 265, loss 2.25868821144104, acc 0.17000000178813934\n",
      "Epoch 8, iter 266, loss 2.206742763519287, acc 0.14000000059604645\n",
      "Epoch 8, iter 267, loss 2.2238996028900146, acc 0.23000000417232513\n",
      "Epoch 8, iter 268, loss 2.2541136741638184, acc 0.18000000715255737\n",
      "Epoch 8, iter 269, loss 2.203199863433838, acc 0.12999999523162842\n",
      "Epoch 8, iter 270, loss 2.242892265319824, acc 0.11999999731779099\n",
      "Epoch 8, iter 271, loss 2.2373251914978027, acc 0.20000000298023224\n",
      "Epoch 8, iter 272, loss 2.2338130474090576, acc 0.15000000596046448\n",
      "Epoch 8, iter 273, loss 2.2268426418304443, acc 0.17000000178813934\n",
      "Epoch 8, iter 274, loss 2.178833484649658, acc 0.18000000715255737\n",
      "Epoch 8, iter 275, loss 2.237887382507324, acc 0.17000000178813934\n",
      "Epoch 8, iter 276, loss 2.297981023788452, acc 0.14000000059604645\n",
      "Epoch 8, iter 277, loss 2.2212607860565186, acc 0.12999999523162842\n",
      "Epoch 8, iter 278, loss 2.2031099796295166, acc 0.1599999964237213\n",
      "Epoch 8, iter 279, loss 2.2172272205352783, acc 0.09000000357627869\n",
      "Epoch 8, iter 280, loss 2.2150216102600098, acc 0.1599999964237213\n",
      "Epoch 8, iter 281, loss 2.1982853412628174, acc 0.12999999523162842\n",
      "Epoch 8, iter 282, loss 2.2655680179595947, acc 0.15000000596046448\n",
      "Epoch 8, iter 283, loss 2.2094924449920654, acc 0.11999999731779099\n",
      "Epoch 8, iter 284, loss 2.273092031478882, acc 0.10999999940395355\n",
      "Epoch 8, iter 285, loss 2.228672742843628, acc 0.09000000357627869\n",
      "Epoch 8, iter 286, loss 2.237344264984131, acc 0.11999999731779099\n",
      "Epoch 8, iter 287, loss 2.253755807876587, acc 0.1599999964237213\n",
      "Epoch 8, iter 288, loss 2.262195348739624, acc 0.09000000357627869\n",
      "Epoch 8, iter 289, loss 2.1797876358032227, acc 0.17000000178813934\n",
      "Epoch 8, iter 290, loss 2.269415855407715, acc 0.10000000149011612\n",
      "Epoch 8, iter 291, loss 2.2230546474456787, acc 0.15000000596046448\n",
      "Epoch 8, iter 292, loss 2.2275731563568115, acc 0.14000000059604645\n",
      "Epoch 8, iter 293, loss 2.2078638076782227, acc 0.11999999731779099\n",
      "Epoch 8, iter 294, loss 2.2559947967529297, acc 0.1599999964237213\n",
      "Epoch 8, iter 295, loss 2.236419439315796, acc 0.1599999964237213\n",
      "Epoch 8, iter 296, loss 2.2566304206848145, acc 0.10999999940395355\n",
      "Epoch 8, iter 297, loss 2.297081470489502, acc 0.12999999523162842\n",
      "Epoch 8, iter 298, loss 2.226414680480957, acc 0.1599999964237213\n",
      "Epoch 8, iter 299, loss 2.280362129211426, acc 0.17000000178813934\n",
      "Epoch 8, iter 300, loss 2.226868152618408, acc 0.10999999940395355\n",
      "Epoch 8, iter 301, loss 2.2533011436462402, acc 0.09000000357627869\n",
      "Epoch 8, iter 302, loss 2.229200839996338, acc 0.1899999976158142\n",
      "Epoch 8, iter 303, loss 2.239868402481079, acc 0.15000000596046448\n",
      "Epoch 8, iter 304, loss 2.268066167831421, acc 0.12999999523162842\n",
      "Epoch 8, iter 305, loss 2.2030653953552246, acc 0.1599999964237213\n",
      "Epoch 8, iter 306, loss 2.2446954250335693, acc 0.14000000059604645\n",
      "Epoch 8, iter 307, loss 2.2061429023742676, acc 0.15000000596046448\n",
      "Epoch 8, iter 308, loss 2.2207229137420654, acc 0.20999999344348907\n",
      "Epoch 8, iter 309, loss 2.2479915618896484, acc 0.11999999731779099\n",
      "Epoch 8, iter 310, loss 2.2710518836975098, acc 0.07000000029802322\n",
      "Epoch 8, iter 311, loss 2.2295045852661133, acc 0.18000000715255737\n",
      "Epoch 8, iter 312, loss 2.2449958324432373, acc 0.10000000149011612\n",
      "Epoch 8, iter 313, loss 2.263424873352051, acc 0.12999999523162842\n",
      "Epoch 8, iter 314, loss 2.248082399368286, acc 0.1899999976158142\n",
      "Epoch 8, iter 315, loss 2.2657346725463867, acc 0.15000000596046448\n",
      "Epoch 8, iter 316, loss 2.2148141860961914, acc 0.14000000059604645\n",
      "Epoch 8, iter 317, loss 2.1932289600372314, acc 0.18000000715255737\n",
      "Epoch 8, iter 318, loss 2.2882239818573, acc 0.07999999821186066\n",
      "Epoch 8, iter 319, loss 2.2062597274780273, acc 0.11999999731779099\n",
      "Epoch 8, iter 320, loss 2.185206651687622, acc 0.14000000059604645\n",
      "Epoch 8, iter 321, loss 2.2812063694000244, acc 0.10000000149011612\n",
      "Epoch 8, iter 322, loss 2.2506215572357178, acc 0.1599999964237213\n",
      "Epoch 8, iter 323, loss 2.2756714820861816, acc 0.11999999731779099\n",
      "Epoch 8, iter 324, loss 2.138500452041626, acc 0.1599999964237213\n",
      "Epoch 8, iter 325, loss 2.2618017196655273, acc 0.14000000059604645\n",
      "Epoch 8, iter 326, loss 2.2082245349884033, acc 0.15000000596046448\n",
      "Epoch 8, iter 327, loss 2.2605605125427246, acc 0.15000000596046448\n",
      "Epoch 8, iter 328, loss 2.3553197383880615, acc 0.09000000357627869\n",
      "Epoch 8, iter 329, loss 2.2350614070892334, acc 0.10000000149011612\n",
      "Epoch 8, iter 330, loss 2.226890802383423, acc 0.11999999731779099\n",
      "Epoch 8, iter 331, loss 2.2405855655670166, acc 0.12999999523162842\n",
      "Epoch 8, iter 332, loss 2.239198684692383, acc 0.15000000596046448\n",
      "Epoch 8, iter 333, loss 2.225217342376709, acc 0.10999999940395355\n",
      "Epoch 8, iter 334, loss 2.1659462451934814, acc 0.12999999523162842\n",
      "Epoch 8, iter 335, loss 2.211108922958374, acc 0.11999999731779099\n",
      "Epoch 8, iter 336, loss 2.2281699180603027, acc 0.07000000029802322\n",
      "Epoch 8, iter 337, loss 2.2033698558807373, acc 0.10999999940395355\n",
      "Epoch 8, iter 338, loss 2.2399351596832275, acc 0.09000000357627869\n",
      "Epoch 8, iter 339, loss 2.2464725971221924, acc 0.15000000596046448\n",
      "Epoch 8, iter 340, loss 2.2649059295654297, acc 0.11999999731779099\n",
      "Epoch 8, iter 341, loss 2.223078727722168, acc 0.10000000149011612\n",
      "Epoch 8, iter 342, loss 2.2416467666625977, acc 0.10999999940395355\n",
      "Epoch 8, iter 343, loss 2.18926739692688, acc 0.17000000178813934\n",
      "Epoch 8, iter 344, loss 2.260986566543579, acc 0.07999999821186066\n",
      "Epoch 8, iter 345, loss 2.2388193607330322, acc 0.09000000357627869\n",
      "Epoch 8, iter 346, loss 2.311789035797119, acc 0.07999999821186066\n",
      "Epoch 8, iter 347, loss 2.2672629356384277, acc 0.18000000715255737\n",
      "Epoch 8, iter 348, loss 2.1939711570739746, acc 0.14000000059604645\n",
      "Epoch 8, iter 349, loss 2.2751104831695557, acc 0.09000000357627869\n",
      "Epoch 8, iter 350, loss 2.258112668991089, acc 0.11999999731779099\n",
      "Epoch 8, iter 351, loss 2.1976773738861084, acc 0.1899999976158142\n",
      "Epoch 8, iter 352, loss 2.262512445449829, acc 0.14000000059604645\n",
      "Epoch 8, iter 353, loss 2.156188488006592, acc 0.2199999988079071\n",
      "Epoch 8, iter 354, loss 2.235027551651001, acc 0.15000000596046448\n",
      "Epoch 8, iter 355, loss 2.2544350624084473, acc 0.10000000149011612\n",
      "Epoch 8, iter 356, loss 2.2537310123443604, acc 0.10000000149011612\n",
      "Epoch 8, iter 357, loss 2.231550693511963, acc 0.15000000596046448\n",
      "Epoch 8, iter 358, loss 2.208982467651367, acc 0.1599999964237213\n",
      "Epoch 8, iter 359, loss 2.2615790367126465, acc 0.12999999523162842\n",
      "Epoch 8, iter 360, loss 2.269012689590454, acc 0.10999999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 361, loss 2.2089877128601074, acc 0.20999999344348907\n",
      "Epoch 8, iter 362, loss 2.238166332244873, acc 0.10000000149011612\n",
      "Epoch 8, iter 363, loss 2.223954200744629, acc 0.11999999731779099\n",
      "Epoch 8, iter 364, loss 2.3078362941741943, acc 0.14000000059604645\n",
      "Epoch 8, iter 365, loss 2.27428936958313, acc 0.14000000059604645\n",
      "Epoch 8, iter 366, loss 2.2728371620178223, acc 0.10999999940395355\n",
      "Epoch 8, iter 367, loss 2.2523114681243896, acc 0.09000000357627869\n",
      "Epoch 8, iter 368, loss 2.284158706665039, acc 0.09000000357627869\n",
      "Epoch 8, iter 369, loss 2.1754257678985596, acc 0.20000000298023224\n",
      "Epoch 8, iter 370, loss 2.193302869796753, acc 0.12999999523162842\n",
      "Epoch 8, iter 371, loss 2.2446327209472656, acc 0.10999999940395355\n",
      "Epoch 8, iter 372, loss 2.204369306564331, acc 0.1599999964237213\n",
      "Epoch 8, iter 373, loss 2.235804796218872, acc 0.14000000059604645\n",
      "Epoch 8, iter 374, loss 2.2094075679779053, acc 0.20000000298023224\n",
      "Epoch 8, iter 375, loss 2.2531237602233887, acc 0.10999999940395355\n",
      "Epoch 8, iter 376, loss 2.184359550476074, acc 0.18000000715255737\n",
      "Epoch 8, iter 377, loss 2.24495005607605, acc 0.15000000596046448\n",
      "Epoch 8, iter 378, loss 2.2413039207458496, acc 0.15000000596046448\n",
      "Epoch 8, iter 379, loss 2.316037178039551, acc 0.10000000149011612\n",
      "Epoch 8, iter 380, loss 2.1841962337493896, acc 0.10000000149011612\n",
      "Epoch 8, iter 381, loss 2.2838335037231445, acc 0.05999999865889549\n",
      "Epoch 8, iter 382, loss 2.261046886444092, acc 0.10999999940395355\n",
      "Epoch 8, iter 383, loss 2.246466636657715, acc 0.10999999940395355\n",
      "Epoch 8, iter 384, loss 2.234229803085327, acc 0.18000000715255737\n",
      "Epoch 8, iter 385, loss 2.204801559448242, acc 0.11999999731779099\n",
      "Epoch 8, iter 386, loss 2.224726676940918, acc 0.07999999821186066\n",
      "Epoch 8, iter 387, loss 2.2595362663269043, acc 0.10999999940395355\n",
      "Epoch 8, iter 388, loss 2.2354576587677, acc 0.15000000596046448\n",
      "Epoch 8, iter 389, loss 2.23209285736084, acc 0.1899999976158142\n",
      "Epoch 8, iter 390, loss 2.2603440284729004, acc 0.15000000596046448\n",
      "Epoch 8, iter 391, loss 2.201813220977783, acc 0.18000000715255737\n",
      "Epoch 8, iter 392, loss 2.23477840423584, acc 0.14000000059604645\n",
      "Epoch 8, iter 393, loss 2.2647385597229004, acc 0.1599999964237213\n",
      "Epoch 8, iter 394, loss 2.2535221576690674, acc 0.11999999731779099\n",
      "Epoch 8, iter 395, loss 2.218799114227295, acc 0.12999999523162842\n",
      "Epoch 8, iter 396, loss 2.256376266479492, acc 0.10999999940395355\n",
      "Epoch 8, iter 397, loss 2.2933523654937744, acc 0.10999999940395355\n",
      "Epoch 8, iter 398, loss 2.229860782623291, acc 0.14000000059604645\n",
      "Epoch 8, iter 399, loss 2.280893564224243, acc 0.14000000059604645\n",
      "Epoch 8, iter 400, loss 2.1969900131225586, acc 0.14000000059604645\n",
      "Epoch 8, iter 401, loss 2.221088171005249, acc 0.11999999731779099\n",
      "Epoch 8, iter 402, loss 2.212395429611206, acc 0.10000000149011612\n",
      "Epoch 8, iter 403, loss 2.2082016468048096, acc 0.14000000059604645\n",
      "Epoch 8, iter 404, loss 2.206822633743286, acc 0.15000000596046448\n",
      "Epoch 8, iter 405, loss 2.1933279037475586, acc 0.17000000178813934\n",
      "Epoch 8, iter 406, loss 2.2704007625579834, acc 0.10999999940395355\n",
      "Epoch 8, iter 407, loss 2.2640037536621094, acc 0.15000000596046448\n",
      "Epoch 8, iter 408, loss 2.174039840698242, acc 0.18000000715255737\n",
      "Epoch 8, iter 409, loss 2.254211187362671, acc 0.14000000059604645\n",
      "Epoch 8, iter 410, loss 2.269630193710327, acc 0.15000000596046448\n",
      "Epoch 8, iter 411, loss 2.217109441757202, acc 0.09000000357627869\n",
      "Epoch 8, iter 412, loss 2.1998848915100098, acc 0.17000000178813934\n",
      "Epoch 8, iter 413, loss 2.276406764984131, acc 0.10000000149011612\n",
      "Epoch 8, iter 414, loss 2.2083699703216553, acc 0.17000000178813934\n",
      "Epoch 8, iter 415, loss 2.187417507171631, acc 0.1899999976158142\n",
      "Epoch 8, iter 416, loss 2.215806007385254, acc 0.14000000059604645\n",
      "Epoch 8, iter 417, loss 2.269765853881836, acc 0.10999999940395355\n",
      "Epoch 8, iter 418, loss 2.270200729370117, acc 0.10000000149011612\n",
      "Epoch 8, iter 419, loss 2.211840867996216, acc 0.12999999523162842\n",
      "Epoch 8, iter 420, loss 2.166316270828247, acc 0.18000000715255737\n",
      "Epoch 9, iter 1, loss 2.254966974258423, acc 0.15000000596046448\n",
      "Epoch 9, iter 2, loss 2.237783432006836, acc 0.12999999523162842\n",
      "Epoch 9, iter 3, loss 2.215519666671753, acc 0.17000000178813934\n",
      "Epoch 9, iter 4, loss 2.183079957962036, acc 0.1599999964237213\n",
      "Epoch 9, iter 5, loss 2.19486927986145, acc 0.17000000178813934\n",
      "Epoch 9, iter 6, loss 2.242086172103882, acc 0.15000000596046448\n",
      "Epoch 9, iter 7, loss 2.2327933311462402, acc 0.14000000059604645\n",
      "Epoch 9, iter 8, loss 2.222416877746582, acc 0.10999999940395355\n",
      "Epoch 9, iter 9, loss 2.1908059120178223, acc 0.20999999344348907\n",
      "Epoch 9, iter 10, loss 2.1554112434387207, acc 0.20000000298023224\n",
      "Epoch 9, iter 11, loss 2.184075355529785, acc 0.20000000298023224\n",
      "Epoch 9, iter 12, loss 2.209481954574585, acc 0.15000000596046448\n",
      "Epoch 9, iter 13, loss 2.219153642654419, acc 0.23000000417232513\n",
      "Epoch 9, iter 14, loss 2.2708945274353027, acc 0.10999999940395355\n",
      "Epoch 9, iter 15, loss 2.2203595638275146, acc 0.1899999976158142\n",
      "Epoch 9, iter 16, loss 2.2393665313720703, acc 0.14000000059604645\n",
      "Epoch 9, iter 17, loss 2.164048194885254, acc 0.1599999964237213\n",
      "Epoch 9, iter 18, loss 2.218677043914795, acc 0.11999999731779099\n",
      "Epoch 9, iter 19, loss 2.1417672634124756, acc 0.18000000715255737\n",
      "Epoch 9, iter 20, loss 2.1688432693481445, acc 0.18000000715255737\n",
      "Epoch 9, iter 21, loss 2.2009119987487793, acc 0.10999999940395355\n",
      "Epoch 9, iter 22, loss 2.225094795227051, acc 0.15000000596046448\n",
      "Epoch 9, iter 23, loss 2.223029613494873, acc 0.12999999523162842\n",
      "Epoch 9, iter 24, loss 2.227060556411743, acc 0.12999999523162842\n",
      "Epoch 9, iter 25, loss 2.2689104080200195, acc 0.10999999940395355\n",
      "Epoch 9, iter 26, loss 2.226827621459961, acc 0.09000000357627869\n",
      "Epoch 9, iter 27, loss 2.201464891433716, acc 0.15000000596046448\n",
      "Epoch 9, iter 28, loss 2.2594971656799316, acc 0.10000000149011612\n",
      "Epoch 9, iter 29, loss 2.2054286003112793, acc 0.17000000178813934\n",
      "Epoch 9, iter 30, loss 2.3405771255493164, acc 0.05999999865889549\n",
      "Epoch 9, iter 31, loss 2.247488498687744, acc 0.18000000715255737\n",
      "Epoch 9, iter 32, loss 2.224121332168579, acc 0.14000000059604645\n",
      "Epoch 9, iter 33, loss 2.246716022491455, acc 0.11999999731779099\n",
      "Epoch 9, iter 34, loss 2.2790606021881104, acc 0.11999999731779099\n",
      "Epoch 9, iter 35, loss 2.2286505699157715, acc 0.1899999976158142\n",
      "Epoch 9, iter 36, loss 2.239034652709961, acc 0.17000000178813934\n",
      "Epoch 9, iter 37, loss 2.268315315246582, acc 0.11999999731779099\n",
      "Epoch 9, iter 38, loss 2.221877098083496, acc 0.15000000596046448\n",
      "Epoch 9, iter 39, loss 2.189116954803467, acc 0.15000000596046448\n",
      "Epoch 9, iter 40, loss 2.278083562850952, acc 0.11999999731779099\n",
      "Epoch 9, iter 41, loss 2.278247594833374, acc 0.12999999523162842\n",
      "Epoch 9, iter 42, loss 2.191819667816162, acc 0.17000000178813934\n",
      "Epoch 9, iter 43, loss 2.1930415630340576, acc 0.14000000059604645\n",
      "Epoch 9, iter 44, loss 2.208902359008789, acc 0.1899999976158142\n",
      "Epoch 9, iter 45, loss 2.247248888015747, acc 0.10999999940395355\n",
      "Epoch 9, iter 46, loss 2.2684550285339355, acc 0.12999999523162842\n",
      "Epoch 9, iter 47, loss 2.2365968227386475, acc 0.12999999523162842\n",
      "Epoch 9, iter 48, loss 2.2650718688964844, acc 0.10999999940395355\n",
      "Epoch 9, iter 49, loss 2.2659032344818115, acc 0.11999999731779099\n",
      "Epoch 9, iter 50, loss 2.214226484298706, acc 0.1599999964237213\n",
      "Epoch 9, iter 51, loss 2.2242112159729004, acc 0.1599999964237213\n",
      "Epoch 9, iter 52, loss 2.2229464054107666, acc 0.12999999523162842\n",
      "Epoch 9, iter 53, loss 2.282254219055176, acc 0.14000000059604645\n",
      "Epoch 9, iter 54, loss 2.174515724182129, acc 0.18000000715255737\n",
      "Epoch 9, iter 55, loss 2.223022222518921, acc 0.17000000178813934\n",
      "Epoch 9, iter 56, loss 2.2099075317382812, acc 0.12999999523162842\n",
      "Epoch 9, iter 57, loss 2.1845476627349854, acc 0.1599999964237213\n",
      "Epoch 9, iter 58, loss 2.2401726245880127, acc 0.10999999940395355\n",
      "Epoch 9, iter 59, loss 2.2900173664093018, acc 0.10000000149011612\n",
      "Epoch 9, iter 60, loss 2.2391161918640137, acc 0.10999999940395355\n",
      "Epoch 9, iter 61, loss 2.167334794998169, acc 0.15000000596046448\n",
      "Epoch 9, iter 62, loss 2.192373037338257, acc 0.18000000715255737\n",
      "Epoch 9, iter 63, loss 2.2136049270629883, acc 0.1599999964237213\n",
      "Epoch 9, iter 64, loss 2.1746370792388916, acc 0.11999999731779099\n",
      "Epoch 9, iter 65, loss 2.199869155883789, acc 0.10999999940395355\n",
      "Epoch 9, iter 66, loss 2.221233606338501, acc 0.12999999523162842\n",
      "Epoch 9, iter 67, loss 2.252190589904785, acc 0.12999999523162842\n",
      "Epoch 9, iter 68, loss 2.21704363822937, acc 0.11999999731779099\n",
      "Epoch 9, iter 69, loss 2.1761367321014404, acc 0.14000000059604645\n",
      "Epoch 9, iter 70, loss 2.256906032562256, acc 0.11999999731779099\n",
      "Epoch 9, iter 71, loss 2.241708278656006, acc 0.1599999964237213\n",
      "Epoch 9, iter 72, loss 2.2598001956939697, acc 0.09000000357627869\n",
      "Epoch 9, iter 73, loss 2.2254230976104736, acc 0.15000000596046448\n",
      "Epoch 9, iter 74, loss 2.184699773788452, acc 0.14000000059604645\n",
      "Epoch 9, iter 75, loss 2.259589195251465, acc 0.14000000059604645\n",
      "Epoch 9, iter 76, loss 2.2366037368774414, acc 0.17000000178813934\n",
      "Epoch 9, iter 77, loss 2.251020908355713, acc 0.11999999731779099\n",
      "Epoch 9, iter 78, loss 2.231527328491211, acc 0.15000000596046448\n",
      "Epoch 9, iter 79, loss 2.2400832176208496, acc 0.11999999731779099\n",
      "Epoch 9, iter 80, loss 2.2253212928771973, acc 0.1899999976158142\n",
      "Epoch 9, iter 81, loss 2.19161319732666, acc 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 82, loss 2.1933014392852783, acc 0.15000000596046448\n",
      "Epoch 9, iter 83, loss 2.249595880508423, acc 0.10000000149011612\n",
      "Epoch 9, iter 84, loss 2.193284034729004, acc 0.17000000178813934\n",
      "Epoch 9, iter 85, loss 2.2354674339294434, acc 0.10000000149011612\n",
      "Epoch 9, iter 86, loss 2.1643872261047363, acc 0.1899999976158142\n",
      "Epoch 9, iter 87, loss 2.1572983264923096, acc 0.15000000596046448\n",
      "Epoch 9, iter 88, loss 2.213644504547119, acc 0.12999999523162842\n",
      "Epoch 9, iter 89, loss 2.2233903408050537, acc 0.14000000059604645\n",
      "Epoch 9, iter 90, loss 2.2356746196746826, acc 0.1599999964237213\n",
      "Epoch 9, iter 91, loss 2.203730821609497, acc 0.12999999523162842\n",
      "Epoch 9, iter 92, loss 2.182021379470825, acc 0.20000000298023224\n",
      "Epoch 9, iter 93, loss 2.238041877746582, acc 0.07999999821186066\n",
      "Epoch 9, iter 94, loss 2.2237186431884766, acc 0.1599999964237213\n",
      "Epoch 9, iter 95, loss 2.2070066928863525, acc 0.1599999964237213\n",
      "Epoch 9, iter 96, loss 2.2332024574279785, acc 0.12999999523162842\n",
      "Epoch 9, iter 97, loss 2.264636278152466, acc 0.10000000149011612\n",
      "Epoch 9, iter 98, loss 2.2704148292541504, acc 0.09000000357627869\n",
      "Epoch 9, iter 99, loss 2.194619655609131, acc 0.12999999523162842\n",
      "Epoch 9, iter 100, loss 2.2602481842041016, acc 0.20000000298023224\n",
      "Epoch 9, iter 101, loss 2.2671093940734863, acc 0.14000000059604645\n",
      "Epoch 9, iter 102, loss 2.2361416816711426, acc 0.14000000059604645\n",
      "Epoch 9, iter 103, loss 2.2537283897399902, acc 0.14000000059604645\n",
      "Epoch 9, iter 104, loss 2.2081985473632812, acc 0.15000000596046448\n",
      "Epoch 9, iter 105, loss 2.2125463485717773, acc 0.23999999463558197\n",
      "Epoch 9, iter 106, loss 2.203875780105591, acc 0.18000000715255737\n",
      "Epoch 9, iter 107, loss 2.175342082977295, acc 0.2199999988079071\n",
      "Epoch 9, iter 108, loss 2.182851791381836, acc 0.17000000178813934\n",
      "Epoch 9, iter 109, loss 2.2653048038482666, acc 0.11999999731779099\n",
      "Epoch 9, iter 110, loss 2.2582900524139404, acc 0.1599999964237213\n",
      "Epoch 9, iter 111, loss 2.2635223865509033, acc 0.11999999731779099\n",
      "Epoch 9, iter 112, loss 2.258369207382202, acc 0.10999999940395355\n",
      "Epoch 9, iter 113, loss 2.1697821617126465, acc 0.14000000059604645\n",
      "Epoch 9, iter 114, loss 2.2762231826782227, acc 0.1599999964237213\n",
      "Epoch 9, iter 115, loss 2.1771552562713623, acc 0.17000000178813934\n",
      "Epoch 9, iter 116, loss 2.2321598529815674, acc 0.10000000149011612\n",
      "Epoch 9, iter 117, loss 2.2221038341522217, acc 0.18000000715255737\n",
      "Epoch 9, iter 118, loss 2.241515874862671, acc 0.15000000596046448\n",
      "Epoch 9, iter 119, loss 2.158935070037842, acc 0.20000000298023224\n",
      "Epoch 9, iter 120, loss 2.2044646739959717, acc 0.1899999976158142\n",
      "Epoch 9, iter 121, loss 2.1853432655334473, acc 0.10999999940395355\n",
      "Epoch 9, iter 122, loss 2.2326908111572266, acc 0.17000000178813934\n",
      "Epoch 9, iter 123, loss 2.2078351974487305, acc 0.14000000059604645\n",
      "Epoch 9, iter 124, loss 2.258962392807007, acc 0.20000000298023224\n",
      "Epoch 9, iter 125, loss 2.1970248222351074, acc 0.1599999964237213\n",
      "Epoch 9, iter 126, loss 2.267820358276367, acc 0.10999999940395355\n",
      "Epoch 9, iter 127, loss 2.2211802005767822, acc 0.11999999731779099\n",
      "Epoch 9, iter 128, loss 2.213310480117798, acc 0.1599999964237213\n",
      "Epoch 9, iter 129, loss 2.226703405380249, acc 0.1899999976158142\n",
      "Epoch 9, iter 130, loss 2.2508084774017334, acc 0.14000000059604645\n",
      "Epoch 9, iter 131, loss 2.2175192832946777, acc 0.12999999523162842\n",
      "Epoch 9, iter 132, loss 2.2255759239196777, acc 0.1599999964237213\n",
      "Epoch 9, iter 133, loss 2.2189502716064453, acc 0.20000000298023224\n",
      "Epoch 9, iter 134, loss 2.195302963256836, acc 0.17000000178813934\n",
      "Epoch 9, iter 135, loss 2.2823355197906494, acc 0.10000000149011612\n",
      "Epoch 9, iter 136, loss 2.184892416000366, acc 0.17000000178813934\n",
      "Epoch 9, iter 137, loss 2.2276463508605957, acc 0.11999999731779099\n",
      "Epoch 9, iter 138, loss 2.1700146198272705, acc 0.18000000715255737\n",
      "Epoch 9, iter 139, loss 2.2062647342681885, acc 0.12999999523162842\n",
      "Epoch 9, iter 140, loss 2.1949405670166016, acc 0.1599999964237213\n",
      "Epoch 9, iter 141, loss 2.2342944145202637, acc 0.17000000178813934\n",
      "Epoch 9, iter 142, loss 2.3070309162139893, acc 0.12999999523162842\n",
      "Epoch 9, iter 143, loss 2.1502456665039062, acc 0.1599999964237213\n",
      "Epoch 9, iter 144, loss 2.218189001083374, acc 0.1599999964237213\n",
      "Epoch 9, iter 145, loss 2.1846354007720947, acc 0.1899999976158142\n",
      "Epoch 9, iter 146, loss 2.20862078666687, acc 0.14000000059604645\n",
      "Epoch 9, iter 147, loss 2.236663818359375, acc 0.15000000596046448\n",
      "Epoch 9, iter 148, loss 2.2939631938934326, acc 0.10000000149011612\n",
      "Epoch 9, iter 149, loss 2.2312119007110596, acc 0.1599999964237213\n",
      "Epoch 9, iter 150, loss 2.2191734313964844, acc 0.10000000149011612\n",
      "Epoch 9, iter 151, loss 2.247235059738159, acc 0.17000000178813934\n",
      "Epoch 9, iter 152, loss 2.2938125133514404, acc 0.15000000596046448\n",
      "Epoch 9, iter 153, loss 2.2042975425720215, acc 0.1899999976158142\n",
      "Epoch 9, iter 154, loss 2.224337577819824, acc 0.11999999731779099\n",
      "Epoch 9, iter 155, loss 2.2280356884002686, acc 0.11999999731779099\n",
      "Epoch 9, iter 156, loss 2.203639507293701, acc 0.14000000059604645\n",
      "Epoch 9, iter 157, loss 2.2720940113067627, acc 0.14000000059604645\n",
      "Epoch 9, iter 158, loss 2.229372262954712, acc 0.1599999964237213\n",
      "Epoch 9, iter 159, loss 2.2559361457824707, acc 0.12999999523162842\n",
      "Epoch 9, iter 160, loss 2.2173235416412354, acc 0.12999999523162842\n",
      "Epoch 9, iter 161, loss 2.152188301086426, acc 0.2199999988079071\n",
      "Epoch 9, iter 162, loss 2.2229535579681396, acc 0.12999999523162842\n",
      "Epoch 9, iter 163, loss 2.2200610637664795, acc 0.1599999964237213\n",
      "Epoch 9, iter 164, loss 2.256382703781128, acc 0.10999999940395355\n",
      "Epoch 9, iter 165, loss 2.2205922603607178, acc 0.14000000059604645\n",
      "Epoch 9, iter 166, loss 2.1976020336151123, acc 0.20999999344348907\n",
      "Epoch 9, iter 167, loss 2.194213628768921, acc 0.1599999964237213\n",
      "Epoch 9, iter 168, loss 2.2767348289489746, acc 0.15000000596046448\n",
      "Epoch 9, iter 169, loss 2.2442498207092285, acc 0.11999999731779099\n",
      "Epoch 9, iter 170, loss 2.275564193725586, acc 0.11999999731779099\n",
      "Epoch 9, iter 171, loss 2.1826491355895996, acc 0.23999999463558197\n",
      "Epoch 9, iter 172, loss 2.256903648376465, acc 0.11999999731779099\n",
      "Epoch 9, iter 173, loss 2.2794618606567383, acc 0.10999999940395355\n",
      "Epoch 9, iter 174, loss 2.218554735183716, acc 0.15000000596046448\n",
      "Epoch 9, iter 175, loss 2.1947476863861084, acc 0.20999999344348907\n",
      "Epoch 9, iter 176, loss 2.2690064907073975, acc 0.11999999731779099\n",
      "Epoch 9, iter 177, loss 2.2399168014526367, acc 0.20000000298023224\n",
      "Epoch 9, iter 178, loss 2.212661027908325, acc 0.14000000059604645\n",
      "Epoch 9, iter 179, loss 2.1897106170654297, acc 0.18000000715255737\n",
      "Epoch 9, iter 180, loss 2.171062707901001, acc 0.11999999731779099\n",
      "Epoch 9, iter 181, loss 2.1629250049591064, acc 0.2199999988079071\n",
      "Epoch 9, iter 182, loss 2.1739084720611572, acc 0.17000000178813934\n",
      "Epoch 9, iter 183, loss 2.2031409740448, acc 0.12999999523162842\n",
      "Epoch 9, iter 184, loss 2.260453701019287, acc 0.14000000059604645\n",
      "Epoch 9, iter 185, loss 2.236441135406494, acc 0.11999999731779099\n",
      "Epoch 9, iter 186, loss 2.2262661457061768, acc 0.15000000596046448\n",
      "Epoch 9, iter 187, loss 2.1727399826049805, acc 0.1599999964237213\n",
      "Epoch 9, iter 188, loss 2.238952875137329, acc 0.09000000357627869\n",
      "Epoch 9, iter 189, loss 2.256891965866089, acc 0.14000000059604645\n",
      "Epoch 9, iter 190, loss 2.1783454418182373, acc 0.20000000298023224\n",
      "Epoch 9, iter 191, loss 2.2299141883850098, acc 0.12999999523162842\n",
      "Epoch 9, iter 192, loss 2.233285665512085, acc 0.15000000596046448\n",
      "Epoch 9, iter 193, loss 2.258779287338257, acc 0.11999999731779099\n",
      "Epoch 9, iter 194, loss 2.1864538192749023, acc 0.15000000596046448\n",
      "Epoch 9, iter 195, loss 2.1934754848480225, acc 0.25\n",
      "Epoch 9, iter 196, loss 2.187474489212036, acc 0.1899999976158142\n",
      "Epoch 9, iter 197, loss 2.1894633769989014, acc 0.2199999988079071\n",
      "Epoch 9, iter 198, loss 2.2124173641204834, acc 0.10999999940395355\n",
      "Epoch 9, iter 199, loss 2.2598226070404053, acc 0.10000000149011612\n",
      "Epoch 9, iter 200, loss 2.2465646266937256, acc 0.10000000149011612\n",
      "Epoch 9, iter 201, loss 2.2347333431243896, acc 0.11999999731779099\n",
      "Epoch 9, iter 202, loss 2.194103956222534, acc 0.12999999523162842\n",
      "Epoch 9, iter 203, loss 2.216076612472534, acc 0.12999999523162842\n",
      "Epoch 9, iter 204, loss 2.213155746459961, acc 0.2199999988079071\n",
      "Epoch 9, iter 205, loss 2.2454495429992676, acc 0.17000000178813934\n",
      "Epoch 9, iter 206, loss 2.2106988430023193, acc 0.15000000596046448\n",
      "Epoch 9, iter 207, loss 2.2874863147735596, acc 0.1599999964237213\n",
      "Epoch 9, iter 208, loss 2.2709739208221436, acc 0.1599999964237213\n",
      "Epoch 9, iter 209, loss 2.236422061920166, acc 0.14000000059604645\n",
      "Epoch 9, iter 210, loss 2.2037999629974365, acc 0.15000000596046448\n",
      "Epoch 9, iter 211, loss 2.2626638412475586, acc 0.1599999964237213\n",
      "Epoch 9, iter 212, loss 2.2377610206604004, acc 0.20999999344348907\n",
      "Epoch 9, iter 213, loss 2.1550893783569336, acc 0.20999999344348907\n",
      "Epoch 9, iter 214, loss 2.2719788551330566, acc 0.10000000149011612\n",
      "Epoch 9, iter 215, loss 2.2485098838806152, acc 0.14000000059604645\n",
      "Epoch 9, iter 216, loss 2.2517216205596924, acc 0.12999999523162842\n",
      "Epoch 9, iter 217, loss 2.159327507019043, acc 0.1899999976158142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 218, loss 2.3278446197509766, acc 0.09000000357627869\n",
      "Epoch 9, iter 219, loss 2.2006189823150635, acc 0.17000000178813934\n",
      "Epoch 9, iter 220, loss 2.262097120285034, acc 0.1899999976158142\n",
      "Epoch 9, iter 221, loss 2.2050256729125977, acc 0.18000000715255737\n",
      "Epoch 9, iter 222, loss 2.218829870223999, acc 0.10999999940395355\n",
      "Epoch 9, iter 223, loss 2.139516830444336, acc 0.25999999046325684\n",
      "Epoch 9, iter 224, loss 2.223281145095825, acc 0.10999999940395355\n",
      "Epoch 9, iter 225, loss 2.247053384780884, acc 0.09000000357627869\n",
      "Epoch 9, iter 226, loss 2.1675217151641846, acc 0.1899999976158142\n",
      "Epoch 9, iter 227, loss 2.2241551876068115, acc 0.14000000059604645\n",
      "Epoch 9, iter 228, loss 2.173682451248169, acc 0.2199999988079071\n",
      "Epoch 9, iter 229, loss 2.2408699989318848, acc 0.11999999731779099\n",
      "Epoch 9, iter 230, loss 2.2311513423919678, acc 0.11999999731779099\n",
      "Epoch 9, iter 231, loss 2.2069907188415527, acc 0.1599999964237213\n",
      "Epoch 9, iter 232, loss 2.297337532043457, acc 0.14000000059604645\n",
      "Epoch 9, iter 233, loss 2.193723201751709, acc 0.1599999964237213\n",
      "Epoch 9, iter 234, loss 2.1799309253692627, acc 0.20999999344348907\n",
      "Epoch 9, iter 235, loss 2.1795873641967773, acc 0.1599999964237213\n",
      "Epoch 9, iter 236, loss 2.2367002964019775, acc 0.18000000715255737\n",
      "Epoch 9, iter 237, loss 2.241992473602295, acc 0.11999999731779099\n",
      "Epoch 9, iter 238, loss 2.1674201488494873, acc 0.23000000417232513\n",
      "Epoch 9, iter 239, loss 2.186237335205078, acc 0.1899999976158142\n",
      "Epoch 9, iter 240, loss 2.281121253967285, acc 0.09000000357627869\n",
      "Epoch 9, iter 241, loss 2.277893304824829, acc 0.11999999731779099\n",
      "Epoch 9, iter 242, loss 2.2011959552764893, acc 0.18000000715255737\n",
      "Epoch 9, iter 243, loss 2.2148356437683105, acc 0.1599999964237213\n",
      "Epoch 9, iter 244, loss 2.2344582080841064, acc 0.14000000059604645\n",
      "Epoch 9, iter 245, loss 2.1558470726013184, acc 0.1899999976158142\n",
      "Epoch 9, iter 246, loss 2.2221670150756836, acc 0.11999999731779099\n",
      "Epoch 9, iter 247, loss 2.178985357284546, acc 0.2199999988079071\n",
      "Epoch 9, iter 248, loss 2.1995720863342285, acc 0.11999999731779099\n",
      "Epoch 9, iter 249, loss 2.223257541656494, acc 0.12999999523162842\n",
      "Epoch 9, iter 250, loss 2.136270523071289, acc 0.23000000417232513\n",
      "Epoch 9, iter 251, loss 2.219853639602661, acc 0.12999999523162842\n",
      "Epoch 9, iter 252, loss 2.144941568374634, acc 0.1899999976158142\n",
      "Epoch 9, iter 253, loss 2.3162922859191895, acc 0.14000000059604645\n",
      "Epoch 9, iter 254, loss 2.235623359680176, acc 0.11999999731779099\n",
      "Epoch 9, iter 255, loss 2.2582781314849854, acc 0.20999999344348907\n",
      "Epoch 9, iter 256, loss 2.2719523906707764, acc 0.2199999988079071\n",
      "Epoch 9, iter 257, loss 2.268605947494507, acc 0.14000000059604645\n",
      "Epoch 9, iter 258, loss 2.1745619773864746, acc 0.20000000298023224\n",
      "Epoch 9, iter 259, loss 2.157855749130249, acc 0.20999999344348907\n",
      "Epoch 9, iter 260, loss 2.2176413536071777, acc 0.17000000178813934\n",
      "Epoch 9, iter 261, loss 2.194951295852661, acc 0.15000000596046448\n",
      "Epoch 9, iter 262, loss 2.2142701148986816, acc 0.12999999523162842\n",
      "Epoch 9, iter 263, loss 2.2011513710021973, acc 0.1599999964237213\n",
      "Epoch 9, iter 264, loss 2.20210337638855, acc 0.1899999976158142\n",
      "Epoch 9, iter 265, loss 2.247634172439575, acc 0.14000000059604645\n",
      "Epoch 9, iter 266, loss 2.1908812522888184, acc 0.18000000715255737\n",
      "Epoch 9, iter 267, loss 2.2073068618774414, acc 0.15000000596046448\n",
      "Epoch 9, iter 268, loss 2.2378597259521484, acc 0.15000000596046448\n",
      "Epoch 9, iter 269, loss 2.192476511001587, acc 0.14000000059604645\n",
      "Epoch 9, iter 270, loss 2.230783700942993, acc 0.14000000059604645\n",
      "Epoch 9, iter 271, loss 2.223644495010376, acc 0.25999999046325684\n",
      "Epoch 9, iter 272, loss 2.214676856994629, acc 0.15000000596046448\n",
      "Epoch 9, iter 273, loss 2.2113678455352783, acc 0.18000000715255737\n",
      "Epoch 9, iter 274, loss 2.1636743545532227, acc 0.1899999976158142\n",
      "Epoch 9, iter 275, loss 2.1934099197387695, acc 0.2199999988079071\n",
      "Epoch 9, iter 276, loss 2.2759175300598145, acc 0.12999999523162842\n",
      "Epoch 9, iter 277, loss 2.213696002960205, acc 0.14000000059604645\n",
      "Epoch 9, iter 278, loss 2.1999588012695312, acc 0.20000000298023224\n",
      "Epoch 9, iter 279, loss 2.197702407836914, acc 0.12999999523162842\n",
      "Epoch 9, iter 280, loss 2.207749366760254, acc 0.20999999344348907\n",
      "Epoch 9, iter 281, loss 2.1819865703582764, acc 0.17000000178813934\n",
      "Epoch 9, iter 282, loss 2.2523677349090576, acc 0.10000000149011612\n",
      "Epoch 9, iter 283, loss 2.2060155868530273, acc 0.1899999976158142\n",
      "Epoch 9, iter 284, loss 2.2695605754852295, acc 0.11999999731779099\n",
      "Epoch 9, iter 285, loss 2.2075648307800293, acc 0.11999999731779099\n",
      "Epoch 9, iter 286, loss 2.210716485977173, acc 0.15000000596046448\n",
      "Epoch 9, iter 287, loss 2.2339558601379395, acc 0.15000000596046448\n",
      "Epoch 9, iter 288, loss 2.2525789737701416, acc 0.1899999976158142\n",
      "Epoch 9, iter 289, loss 2.163581132888794, acc 0.15000000596046448\n",
      "Epoch 9, iter 290, loss 2.2462282180786133, acc 0.11999999731779099\n",
      "Epoch 9, iter 291, loss 2.210603713989258, acc 0.1899999976158142\n",
      "Epoch 9, iter 292, loss 2.2190256118774414, acc 0.14000000059604645\n",
      "Epoch 9, iter 293, loss 2.1885271072387695, acc 0.1899999976158142\n",
      "Epoch 9, iter 294, loss 2.2197961807250977, acc 0.12999999523162842\n",
      "Epoch 9, iter 295, loss 2.2277793884277344, acc 0.1599999964237213\n",
      "Epoch 9, iter 296, loss 2.2438576221466064, acc 0.1599999964237213\n",
      "Epoch 9, iter 297, loss 2.267354965209961, acc 0.09000000357627869\n",
      "Epoch 9, iter 298, loss 2.219351053237915, acc 0.14000000059604645\n",
      "Epoch 9, iter 299, loss 2.2930805683135986, acc 0.14000000059604645\n",
      "Epoch 9, iter 300, loss 2.2000815868377686, acc 0.1599999964237213\n",
      "Epoch 9, iter 301, loss 2.2467527389526367, acc 0.10000000149011612\n",
      "Epoch 9, iter 302, loss 2.219005823135376, acc 0.20000000298023224\n",
      "Epoch 9, iter 303, loss 2.222454309463501, acc 0.17000000178813934\n",
      "Epoch 9, iter 304, loss 2.2549524307250977, acc 0.14000000059604645\n",
      "Epoch 9, iter 305, loss 2.186190366744995, acc 0.11999999731779099\n",
      "Epoch 9, iter 306, loss 2.241196870803833, acc 0.20000000298023224\n",
      "Epoch 9, iter 307, loss 2.191409111022949, acc 0.1899999976158142\n",
      "Epoch 9, iter 308, loss 2.208606243133545, acc 0.1599999964237213\n",
      "Epoch 9, iter 309, loss 2.2376596927642822, acc 0.09000000357627869\n",
      "Epoch 9, iter 310, loss 2.261428117752075, acc 0.10999999940395355\n",
      "Epoch 9, iter 311, loss 2.195317029953003, acc 0.18000000715255737\n",
      "Epoch 9, iter 312, loss 2.2334609031677246, acc 0.10000000149011612\n",
      "Epoch 9, iter 313, loss 2.2366721630096436, acc 0.10000000149011612\n",
      "Epoch 9, iter 314, loss 2.237907648086548, acc 0.12999999523162842\n",
      "Epoch 9, iter 315, loss 2.2405126094818115, acc 0.12999999523162842\n",
      "Epoch 9, iter 316, loss 2.1981165409088135, acc 0.1899999976158142\n",
      "Epoch 9, iter 317, loss 2.1777920722961426, acc 0.23999999463558197\n",
      "Epoch 9, iter 318, loss 2.2694454193115234, acc 0.09000000357627869\n",
      "Epoch 9, iter 319, loss 2.194293737411499, acc 0.1599999964237213\n",
      "Epoch 9, iter 320, loss 2.163834810256958, acc 0.12999999523162842\n",
      "Epoch 9, iter 321, loss 2.2692506313323975, acc 0.12999999523162842\n",
      "Epoch 9, iter 322, loss 2.2311837673187256, acc 0.17000000178813934\n",
      "Epoch 9, iter 323, loss 2.264662265777588, acc 0.15000000596046448\n",
      "Epoch 9, iter 324, loss 2.1274516582489014, acc 0.23000000417232513\n",
      "Epoch 9, iter 325, loss 2.245388984680176, acc 0.14000000059604645\n",
      "Epoch 9, iter 326, loss 2.2016847133636475, acc 0.15000000596046448\n",
      "Epoch 9, iter 327, loss 2.251326084136963, acc 0.12999999523162842\n",
      "Epoch 9, iter 328, loss 2.331723213195801, acc 0.12999999523162842\n",
      "Epoch 9, iter 329, loss 2.216691255569458, acc 0.1599999964237213\n",
      "Epoch 9, iter 330, loss 2.2263810634613037, acc 0.1599999964237213\n",
      "Epoch 9, iter 331, loss 2.2288644313812256, acc 0.14000000059604645\n",
      "Epoch 9, iter 332, loss 2.2302651405334473, acc 0.11999999731779099\n",
      "Epoch 9, iter 333, loss 2.2190771102905273, acc 0.15000000596046448\n",
      "Epoch 9, iter 334, loss 2.139035224914551, acc 0.14000000059604645\n",
      "Epoch 9, iter 335, loss 2.1982693672180176, acc 0.1899999976158142\n",
      "Epoch 9, iter 336, loss 2.215834617614746, acc 0.11999999731779099\n",
      "Epoch 9, iter 337, loss 2.1830990314483643, acc 0.1899999976158142\n",
      "Epoch 9, iter 338, loss 2.2253661155700684, acc 0.18000000715255737\n",
      "Epoch 9, iter 339, loss 2.2511749267578125, acc 0.14000000059604645\n",
      "Epoch 9, iter 340, loss 2.2539544105529785, acc 0.11999999731779099\n",
      "Epoch 9, iter 341, loss 2.2132184505462646, acc 0.07000000029802322\n",
      "Epoch 9, iter 342, loss 2.2277917861938477, acc 0.14000000059604645\n",
      "Epoch 9, iter 343, loss 2.1606972217559814, acc 0.14000000059604645\n",
      "Epoch 9, iter 344, loss 2.245532751083374, acc 0.11999999731779099\n",
      "Epoch 9, iter 345, loss 2.2357048988342285, acc 0.10000000149011612\n",
      "Epoch 9, iter 346, loss 2.301276683807373, acc 0.15000000596046448\n",
      "Epoch 9, iter 347, loss 2.253446102142334, acc 0.10999999940395355\n",
      "Epoch 9, iter 348, loss 2.177776575088501, acc 0.1599999964237213\n",
      "Epoch 9, iter 349, loss 2.2651350498199463, acc 0.12999999523162842\n",
      "Epoch 9, iter 350, loss 2.2313361167907715, acc 0.07999999821186066\n",
      "Epoch 9, iter 351, loss 2.199864149093628, acc 0.2199999988079071\n",
      "Epoch 9, iter 352, loss 2.242979049682617, acc 0.11999999731779099\n",
      "Epoch 9, iter 353, loss 2.142284870147705, acc 0.25\n",
      "Epoch 9, iter 354, loss 2.2250425815582275, acc 0.20999999344348907\n",
      "Epoch 9, iter 355, loss 2.2468321323394775, acc 0.11999999731779099\n",
      "Epoch 9, iter 356, loss 2.243551254272461, acc 0.10999999940395355\n",
      "Epoch 9, iter 357, loss 2.2277755737304688, acc 0.15000000596046448\n",
      "Epoch 9, iter 358, loss 2.197890043258667, acc 0.14000000059604645\n",
      "Epoch 9, iter 359, loss 2.2494678497314453, acc 0.1899999976158142\n",
      "Epoch 9, iter 360, loss 2.2604169845581055, acc 0.10000000149011612\n",
      "Epoch 9, iter 361, loss 2.208583116531372, acc 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 362, loss 2.230534315109253, acc 0.09000000357627869\n",
      "Epoch 9, iter 363, loss 2.2121758460998535, acc 0.10999999940395355\n",
      "Epoch 9, iter 364, loss 2.2986409664154053, acc 0.1899999976158142\n",
      "Epoch 9, iter 365, loss 2.252180576324463, acc 0.17000000178813934\n",
      "Epoch 9, iter 366, loss 2.2563207149505615, acc 0.10999999940395355\n",
      "Epoch 9, iter 367, loss 2.2302114963531494, acc 0.10999999940395355\n",
      "Epoch 9, iter 368, loss 2.2860896587371826, acc 0.15000000596046448\n",
      "Epoch 9, iter 369, loss 2.1738696098327637, acc 0.2199999988079071\n",
      "Epoch 9, iter 370, loss 2.1816775798797607, acc 0.1899999976158142\n",
      "Epoch 9, iter 371, loss 2.2049436569213867, acc 0.18000000715255737\n",
      "Epoch 9, iter 372, loss 2.1889820098876953, acc 0.11999999731779099\n",
      "Epoch 9, iter 373, loss 2.2181906700134277, acc 0.17000000178813934\n",
      "Epoch 9, iter 374, loss 2.1991164684295654, acc 0.18000000715255737\n",
      "Epoch 9, iter 375, loss 2.2328460216522217, acc 0.09000000357627869\n",
      "Epoch 9, iter 376, loss 2.1550426483154297, acc 0.20000000298023224\n",
      "Epoch 9, iter 377, loss 2.226315975189209, acc 0.20000000298023224\n",
      "Epoch 9, iter 378, loss 2.2302608489990234, acc 0.20000000298023224\n",
      "Epoch 9, iter 379, loss 2.306244134902954, acc 0.05999999865889549\n",
      "Epoch 9, iter 380, loss 2.1644606590270996, acc 0.14000000059604645\n",
      "Epoch 9, iter 381, loss 2.2556450366973877, acc 0.12999999523162842\n",
      "Epoch 9, iter 382, loss 2.2395358085632324, acc 0.10999999940395355\n",
      "Epoch 9, iter 383, loss 2.2243127822875977, acc 0.10999999940395355\n",
      "Epoch 9, iter 384, loss 2.237638473510742, acc 0.18000000715255737\n",
      "Epoch 9, iter 385, loss 2.1953206062316895, acc 0.10000000149011612\n",
      "Epoch 9, iter 386, loss 2.2083427906036377, acc 0.10000000149011612\n",
      "Epoch 9, iter 387, loss 2.239985942840576, acc 0.11999999731779099\n",
      "Epoch 9, iter 388, loss 2.2284772396087646, acc 0.1899999976158142\n",
      "Epoch 9, iter 389, loss 2.2315406799316406, acc 0.1599999964237213\n",
      "Epoch 9, iter 390, loss 2.2486608028411865, acc 0.15000000596046448\n",
      "Epoch 9, iter 391, loss 2.1753454208374023, acc 0.1899999976158142\n",
      "Epoch 9, iter 392, loss 2.2115142345428467, acc 0.17000000178813934\n",
      "Epoch 9, iter 393, loss 2.253115177154541, acc 0.12999999523162842\n",
      "Epoch 9, iter 394, loss 2.2364845275878906, acc 0.18000000715255737\n",
      "Epoch 9, iter 395, loss 2.2095046043395996, acc 0.15000000596046448\n",
      "Epoch 9, iter 396, loss 2.2380590438842773, acc 0.07999999821186066\n",
      "Epoch 9, iter 397, loss 2.27964186668396, acc 0.12999999523162842\n",
      "Epoch 9, iter 398, loss 2.2218544483184814, acc 0.15000000596046448\n",
      "Epoch 9, iter 399, loss 2.2656805515289307, acc 0.15000000596046448\n",
      "Epoch 9, iter 400, loss 2.180500030517578, acc 0.17000000178813934\n",
      "Epoch 9, iter 401, loss 2.1995596885681152, acc 0.23000000417232513\n",
      "Epoch 9, iter 402, loss 2.203486919403076, acc 0.15000000596046448\n",
      "Epoch 9, iter 403, loss 2.200765609741211, acc 0.15000000596046448\n",
      "Epoch 9, iter 404, loss 2.1839792728424072, acc 0.18000000715255737\n",
      "Epoch 9, iter 405, loss 2.172828197479248, acc 0.20999999344348907\n",
      "Epoch 9, iter 406, loss 2.2437305450439453, acc 0.15000000596046448\n",
      "Epoch 9, iter 407, loss 2.2380869388580322, acc 0.18000000715255737\n",
      "Epoch 9, iter 408, loss 2.1662213802337646, acc 0.1599999964237213\n",
      "Epoch 9, iter 409, loss 2.2349653244018555, acc 0.17000000178813934\n",
      "Epoch 9, iter 410, loss 2.2700610160827637, acc 0.18000000715255737\n",
      "Epoch 9, iter 411, loss 2.189704179763794, acc 0.11999999731779099\n",
      "Epoch 9, iter 412, loss 2.184053421020508, acc 0.1899999976158142\n",
      "Epoch 9, iter 413, loss 2.2664926052093506, acc 0.18000000715255737\n",
      "Epoch 9, iter 414, loss 2.1774556636810303, acc 0.1899999976158142\n",
      "Epoch 9, iter 415, loss 2.1765053272247314, acc 0.1599999964237213\n",
      "Epoch 9, iter 416, loss 2.1951684951782227, acc 0.1599999964237213\n",
      "Epoch 9, iter 417, loss 2.2513797283172607, acc 0.12999999523162842\n",
      "Epoch 9, iter 418, loss 2.2575433254241943, acc 0.15000000596046448\n",
      "Epoch 9, iter 419, loss 2.191985845565796, acc 0.14000000059604645\n",
      "Epoch 9, iter 420, loss 2.1520462036132812, acc 0.1599999964237213\n",
      "Epoch 10, iter 1, loss 2.2528178691864014, acc 0.12999999523162842\n",
      "Epoch 10, iter 2, loss 2.227402687072754, acc 0.1599999964237213\n",
      "Epoch 10, iter 3, loss 2.197645664215088, acc 0.15000000596046448\n",
      "Epoch 10, iter 4, loss 2.171307325363159, acc 0.1599999964237213\n",
      "Epoch 10, iter 5, loss 2.179360866546631, acc 0.15000000596046448\n",
      "Epoch 10, iter 6, loss 2.2248635292053223, acc 0.14000000059604645\n",
      "Epoch 10, iter 7, loss 2.2173523902893066, acc 0.15000000596046448\n",
      "Epoch 10, iter 8, loss 2.195899724960327, acc 0.14000000059604645\n",
      "Epoch 10, iter 9, loss 2.176748514175415, acc 0.23000000417232513\n",
      "Epoch 10, iter 10, loss 2.1395998001098633, acc 0.1599999964237213\n",
      "Epoch 10, iter 11, loss 2.1706435680389404, acc 0.1899999976158142\n",
      "Epoch 10, iter 12, loss 2.1856086254119873, acc 0.1599999964237213\n",
      "Epoch 10, iter 13, loss 2.2113497257232666, acc 0.18000000715255737\n",
      "Epoch 10, iter 14, loss 2.260906457901001, acc 0.20999999344348907\n",
      "Epoch 10, iter 15, loss 2.207839250564575, acc 0.1599999964237213\n",
      "Epoch 10, iter 16, loss 2.2254648208618164, acc 0.18000000715255737\n",
      "Epoch 10, iter 17, loss 2.1596012115478516, acc 0.15000000596046448\n",
      "Epoch 10, iter 18, loss 2.175708293914795, acc 0.17000000178813934\n",
      "Epoch 10, iter 19, loss 2.127739906311035, acc 0.20999999344348907\n",
      "Epoch 10, iter 20, loss 2.161235809326172, acc 0.25999999046325684\n",
      "Epoch 10, iter 21, loss 2.186253070831299, acc 0.20999999344348907\n",
      "Epoch 10, iter 22, loss 2.2017476558685303, acc 0.18000000715255737\n",
      "Epoch 10, iter 23, loss 2.205667018890381, acc 0.20000000298023224\n",
      "Epoch 10, iter 24, loss 2.2185497283935547, acc 0.12999999523162842\n",
      "Epoch 10, iter 25, loss 2.2590367794036865, acc 0.15000000596046448\n",
      "Epoch 10, iter 26, loss 2.205907106399536, acc 0.20000000298023224\n",
      "Epoch 10, iter 27, loss 2.1958119869232178, acc 0.1599999964237213\n",
      "Epoch 10, iter 28, loss 2.2250027656555176, acc 0.17000000178813934\n",
      "Epoch 10, iter 29, loss 2.1929845809936523, acc 0.15000000596046448\n",
      "Epoch 10, iter 30, loss 2.3334028720855713, acc 0.1599999964237213\n",
      "Epoch 10, iter 31, loss 2.204507350921631, acc 0.20999999344348907\n",
      "Epoch 10, iter 32, loss 2.209094762802124, acc 0.18000000715255737\n",
      "Epoch 10, iter 33, loss 2.2258214950561523, acc 0.10999999940395355\n",
      "Epoch 10, iter 34, loss 2.2633872032165527, acc 0.2199999988079071\n",
      "Epoch 10, iter 35, loss 2.2215769290924072, acc 0.1899999976158142\n",
      "Epoch 10, iter 36, loss 2.2249138355255127, acc 0.20000000298023224\n",
      "Epoch 10, iter 37, loss 2.267303705215454, acc 0.14000000059604645\n",
      "Epoch 10, iter 38, loss 2.2107553482055664, acc 0.1899999976158142\n",
      "Epoch 10, iter 39, loss 2.1807944774627686, acc 0.23999999463558197\n",
      "Epoch 10, iter 40, loss 2.2646987438201904, acc 0.12999999523162842\n",
      "Epoch 10, iter 41, loss 2.2659895420074463, acc 0.20999999344348907\n",
      "Epoch 10, iter 42, loss 2.1692943572998047, acc 0.25999999046325684\n",
      "Epoch 10, iter 43, loss 2.1641952991485596, acc 0.25\n",
      "Epoch 10, iter 44, loss 2.201921224594116, acc 0.1899999976158142\n",
      "Epoch 10, iter 45, loss 2.2169883251190186, acc 0.17000000178813934\n",
      "Epoch 10, iter 46, loss 2.2467575073242188, acc 0.15000000596046448\n",
      "Epoch 10, iter 47, loss 2.220127820968628, acc 0.17000000178813934\n",
      "Epoch 10, iter 48, loss 2.248885154724121, acc 0.1899999976158142\n",
      "Epoch 10, iter 49, loss 2.238417625427246, acc 0.12999999523162842\n",
      "Epoch 10, iter 50, loss 2.1967220306396484, acc 0.2199999988079071\n",
      "Epoch 10, iter 51, loss 2.2060189247131348, acc 0.23000000417232513\n",
      "Epoch 10, iter 52, loss 2.215924024581909, acc 0.17000000178813934\n",
      "Epoch 10, iter 53, loss 2.260429620742798, acc 0.14000000059604645\n",
      "Epoch 10, iter 54, loss 2.1652567386627197, acc 0.27000001072883606\n",
      "Epoch 10, iter 55, loss 2.2072391510009766, acc 0.20999999344348907\n",
      "Epoch 10, iter 56, loss 2.190993070602417, acc 0.20000000298023224\n",
      "Epoch 10, iter 57, loss 2.1692545413970947, acc 0.17000000178813934\n",
      "Epoch 10, iter 58, loss 2.2275567054748535, acc 0.18000000715255737\n",
      "Epoch 10, iter 59, loss 2.2711660861968994, acc 0.10000000149011612\n",
      "Epoch 10, iter 60, loss 2.2321856021881104, acc 0.2199999988079071\n",
      "Epoch 10, iter 61, loss 2.151873826980591, acc 0.27000001072883606\n",
      "Epoch 10, iter 62, loss 2.1781821250915527, acc 0.17000000178813934\n",
      "Epoch 10, iter 63, loss 2.1968445777893066, acc 0.2199999988079071\n",
      "Epoch 10, iter 64, loss 2.1668641567230225, acc 0.1599999964237213\n",
      "Epoch 10, iter 65, loss 2.177135944366455, acc 0.12999999523162842\n",
      "Epoch 10, iter 66, loss 2.204563856124878, acc 0.1599999964237213\n",
      "Epoch 10, iter 67, loss 2.217984676361084, acc 0.20000000298023224\n",
      "Epoch 10, iter 68, loss 2.2118494510650635, acc 0.10000000149011612\n",
      "Epoch 10, iter 69, loss 2.1660215854644775, acc 0.2199999988079071\n",
      "Epoch 10, iter 70, loss 2.2321584224700928, acc 0.12999999523162842\n",
      "Epoch 10, iter 71, loss 2.230694532394409, acc 0.20000000298023224\n",
      "Epoch 10, iter 72, loss 2.247695207595825, acc 0.15000000596046448\n",
      "Epoch 10, iter 73, loss 2.209637403488159, acc 0.1599999964237213\n",
      "Epoch 10, iter 74, loss 2.1753149032592773, acc 0.1599999964237213\n",
      "Epoch 10, iter 75, loss 2.242921829223633, acc 0.23000000417232513\n",
      "Epoch 10, iter 76, loss 2.2285573482513428, acc 0.14000000059604645\n",
      "Epoch 10, iter 77, loss 2.246645212173462, acc 0.1599999964237213\n",
      "Epoch 10, iter 78, loss 2.2238357067108154, acc 0.18000000715255737\n",
      "Epoch 10, iter 79, loss 2.2209420204162598, acc 0.20000000298023224\n",
      "Epoch 10, iter 80, loss 2.2214982509613037, acc 0.20000000298023224\n",
      "Epoch 10, iter 81, loss 2.183980941772461, acc 0.2199999988079071\n",
      "Epoch 10, iter 82, loss 2.1726174354553223, acc 0.25999999046325684\n",
      "Epoch 10, iter 83, loss 2.210881233215332, acc 0.15000000596046448\n",
      "Epoch 10, iter 84, loss 2.1797354221343994, acc 0.25\n",
      "Epoch 10, iter 85, loss 2.218618631362915, acc 0.12999999523162842\n",
      "Epoch 10, iter 86, loss 2.1352035999298096, acc 0.20999999344348907\n",
      "Epoch 10, iter 87, loss 2.147538661956787, acc 0.1899999976158142\n",
      "Epoch 10, iter 88, loss 2.1994335651397705, acc 0.14000000059604645\n",
      "Epoch 10, iter 89, loss 2.209930658340454, acc 0.20999999344348907\n",
      "Epoch 10, iter 90, loss 2.219083309173584, acc 0.2199999988079071\n",
      "Epoch 10, iter 91, loss 2.192356586456299, acc 0.23999999463558197\n",
      "Epoch 10, iter 92, loss 2.1709461212158203, acc 0.17000000178813934\n",
      "Epoch 10, iter 93, loss 2.2169668674468994, acc 0.20999999344348907\n",
      "Epoch 10, iter 94, loss 2.2051281929016113, acc 0.20000000298023224\n",
      "Epoch 10, iter 95, loss 2.192147731781006, acc 0.20999999344348907\n",
      "Epoch 10, iter 96, loss 2.217885971069336, acc 0.17000000178813934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 97, loss 2.2527050971984863, acc 0.15000000596046448\n",
      "Epoch 10, iter 98, loss 2.2525832653045654, acc 0.18000000715255737\n",
      "Epoch 10, iter 99, loss 2.1898577213287354, acc 0.2199999988079071\n",
      "Epoch 10, iter 100, loss 2.2443125247955322, acc 0.23000000417232513\n",
      "Epoch 10, iter 101, loss 2.2557930946350098, acc 0.1599999964237213\n",
      "Epoch 10, iter 102, loss 2.2154135704040527, acc 0.1899999976158142\n",
      "Epoch 10, iter 103, loss 2.2411398887634277, acc 0.15000000596046448\n",
      "Epoch 10, iter 104, loss 2.1960740089416504, acc 0.18000000715255737\n",
      "Epoch 10, iter 105, loss 2.2006664276123047, acc 0.2800000011920929\n",
      "Epoch 10, iter 106, loss 2.195821762084961, acc 0.25\n",
      "Epoch 10, iter 107, loss 2.1618785858154297, acc 0.25\n",
      "Epoch 10, iter 108, loss 2.1721534729003906, acc 0.20000000298023224\n",
      "Epoch 10, iter 109, loss 2.2558882236480713, acc 0.14000000059604645\n",
      "Epoch 10, iter 110, loss 2.2450149059295654, acc 0.20000000298023224\n",
      "Epoch 10, iter 111, loss 2.2477807998657227, acc 0.17000000178813934\n",
      "Epoch 10, iter 112, loss 2.2479188442230225, acc 0.14000000059604645\n",
      "Epoch 10, iter 113, loss 2.162304401397705, acc 0.18000000715255737\n",
      "Epoch 10, iter 114, loss 2.2621798515319824, acc 0.18000000715255737\n",
      "Epoch 10, iter 115, loss 2.167144536972046, acc 0.20999999344348907\n",
      "Epoch 10, iter 116, loss 2.2200722694396973, acc 0.15000000596046448\n",
      "Epoch 10, iter 117, loss 2.2083795070648193, acc 0.1899999976158142\n",
      "Epoch 10, iter 118, loss 2.2068703174591064, acc 0.23999999463558197\n",
      "Epoch 10, iter 119, loss 2.1331326961517334, acc 0.1899999976158142\n",
      "Epoch 10, iter 120, loss 2.1913063526153564, acc 0.1899999976158142\n",
      "Epoch 10, iter 121, loss 2.172927141189575, acc 0.12999999523162842\n",
      "Epoch 10, iter 122, loss 2.2205333709716797, acc 0.20000000298023224\n",
      "Epoch 10, iter 123, loss 2.2002158164978027, acc 0.17000000178813934\n",
      "Epoch 10, iter 124, loss 2.2487876415252686, acc 0.1899999976158142\n",
      "Epoch 10, iter 125, loss 2.169020414352417, acc 0.1899999976158142\n",
      "Epoch 10, iter 126, loss 2.2534494400024414, acc 0.10999999940395355\n",
      "Epoch 10, iter 127, loss 2.2038590908050537, acc 0.15000000596046448\n",
      "Epoch 10, iter 128, loss 2.193983316421509, acc 0.1899999976158142\n",
      "Epoch 10, iter 129, loss 2.2158918380737305, acc 0.20000000298023224\n",
      "Epoch 10, iter 130, loss 2.2370314598083496, acc 0.1899999976158142\n",
      "Epoch 10, iter 131, loss 2.201883316040039, acc 0.14000000059604645\n",
      "Epoch 10, iter 132, loss 2.210402488708496, acc 0.17000000178813934\n",
      "Epoch 10, iter 133, loss 2.1988518238067627, acc 0.23000000417232513\n",
      "Epoch 10, iter 134, loss 2.187167167663574, acc 0.23000000417232513\n",
      "Epoch 10, iter 135, loss 2.259526014328003, acc 0.12999999523162842\n",
      "Epoch 10, iter 136, loss 2.1637496948242188, acc 0.1599999964237213\n",
      "Epoch 10, iter 137, loss 2.207906484603882, acc 0.14000000059604645\n",
      "Epoch 10, iter 138, loss 2.161344528198242, acc 0.20999999344348907\n",
      "Epoch 10, iter 139, loss 2.1851613521575928, acc 0.18000000715255737\n",
      "Epoch 10, iter 140, loss 2.182537794113159, acc 0.1899999976158142\n",
      "Epoch 10, iter 141, loss 2.22819447517395, acc 0.15000000596046448\n",
      "Epoch 10, iter 142, loss 2.292145252227783, acc 0.14000000059604645\n",
      "Epoch 10, iter 143, loss 2.1335434913635254, acc 0.20000000298023224\n",
      "Epoch 10, iter 144, loss 2.202465295791626, acc 0.23000000417232513\n",
      "Epoch 10, iter 145, loss 2.168022871017456, acc 0.2199999988079071\n",
      "Epoch 10, iter 146, loss 2.1947550773620605, acc 0.18000000715255737\n",
      "Epoch 10, iter 147, loss 2.2264418601989746, acc 0.20000000298023224\n",
      "Epoch 10, iter 148, loss 2.2822725772857666, acc 0.14000000059604645\n",
      "Epoch 10, iter 149, loss 2.2117738723754883, acc 0.25999999046325684\n",
      "Epoch 10, iter 150, loss 2.198639154434204, acc 0.23999999463558197\n",
      "Epoch 10, iter 151, loss 2.2352705001831055, acc 0.1899999976158142\n",
      "Epoch 10, iter 152, loss 2.276885986328125, acc 0.14000000059604645\n",
      "Epoch 10, iter 153, loss 2.189910650253296, acc 0.20000000298023224\n",
      "Epoch 10, iter 154, loss 2.2167110443115234, acc 0.1599999964237213\n",
      "Epoch 10, iter 155, loss 2.209601640701294, acc 0.14000000059604645\n",
      "Epoch 10, iter 156, loss 2.196247100830078, acc 0.1899999976158142\n",
      "Epoch 10, iter 157, loss 2.2454442977905273, acc 0.20000000298023224\n",
      "Epoch 10, iter 158, loss 2.2229013442993164, acc 0.15000000596046448\n",
      "Epoch 10, iter 159, loss 2.2455263137817383, acc 0.14000000059604645\n",
      "Epoch 10, iter 160, loss 2.208831310272217, acc 0.20000000298023224\n",
      "Epoch 10, iter 161, loss 2.138005256652832, acc 0.25\n",
      "Epoch 10, iter 162, loss 2.2145659923553467, acc 0.20999999344348907\n",
      "Epoch 10, iter 163, loss 2.212212324142456, acc 0.20000000298023224\n",
      "Epoch 10, iter 164, loss 2.2460434436798096, acc 0.14000000059604645\n",
      "Epoch 10, iter 165, loss 2.1988582611083984, acc 0.18000000715255737\n",
      "Epoch 10, iter 166, loss 2.1869966983795166, acc 0.25\n",
      "Epoch 10, iter 167, loss 2.1841490268707275, acc 0.23999999463558197\n",
      "Epoch 10, iter 168, loss 2.268763303756714, acc 0.20999999344348907\n",
      "Epoch 10, iter 169, loss 2.231931209564209, acc 0.1899999976158142\n",
      "Epoch 10, iter 170, loss 2.2620325088500977, acc 0.18000000715255737\n",
      "Epoch 10, iter 171, loss 2.169146776199341, acc 0.1899999976158142\n",
      "Epoch 10, iter 172, loss 2.238112688064575, acc 0.18000000715255737\n",
      "Epoch 10, iter 173, loss 2.2655725479125977, acc 0.12999999523162842\n",
      "Epoch 10, iter 174, loss 2.213831901550293, acc 0.15000000596046448\n",
      "Epoch 10, iter 175, loss 2.1856014728546143, acc 0.20000000298023224\n",
      "Epoch 10, iter 176, loss 2.24845814704895, acc 0.17000000178813934\n",
      "Epoch 10, iter 177, loss 2.228154182434082, acc 0.20000000298023224\n",
      "Epoch 10, iter 178, loss 2.201946258544922, acc 0.1599999964237213\n",
      "Epoch 10, iter 179, loss 2.1764845848083496, acc 0.20999999344348907\n",
      "Epoch 10, iter 180, loss 2.1527791023254395, acc 0.1599999964237213\n",
      "Epoch 10, iter 181, loss 2.1609084606170654, acc 0.20999999344348907\n",
      "Epoch 10, iter 182, loss 2.149966239929199, acc 0.23000000417232513\n",
      "Epoch 10, iter 183, loss 2.1900010108947754, acc 0.18000000715255737\n",
      "Epoch 10, iter 184, loss 2.229111433029175, acc 0.2199999988079071\n",
      "Epoch 10, iter 185, loss 2.225207805633545, acc 0.1599999964237213\n",
      "Epoch 10, iter 186, loss 2.20365047454834, acc 0.20999999344348907\n",
      "Epoch 10, iter 187, loss 2.151151418685913, acc 0.20999999344348907\n",
      "Epoch 10, iter 188, loss 2.2282447814941406, acc 0.1599999964237213\n",
      "Epoch 10, iter 189, loss 2.230569362640381, acc 0.11999999731779099\n",
      "Epoch 10, iter 190, loss 2.1605281829833984, acc 0.18000000715255737\n",
      "Epoch 10, iter 191, loss 2.2202086448669434, acc 0.18000000715255737\n",
      "Epoch 10, iter 192, loss 2.2136542797088623, acc 0.23000000417232513\n",
      "Epoch 10, iter 193, loss 2.245436668395996, acc 0.20999999344348907\n",
      "Epoch 10, iter 194, loss 2.17450213432312, acc 0.20999999344348907\n",
      "Epoch 10, iter 195, loss 2.1718759536743164, acc 0.23000000417232513\n",
      "Epoch 10, iter 196, loss 2.1714441776275635, acc 0.20999999344348907\n",
      "Epoch 10, iter 197, loss 2.167940855026245, acc 0.2199999988079071\n",
      "Epoch 10, iter 198, loss 2.200198173522949, acc 0.25999999046325684\n",
      "Epoch 10, iter 199, loss 2.2306160926818848, acc 0.17000000178813934\n",
      "Epoch 10, iter 200, loss 2.2227585315704346, acc 0.18000000715255737\n",
      "Epoch 10, iter 201, loss 2.221266269683838, acc 0.18000000715255737\n",
      "Epoch 10, iter 202, loss 2.1792287826538086, acc 0.20000000298023224\n",
      "Epoch 10, iter 203, loss 2.206841468811035, acc 0.15000000596046448\n",
      "Epoch 10, iter 204, loss 2.2019476890563965, acc 0.25\n",
      "Epoch 10, iter 205, loss 2.2262465953826904, acc 0.23000000417232513\n",
      "Epoch 10, iter 206, loss 2.187584638595581, acc 0.25\n",
      "Epoch 10, iter 207, loss 2.278154134750366, acc 0.1599999964237213\n",
      "Epoch 10, iter 208, loss 2.251537799835205, acc 0.15000000596046448\n",
      "Epoch 10, iter 209, loss 2.231498956680298, acc 0.20000000298023224\n",
      "Epoch 10, iter 210, loss 2.185176134109497, acc 0.25999999046325684\n",
      "Epoch 10, iter 211, loss 2.243089199066162, acc 0.20999999344348907\n",
      "Epoch 10, iter 212, loss 2.2252020835876465, acc 0.25\n",
      "Epoch 10, iter 213, loss 2.146848440170288, acc 0.15000000596046448\n",
      "Epoch 10, iter 214, loss 2.2617597579956055, acc 0.18000000715255737\n",
      "Epoch 10, iter 215, loss 2.239854335784912, acc 0.2199999988079071\n",
      "Epoch 10, iter 216, loss 2.2292375564575195, acc 0.15000000596046448\n",
      "Epoch 10, iter 217, loss 2.1405389308929443, acc 0.20000000298023224\n",
      "Epoch 10, iter 218, loss 2.2817232608795166, acc 0.1599999964237213\n",
      "Epoch 10, iter 219, loss 2.1958250999450684, acc 0.1899999976158142\n",
      "Epoch 10, iter 220, loss 2.2236757278442383, acc 0.23999999463558197\n",
      "Epoch 10, iter 221, loss 2.197477340698242, acc 0.1599999964237213\n",
      "Epoch 10, iter 222, loss 2.2016212940216064, acc 0.2199999988079071\n",
      "Epoch 10, iter 223, loss 2.1310324668884277, acc 0.23000000417232513\n",
      "Epoch 10, iter 224, loss 2.207725763320923, acc 0.1599999964237213\n",
      "Epoch 10, iter 225, loss 2.231112480163574, acc 0.2199999988079071\n",
      "Epoch 10, iter 226, loss 2.1482410430908203, acc 0.28999999165534973\n",
      "Epoch 10, iter 227, loss 2.2068262100219727, acc 0.2199999988079071\n",
      "Epoch 10, iter 228, loss 2.166571855545044, acc 0.25\n",
      "Epoch 10, iter 229, loss 2.2281885147094727, acc 0.20000000298023224\n",
      "Epoch 10, iter 230, loss 2.221820592880249, acc 0.1899999976158142\n",
      "Epoch 10, iter 231, loss 2.179094076156616, acc 0.25999999046325684\n",
      "Epoch 10, iter 232, loss 2.2690818309783936, acc 0.1599999964237213\n",
      "Epoch 10, iter 233, loss 2.179400682449341, acc 0.25999999046325684\n",
      "Epoch 10, iter 234, loss 2.1574034690856934, acc 0.2800000011920929\n",
      "Epoch 10, iter 235, loss 2.1589207649230957, acc 0.23999999463558197\n",
      "Epoch 10, iter 236, loss 2.239776372909546, acc 0.1599999964237213\n",
      "Epoch 10, iter 237, loss 2.2161314487457275, acc 0.1899999976158142\n",
      "Epoch 10, iter 238, loss 2.1600191593170166, acc 0.20999999344348907\n",
      "Epoch 10, iter 239, loss 2.173265218734741, acc 0.1899999976158142\n",
      "Epoch 10, iter 240, loss 2.274885416030884, acc 0.10999999940395355\n",
      "Epoch 10, iter 241, loss 2.257347822189331, acc 0.1599999964237213\n",
      "Epoch 10, iter 242, loss 2.187488317489624, acc 0.1899999976158142\n",
      "Epoch 10, iter 243, loss 2.168043613433838, acc 0.2199999988079071\n",
      "Epoch 10, iter 244, loss 2.2150096893310547, acc 0.20000000298023224\n",
      "Epoch 10, iter 245, loss 2.1402359008789062, acc 0.25999999046325684\n",
      "Epoch 10, iter 246, loss 2.202277183532715, acc 0.20000000298023224\n",
      "Epoch 10, iter 247, loss 2.1466922760009766, acc 0.23999999463558197\n",
      "Epoch 10, iter 248, loss 2.1833505630493164, acc 0.23000000417232513\n",
      "Epoch 10, iter 249, loss 2.2045679092407227, acc 0.17000000178813934\n",
      "Epoch 10, iter 250, loss 2.105717420578003, acc 0.2800000011920929\n",
      "Epoch 10, iter 251, loss 2.21296763420105, acc 0.17000000178813934\n",
      "Epoch 10, iter 252, loss 2.1243605613708496, acc 0.20999999344348907\n",
      "Epoch 10, iter 253, loss 2.306793689727783, acc 0.15000000596046448\n",
      "Epoch 10, iter 254, loss 2.2175354957580566, acc 0.17000000178813934\n",
      "Epoch 10, iter 255, loss 2.2585127353668213, acc 0.20999999344348907\n",
      "Epoch 10, iter 256, loss 2.240072727203369, acc 0.20999999344348907\n",
      "Epoch 10, iter 257, loss 2.2573800086975098, acc 0.17000000178813934\n",
      "Epoch 10, iter 258, loss 2.146174907684326, acc 0.23000000417232513\n",
      "Epoch 10, iter 259, loss 2.1158313751220703, acc 0.25\n",
      "Epoch 10, iter 260, loss 2.206406593322754, acc 0.23999999463558197\n",
      "Epoch 10, iter 261, loss 2.187110424041748, acc 0.25999999046325684\n",
      "Epoch 10, iter 262, loss 2.1939516067504883, acc 0.18000000715255737\n",
      "Epoch 10, iter 263, loss 2.1910593509674072, acc 0.1899999976158142\n",
      "Epoch 10, iter 264, loss 2.1906850337982178, acc 0.23999999463558197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 265, loss 2.224194288253784, acc 0.18000000715255737\n",
      "Epoch 10, iter 266, loss 2.164968967437744, acc 0.23999999463558197\n",
      "Epoch 10, iter 267, loss 2.188218116760254, acc 0.23999999463558197\n",
      "Epoch 10, iter 268, loss 2.2271294593811035, acc 0.1899999976158142\n",
      "Epoch 10, iter 269, loss 2.175137758255005, acc 0.23999999463558197\n",
      "Epoch 10, iter 270, loss 2.218823194503784, acc 0.11999999731779099\n",
      "Epoch 10, iter 271, loss 2.206106185913086, acc 0.20000000298023224\n",
      "Epoch 10, iter 272, loss 2.205829381942749, acc 0.20999999344348907\n",
      "Epoch 10, iter 273, loss 2.200883626937866, acc 0.20000000298023224\n",
      "Epoch 10, iter 274, loss 2.145418643951416, acc 0.27000001072883606\n",
      "Epoch 10, iter 275, loss 2.1819567680358887, acc 0.25999999046325684\n",
      "Epoch 10, iter 276, loss 2.244549512863159, acc 0.15000000596046448\n",
      "Epoch 10, iter 277, loss 2.203664779663086, acc 0.18000000715255737\n",
      "Epoch 10, iter 278, loss 2.202664375305176, acc 0.18000000715255737\n",
      "Epoch 10, iter 279, loss 2.180101156234741, acc 0.20999999344348907\n",
      "Epoch 10, iter 280, loss 2.1951639652252197, acc 0.23999999463558197\n",
      "Epoch 10, iter 281, loss 2.1662445068359375, acc 0.20000000298023224\n",
      "Epoch 10, iter 282, loss 2.2400364875793457, acc 0.12999999523162842\n",
      "Epoch 10, iter 283, loss 2.186105251312256, acc 0.20000000298023224\n",
      "Epoch 10, iter 284, loss 2.2611937522888184, acc 0.20000000298023224\n",
      "Epoch 10, iter 285, loss 2.2025983333587646, acc 0.20999999344348907\n",
      "Epoch 10, iter 286, loss 2.1907730102539062, acc 0.1899999976158142\n",
      "Epoch 10, iter 287, loss 2.224205255508423, acc 0.1899999976158142\n",
      "Epoch 10, iter 288, loss 2.2468254566192627, acc 0.20999999344348907\n",
      "Epoch 10, iter 289, loss 2.1412606239318848, acc 0.23999999463558197\n",
      "Epoch 10, iter 290, loss 2.2173545360565186, acc 0.25999999046325684\n",
      "Epoch 10, iter 291, loss 2.1996347904205322, acc 0.2199999988079071\n",
      "Epoch 10, iter 292, loss 2.2073349952697754, acc 0.23000000417232513\n",
      "Epoch 10, iter 293, loss 2.1700174808502197, acc 0.1599999964237213\n",
      "Epoch 10, iter 294, loss 2.2131505012512207, acc 0.18000000715255737\n",
      "Epoch 10, iter 295, loss 2.2093214988708496, acc 0.20000000298023224\n",
      "Epoch 10, iter 296, loss 2.205587148666382, acc 0.18000000715255737\n",
      "Epoch 10, iter 297, loss 2.272437810897827, acc 0.2199999988079071\n",
      "Epoch 10, iter 298, loss 2.2026450634002686, acc 0.20000000298023224\n",
      "Epoch 10, iter 299, loss 2.2760980129241943, acc 0.12999999523162842\n",
      "Epoch 10, iter 300, loss 2.1965012550354004, acc 0.20999999344348907\n",
      "Epoch 10, iter 301, loss 2.2326059341430664, acc 0.1599999964237213\n",
      "Epoch 10, iter 302, loss 2.19555401802063, acc 0.2800000011920929\n",
      "Epoch 10, iter 303, loss 2.1946098804473877, acc 0.17000000178813934\n",
      "Epoch 10, iter 304, loss 2.225928544998169, acc 0.1899999976158142\n",
      "Epoch 10, iter 305, loss 2.1665198802948, acc 0.20999999344348907\n",
      "Epoch 10, iter 306, loss 2.2206826210021973, acc 0.2199999988079071\n",
      "Epoch 10, iter 307, loss 2.1649582386016846, acc 0.20999999344348907\n",
      "Epoch 10, iter 308, loss 2.1816108226776123, acc 0.23999999463558197\n",
      "Epoch 10, iter 309, loss 2.2305753231048584, acc 0.15000000596046448\n",
      "Epoch 10, iter 310, loss 2.248499631881714, acc 0.18000000715255737\n",
      "Epoch 10, iter 311, loss 2.184591293334961, acc 0.25\n",
      "Epoch 10, iter 312, loss 2.223686456680298, acc 0.2199999988079071\n",
      "Epoch 10, iter 313, loss 2.225153684616089, acc 0.14000000059604645\n",
      "Epoch 10, iter 314, loss 2.229729413986206, acc 0.25999999046325684\n",
      "Epoch 10, iter 315, loss 2.2115988731384277, acc 0.20999999344348907\n",
      "Epoch 10, iter 316, loss 2.195612907409668, acc 0.20000000298023224\n",
      "Epoch 10, iter 317, loss 2.176597833633423, acc 0.25\n",
      "Epoch 10, iter 318, loss 2.257965326309204, acc 0.1899999976158142\n",
      "Epoch 10, iter 319, loss 2.1978957653045654, acc 0.15000000596046448\n",
      "Epoch 10, iter 320, loss 2.133139133453369, acc 0.23999999463558197\n",
      "Epoch 10, iter 321, loss 2.2519898414611816, acc 0.1599999964237213\n",
      "Epoch 10, iter 322, loss 2.195537805557251, acc 0.23999999463558197\n",
      "Epoch 10, iter 323, loss 2.245485305786133, acc 0.15000000596046448\n",
      "Epoch 10, iter 324, loss 2.0970685482025146, acc 0.3100000023841858\n",
      "Epoch 10, iter 325, loss 2.206841230392456, acc 0.2199999988079071\n",
      "Epoch 10, iter 326, loss 2.1835873126983643, acc 0.20999999344348907\n",
      "Epoch 10, iter 327, loss 2.243732213973999, acc 0.20000000298023224\n",
      "Epoch 10, iter 328, loss 2.310241937637329, acc 0.1899999976158142\n",
      "Epoch 10, iter 329, loss 2.1978907585144043, acc 0.25999999046325684\n",
      "Epoch 10, iter 330, loss 2.2134711742401123, acc 0.20999999344348907\n",
      "Epoch 10, iter 331, loss 2.218449831008911, acc 0.20999999344348907\n",
      "Epoch 10, iter 332, loss 2.2234950065612793, acc 0.18000000715255737\n",
      "Epoch 10, iter 333, loss 2.1988418102264404, acc 0.1899999976158142\n",
      "Epoch 10, iter 334, loss 2.119811773300171, acc 0.20000000298023224\n",
      "Epoch 10, iter 335, loss 2.192293643951416, acc 0.27000001072883606\n",
      "Epoch 10, iter 336, loss 2.205204725265503, acc 0.15000000596046448\n",
      "Epoch 10, iter 337, loss 2.1604745388031006, acc 0.25\n",
      "Epoch 10, iter 338, loss 2.2185349464416504, acc 0.1599999964237213\n",
      "Epoch 10, iter 339, loss 2.222202777862549, acc 0.18000000715255737\n",
      "Epoch 10, iter 340, loss 2.240389108657837, acc 0.12999999523162842\n",
      "Epoch 10, iter 341, loss 2.1801035404205322, acc 0.25\n",
      "Epoch 10, iter 342, loss 2.2230396270751953, acc 0.17000000178813934\n",
      "Epoch 10, iter 343, loss 2.1662211418151855, acc 0.17000000178813934\n",
      "Epoch 10, iter 344, loss 2.213306188583374, acc 0.2199999988079071\n",
      "Epoch 10, iter 345, loss 2.190091371536255, acc 0.1899999976158142\n",
      "Epoch 10, iter 346, loss 2.268902063369751, acc 0.2199999988079071\n",
      "Epoch 10, iter 347, loss 2.2309536933898926, acc 0.20000000298023224\n",
      "Epoch 10, iter 348, loss 2.154883623123169, acc 0.27000001072883606\n",
      "Epoch 10, iter 349, loss 2.2550041675567627, acc 0.20999999344348907\n",
      "Epoch 10, iter 350, loss 2.221748113632202, acc 0.20000000298023224\n",
      "Epoch 10, iter 351, loss 2.186281204223633, acc 0.18000000715255737\n",
      "Epoch 10, iter 352, loss 2.2414793968200684, acc 0.1899999976158142\n",
      "Epoch 10, iter 353, loss 2.1099770069122314, acc 0.2800000011920929\n",
      "Epoch 10, iter 354, loss 2.204819679260254, acc 0.1899999976158142\n",
      "Epoch 10, iter 355, loss 2.2369167804718018, acc 0.14000000059604645\n",
      "Epoch 10, iter 356, loss 2.228262424468994, acc 0.14000000059604645\n",
      "Epoch 10, iter 357, loss 2.1835155487060547, acc 0.20999999344348907\n",
      "Epoch 10, iter 358, loss 2.174086570739746, acc 0.20999999344348907\n",
      "Epoch 10, iter 359, loss 2.239218235015869, acc 0.12999999523162842\n",
      "Epoch 10, iter 360, loss 2.2526309490203857, acc 0.18000000715255737\n",
      "Epoch 10, iter 361, loss 2.18087100982666, acc 0.23000000417232513\n",
      "Epoch 10, iter 362, loss 2.1953351497650146, acc 0.20000000298023224\n",
      "Epoch 10, iter 363, loss 2.1978673934936523, acc 0.20999999344348907\n",
      "Epoch 10, iter 364, loss 2.3000850677490234, acc 0.1599999964237213\n",
      "Epoch 10, iter 365, loss 2.259920120239258, acc 0.17000000178813934\n",
      "Epoch 10, iter 366, loss 2.226630687713623, acc 0.23000000417232513\n",
      "Epoch 10, iter 367, loss 2.217343807220459, acc 0.23000000417232513\n",
      "Epoch 10, iter 368, loss 2.2643117904663086, acc 0.12999999523162842\n",
      "Epoch 10, iter 369, loss 2.155756950378418, acc 0.23999999463558197\n",
      "Epoch 10, iter 370, loss 2.1663706302642822, acc 0.20000000298023224\n",
      "Epoch 10, iter 371, loss 2.1848607063293457, acc 0.2800000011920929\n",
      "Epoch 10, iter 372, loss 2.1793789863586426, acc 0.23999999463558197\n",
      "Epoch 10, iter 373, loss 2.203597068786621, acc 0.18000000715255737\n",
      "Epoch 10, iter 374, loss 2.180652141571045, acc 0.23999999463558197\n",
      "Epoch 10, iter 375, loss 2.1846275329589844, acc 0.27000001072883606\n",
      "Epoch 10, iter 376, loss 2.148252487182617, acc 0.2199999988079071\n",
      "Epoch 10, iter 377, loss 2.194904088973999, acc 0.23000000417232513\n",
      "Epoch 10, iter 378, loss 2.1795907020568848, acc 0.1899999976158142\n",
      "Epoch 10, iter 379, loss 2.283567428588867, acc 0.07000000029802322\n",
      "Epoch 10, iter 380, loss 2.1638174057006836, acc 0.2199999988079071\n",
      "Epoch 10, iter 381, loss 2.2415034770965576, acc 0.11999999731779099\n",
      "Epoch 10, iter 382, loss 2.212543487548828, acc 0.2199999988079071\n",
      "Epoch 10, iter 383, loss 2.177680492401123, acc 0.23999999463558197\n",
      "Epoch 10, iter 384, loss 2.2066893577575684, acc 0.20000000298023224\n",
      "Epoch 10, iter 385, loss 2.185279607772827, acc 0.2800000011920929\n",
      "Epoch 10, iter 386, loss 2.2055747509002686, acc 0.18000000715255737\n",
      "Epoch 10, iter 387, loss 2.2214548587799072, acc 0.2199999988079071\n",
      "Epoch 10, iter 388, loss 2.2170352935791016, acc 0.17000000178813934\n",
      "Epoch 10, iter 389, loss 2.20176100730896, acc 0.23999999463558197\n",
      "Epoch 10, iter 390, loss 2.2104408740997314, acc 0.1599999964237213\n",
      "Epoch 10, iter 391, loss 2.162623405456543, acc 0.20000000298023224\n",
      "Epoch 10, iter 392, loss 2.1776721477508545, acc 0.18000000715255737\n",
      "Epoch 10, iter 393, loss 2.2432146072387695, acc 0.15000000596046448\n",
      "Epoch 10, iter 394, loss 2.188875198364258, acc 0.27000001072883606\n",
      "Epoch 10, iter 395, loss 2.1953301429748535, acc 0.2199999988079071\n",
      "Epoch 10, iter 396, loss 2.217334032058716, acc 0.17000000178813934\n",
      "Epoch 10, iter 397, loss 2.2527451515197754, acc 0.1899999976158142\n",
      "Epoch 10, iter 398, loss 2.2007205486297607, acc 0.17000000178813934\n",
      "Epoch 10, iter 399, loss 2.2415106296539307, acc 0.2199999988079071\n",
      "Epoch 10, iter 400, loss 2.1460137367248535, acc 0.2800000011920929\n",
      "Epoch 10, iter 401, loss 2.186393976211548, acc 0.15000000596046448\n",
      "Epoch 10, iter 402, loss 2.2011559009552, acc 0.20000000298023224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 403, loss 2.190093755722046, acc 0.20000000298023224\n",
      "Epoch 10, iter 404, loss 2.165290594100952, acc 0.17000000178813934\n",
      "Epoch 10, iter 405, loss 2.1373605728149414, acc 0.23999999463558197\n",
      "Epoch 10, iter 406, loss 2.229752779006958, acc 0.15000000596046448\n",
      "Epoch 10, iter 407, loss 2.2153546810150146, acc 0.1899999976158142\n",
      "Epoch 10, iter 408, loss 2.14640212059021, acc 0.25\n",
      "Epoch 10, iter 409, loss 2.2358946800231934, acc 0.1899999976158142\n",
      "Epoch 10, iter 410, loss 2.2484934329986572, acc 0.2199999988079071\n",
      "Epoch 10, iter 411, loss 2.194058895111084, acc 0.25999999046325684\n",
      "Epoch 10, iter 412, loss 2.1744208335876465, acc 0.2199999988079071\n",
      "Epoch 10, iter 413, loss 2.235090732574463, acc 0.14000000059604645\n",
      "Epoch 10, iter 414, loss 2.1612958908081055, acc 0.1899999976158142\n",
      "Epoch 10, iter 415, loss 2.149182081222534, acc 0.28999999165534973\n",
      "Epoch 10, iter 416, loss 2.1767475605010986, acc 0.25999999046325684\n",
      "Epoch 10, iter 417, loss 2.2383384704589844, acc 0.14000000059604645\n",
      "Epoch 10, iter 418, loss 2.2519888877868652, acc 0.18000000715255737\n",
      "Epoch 10, iter 419, loss 2.1662824153900146, acc 0.3199999928474426\n",
      "Epoch 10, iter 420, loss 2.133620023727417, acc 0.27000001072883606\n"
     ]
    }
   ],
   "source": [
    "w1=torch.randn((784,3),dtype=torch.float,requires_grad=True)\n",
    "b1=torch.randn((3,),dtype=torch.float,requires_grad=True)\n",
    "w2=torch.randn((3,10),dtype=torch.float,requires_grad=True)\n",
    "b2=torch.randn((10,),dtype=torch.float,requires_grad=True)\n",
    "lr=0.01\n",
    "Loss=[]\n",
    "num_epoch=10\n",
    "for i in range(num_epoch):\n",
    "    for j,batch in enumerate(mnist_batched):\n",
    "        x=batch['X']\n",
    "        Y=batch['y']\n",
    "        p=network(x,w1,b1,w2,b2)\n",
    "        loss=CE(p,Y)\n",
    "        loss.backward()\n",
    "        Loss.append(loss.item())\n",
    "        acc=(p.argmax(axis=1)==Y).float().mean().item()\n",
    "        print(f\"Epoch {i+1}, iter {j+1}, loss {loss.item()}, acc {acc}\")\n",
    "        with torch.no_grad():\n",
    "            w1-=lr*w1.grad\n",
    "            b1-=lr*b1.grad\n",
    "            w2-=lr*w2.grad\n",
    "            b2-=lr*b2.grad\n",
    "            w1.grad.zero_()\n",
    "            b1.grad.zero_()\n",
    "            w2.grad.zero_()\n",
    "            b2.grad.zero_()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1350c5b90>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3hUVfoH8O+bRu+EIi2E3qsYRQGBpbrYV9cFsaILq7iyu4K9i/qTta2L7MrasIuCoCBdQQiG3nvokBAkBUhIeX9/zJ3JlHtnJmQmk5l8P8+TxzvnnsycuZJ3zpx7zntEVUFEROEvKtQNICKiwGBAJyKKEAzoREQRggGdiChCMKATEUWImFC9cP369TUhISFUL09EFJbWrVt3SlXjzc6FLKAnJCQgJSUlVC9PRBSWROSg1TkOuRARRQgGdCKiCMGATkQUIRjQiYgiBAM6EVGEYEAnIooQDOhERBEi7AL6rhPZmPbjLpzKyQt1U4iIypWwC+h70rLx5tK9OH32QqibQkRUroRdQBcIAID7chARuQq/gC6hbgERUfkUdgHd7r6PUrB6X0aom0FEVG6EXUC3d9BTM85h3IdM7kVEZBd+AZ1DLkREpnwGdBGpLCJrRWSTiGwTkWe81L1JRFREege2mS6vErynJiIKY/7kQ88DMFBVc0QkFsBKEflBVdc4VxKRGgAeBJAchHY6vU4wn52IKHz57KGrTY7xMNb4MZs0+ByAVwDkBq55RETkL7/G0EUkWkQ2AkgDsEhVk93O9wDQTFXn+XiecSKSIiIp6enpF9VgdtCJiMz5FdBVtVBVuwNoCqCPiHS2nxORKAD/BDDJj+eZoaq9VbV3fLzplng+CcdciIhMlWiWi6qeAbAcwDCn4hoAOgNYLiKpAJIAzA3WjVGGcyIic/7McokXkdrGcRUAgwHstJ9X1UxVra+qCaqaAGANgFGqGpRJ4uygExGZ86eH3hjAMhHZDOBX2MbQ54nIsyIyKrjNIyIif/mctqiqmwH0MCl/0qL+gNI3y1pWbr7jOK+wCB/8kooxSS0QFcWuOxFVbGG3UvTHbScdxxcKivDU3G34ZsPRELaIiKh8CLuAbpY29+yFgrJvCBFRORN+Ad10TRMREYVfQGc8JyIyFX4BPdQNICIqp8IvoDOiExGZCruAbiYvvyjUTSAiCrkwDOieXfQXvt8RgnYQEZUvYRfQOeRCRGQu7AL6dT2ahLoJRETlUtgF9Fbx1UPdBCKicinsAjoREZkLu4DOlaJERObCL6AznhMRmWJAJyKKEGEX0IsY0YmITDGgExFFiDAM6KFuARFR+RR2Ab121dhQN4GIqFwKu4DOhUVEROZ8BnQRqSwia0Vkk4hsE5FnTOo8LCLbRWSziCwRkRbBaa611FNny/oliYjKFX966HkABqpqNwDdAQwTkSS3OhsA9FbVrgC+AvBKYJvpG2+WElFF5zOgq02O8TDW+FG3OstU9ZzxcA2ApgFtpR+io6SsX5KIqFzxawxdRKJFZCOANACLVDXZS/W7Afxg8TzjRCRFRFLS09NL3lovooQBnYgqNr8CuqoWqmp32HrefUSks1k9ERkNoDeAVy2eZ4aq9lbV3vHx8RfbZlPLd6ejoJA7FxFRxVWiWS6qegbAcgDD3M+JyGAAjwEYpap5AWldCTzx7Va8tXRvWb8sEVG54c8sl3gRqW0cVwEwGMBOtzo9ALwLWzBPC0ZD/XHkt/OhemkiopCL8aNOYwAfiEg0bB8AX6jqPBF5FkCKqs6FbYilOoAvxTaWfUhVRwWr0VY4jE5EFZnPgK6qmwH0MCl/0ul4cIDbRUREJRR2K0W9YQediCqyyArojOhEVIFFVkBnH52IKrCICug7TmQ5jnPzC0PYEiKishdRAX3zkUwAwJcph9H+iQU4wIRdRFSBRFRAt1u47SQAYM/J7BC3hIio7ERkQCciqoj8WVgUVgZPW4G9aTm+KxIRRZiI66E7B3PhPEYiqkAiLqA7YzgnoookogM6EVFFwoBORBQhIjqgcwidiCqSiA7oREQVCQM6EVGEYEAnIooQER3QOYZORBVJRAd0IqKKJOID+tm8AiRMno+5m46FuilEREEV0QFdIDh65jwA4M0le0LcGiKi4PIZ0EWksoisFZFNIrJNRJ4xqVNJRD4Xkb0ikiwiCcFobIkJl/8TUcXhTw89D8BAVe0GoDuAYSKS5FbnbgC/qWprAP8E8HJgm3lxvll/FPu5yQURVRA+0+eqqgKwpzCMNX7Urdq1AJ42jr8C8LaIiPG7ITN30zGOnRNRheHXGLqIRIvIRgBpABaparJblSYADgOAqhYAyARQz+R5xolIioikpKenl67lJRTizxYioqDzK6CraqGqdgfQFEAfEensVsVsqNojgqrqDFXtraq94+PjS95aIiKyVKJZLqp6BsByAMPcTh0B0AwARCQGQC0ApwPQPiIi8pM/s1ziRaS2cVwFwGAAO92qzQUw1ji+CcDSUI+fExFVNP7sKdoYwAciEg3bB8AXqjpPRJ4FkKKqcwG8B+AjEdkLW8/81qC1mIiITPkzy2UzgB4m5U86HecCuDmwTSMiopKI6JWiREQVSVgH9Fdu6up3XQ7oE1GkC+uA/ofezULdBCKiciOsAzoRERWrOAGdYy5EFOEqTkAnIopwFSagM+siEUW6sA/ozetWDXUTiIjKhbAP6CO6NPa77pTZm9H7+UVBbA0RUej4s/Q/Yny69nCom0BEFDRh30NXTl8hIgIQAQGd8ZyIyCbsAzrjORGRTdgH9NLYm5aN385eCHUziIgCIuwDemn20Rg87SeMfPPnALaGiCh0wj6gD2jXoMS/8+CnGzDg1WUAgGOZuYFuEhFRSIR9QO/buj72vziiRL8zd9MxpGacC1KLiIhCI+wDOgBERUmom0BEFHIREdCJiIgBHQBwMOMszuYVhLoZRESl4jOgi0gzEVkmIjtEZJuITDSpU0tEvhORTUadO4PT3ODo/+pyjH4vOdTNICIqFX9yuRQAmKSq60WkBoB1IrJIVbc71ZkAYLuq/l5E4gHsEpFZqho2k7w3HDoT6iYQEZWKzx66qh5X1fXGcTaAHQCauFcDUENEBEB1AKdh+yAIK9m5+cg8lx/qZhARXZQSjaGLSAKAHgDcxyfeBtABwDEAWwBMVNUik98fJyIpIpKSnp5+UQ0Opq7P/Ihuz/7oUb79WBaO/MZpjkRUvvkd0EWkOoCvATykqllup4cC2AjgEgDdAbwtIjXdn0NVZ6hqb1XtHR8fX4pmB4fVotMRb/6MK19eVraNISIqIb8CuojEwhbMZ6nqbJMqdwKYrTZ7ARwA0D5wzXTV6ZKaeGhwm2A9PRFRWPJ5U9QYF38PwA5VnWZR7RCAQQB+FpGGANoB2B+wVrqZ/+BVwXpqIqKw5c8sl74AxgDYIiIbjbJHATQHAFWdDuA5AO+LyBYAAuARVT0VhPYSEZEFnwFdVVfCFqS91TkGYEigGnUxFj7UD0Nf/ymUTSAiCqmIWSnarlGNUDeBiCikIiagExFVdAzoREQRggGdiChCMKATEUUIBnQTK3anY+UezrokovASkQG9W7Papfr9sTPXMp0uEYWdiAzok4e1L3VQJyIKNxEZ0AHgilb1Qt0EIqIyFbEB/W9D2oW6CUREZSpiA3p0lNdsBX4rKPRI605EVC75k5yrwpqz8Sh2n8wOdTOIiPzCgO7FxM82mpYv3HYCbRpUR2J89TJuERGRtYgacrmsZd0yeZ37PlqHga+tKJPXIiLyV0QFdIsd5IiIKoSICuh2Epj7oUREYSUiA7rVZs9ERJEsIgN6sCRMno/07LxQN4OIyFREBvRgDrk89PkG0/K0rFwcO3MeAHAw4yy2Hs0MXiOIiExE5LTFYA65rNqb4fJ427FMqALXvLUSAJA6dST6v7rccUxEVFZ89tBFpJmILBORHSKyTUQmWtQbICIbjTrlYk7fdd0vCfprjHxzpSOYu1t74HTQX5+IyM6fIZcCAJNUtQOAJAATRKSjcwURqQ3gHQCjVLUTgJsD3tISsA+53Nm3pUv5lOHtEROglAD++MO7q8vstYiIfAZ0VT2uquuN42wAOwA0cat2G4DZqnrIqJcW6IZeDPex9OgowU29mgb1NRMmz/f6mIgoWEp0U1REEgD0AOC++0NbAHVEZLmIrBOR2y1+f5yIpIhISnp6+sW01y/extA5pZGIIpXfAV1EqgP4GsBDqprldjoGQC8AIwEMBfCEiLR1fw5VnaGqvVW1d3x8fCmaHd7OXSjAzhPul5CIqHT8CugiEgtbMJ+lqrNNqhwBsEBVz6rqKQA/AegWuGaWjH2oReA5Xq4BTBBwscMp42etx7DXf0ZeQWHA2kJE5M8sFwHwHoAdqjrNotocAFeJSIyIVAVwGWxj7WUqLtr2duxhvEmdKgDguBEqIcoJcObcBby+eDf2p+cAAJL322a/FBZx/IeIAsefHnpfAGMADDSmJW4UkREicr+I3A8AqroDwAIAmwGsBfBfVd0atFZbeO0P3XBf/0RcmmDLuli3WhxSp47E6KQWjjrOY+jTR/cqk3ZN+mITXl+8hxkaiSiofC4sUtWVgMnYhWe9VwG8GohGXayGNStjyvAOlufd30RTowcfbOk5TBdARMEXkUv/rYgUp9gd0rEhOjepVSavu/lIcRqAxdtPOo4544aIAqlCBHR1ipz2w8EdG4akLeM/We84LmJEJ6IAqhABvXXDGgCA5nWrOsrswy9tG5btNnIXCoo3nTa7J5qbX8iNqYnoolSIgD76suaYPf4KDOrQELHRtlAebcx8CUUn+Xy+bbpiYZEiN9916mL7Jxbg1hlryr5RRBT2IjLbojsRQc/mdQAAk4e3R7VKMbimqy1xVygHPf725SYs3ZnmkZUx5eBvIWoREYWzChHQndWuGocnrinOLRbKceylO8tFyhsiihAVYsjFm+qVKtxnGhFFqAof0Ns0qBHqJrjMwimpQxnn0HfqUpzIzAUAjzF5Iqo4KnxAL00wDZSs3AIMeHUZXlmws8S/Oyv5II6eOY9vNx7F+kO/of0TC7B8F4dyiCoiBnSTskY1K5dpGzYc+g2pGefwzvJ9LuVr9mdg4P8t997rNuZfTv1hJ1JSbTlipszegvMX2FMnqmgY0E166Fe0qle2bTAp23o0E8/N2479p85ib1oOvt1wFMNe/8mjnnNGyZw8WxA/npmLp+duC1ZziaicYkA3KyzjpIxpWbkeZde8tdKRBrhIFQ99vhE7T2RjzsajLvWcE0g6N/tY5nnH8bsr9mHoPz0/DIgosjCgm0R0szzqwfTI11tMy7NzCwAA+9PPOsomfrbRpY7zFqlvLNlj+jwv/bATu05mAwB+TT2NrNz80jSXiMopBnSTshClTfdwMOMcAOChzzfCam9rqw+fn/ecQvL+DKw7eNpRlpNXgJunr8afP14X8LYSUehV+EnYj45ojyJVzN983FFWTuK5C+e8L4cyzuF45nncMmMNhnhJMvbtxqNIrF+cqybfyCOz7Ri3vyOKRBW+h964VhX867aeLmXlpYdupd+ryxwzYn50SsfrSXDSZHyeiCJThQ/odi9e3wV9jJ2OwmFnuBW7033Wmbf5GP678oBHudl9g1/2ncKg15Zj9vojF9WeVxbsxDvL917U7xJRYDCgG267rDmGd2kEAKgWF+2z/uAODYLdpFKz31S123os06NO8v4M/G/VAdz2n2TsSz+Lh7/YhMOnz/n9Gm8u2YO9adl4Z/k+vLJgV6nbTEQXr8KPoVupUzUWv53zNhuknI/LmBjz3lqXx3tOZuMWk1S9+X7mY8/Kzce0Rbvx4erUALSOiEqLPXQnziFafAykW806CQf2xVQ3v7va9LyI4OM1B30G6iJjbMp50469aTnYn54DADh3ocCxYjU3vxCnz14oZcuJyBufAV1EmonIMhHZISLbRGSil7qXikihiNwU2GaWjcsSbStEh3Rq5FI+6XdtAQBXtanvKCvvN069UQWemrMVZyy+gQiAx7/diifnbEPm+XwUFSnaPv4DxryX7PE8ABDl9Ok2eNoKDHxtBQCg45ML0fO5RQCAm6evdhyXRG5+IXYbc+it5OQVeD1PVFH400MvADBJVTsASAIwQUQ6ulcSkWgALwNYGNgmlp0OjWsidepI9G1d36V8VPdL8JerW+OdP/W0+M3wkp1XgA9WH7Q879xz7/bMj3h8zlZcKCjCz3tOudSb+oMtmZi3zzb77kxbjnqO36sqdp7IQnZuvuW2ew9/sRFD/vkTsi0WQ32Rchidn1qIvWnegz5RReBzDF1VjwM4bhxni8gOAE0AbHer+gCArwFcGuhGhlpMdBT+NrRdqJtRZtKz81wef5J8yHGckZOHO9//FT2b18HnKYcBAFE+vq58adRzNyv5EB7/disA4IYeTTDtlu4edZL32xZG5eYXoYZJzrQlO2zTNveczEHrAKdCPnehAJVioh3bFRKVdyUaQxeRBAA9ACS7lTcBcD2A6T5+f5yIpIhISnq672l3oWT/E46vUQkNalRylM+8ozeGuQ3JVCS9nl+MzUcy8f4vqY6yDJOxcedhkL9/tdn0ubYfL17gNHvDUdM69nsZ6ramd9PhM7jmrZ+RX6hGPf/a79w+b1ksC4sUHZ9ciCfnbC3ZExOFkN8BXUSqw9YDf0hV3Zcavg7gEVX1mrNVVWeoam9V7R0fH1/y1obA9w9ehdjo4ss0sH1DTB/TyzEsM++BK0PVtHLtzv+t9V3JhKpiq9PwjD1Qu8+dv/Zfq7D1aJZjG7/7P16PHcf9XwHb+amFGPnmz5bnC40bvl9YfLsgKo/8CugiEgtbMJ+lqrNNqvQG8JmIpAK4CcA7InJdwFpZDo1JaoE1Uwahc5NajrJKMdaX896rWpZFs8qNX1O9b3RdVKT41q1Xnp6dh4/WHMQ1b610DKVEmQR0e953dwu3nShRG/c5JT2zbGcIFpmlZ+dh85EzZf/CFPb8meUiAN4DsENVp5nVUdWWqpqgqgkAvgIwXlW/DWhLy9j1PZoAAKpVMl9kJCJoVMt1ULdD45ouj0cnNXcc/2NY+wC3MDzlFRRCVfHpr4dwzm0TjktfWOwYyvnzrPVIST2Nk1m28fwrpi5xjO3bb8a6c54W+dHqVIx882esO+j9g+WhzzaYltuHeLztaPXYN1vwzYaSraxde+A0rnnrZ+QVWH+ZHf7GTxj19qoSPa8//rfqALb7yOOTknraZRoqhRd/euh9AYwBMFBENho/I0TkfhG5P8jtC5lHR3TAlqeHoGqc/2uv2jcqvilXo1IMnr+ui+NxbHQUdj8/HG0aVDf71Qqj3eML8PriPXh+3g7T8/ZUwRcKinDT9OLZNkUK/Ljd1gO3ugn74eqD2HzkDBZsPYEn5mzDtmNZuPHfvyBh8nzLWTDfbjxmWm6P49466LOSD+Gvn2/yUsPTE99uxdajWThwyvrbwamc4MzXf+a77RjhZZhp14ls3DR9NV783vz/DZV/PgO6qq5UVVHVrqra3fj5XlWnq6rHTVBVvUNVvwpOc8tOVJSgRuXYEv1Ol6a1sHRSfwBAFZP0AXExUWhRr1pA2hfO3liyxzGdsST2pdmCYJSXf7W7T+Z4DOUAwOBpvjf4uP6dVXj2O9fJW8HacrYcbGXrwf4NZ3sJ7kX440JBEc6c46KyssCVogGWGF8dfx/aDp+NSwp1UyLOzFUHMOGT9V43IPnnot0osoiWz363HTl5Bfjnot0u5f9aZksqtuHQGcxcZUtm5i3grtidbjlkcionD9NX7IOqYtPhMziY4doTt3+52H4sq9wNbTi++AT4w+aBT9ej+7MlX1RGJcdcLkEw4erWXs6Ww65ZGJm/+ThqVLL+Z3v0zHkcPXPe9NzMVQccAdvZqwt34dWFxYnFnp67Dd9YTKPcePgMxs5cizuuSHCU3TpjNZ4Z1RntGtXAbf9Zg90nc3BJ7Sp48FPb+Hzq1JEezzPpy03YfOQMnrm2s+V7sZKSehrv/rQf00f3Cugc+SiLKaKltXCbtxTPFEjsoQdAt6a2mS5l9TXa/eZrRZMd5KX+7/+SiszzxStTn/1uO+ZuOobCIsUL87c76tit2X8aQ40NvHeftOWxsQdzbz5YfRCLtp/E2gOnMeIN7zdKnd3/8Xos2n4SGTl5viuXQPEetgF9Wr/c9O9f0PmpsF1kXm4woAdAJ6epi/56cKC3XrynjhU8iIfSzFUH8OCnG/DwFxu9Tsf0NdVwb1oOdp5wvTl774cp+MO7q7H9eBZST3mmLVZVk7QIRsQtQefcebbOuQu2D0T3HDhiUtfd20v3YJfbe8jNLyxRymUzKQd/u6icPGlZuZZpIwoKizBh1npsM0kbbbftWCYSJs/HxsORMU2UAT2A/OnY2P9WujSt7Si7r1+iZf1Ff+2HRX/t55JHxtsfHAXPHIsZMXb7jCyT7uzpiO29eyvnLhR4fCg8+s0WtH7sB9P6zvcSzl8oxIrd6dhyJBNzNx1DwuT5LpuBO/e6Oz65EMt2pqHzUwvxq9OcfsciLov2XSgowv/9uBs3/vsXl/Lxs9bjqleWQVWx43gWMi2SvgX6321Wbj76vLgEz3xnfl33pZ/F/C3H8ZDbxurOlhkL0xZtL9kahvKKY+gBcMcVCZi36ZjX/T3tOjWphSU709CoZmWsmTIIZy8UoFV8dXRpWgux0VG476PiDZzjoqPQpqFtKmSqMc2ted2qwXkTVGpW0ynbPPYDXrqhC5bt8p7u4vp3XANlbn4hPl1bvFL1/IVCFKk6OgV70rKxNy0Hl7eqh67PLHSkQbA7lHHOsfDNPZje+f6vAGxTPVvHV0edanGw99Gt4q79ZrN7vnz7al1VYPgbP6NNg+pY9HB/k98HogVYsz8DtarElnroMMfYwGXxjpMY1y8RGw6fwahulzjO2+8FhHNm1JJiQA+Atg1rYPPTQ/2qO3FQG/yuQ0N0aeo6THNN10tcHk8e3h4D2pUsPcKAdvFY7iNoUPBsPmL91X7K7C0lfr72Tyxwedz35aUui6du+48tpdKaKYM8gjkAFDh1y63Gxb/bdAzbj2ViyaQBPnvo9tz2eRazc45l2m5G70kz/6bS+amFePOPPXDvhykAzG8WW8nNL8T5C4XGB48rVeD3b6/EmXP5LgHdThwfVLYPwyiTG8ml+fKQeT4fNSrFuDzvL/tO4fDpc7jl0uZefjPwOORSxqKjxCOYO6tr/IO9v38rtG9U3IOpasxrb9+oBmpUtn0OX5pQx3G+ca3KeHZUyWdMWOnfNjxy7ZQn75ns3xooadm5lhuEWN1M/TT5EFQVT87ZivGz1pnWAYpTIDhmuaji4c83ugzHAMD9H1s/BwBc+fIyr+fP5xc6gnlJjZ25Fj3c8uk797zNcvvbg3RqxlkcPn0On6w9hMRHv0ea08bpvjay8eXMuQvo9syPeG2R6/aLt/0nGY98bfsQz8jJsxznDzT20MtA6xKsDv3ugSuxxaSn16BmZXw2LgldmtTCb+cu4L2VB5BYv5rjJt3Tozqheb2q2PfiCCTvz8Bz83dgx/EszHvgSlzz1krT1/r47svw5brDpmPD7995KbYezcLHaw460uRS6PR5YYnluZe+N0+F8HnKYbRqUA0fesl9bzdn41FMNMaaNx/JxOYjmZi94ShWTxmIxrWqAACSDxQH+F9TTyOxfjWPfWvtujy1EH9KaoEW9ayHCNOyc9HALCeyCftrp2fnId4p+ykAnHAK0HYZOXmOgJ5XUISrXin+sDn82zk0qOnf6/pi/5D9fssJ/H2oZ3qPvIJC9Hp+MW7p3Qwv39Q1IK/pDXvoQbbzuWH4/sGr/K7fpHYVDOtsnp43KbEeqlWKQdM6VfHU7zu5dFHs/3ijowRXtK7vMgHi18cGmz5fo1qVTb+idmtWGyK2bxJ/cspHc+ClEX6/Dyo7C7wkJXvRIti7m2hx4/D+j9cjv7AIi7e7ziW/efpq9Hp+sem8fsA2tXT6in1eh5rMPqRW7jmFN5fssfydS19Y7Di2TxF1pqrYciQTvZ5fjK/WmefZKUmvPD07DwmT5+NrH89ldcPXPhQ2b7P3G+qBwoAeZJVjoxHnJQtjqTj9I2pQs5JlNfcejV3rBtUxqENDfP3nKzDzjt4AgDYNqmPOhL6OOl2dZuOU9usphZ/0rFy0eewH3GMxVBLjLQ/DRRj9XjKmua3kdQ+Wx42x+rEzPVM0qwK7jC0Lf9l3yuM8ABw/Yz3V0Z19f9xJX7rm7Nl1ItvlQ85qCN7+F3P2QiF+2HLcr9csDQb0MOZ8o6tn8zou59xj72fjknDrpc1Mn6dXizpoWsf21fhi7g01qV3FcfzvCNmmj2yOZXoOZzj7aU/pbsIPeHWZ1wVVK3ane2yQcvlLS7HJYt74R2sOYvmuNK+vOeGT9XjBzwRkzn9j9g1Rvkg5jKGv/4R7PkzBN+tde+4frk7FrGTzIa4/z1rv12uWBgN6GOvcxPe0L3vnJimxHgZ1sJ5W6c+iEivOQ0reXsPZ2scGlfh1qPzZazGjxV+pGefQ7vEFpufGzlyLsTPXmg6dLLMI2k/N3YZ5m209YfdFXM7+tyoVP+0u/jD6aPVBJEyejwVbXYevnP8ern17FTJy8vD+qlRH2ZtL9xr1bI+fnLMNj31TvMvV03O3WbYhGBjQw1ivFnUtz5mNjvyuY0OsmjzQa31/wvnNvZq6PK5VtTgrpb+pRaxuhv0w0f/7DRS5vl53BCt2W/f+X19sPc7ur9tnrsX/jHsA9nQS9t51fmERHv92i0vmyV0ns9Hr+cWm+XMuFBRh6U7PnDVfWoy9BwtnuYS58QNaoWV9z5S8ifWrY+vRLI8NOprUroLkRwd5LLOuaaQKdh+6cWefO2z1D9WfZFG3X97C63M//fuOePq77birb0vMXHUAtarEuuRWMdOrRR2fm1lQ+HAfsw4W99zzIoKzeQXo5CWvjNm/8RNZubjrfd9TMvel5yAuOgqX1K4SlM3HGdDDnNVOSFNv7IIbejZBYrznlMmGNSvDfWCkQc3K+P7Bq5AY71++dhHb18yXb7Rt4rH+id+hoKjI5cbpqG6XYPWzNX4AAA6mSURBVO4m67v7/dvGm/bC7ujbEnf0bemYWTCofQPLTaTtBnVowIBOpfbT7nQMf8N6ExDANq/9Yg16bQUA4IGBrTFpSLuLfh4rHHKJUFXjYjCgXYMS/U7HS2qicqznxhyf3HMZnrvOddFSOyMlgX0WTN1qcR7DKG/+sYfX15t5x6XY/fzwErXx9ybTLAPFvmCLKrZDPhKNmS1iKqnV+zJK/RxmGNDJpyta18eYJPNhEn/uoQ7t5Pp9wJ45MjpK/J7S2c9Yuer+JdVsHr03n49Lwn9v7+1R/um9SVhikn+klZ/fWIhKIlgzgNkloYtiH3O3Ggfs09J2w3b/iyMgUjyHfeeJLEfv3u6b8Vfg2Bnv0+PeHd0Ladm5HjMe7AmjvO1i5OyyxHpYssP15tVNvZri8lb1ANjG8TNy8tDredsClh8m9kPbx82zHdpd3S7eZ+ItoHiYiig3PzipANhDp4vy9m09MGV4e7Rt6DlGv2bKIHxwZx8AtkRIzuPq7RvV9Fig1KN5HYzs2tjytRS2PVpb1KuGiYPaOMrv798KlybYPjgaOC2eGuclHbEZ98+ketWLnysuJgqpU0d6TST11O87+fU69/dvZVr+p8vKNoEThV6weug+A7qINBORZSKyQ0S2ichEkzp/EpHNxs8vItItOM2l8qJBzcq4r38r09WjjWpVNt0ku6TaNbL15K8wes8AEBMdhb8PbYdvJ/TF5OHtMSapBWaM6YUbejZx1PnHUM+bTX8e0Mqxz6u9yd2a1sINPZpg8vAOpWqnv7MVKseYX5O/mGx28sc+5ovAKDIE65uaPz30AgCTVLUDgCQAE0Sko1udAwD6q2pXAM8BmBHYZlJF1LlJLax7fDBu7u0a3CZc3Rrdm9luxkZFCYZ0auTywRIdJXhshC1I92phm4bZt1V9JCXWc3meutXiMO2W7o4Ml/7q27oe3r7N84Zvs7pVTGrb9GheG/f19/zmsGbKIEfyK2fOmTYp8gR631Y7nwFdVY+r6nrjOBvADgBN3Or8oqr2OWNrALiuPCG6SM7DH74kGvPxRQT39ktE6tSRjpuazvPxezavg2px0RjvdTNvT89e2wkf3tUHs+5Jcslf79zbalrHMzj/5/be+GZ8X9MZRI1q2WYGPTqiveO+g+09lKhpFGZC2UN3EJEEAD0AJHupdjcA07tIIjJORFJEJCU9nRsxUGB9cf/l+OSey1zKnhnVGW/f1gM9nBZM1a4ah23PDnOMv5v58K4++N+dl7qU3X55gmO2jbPqxnTHKxLrY8FD/TzO/85kJ6t9L47AvheLs1eO69fKpe0C2wKr4Z0bOXLhA8CPfy1+fvu3EABo5CUd7LwHrsRfLD68+ni5BhQ8IQ/oIlIdwNcAHlLVLIs6V8MW0B8xO6+qM1S1t6r2jo/nBgoUWPWrV8IVreu7lFWJi/bYDcof/drG42o/5/HXrRaHJZP647nrOqNKbDRqVYnFIxYLvkZ2bYyezWsjOko8xt5joqNcbpDe0bcl/j26F5oZidOm/aEb2jas4Rhu6uq0Ucq1Pczf4/DOjRzb0DkTAZIfHYSpxsIwZ/dc2dLHO/Yf7wWYKwpSRPdr2qKIxMIWzGep6myLOl0B/BfAcFUNzqx5onLkx7/2QxVjGKWV04rcTU8NAQC8vGAnxg9wndnyr9u8Z6O8oWcTzEo+hCvbFHd4PrirD7YezcRgo6cfG138QbDykauRkXMB7RrVwLsr9rs814d39fH4RlG/eiWcysnDC9d1QUOjV7/3heEuG1E/Mrw9rul2CRLjq6Hr0z96bW/TOlVw5LfzluevbB3vsi+qNzPG9MK4j7zvikTe+QzoYrvb9B6AHao6zaJOcwCzAYxR1d1mdYgiTVu3+fTuSrJnpl2vFnU9fq9RrcqOsXYAmDKiA/7+5SZ0aVoLVeNiHKmP3fV22qLQfhNu7OUtMObyFqhVpTihWkx0FFo3qO7InBgbHeX4FvDi9V3Qp2UdvLfyAO7r1woD/m+5y2uMvTzBNBVth8Y1kZRY13KzltSpI5Eweb5Lmdk3iUgVrCEXf3rofQGMAbBFROzbmjwKoLmtYTodwJMA6gF4x5htUKCqnsvxiKjUejavgyWTBvisVzWu+M/bvg1iYnx11K7qOatn9vgrTHvjtxlDQC/d4Lp92rK/DUBObgE6XVLTNKB7y5q57G+2ts/9S1+MenuVozwmWhAXHYULZbT/ZiiFcpbLSlUVVe2qqt2Nn+9VdboRzKGq96hqHafzDOZEZeyPfWzBd8FDV+G9sa5/gtd1b4I5E/paLuCqWTkWtavGYojJDVx3zepWQcv61dClaS1ERQnuvapkY+727KBdm9bGLU5TUmOiorD2sUGYPrp4WGrycPN7Eb7y7lht5gIAy40PlFAK+U1RIirfXrqhC1KnjkT7RjU9NhoREXRrVtviN202PjkEM0zy3Dj78a/98N1frnQpm3B1a8RFR+EmI09+NYtFZYn1q3mcG3918T2GaBHUrhqHYZ0b49ER7dGsbhWMvTwBo5NcV9Le2LMpNjzxO4w1ScP86b1JSJ06ElNv7IqkRPMZPAn1qznyCdm5D3P1aO79Wnkz4WrzFcHOgnVTlAGdiPzWtmENjyGb2lXjsPuF4Y5MmHf2Ne+xL5nUH1ueHupS1qJecfIz5+1Jx/VrhZ//MRBV4qLx/HVd8Ny1nSAC3Nk3AU9c0wEx0VF44hr39Y1w5OQx88DA1kh+1LZT1vTRvRzllWNtL/zgwNZ40EgtUcdkWMrOfYMXd1F+LCII1sIxJuciooDo16Y+Zozphavbm0/3FBHTBVN/7NMMn649jEoWqREAYMzlCRhzeYJLWUx0yfqjV7dv4JjZ07xe8Y3kaKNRDw9ph/nG9nWVLLKA+trgBYDpArKf/n41Ms7m4fp3fgEAtKhnfiO7tBjQiSggRGxpGNy9cWt3rz3e567tjEeGtfc7lbKz+Q9eibN5hXhn+V7HJs7u7uybgEdHdECs2wfAZ+OScOuMNYhyWg9gTzY3rHMj/OC2v+hrNxenqLr10mb47FfX6Zi7nh+GtKw8bDDZwLp5vaq4pHZlXNWmPn7ec8pl8+lAYkAnoqC6tnsTr+djoqNMZ974o9MltqmOfVr28Th3Wct6WLP/NMYktfAI5gAcUzNHdim+UdymYQ3seHYYqsRFo23DGoiNjkJWbj7aNayBapWKw+VjIzsgv1CxeMdJx/aIlWKi0axuVTStUwUPfrrB9H1+dPdl+HrdEbQxyVIaCAzoRBSRHhzUBjf0bOIyTu+scmw0fn1sMOo4bXIOwJEptENj63HuGpVj8dofumHK7M0eC6fMMpA6u9HHGHxpMKATUUSKjhLLYG4XX8P/5G9Wr1GeMKATEV2k5nVtNzed5847++vgtmhcyzpxWqAxoBMRXaS7r0xEmwY1MKCdebLBiYPbmJYHCwM6EdFFio4S02maz1/XGV1CkJuGAZ2IKMBGJ3muYi0LXClKRBQhGNCJiCIEAzoRUYRgQCciihAM6EREEYIBnYgoQjCgExFFCAZ0IqIIIRqsze18vbBIOoCDF/nr9QGcCmBzIhGvkXe8Pr7xGnkXquvTQlVNcw2ELKCXhoikcCNq73iNvOP18Y3XyLvyeH045EJEFCEY0ImIIkS4BvQZoW5AGOA18o7XxzdeI+/K3fUJyzF0IiLyFK49dCIicsOATkQUIcIuoIvIMBHZJSJ7RWRyqNtTVkRkpoikichWp7K6IrJIRPYY/61jlIuIvGlco80i0tPpd8Ya9feIyNhQvJdgEZFmIrJMRHaIyDYRmWiU8zoBEJHKIrJWRDYZ1+cZo7yliCQb7/VzEYkzyisZj/ca5xOcnmuKUb5LRIaG5h0Fh4hEi8gGEZlnPA6f66OqYfMDIBrAPgCJAOIAbALQMdTtKqP33g9ATwBbncpeATDZOJ4M4GXjeASAHwAIgCQAyUZ5XQD7jf/WMY7rhPq9BfAaNQbQ0ziuAWA3gI68To7rIwCqG8exAJKN9/0FgFuN8ukA/mwcjwcw3Ti+FcDnxnFH42+vEoCWxt9kdKjfXwCv08MAPgEwz3gcNtcn3HrofQDsVdX9qnoBwGcArg1xm8qEqv4E4LRb8bUAPjCOPwBwnVP5h2qzBkBtEWkMYCiARap6WlV/A7AIwLDgt75sqOpxVV1vHGcD2AGgCXidAADG+8wxHsYaPwpgIICvjHL362O/bl8BGCQiYpR/pqp5qnoAwF7Y/jbDnog0BTASwH+Nx4Iwuj7hFtCbADjs9PiIUVZRNVTV44AtmAGw71ZrdZ0qzPUzvv72gK0XyutkMIYTNgJIg+2Dah+AM6paYFRxfq+O62CczwRQDxF8fQC8DuAfAIqMx/UQRtcn3AK6mJRx3qUnq+tUIa6fiFQH8DWAh1Q1y1tVk7KIvk6qWqiq3QE0ha3X2MGsmvHfCnV9ROQaAGmqus652KRqub0+4RbQjwBo5vS4KYBjIWpLeXDSGCKA8d80o9zqOkX89RORWNiC+SxVnW0U8zq5UdUzAJbDNoZeW0RijFPO79VxHYzztWAb9ovU69MXwCgRSYVtOHcgbD32sLk+4RbQfwXQxrjrHAfbjYi5IW5TKM0FYJ+BMRbAHKfy241ZHEkAMo2hhoUAhohIHWOmxxCjLCIY45fvAdihqtOcTvE6ARCReBGpbRxXATAYtvsMywDcZFRzvz7263YTgKVqu+s3F8CtxiyPlgDaAFhbNu8ieFR1iqo2VdUE2GLLUlX9E8Lp+oT6jvJF3IEeAdvshX0AHgt1e8rwfX8K4DiAfNh6AHfDNl63BMAe4791jboC4F/GNdoCoLfT89wF202avQDuDPX7CvA1uhK2r7abAWw0fkbwOjneU1cAG4zrsxXAk0Z5ImwBZy+ALwFUMsorG4/3GucTnZ7rMeO67QIwPNTvLQjXagCKZ7mEzfXh0n8ioggRbkMuRERkgQGdiChCMKATEUUIBnQiogjBgE5EFCEY0ImIIgQDOhFRhPh/CU07rCCpzS4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(Loss)),Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Another abstraction that any dl framework would provide is at the level of parameter updates and layer creation\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create a model with nn class ####\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w1=nn.Parameter(torch.randn((784,3),dtype=torch.float))\n",
    "        self.b1=nn.Parameter(torch.randn((3,),dtype=torch.float))\n",
    "        self.w2=nn.Parameter(torch.randn((3,10),dtype=torch.float))\n",
    "        self.b2=nn.Parameter(torch.randn((10,),dtype=torch.float))\n",
    "    def forward(self,X):\n",
    "        z1=torch.matmul(X.float(),self.w1)+self.b1\n",
    "        res1=torch.sigmoid(z1)\n",
    "        z2=torch.matmul(res1,self.w2)+self.b2\n",
    "        probs=torch.softmax(z2,axis=1)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 1, loss 3.0090157985687256, acc 0.10000000149011612\n",
      "Epoch 1, iter 2, loss 3.146354913711548, acc 0.07999999821186066\n",
      "Epoch 1, iter 3, loss 2.8467047214508057, acc 0.12999999523162842\n",
      "Epoch 1, iter 4, loss 2.9656484127044678, acc 0.15000000596046448\n",
      "Epoch 1, iter 5, loss 3.011373996734619, acc 0.15000000596046448\n",
      "Epoch 1, iter 6, loss 2.895967483520508, acc 0.11999999731779099\n",
      "Epoch 1, iter 7, loss 3.105537176132202, acc 0.05000000074505806\n",
      "Epoch 1, iter 8, loss 2.8901865482330322, acc 0.09000000357627869\n",
      "Epoch 1, iter 9, loss 3.0819036960601807, acc 0.07999999821186066\n",
      "Epoch 1, iter 10, loss 2.9675917625427246, acc 0.1599999964237213\n",
      "Epoch 1, iter 11, loss 3.1372387409210205, acc 0.10000000149011612\n",
      "Epoch 1, iter 12, loss 2.8326616287231445, acc 0.14000000059604645\n",
      "Epoch 1, iter 13, loss 2.829378366470337, acc 0.1599999964237213\n",
      "Epoch 1, iter 14, loss 2.8728878498077393, acc 0.10000000149011612\n",
      "Epoch 1, iter 15, loss 2.84531307220459, acc 0.07999999821186066\n",
      "Epoch 1, iter 16, loss 2.899996280670166, acc 0.10999999940395355\n",
      "Epoch 1, iter 17, loss 3.0152153968811035, acc 0.09000000357627869\n",
      "Epoch 1, iter 18, loss 3.2054593563079834, acc 0.03999999910593033\n",
      "Epoch 1, iter 19, loss 2.8189542293548584, acc 0.11999999731779099\n",
      "Epoch 1, iter 20, loss 2.959031343460083, acc 0.09000000357627869\n",
      "Epoch 1, iter 21, loss 3.113741874694824, acc 0.07000000029802322\n",
      "Epoch 1, iter 22, loss 3.2112433910369873, acc 0.07000000029802322\n",
      "Epoch 1, iter 23, loss 2.922739028930664, acc 0.12999999523162842\n",
      "Epoch 1, iter 24, loss 2.78700590133667, acc 0.14000000059604645\n",
      "Epoch 1, iter 25, loss 2.8865890502929688, acc 0.12999999523162842\n",
      "Epoch 1, iter 26, loss 2.970494270324707, acc 0.07000000029802322\n",
      "Epoch 1, iter 27, loss 3.1276679039001465, acc 0.10000000149011612\n",
      "Epoch 1, iter 28, loss 2.980419635772705, acc 0.09000000357627869\n",
      "Epoch 1, iter 29, loss 3.0857715606689453, acc 0.10000000149011612\n",
      "Epoch 1, iter 30, loss 3.0365800857543945, acc 0.09000000357627869\n",
      "Epoch 1, iter 31, loss 3.136364459991455, acc 0.07999999821186066\n",
      "Epoch 1, iter 32, loss 2.8228695392608643, acc 0.07999999821186066\n",
      "Epoch 1, iter 33, loss 2.9791247844696045, acc 0.11999999731779099\n",
      "Epoch 1, iter 34, loss 2.933439016342163, acc 0.07000000029802322\n",
      "Epoch 1, iter 35, loss 2.885084867477417, acc 0.12999999523162842\n",
      "Epoch 1, iter 36, loss 2.8036978244781494, acc 0.11999999731779099\n",
      "Epoch 1, iter 37, loss 2.981194496154785, acc 0.10000000149011612\n",
      "Epoch 1, iter 38, loss 3.0346453189849854, acc 0.11999999731779099\n",
      "Epoch 1, iter 39, loss 2.7387800216674805, acc 0.1599999964237213\n",
      "Epoch 1, iter 40, loss 3.000148057937622, acc 0.05999999865889549\n",
      "Epoch 1, iter 41, loss 2.9726085662841797, acc 0.07999999821186066\n",
      "Epoch 1, iter 42, loss 2.995781660079956, acc 0.07000000029802322\n",
      "Epoch 1, iter 43, loss 2.646263837814331, acc 0.10000000149011612\n",
      "Epoch 1, iter 44, loss 2.7455148696899414, acc 0.07999999821186066\n",
      "Epoch 1, iter 45, loss 2.9697940349578857, acc 0.05999999865889549\n",
      "Epoch 1, iter 46, loss 2.9051151275634766, acc 0.11999999731779099\n",
      "Epoch 1, iter 47, loss 2.8613266944885254, acc 0.17000000178813934\n",
      "Epoch 1, iter 48, loss 2.6783933639526367, acc 0.14000000059604645\n",
      "Epoch 1, iter 49, loss 2.8316216468811035, acc 0.10999999940395355\n",
      "Epoch 1, iter 50, loss 2.975616216659546, acc 0.09000000357627869\n",
      "Epoch 1, iter 51, loss 2.7961721420288086, acc 0.09000000357627869\n",
      "Epoch 1, iter 52, loss 2.881479263305664, acc 0.11999999731779099\n",
      "Epoch 1, iter 53, loss 2.746981620788574, acc 0.14000000059604645\n",
      "Epoch 1, iter 54, loss 2.6680755615234375, acc 0.12999999523162842\n",
      "Epoch 1, iter 55, loss 3.0280351638793945, acc 0.12999999523162842\n",
      "Epoch 1, iter 56, loss 2.820237159729004, acc 0.10999999940395355\n",
      "Epoch 1, iter 57, loss 3.0799038410186768, acc 0.10999999940395355\n",
      "Epoch 1, iter 58, loss 2.9302377700805664, acc 0.07999999821186066\n",
      "Epoch 1, iter 59, loss 2.8411693572998047, acc 0.10000000149011612\n",
      "Epoch 1, iter 60, loss 2.648676872253418, acc 0.10999999940395355\n",
      "Epoch 1, iter 61, loss 2.872912883758545, acc 0.11999999731779099\n",
      "Epoch 1, iter 62, loss 2.7316057682037354, acc 0.1899999976158142\n",
      "Epoch 1, iter 63, loss 2.978553056716919, acc 0.10999999940395355\n",
      "Epoch 1, iter 64, loss 2.7781708240509033, acc 0.09000000357627869\n",
      "Epoch 1, iter 65, loss 3.063830852508545, acc 0.11999999731779099\n",
      "Epoch 1, iter 66, loss 2.9706225395202637, acc 0.05999999865889549\n",
      "Epoch 1, iter 67, loss 2.8219046592712402, acc 0.12999999523162842\n",
      "Epoch 1, iter 68, loss 2.778524875640869, acc 0.10999999940395355\n",
      "Epoch 1, iter 69, loss 2.9083242416381836, acc 0.09000000357627869\n",
      "Epoch 1, iter 70, loss 2.9143130779266357, acc 0.12999999523162842\n",
      "Epoch 1, iter 71, loss 2.9963207244873047, acc 0.1599999964237213\n",
      "Epoch 1, iter 72, loss 2.8442819118499756, acc 0.07999999821186066\n",
      "Epoch 1, iter 73, loss 2.9701898097991943, acc 0.07999999821186066\n",
      "Epoch 1, iter 74, loss 2.758939743041992, acc 0.07999999821186066\n",
      "Epoch 1, iter 75, loss 2.870792865753174, acc 0.11999999731779099\n",
      "Epoch 1, iter 76, loss 2.8561513423919678, acc 0.07999999821186066\n",
      "Epoch 1, iter 77, loss 2.8084235191345215, acc 0.12999999523162842\n",
      "Epoch 1, iter 78, loss 2.8758018016815186, acc 0.10000000149011612\n",
      "Epoch 1, iter 79, loss 2.9838454723358154, acc 0.07000000029802322\n",
      "Epoch 1, iter 80, loss 2.7862415313720703, acc 0.15000000596046448\n",
      "Epoch 1, iter 81, loss 2.7910447120666504, acc 0.1599999964237213\n",
      "Epoch 1, iter 82, loss 2.8851325511932373, acc 0.14000000059604645\n",
      "Epoch 1, iter 83, loss 2.9924263954162598, acc 0.05000000074505806\n",
      "Epoch 1, iter 84, loss 2.817366600036621, acc 0.10999999940395355\n",
      "Epoch 1, iter 85, loss 2.8097083568573, acc 0.14000000059604645\n",
      "Epoch 1, iter 86, loss 2.903002977371216, acc 0.11999999731779099\n",
      "Epoch 1, iter 87, loss 2.670137882232666, acc 0.1599999964237213\n",
      "Epoch 1, iter 88, loss 2.8943238258361816, acc 0.07000000029802322\n",
      "Epoch 1, iter 89, loss 2.891507863998413, acc 0.10000000149011612\n",
      "Epoch 1, iter 90, loss 2.7615668773651123, acc 0.09000000357627869\n",
      "Epoch 1, iter 91, loss 2.802041530609131, acc 0.10999999940395355\n",
      "Epoch 1, iter 92, loss 2.944340705871582, acc 0.10000000149011612\n",
      "Epoch 1, iter 93, loss 2.791567325592041, acc 0.10999999940395355\n",
      "Epoch 1, iter 94, loss 2.6291136741638184, acc 0.18000000715255737\n",
      "Epoch 1, iter 95, loss 2.854802131652832, acc 0.15000000596046448\n",
      "Epoch 1, iter 96, loss 2.7641613483428955, acc 0.10000000149011612\n",
      "Epoch 1, iter 97, loss 2.876215934753418, acc 0.11999999731779099\n",
      "Epoch 1, iter 98, loss 2.7825167179107666, acc 0.07999999821186066\n",
      "Epoch 1, iter 99, loss 2.912313222885132, acc 0.07999999821186066\n",
      "Epoch 1, iter 100, loss 2.7037007808685303, acc 0.14000000059604645\n",
      "Epoch 1, iter 101, loss 2.6449079513549805, acc 0.14000000059604645\n",
      "Epoch 1, iter 102, loss 2.62498140335083, acc 0.12999999523162842\n",
      "Epoch 1, iter 103, loss 2.9078638553619385, acc 0.10999999940395355\n",
      "Epoch 1, iter 104, loss 2.797332763671875, acc 0.09000000357627869\n",
      "Epoch 1, iter 105, loss 2.659376621246338, acc 0.05999999865889549\n",
      "Epoch 1, iter 106, loss 2.524892807006836, acc 0.11999999731779099\n",
      "Epoch 1, iter 107, loss 2.689596652984619, acc 0.09000000357627869\n",
      "Epoch 1, iter 108, loss 2.7670998573303223, acc 0.11999999731779099\n",
      "Epoch 1, iter 109, loss 2.6306753158569336, acc 0.10999999940395355\n",
      "Epoch 1, iter 110, loss 2.941981315612793, acc 0.09000000357627869\n",
      "Epoch 1, iter 111, loss 2.772361993789673, acc 0.10000000149011612\n",
      "Epoch 1, iter 112, loss 2.628167152404785, acc 0.10999999940395355\n",
      "Epoch 1, iter 113, loss 2.823176622390747, acc 0.09000000357627869\n",
      "Epoch 1, iter 114, loss 2.5424654483795166, acc 0.10999999940395355\n",
      "Epoch 1, iter 115, loss 2.6544530391693115, acc 0.10999999940395355\n",
      "Epoch 1, iter 116, loss 2.6493515968322754, acc 0.09000000357627869\n",
      "Epoch 1, iter 117, loss 2.818375587463379, acc 0.10000000149011612\n",
      "Epoch 1, iter 118, loss 2.831451416015625, acc 0.09000000357627869\n",
      "Epoch 1, iter 119, loss 2.743713617324829, acc 0.10999999940395355\n",
      "Epoch 1, iter 120, loss 2.7771570682525635, acc 0.14000000059604645\n",
      "Epoch 1, iter 121, loss 2.8028757572174072, acc 0.11999999731779099\n",
      "Epoch 1, iter 122, loss 2.8883981704711914, acc 0.07999999821186066\n",
      "Epoch 1, iter 123, loss 2.850902795791626, acc 0.10000000149011612\n",
      "Epoch 1, iter 124, loss 2.6572604179382324, acc 0.07000000029802322\n",
      "Epoch 1, iter 125, loss 2.6513686180114746, acc 0.17000000178813934\n",
      "Epoch 1, iter 126, loss 2.816258430480957, acc 0.05999999865889549\n",
      "Epoch 1, iter 127, loss 2.7655575275421143, acc 0.10000000149011612\n",
      "Epoch 1, iter 128, loss 2.59417724609375, acc 0.18000000715255737\n",
      "Epoch 1, iter 129, loss 2.8237781524658203, acc 0.10000000149011612\n",
      "Epoch 1, iter 130, loss 2.8849337100982666, acc 0.10999999940395355\n",
      "Epoch 1, iter 131, loss 2.8522565364837646, acc 0.09000000357627869\n",
      "Epoch 1, iter 132, loss 2.688944101333618, acc 0.10999999940395355\n",
      "Epoch 1, iter 133, loss 2.735487937927246, acc 0.09000000357627869\n",
      "Epoch 1, iter 134, loss 2.8819468021392822, acc 0.07000000029802322\n",
      "Epoch 1, iter 135, loss 2.6598660945892334, acc 0.10999999940395355\n",
      "Epoch 1, iter 136, loss 2.804455041885376, acc 0.05999999865889549\n",
      "Epoch 1, iter 137, loss 2.751587152481079, acc 0.10000000149011612\n",
      "Epoch 1, iter 138, loss 2.6380059719085693, acc 0.15000000596046448\n",
      "Epoch 1, iter 139, loss 2.8175160884857178, acc 0.09000000357627869\n",
      "Epoch 1, iter 140, loss 2.92075252532959, acc 0.07000000029802322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 141, loss 2.7146570682525635, acc 0.10000000149011612\n",
      "Epoch 1, iter 142, loss 2.736245632171631, acc 0.12999999523162842\n",
      "Epoch 1, iter 143, loss 2.6926608085632324, acc 0.10999999940395355\n",
      "Epoch 1, iter 144, loss 2.8272898197174072, acc 0.10000000149011612\n",
      "Epoch 1, iter 145, loss 2.866701126098633, acc 0.05999999865889549\n",
      "Epoch 1, iter 146, loss 2.7772417068481445, acc 0.09000000357627869\n",
      "Epoch 1, iter 147, loss 2.6977148056030273, acc 0.07000000029802322\n",
      "Epoch 1, iter 148, loss 2.7026844024658203, acc 0.05000000074505806\n",
      "Epoch 1, iter 149, loss 2.8730220794677734, acc 0.009999999776482582\n",
      "Epoch 1, iter 150, loss 2.516557216644287, acc 0.14000000059604645\n",
      "Epoch 1, iter 151, loss 2.612522602081299, acc 0.07000000029802322\n",
      "Epoch 1, iter 152, loss 2.673288583755493, acc 0.11999999731779099\n",
      "Epoch 1, iter 153, loss 2.746077299118042, acc 0.11999999731779099\n",
      "Epoch 1, iter 154, loss 2.7219648361206055, acc 0.05999999865889549\n",
      "Epoch 1, iter 155, loss 2.699500799179077, acc 0.07999999821186066\n",
      "Epoch 1, iter 156, loss 2.6088173389434814, acc 0.09000000357627869\n",
      "Epoch 1, iter 157, loss 2.9048497676849365, acc 0.10999999940395355\n",
      "Epoch 1, iter 158, loss 2.7797393798828125, acc 0.10999999940395355\n",
      "Epoch 1, iter 159, loss 2.7137928009033203, acc 0.10999999940395355\n",
      "Epoch 1, iter 160, loss 2.640293836593628, acc 0.14000000059604645\n",
      "Epoch 1, iter 161, loss 2.8616249561309814, acc 0.10000000149011612\n",
      "Epoch 1, iter 162, loss 2.5841546058654785, acc 0.09000000357627869\n",
      "Epoch 1, iter 163, loss 2.9395363330841064, acc 0.09000000357627869\n",
      "Epoch 1, iter 164, loss 2.9723262786865234, acc 0.10000000149011612\n",
      "Epoch 1, iter 165, loss 2.794429063796997, acc 0.12999999523162842\n",
      "Epoch 1, iter 166, loss 2.8184523582458496, acc 0.07999999821186066\n",
      "Epoch 1, iter 167, loss 2.6411190032958984, acc 0.09000000357627869\n",
      "Epoch 1, iter 168, loss 2.7414121627807617, acc 0.05999999865889549\n",
      "Epoch 1, iter 169, loss 2.6808013916015625, acc 0.09000000357627869\n",
      "Epoch 1, iter 170, loss 2.7335641384124756, acc 0.07000000029802322\n",
      "Epoch 1, iter 171, loss 2.7204277515411377, acc 0.10999999940395355\n",
      "Epoch 1, iter 172, loss 2.678483009338379, acc 0.10000000149011612\n",
      "Epoch 1, iter 173, loss 2.632213830947876, acc 0.1899999976158142\n",
      "Epoch 1, iter 174, loss 2.5964267253875732, acc 0.1599999964237213\n",
      "Epoch 1, iter 175, loss 2.640773296356201, acc 0.18000000715255737\n",
      "Epoch 1, iter 176, loss 2.707054853439331, acc 0.14000000059604645\n",
      "Epoch 1, iter 177, loss 2.4894559383392334, acc 0.1899999976158142\n",
      "Epoch 1, iter 178, loss 2.658303737640381, acc 0.15000000596046448\n",
      "Epoch 1, iter 179, loss 2.6728272438049316, acc 0.1599999964237213\n",
      "Epoch 1, iter 180, loss 2.6177098751068115, acc 0.15000000596046448\n",
      "Epoch 1, iter 181, loss 2.593949556350708, acc 0.17000000178813934\n",
      "Epoch 1, iter 182, loss 2.61824893951416, acc 0.17000000178813934\n",
      "Epoch 1, iter 183, loss 2.577254056930542, acc 0.1899999976158142\n",
      "Epoch 1, iter 184, loss 2.813041925430298, acc 0.10999999940395355\n",
      "Epoch 1, iter 185, loss 2.503350019454956, acc 0.17000000178813934\n",
      "Epoch 1, iter 186, loss 2.6313352584838867, acc 0.14000000059604645\n",
      "Epoch 1, iter 187, loss 2.72184419631958, acc 0.1599999964237213\n",
      "Epoch 1, iter 188, loss 2.6817429065704346, acc 0.14000000059604645\n",
      "Epoch 1, iter 189, loss 2.603757381439209, acc 0.1599999964237213\n",
      "Epoch 1, iter 190, loss 2.7587671279907227, acc 0.12999999523162842\n",
      "Epoch 1, iter 191, loss 2.3998067378997803, acc 0.25\n",
      "Epoch 1, iter 192, loss 2.750974416732788, acc 0.11999999731779099\n",
      "Epoch 1, iter 193, loss 2.56655216217041, acc 0.10000000149011612\n",
      "Epoch 1, iter 194, loss 2.5526812076568604, acc 0.14000000059604645\n",
      "Epoch 1, iter 195, loss 2.878053665161133, acc 0.10999999940395355\n",
      "Epoch 1, iter 196, loss 2.7169594764709473, acc 0.07999999821186066\n",
      "Epoch 1, iter 197, loss 2.5992701053619385, acc 0.11999999731779099\n",
      "Epoch 1, iter 198, loss 2.5896942615509033, acc 0.10999999940395355\n",
      "Epoch 1, iter 199, loss 2.5911061763763428, acc 0.12999999523162842\n",
      "Epoch 1, iter 200, loss 2.718924045562744, acc 0.10000000149011612\n",
      "Epoch 1, iter 201, loss 2.7955198287963867, acc 0.09000000357627869\n",
      "Epoch 1, iter 202, loss 2.681118965148926, acc 0.15000000596046448\n",
      "Epoch 1, iter 203, loss 2.712676763534546, acc 0.11999999731779099\n",
      "Epoch 1, iter 204, loss 2.735661029815674, acc 0.10000000149011612\n",
      "Epoch 1, iter 205, loss 2.541356086730957, acc 0.14000000059604645\n",
      "Epoch 1, iter 206, loss 2.5497384071350098, acc 0.1599999964237213\n",
      "Epoch 1, iter 207, loss 2.6588187217712402, acc 0.11999999731779099\n",
      "Epoch 1, iter 208, loss 2.8646581172943115, acc 0.10999999940395355\n",
      "Epoch 1, iter 209, loss 2.660709857940674, acc 0.10999999940395355\n",
      "Epoch 1, iter 210, loss 2.7683093547821045, acc 0.1599999964237213\n",
      "Epoch 1, iter 211, loss 2.631422758102417, acc 0.1599999964237213\n",
      "Epoch 1, iter 212, loss 2.4688947200775146, acc 0.1899999976158142\n",
      "Epoch 1, iter 213, loss 2.601283311843872, acc 0.17000000178813934\n",
      "Epoch 1, iter 214, loss 2.7542409896850586, acc 0.12999999523162842\n",
      "Epoch 1, iter 215, loss 2.5882387161254883, acc 0.1599999964237213\n",
      "Epoch 1, iter 216, loss 2.7881712913513184, acc 0.10999999940395355\n",
      "Epoch 1, iter 217, loss 2.5464060306549072, acc 0.15000000596046448\n",
      "Epoch 1, iter 218, loss 2.726497173309326, acc 0.18000000715255737\n",
      "Epoch 1, iter 219, loss 2.573716163635254, acc 0.20999999344348907\n",
      "Epoch 1, iter 220, loss 2.6157708168029785, acc 0.07000000029802322\n",
      "Epoch 1, iter 221, loss 2.649554491043091, acc 0.14000000059604645\n",
      "Epoch 1, iter 222, loss 2.570880651473999, acc 0.14000000059604645\n",
      "Epoch 1, iter 223, loss 2.7286384105682373, acc 0.11999999731779099\n",
      "Epoch 1, iter 224, loss 2.6129884719848633, acc 0.14000000059604645\n",
      "Epoch 1, iter 225, loss 2.495652198791504, acc 0.1899999976158142\n",
      "Epoch 1, iter 226, loss 2.668095350265503, acc 0.10000000149011612\n",
      "Epoch 1, iter 227, loss 2.6034772396087646, acc 0.1599999964237213\n",
      "Epoch 1, iter 228, loss 2.5647776126861572, acc 0.1599999964237213\n",
      "Epoch 1, iter 229, loss 2.6306886672973633, acc 0.10000000149011612\n",
      "Epoch 1, iter 230, loss 2.605649948120117, acc 0.11999999731779099\n",
      "Epoch 1, iter 231, loss 2.5835883617401123, acc 0.1599999964237213\n",
      "Epoch 1, iter 232, loss 2.7330727577209473, acc 0.10000000149011612\n",
      "Epoch 1, iter 233, loss 2.656290292739868, acc 0.12999999523162842\n",
      "Epoch 1, iter 234, loss 2.609488010406494, acc 0.10999999940395355\n",
      "Epoch 1, iter 235, loss 2.7294037342071533, acc 0.09000000357627869\n",
      "Epoch 1, iter 236, loss 2.653881311416626, acc 0.17000000178813934\n",
      "Epoch 1, iter 237, loss 2.6500627994537354, acc 0.14000000059604645\n",
      "Epoch 1, iter 238, loss 2.6498525142669678, acc 0.14000000059604645\n",
      "Epoch 1, iter 239, loss 2.8607845306396484, acc 0.05000000074505806\n",
      "Epoch 1, iter 240, loss 2.576697587966919, acc 0.18000000715255737\n",
      "Epoch 1, iter 241, loss 2.668736219406128, acc 0.12999999523162842\n",
      "Epoch 1, iter 242, loss 2.757944107055664, acc 0.09000000357627869\n",
      "Epoch 1, iter 243, loss 2.7214667797088623, acc 0.1899999976158142\n",
      "Epoch 1, iter 244, loss 2.6222763061523438, acc 0.1599999964237213\n",
      "Epoch 1, iter 245, loss 2.5265591144561768, acc 0.15000000596046448\n",
      "Epoch 1, iter 246, loss 2.600752830505371, acc 0.1599999964237213\n",
      "Epoch 1, iter 247, loss 2.638399600982666, acc 0.09000000357627869\n",
      "Epoch 1, iter 248, loss 2.5094754695892334, acc 0.1599999964237213\n",
      "Epoch 1, iter 249, loss 2.6294422149658203, acc 0.12999999523162842\n",
      "Epoch 1, iter 250, loss 2.5315020084381104, acc 0.1599999964237213\n",
      "Epoch 1, iter 251, loss 2.5706818103790283, acc 0.1599999964237213\n",
      "Epoch 1, iter 252, loss 2.5061981678009033, acc 0.14000000059604645\n",
      "Epoch 1, iter 253, loss 2.7461159229278564, acc 0.14000000059604645\n",
      "Epoch 1, iter 254, loss 2.551682949066162, acc 0.17000000178813934\n",
      "Epoch 1, iter 255, loss 2.779128313064575, acc 0.1599999964237213\n",
      "Epoch 1, iter 256, loss 2.7640132904052734, acc 0.11999999731779099\n",
      "Epoch 1, iter 257, loss 2.5434794425964355, acc 0.1899999976158142\n",
      "Epoch 1, iter 258, loss 2.696096181869507, acc 0.1599999964237213\n",
      "Epoch 1, iter 259, loss 2.618387460708618, acc 0.11999999731779099\n",
      "Epoch 1, iter 260, loss 2.5272789001464844, acc 0.10999999940395355\n",
      "Epoch 1, iter 261, loss 2.5629334449768066, acc 0.14000000059604645\n",
      "Epoch 1, iter 262, loss 2.7528717517852783, acc 0.14000000059604645\n",
      "Epoch 1, iter 263, loss 2.514197826385498, acc 0.14000000059604645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 264, loss 2.512903928756714, acc 0.12999999523162842\n",
      "Epoch 1, iter 265, loss 2.425286054611206, acc 0.1899999976158142\n",
      "Epoch 1, iter 266, loss 2.6450564861297607, acc 0.14000000059604645\n",
      "Epoch 1, iter 267, loss 2.526576519012451, acc 0.14000000059604645\n",
      "Epoch 1, iter 268, loss 2.5235238075256348, acc 0.18000000715255737\n",
      "Epoch 1, iter 269, loss 2.5095784664154053, acc 0.18000000715255737\n",
      "Epoch 1, iter 270, loss 2.691629409790039, acc 0.09000000357627869\n",
      "Epoch 1, iter 271, loss 2.52885365486145, acc 0.20000000298023224\n",
      "Epoch 1, iter 272, loss 2.5998852252960205, acc 0.12999999523162842\n",
      "Epoch 1, iter 273, loss 2.6757471561431885, acc 0.10000000149011612\n",
      "Epoch 1, iter 274, loss 2.656121253967285, acc 0.07999999821186066\n",
      "Epoch 1, iter 275, loss 2.687093734741211, acc 0.10000000149011612\n",
      "Epoch 1, iter 276, loss 2.6444361209869385, acc 0.12999999523162842\n",
      "Epoch 1, iter 277, loss 2.3674964904785156, acc 0.1899999976158142\n",
      "Epoch 1, iter 278, loss 2.5372507572174072, acc 0.17000000178813934\n",
      "Epoch 1, iter 279, loss 2.6915886402130127, acc 0.15000000596046448\n",
      "Epoch 1, iter 280, loss 2.657419204711914, acc 0.11999999731779099\n",
      "Epoch 1, iter 281, loss 2.551499843597412, acc 0.17000000178813934\n",
      "Epoch 1, iter 282, loss 2.480044364929199, acc 0.2199999988079071\n",
      "Epoch 1, iter 283, loss 2.606762409210205, acc 0.17000000178813934\n",
      "Epoch 1, iter 284, loss 2.577793598175049, acc 0.09000000357627869\n",
      "Epoch 1, iter 285, loss 2.5786054134368896, acc 0.14000000059604645\n",
      "Epoch 1, iter 286, loss 2.595045804977417, acc 0.15000000596046448\n",
      "Epoch 1, iter 287, loss 2.5527241230010986, acc 0.11999999731779099\n",
      "Epoch 1, iter 288, loss 2.6757848262786865, acc 0.07999999821186066\n",
      "Epoch 1, iter 289, loss 2.7660164833068848, acc 0.10000000149011612\n",
      "Epoch 1, iter 290, loss 2.6316051483154297, acc 0.10000000149011612\n",
      "Epoch 1, iter 291, loss 2.664538621902466, acc 0.1599999964237213\n",
      "Epoch 1, iter 292, loss 2.514028549194336, acc 0.14000000059604645\n",
      "Epoch 1, iter 293, loss 2.6435201168060303, acc 0.11999999731779099\n",
      "Epoch 1, iter 294, loss 2.3964109420776367, acc 0.27000001072883606\n",
      "Epoch 1, iter 295, loss 2.6481549739837646, acc 0.15000000596046448\n",
      "Epoch 1, iter 296, loss 2.531294584274292, acc 0.10000000149011612\n",
      "Epoch 1, iter 297, loss 2.7127373218536377, acc 0.12999999523162842\n",
      "Epoch 1, iter 298, loss 2.4885337352752686, acc 0.18000000715255737\n",
      "Epoch 1, iter 299, loss 2.791837215423584, acc 0.10000000149011612\n",
      "Epoch 1, iter 300, loss 2.531855344772339, acc 0.12999999523162842\n",
      "Epoch 1, iter 301, loss 2.7251322269439697, acc 0.12999999523162842\n",
      "Epoch 1, iter 302, loss 2.552349090576172, acc 0.15000000596046448\n",
      "Epoch 1, iter 303, loss 2.7395517826080322, acc 0.07999999821186066\n",
      "Epoch 1, iter 304, loss 2.7860054969787598, acc 0.10999999940395355\n",
      "Epoch 1, iter 305, loss 2.5997049808502197, acc 0.1899999976158142\n",
      "Epoch 1, iter 306, loss 2.5041213035583496, acc 0.12999999523162842\n",
      "Epoch 1, iter 307, loss 2.4732420444488525, acc 0.18000000715255737\n",
      "Epoch 1, iter 308, loss 2.5500986576080322, acc 0.20999999344348907\n",
      "Epoch 1, iter 309, loss 2.5458617210388184, acc 0.14000000059604645\n",
      "Epoch 1, iter 310, loss 2.5776867866516113, acc 0.10999999940395355\n",
      "Epoch 1, iter 311, loss 2.633327007293701, acc 0.15000000596046448\n",
      "Epoch 1, iter 312, loss 2.6112313270568848, acc 0.12999999523162842\n",
      "Epoch 1, iter 313, loss 2.5835299491882324, acc 0.15000000596046448\n",
      "Epoch 1, iter 314, loss 2.3624651432037354, acc 0.1599999964237213\n",
      "Epoch 1, iter 315, loss 2.480156898498535, acc 0.1899999976158142\n",
      "Epoch 1, iter 316, loss 2.6461596488952637, acc 0.17000000178813934\n",
      "Epoch 1, iter 317, loss 2.7292327880859375, acc 0.15000000596046448\n",
      "Epoch 1, iter 318, loss 2.4754750728607178, acc 0.17000000178813934\n",
      "Epoch 1, iter 319, loss 2.4223742485046387, acc 0.23999999463558197\n",
      "Epoch 1, iter 320, loss 2.6553592681884766, acc 0.18000000715255737\n",
      "Epoch 1, iter 321, loss 2.699246883392334, acc 0.14000000059604645\n",
      "Epoch 1, iter 322, loss 2.6843814849853516, acc 0.09000000357627869\n",
      "Epoch 1, iter 323, loss 2.3807315826416016, acc 0.15000000596046448\n",
      "Epoch 1, iter 324, loss 2.4812347888946533, acc 0.11999999731779099\n",
      "Epoch 1, iter 325, loss 2.642979621887207, acc 0.14000000059604645\n",
      "Epoch 1, iter 326, loss 2.48111629486084, acc 0.09000000357627869\n",
      "Epoch 1, iter 327, loss 2.581571340560913, acc 0.14000000059604645\n",
      "Epoch 1, iter 328, loss 2.636928081512451, acc 0.07999999821186066\n",
      "Epoch 1, iter 329, loss 2.5925769805908203, acc 0.11999999731779099\n",
      "Epoch 1, iter 330, loss 2.561513900756836, acc 0.20000000298023224\n",
      "Epoch 1, iter 331, loss 2.4756858348846436, acc 0.20999999344348907\n",
      "Epoch 1, iter 332, loss 2.357901096343994, acc 0.23999999463558197\n",
      "Epoch 1, iter 333, loss 2.5301589965820312, acc 0.14000000059604645\n",
      "Epoch 1, iter 334, loss 2.560044765472412, acc 0.17000000178813934\n",
      "Epoch 1, iter 335, loss 2.462834358215332, acc 0.18000000715255737\n",
      "Epoch 1, iter 336, loss 2.3981008529663086, acc 0.12999999523162842\n",
      "Epoch 1, iter 337, loss 2.6998865604400635, acc 0.07000000029802322\n",
      "Epoch 1, iter 338, loss 2.5173420906066895, acc 0.1599999964237213\n",
      "Epoch 1, iter 339, loss 2.437018871307373, acc 0.1899999976158142\n",
      "Epoch 1, iter 340, loss 2.6646945476531982, acc 0.12999999523162842\n",
      "Epoch 1, iter 341, loss 2.4542622566223145, acc 0.15000000596046448\n",
      "Epoch 1, iter 342, loss 2.470067024230957, acc 0.1599999964237213\n",
      "Epoch 1, iter 343, loss 2.501863718032837, acc 0.17000000178813934\n",
      "Epoch 1, iter 344, loss 2.5735254287719727, acc 0.11999999731779099\n",
      "Epoch 1, iter 345, loss 2.4662187099456787, acc 0.1899999976158142\n",
      "Epoch 1, iter 346, loss 2.6534948348999023, acc 0.09000000357627869\n",
      "Epoch 1, iter 347, loss 2.4001076221466064, acc 0.2199999988079071\n",
      "Epoch 1, iter 348, loss 2.4623804092407227, acc 0.15000000596046448\n",
      "Epoch 1, iter 349, loss 2.3962924480438232, acc 0.1599999964237213\n",
      "Epoch 1, iter 350, loss 2.5585904121398926, acc 0.15000000596046448\n",
      "Epoch 1, iter 351, loss 2.6110565662384033, acc 0.14000000059604645\n",
      "Epoch 1, iter 352, loss 2.4808645248413086, acc 0.15000000596046448\n",
      "Epoch 1, iter 353, loss 2.583644390106201, acc 0.15000000596046448\n",
      "Epoch 1, iter 354, loss 2.5220282077789307, acc 0.12999999523162842\n",
      "Epoch 1, iter 355, loss 2.5821750164031982, acc 0.12999999523162842\n",
      "Epoch 1, iter 356, loss 2.5670852661132812, acc 0.1599999964237213\n",
      "Epoch 1, iter 357, loss 2.5084025859832764, acc 0.18000000715255737\n",
      "Epoch 1, iter 358, loss 2.5387918949127197, acc 0.23000000417232513\n",
      "Epoch 1, iter 359, loss 2.5912489891052246, acc 0.09000000357627869\n",
      "Epoch 1, iter 360, loss 2.5342018604278564, acc 0.12999999523162842\n",
      "Epoch 1, iter 361, loss 2.5938963890075684, acc 0.09000000357627869\n",
      "Epoch 1, iter 362, loss 2.6062047481536865, acc 0.12999999523162842\n",
      "Epoch 1, iter 363, loss 2.4730429649353027, acc 0.14000000059604645\n",
      "Epoch 1, iter 364, loss 2.5251779556274414, acc 0.20000000298023224\n",
      "Epoch 1, iter 365, loss 2.560600519180298, acc 0.14000000059604645\n",
      "Epoch 1, iter 366, loss 2.418112277984619, acc 0.18000000715255737\n",
      "Epoch 1, iter 367, loss 2.560427665710449, acc 0.09000000357627869\n",
      "Epoch 1, iter 368, loss 2.526413679122925, acc 0.17000000178813934\n",
      "Epoch 1, iter 369, loss 2.521268367767334, acc 0.10999999940395355\n",
      "Epoch 1, iter 370, loss 2.553560733795166, acc 0.12999999523162842\n",
      "Epoch 1, iter 371, loss 2.5335280895233154, acc 0.07999999821186066\n",
      "Epoch 1, iter 372, loss 2.3932862281799316, acc 0.20999999344348907\n",
      "Epoch 1, iter 373, loss 2.6373353004455566, acc 0.12999999523162842\n",
      "Epoch 1, iter 374, loss 2.5501303672790527, acc 0.11999999731779099\n",
      "Epoch 1, iter 375, loss 2.5305376052856445, acc 0.10999999940395355\n",
      "Epoch 1, iter 376, loss 2.524247169494629, acc 0.11999999731779099\n",
      "Epoch 1, iter 377, loss 2.612720012664795, acc 0.07000000029802322\n",
      "Epoch 1, iter 378, loss 2.5403971672058105, acc 0.17000000178813934\n",
      "Epoch 1, iter 379, loss 2.588012456893921, acc 0.14000000059604645\n",
      "Epoch 1, iter 380, loss 2.5756237506866455, acc 0.14000000059604645\n",
      "Epoch 1, iter 381, loss 2.6106982231140137, acc 0.15000000596046448\n",
      "Epoch 1, iter 382, loss 2.492779493331909, acc 0.18000000715255737\n",
      "Epoch 1, iter 383, loss 2.521202802658081, acc 0.1899999976158142\n",
      "Epoch 1, iter 384, loss 2.5440616607666016, acc 0.10999999940395355\n",
      "Epoch 1, iter 385, loss 2.632171392440796, acc 0.10000000149011612\n",
      "Epoch 1, iter 386, loss 2.5322694778442383, acc 0.15000000596046448\n",
      "Epoch 1, iter 387, loss 2.5694544315338135, acc 0.12999999523162842\n",
      "Epoch 1, iter 388, loss 2.5325050354003906, acc 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 389, loss 2.5634849071502686, acc 0.17000000178813934\n",
      "Epoch 1, iter 390, loss 2.5601577758789062, acc 0.18000000715255737\n",
      "Epoch 1, iter 391, loss 2.5677378177642822, acc 0.17000000178813934\n",
      "Epoch 1, iter 392, loss 2.7361254692077637, acc 0.11999999731779099\n",
      "Epoch 1, iter 393, loss 2.5047597885131836, acc 0.12999999523162842\n",
      "Epoch 1, iter 394, loss 2.496879816055298, acc 0.1599999964237213\n",
      "Epoch 1, iter 395, loss 2.5064713954925537, acc 0.12999999523162842\n",
      "Epoch 1, iter 396, loss 2.6894681453704834, acc 0.12999999523162842\n",
      "Epoch 1, iter 397, loss 2.560837984085083, acc 0.10000000149011612\n",
      "Epoch 1, iter 398, loss 2.568557024002075, acc 0.15000000596046448\n",
      "Epoch 1, iter 399, loss 2.5939950942993164, acc 0.17000000178813934\n",
      "Epoch 1, iter 400, loss 2.4724254608154297, acc 0.10000000149011612\n",
      "Epoch 1, iter 401, loss 2.5079452991485596, acc 0.11999999731779099\n",
      "Epoch 1, iter 402, loss 2.473536729812622, acc 0.17000000178813934\n",
      "Epoch 1, iter 403, loss 2.6653597354888916, acc 0.11999999731779099\n",
      "Epoch 1, iter 404, loss 2.742100477218628, acc 0.09000000357627869\n",
      "Epoch 1, iter 405, loss 2.526289939880371, acc 0.12999999523162842\n",
      "Epoch 1, iter 406, loss 2.5446619987487793, acc 0.1899999976158142\n",
      "Epoch 1, iter 407, loss 2.504441022872925, acc 0.10999999940395355\n",
      "Epoch 1, iter 408, loss 2.523062229156494, acc 0.18000000715255737\n",
      "Epoch 1, iter 409, loss 2.5778210163116455, acc 0.11999999731779099\n",
      "Epoch 1, iter 410, loss 2.4914865493774414, acc 0.14000000059604645\n",
      "Epoch 1, iter 411, loss 2.4371564388275146, acc 0.11999999731779099\n",
      "Epoch 1, iter 412, loss 2.4152443408966064, acc 0.1599999964237213\n",
      "Epoch 1, iter 413, loss 2.6862704753875732, acc 0.10000000149011612\n",
      "Epoch 1, iter 414, loss 2.5146195888519287, acc 0.15000000596046448\n",
      "Epoch 1, iter 415, loss 2.6823580265045166, acc 0.07999999821186066\n",
      "Epoch 1, iter 416, loss 2.6221206188201904, acc 0.07000000029802322\n",
      "Epoch 1, iter 417, loss 2.505326747894287, acc 0.17000000178813934\n",
      "Epoch 1, iter 418, loss 2.4821574687957764, acc 0.2199999988079071\n",
      "Epoch 1, iter 419, loss 2.3739893436431885, acc 0.14000000059604645\n",
      "Epoch 1, iter 420, loss 2.5103261470794678, acc 0.14000000059604645\n",
      "Epoch 2, iter 1, loss 2.442777633666992, acc 0.1599999964237213\n",
      "Epoch 2, iter 2, loss 2.624884605407715, acc 0.09000000357627869\n",
      "Epoch 2, iter 3, loss 2.43269419670105, acc 0.11999999731779099\n",
      "Epoch 2, iter 4, loss 2.4765377044677734, acc 0.20999999344348907\n",
      "Epoch 2, iter 5, loss 2.457658290863037, acc 0.10999999940395355\n",
      "Epoch 2, iter 6, loss 2.4456870555877686, acc 0.1599999964237213\n",
      "Epoch 2, iter 7, loss 2.6100940704345703, acc 0.07999999821186066\n",
      "Epoch 2, iter 8, loss 2.4826269149780273, acc 0.14000000059604645\n",
      "Epoch 2, iter 9, loss 2.549340009689331, acc 0.10999999940395355\n",
      "Epoch 2, iter 10, loss 2.6057279109954834, acc 0.14000000059604645\n",
      "Epoch 2, iter 11, loss 2.7061612606048584, acc 0.10999999940395355\n",
      "Epoch 2, iter 12, loss 2.499321699142456, acc 0.1599999964237213\n",
      "Epoch 2, iter 13, loss 2.3852930068969727, acc 0.18000000715255737\n",
      "Epoch 2, iter 14, loss 2.5237810611724854, acc 0.10000000149011612\n",
      "Epoch 2, iter 15, loss 2.5217857360839844, acc 0.05000000074505806\n",
      "Epoch 2, iter 16, loss 2.5168073177337646, acc 0.11999999731779099\n",
      "Epoch 2, iter 17, loss 2.4422836303710938, acc 0.14000000059604645\n",
      "Epoch 2, iter 18, loss 2.6201086044311523, acc 0.14000000059604645\n",
      "Epoch 2, iter 19, loss 2.4527060985565186, acc 0.18000000715255737\n",
      "Epoch 2, iter 20, loss 2.4390616416931152, acc 0.1599999964237213\n",
      "Epoch 2, iter 21, loss 2.528702735900879, acc 0.12999999523162842\n",
      "Epoch 2, iter 22, loss 2.6878957748413086, acc 0.10000000149011612\n",
      "Epoch 2, iter 23, loss 2.4345290660858154, acc 0.18000000715255737\n",
      "Epoch 2, iter 24, loss 2.3334314823150635, acc 0.17000000178813934\n",
      "Epoch 2, iter 25, loss 2.452680826187134, acc 0.1599999964237213\n",
      "Epoch 2, iter 26, loss 2.621140241622925, acc 0.10999999940395355\n",
      "Epoch 2, iter 27, loss 2.426072835922241, acc 0.1599999964237213\n",
      "Epoch 2, iter 28, loss 2.507815361022949, acc 0.10999999940395355\n",
      "Epoch 2, iter 29, loss 2.5338993072509766, acc 0.15000000596046448\n",
      "Epoch 2, iter 30, loss 2.5128164291381836, acc 0.18000000715255737\n",
      "Epoch 2, iter 31, loss 2.5181875228881836, acc 0.1599999964237213\n",
      "Epoch 2, iter 32, loss 2.505356550216675, acc 0.11999999731779099\n",
      "Epoch 2, iter 33, loss 2.5290393829345703, acc 0.17000000178813934\n",
      "Epoch 2, iter 34, loss 2.4630463123321533, acc 0.15000000596046448\n",
      "Epoch 2, iter 35, loss 2.580434799194336, acc 0.10999999940395355\n",
      "Epoch 2, iter 36, loss 2.502519369125366, acc 0.12999999523162842\n",
      "Epoch 2, iter 37, loss 2.4828925132751465, acc 0.1599999964237213\n",
      "Epoch 2, iter 38, loss 2.498601198196411, acc 0.15000000596046448\n",
      "Epoch 2, iter 39, loss 2.4221506118774414, acc 0.17000000178813934\n",
      "Epoch 2, iter 40, loss 2.4646615982055664, acc 0.11999999731779099\n",
      "Epoch 2, iter 41, loss 2.545159101486206, acc 0.12999999523162842\n",
      "Epoch 2, iter 42, loss 2.5354197025299072, acc 0.10000000149011612\n",
      "Epoch 2, iter 43, loss 2.3421378135681152, acc 0.15000000596046448\n",
      "Epoch 2, iter 44, loss 2.396256923675537, acc 0.10999999940395355\n",
      "Epoch 2, iter 45, loss 2.476196527481079, acc 0.11999999731779099\n",
      "Epoch 2, iter 46, loss 2.413902997970581, acc 0.17000000178813934\n",
      "Epoch 2, iter 47, loss 2.5430617332458496, acc 0.12999999523162842\n",
      "Epoch 2, iter 48, loss 2.317350387573242, acc 0.12999999523162842\n",
      "Epoch 2, iter 49, loss 2.4020917415618896, acc 0.20999999344348907\n",
      "Epoch 2, iter 50, loss 2.4960315227508545, acc 0.18000000715255737\n",
      "Epoch 2, iter 51, loss 2.452291488647461, acc 0.07999999821186066\n",
      "Epoch 2, iter 52, loss 2.5415146350860596, acc 0.17000000178813934\n",
      "Epoch 2, iter 53, loss 2.374037027359009, acc 0.20000000298023224\n",
      "Epoch 2, iter 54, loss 2.3922910690307617, acc 0.10000000149011612\n",
      "Epoch 2, iter 55, loss 2.6014351844787598, acc 0.1599999964237213\n",
      "Epoch 2, iter 56, loss 2.518975257873535, acc 0.12999999523162842\n",
      "Epoch 2, iter 57, loss 2.650521755218506, acc 0.1599999964237213\n",
      "Epoch 2, iter 58, loss 2.4278340339660645, acc 0.14000000059604645\n",
      "Epoch 2, iter 59, loss 2.5796985626220703, acc 0.10000000149011612\n",
      "Epoch 2, iter 60, loss 2.3585498332977295, acc 0.15000000596046448\n",
      "Epoch 2, iter 61, loss 2.613044500350952, acc 0.11999999731779099\n",
      "Epoch 2, iter 62, loss 2.4656872749328613, acc 0.1599999964237213\n",
      "Epoch 2, iter 63, loss 2.6527764797210693, acc 0.05999999865889549\n",
      "Epoch 2, iter 64, loss 2.379544973373413, acc 0.1899999976158142\n",
      "Epoch 2, iter 65, loss 2.6110358238220215, acc 0.12999999523162842\n",
      "Epoch 2, iter 66, loss 2.546725273132324, acc 0.09000000357627869\n",
      "Epoch 2, iter 67, loss 2.383113384246826, acc 0.1899999976158142\n",
      "Epoch 2, iter 68, loss 2.416644811630249, acc 0.12999999523162842\n",
      "Epoch 2, iter 69, loss 2.507206678390503, acc 0.11999999731779099\n",
      "Epoch 2, iter 70, loss 2.4222171306610107, acc 0.14000000059604645\n",
      "Epoch 2, iter 71, loss 2.542090654373169, acc 0.14000000059604645\n",
      "Epoch 2, iter 72, loss 2.415043592453003, acc 0.11999999731779099\n",
      "Epoch 2, iter 73, loss 2.4419047832489014, acc 0.15000000596046448\n",
      "Epoch 2, iter 74, loss 2.457400321960449, acc 0.17000000178813934\n",
      "Epoch 2, iter 75, loss 2.505821943283081, acc 0.14000000059604645\n",
      "Epoch 2, iter 76, loss 2.4359371662139893, acc 0.1899999976158142\n",
      "Epoch 2, iter 77, loss 2.461200475692749, acc 0.18000000715255737\n",
      "Epoch 2, iter 78, loss 2.494899272918701, acc 0.17000000178813934\n",
      "Epoch 2, iter 79, loss 2.5225610733032227, acc 0.14000000059604645\n",
      "Epoch 2, iter 80, loss 2.5270862579345703, acc 0.10000000149011612\n",
      "Epoch 2, iter 81, loss 2.4494364261627197, acc 0.1899999976158142\n",
      "Epoch 2, iter 82, loss 2.4715726375579834, acc 0.17000000178813934\n",
      "Epoch 2, iter 83, loss 2.492461919784546, acc 0.10000000149011612\n",
      "Epoch 2, iter 84, loss 2.511056423187256, acc 0.1899999976158142\n",
      "Epoch 2, iter 85, loss 2.530329465866089, acc 0.14000000059604645\n",
      "Epoch 2, iter 86, loss 2.5689635276794434, acc 0.09000000357627869\n",
      "Epoch 2, iter 87, loss 2.382330894470215, acc 0.2800000011920929\n",
      "Epoch 2, iter 88, loss 2.4202916622161865, acc 0.15000000596046448\n",
      "Epoch 2, iter 89, loss 2.522411584854126, acc 0.14000000059604645\n",
      "Epoch 2, iter 90, loss 2.4969654083251953, acc 0.10000000149011612\n",
      "Epoch 2, iter 91, loss 2.49178147315979, acc 0.11999999731779099\n",
      "Epoch 2, iter 92, loss 2.5369980335235596, acc 0.14000000059604645\n",
      "Epoch 2, iter 93, loss 2.5051136016845703, acc 0.10999999940395355\n",
      "Epoch 2, iter 94, loss 2.4297287464141846, acc 0.15000000596046448\n",
      "Epoch 2, iter 95, loss 2.5528104305267334, acc 0.09000000357627869\n",
      "Epoch 2, iter 96, loss 2.4003210067749023, acc 0.20000000298023224\n",
      "Epoch 2, iter 97, loss 2.5160915851593018, acc 0.07999999821186066\n",
      "Epoch 2, iter 98, loss 2.423546552658081, acc 0.17000000178813934\n",
      "Epoch 2, iter 99, loss 2.580601453781128, acc 0.17000000178813934\n",
      "Epoch 2, iter 100, loss 2.394077777862549, acc 0.15000000596046448\n",
      "Epoch 2, iter 101, loss 2.426831007003784, acc 0.15000000596046448\n",
      "Epoch 2, iter 102, loss 2.37455677986145, acc 0.18000000715255737\n",
      "Epoch 2, iter 103, loss 2.4866881370544434, acc 0.1599999964237213\n",
      "Epoch 2, iter 104, loss 2.582920551300049, acc 0.11999999731779099\n",
      "Epoch 2, iter 105, loss 2.3891522884368896, acc 0.17000000178813934\n",
      "Epoch 2, iter 106, loss 2.365713119506836, acc 0.15000000596046448\n",
      "Epoch 2, iter 107, loss 2.4081106185913086, acc 0.1899999976158142\n",
      "Epoch 2, iter 108, loss 2.428201198577881, acc 0.1599999964237213\n",
      "Epoch 2, iter 109, loss 2.3964617252349854, acc 0.09000000357627869\n",
      "Epoch 2, iter 110, loss 2.608858346939087, acc 0.10999999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, iter 111, loss 2.497779130935669, acc 0.10000000149011612\n",
      "Epoch 2, iter 112, loss 2.4572393894195557, acc 0.18000000715255737\n",
      "Epoch 2, iter 113, loss 2.441890001296997, acc 0.10999999940395355\n",
      "Epoch 2, iter 114, loss 2.4252822399139404, acc 0.1599999964237213\n",
      "Epoch 2, iter 115, loss 2.396118402481079, acc 0.10999999940395355\n",
      "Epoch 2, iter 116, loss 2.4311935901641846, acc 0.11999999731779099\n",
      "Epoch 2, iter 117, loss 2.5189969539642334, acc 0.1599999964237213\n",
      "Epoch 2, iter 118, loss 2.440319776535034, acc 0.17000000178813934\n",
      "Epoch 2, iter 119, loss 2.424490213394165, acc 0.1599999964237213\n",
      "Epoch 2, iter 120, loss 2.4218268394470215, acc 0.17000000178813934\n",
      "Epoch 2, iter 121, loss 2.500554084777832, acc 0.14000000059604645\n",
      "Epoch 2, iter 122, loss 2.4230780601501465, acc 0.14000000059604645\n",
      "Epoch 2, iter 123, loss 2.4658913612365723, acc 0.1899999976158142\n",
      "Epoch 2, iter 124, loss 2.386932849884033, acc 0.07999999821186066\n",
      "Epoch 2, iter 125, loss 2.449551582336426, acc 0.10000000149011612\n",
      "Epoch 2, iter 126, loss 2.4961283206939697, acc 0.11999999731779099\n",
      "Epoch 2, iter 127, loss 2.523327350616455, acc 0.07999999821186066\n",
      "Epoch 2, iter 128, loss 2.441391706466675, acc 0.11999999731779099\n",
      "Epoch 2, iter 129, loss 2.550726890563965, acc 0.15000000596046448\n",
      "Epoch 2, iter 130, loss 2.520529270172119, acc 0.15000000596046448\n",
      "Epoch 2, iter 131, loss 2.439204454421997, acc 0.20000000298023224\n",
      "Epoch 2, iter 132, loss 2.3773038387298584, acc 0.20000000298023224\n",
      "Epoch 2, iter 133, loss 2.416353702545166, acc 0.11999999731779099\n",
      "Epoch 2, iter 134, loss 2.5756900310516357, acc 0.10999999940395355\n",
      "Epoch 2, iter 135, loss 2.3884689807891846, acc 0.1599999964237213\n",
      "Epoch 2, iter 136, loss 2.4878740310668945, acc 0.10999999940395355\n",
      "Epoch 2, iter 137, loss 2.460569381713867, acc 0.10999999940395355\n",
      "Epoch 2, iter 138, loss 2.3933277130126953, acc 0.12999999523162842\n",
      "Epoch 2, iter 139, loss 2.5246355533599854, acc 0.10999999940395355\n",
      "Epoch 2, iter 140, loss 2.579840660095215, acc 0.10999999940395355\n",
      "Epoch 2, iter 141, loss 2.5380306243896484, acc 0.05999999865889549\n",
      "Epoch 2, iter 142, loss 2.463076114654541, acc 0.11999999731779099\n",
      "Epoch 2, iter 143, loss 2.3909385204315186, acc 0.11999999731779099\n",
      "Epoch 2, iter 144, loss 2.590108633041382, acc 0.10000000149011612\n",
      "Epoch 2, iter 145, loss 2.527549982070923, acc 0.11999999731779099\n",
      "Epoch 2, iter 146, loss 2.4717891216278076, acc 0.12999999523162842\n",
      "Epoch 2, iter 147, loss 2.380859136581421, acc 0.17000000178813934\n",
      "Epoch 2, iter 148, loss 2.389768123626709, acc 0.11999999731779099\n",
      "Epoch 2, iter 149, loss 2.5356788635253906, acc 0.15000000596046448\n",
      "Epoch 2, iter 150, loss 2.2800779342651367, acc 0.2199999988079071\n",
      "Epoch 2, iter 151, loss 2.393448829650879, acc 0.11999999731779099\n",
      "Epoch 2, iter 152, loss 2.4624106884002686, acc 0.12999999523162842\n",
      "Epoch 2, iter 153, loss 2.3614139556884766, acc 0.20000000298023224\n",
      "Epoch 2, iter 154, loss 2.4364428520202637, acc 0.1599999964237213\n",
      "Epoch 2, iter 155, loss 2.320195198059082, acc 0.18000000715255737\n",
      "Epoch 2, iter 156, loss 2.3979222774505615, acc 0.17000000178813934\n",
      "Epoch 2, iter 157, loss 2.5991628170013428, acc 0.05999999865889549\n",
      "Epoch 2, iter 158, loss 2.481097459793091, acc 0.15000000596046448\n",
      "Epoch 2, iter 159, loss 2.424215078353882, acc 0.14000000059604645\n",
      "Epoch 2, iter 160, loss 2.352555751800537, acc 0.20999999344348907\n",
      "Epoch 2, iter 161, loss 2.5836408138275146, acc 0.10000000149011612\n",
      "Epoch 2, iter 162, loss 2.3774514198303223, acc 0.1599999964237213\n",
      "Epoch 2, iter 163, loss 2.656090497970581, acc 0.07999999821186066\n",
      "Epoch 2, iter 164, loss 2.5368900299072266, acc 0.11999999731779099\n",
      "Epoch 2, iter 165, loss 2.455951452255249, acc 0.15000000596046448\n",
      "Epoch 2, iter 166, loss 2.5283362865448, acc 0.05000000074505806\n",
      "Epoch 2, iter 167, loss 2.410060167312622, acc 0.12999999523162842\n",
      "Epoch 2, iter 168, loss 2.456930160522461, acc 0.09000000357627869\n",
      "Epoch 2, iter 169, loss 2.4374606609344482, acc 0.12999999523162842\n",
      "Epoch 2, iter 170, loss 2.5030107498168945, acc 0.14000000059604645\n",
      "Epoch 2, iter 171, loss 2.493468999862671, acc 0.11999999731779099\n",
      "Epoch 2, iter 172, loss 2.4349184036254883, acc 0.10000000149011612\n",
      "Epoch 2, iter 173, loss 2.4457311630249023, acc 0.1899999976158142\n",
      "Epoch 2, iter 174, loss 2.366607666015625, acc 0.1899999976158142\n",
      "Epoch 2, iter 175, loss 2.443631172180176, acc 0.20999999344348907\n",
      "Epoch 2, iter 176, loss 2.4686102867126465, acc 0.1599999964237213\n",
      "Epoch 2, iter 177, loss 2.376296281814575, acc 0.20999999344348907\n",
      "Epoch 2, iter 178, loss 2.4689266681671143, acc 0.15000000596046448\n",
      "Epoch 2, iter 179, loss 2.4956979751586914, acc 0.17000000178813934\n",
      "Epoch 2, iter 180, loss 2.453596591949463, acc 0.1599999964237213\n",
      "Epoch 2, iter 181, loss 2.367302656173706, acc 0.1599999964237213\n",
      "Epoch 2, iter 182, loss 2.3527920246124268, acc 0.15000000596046448\n",
      "Epoch 2, iter 183, loss 2.3426194190979004, acc 0.20000000298023224\n",
      "Epoch 2, iter 184, loss 2.5253102779388428, acc 0.09000000357627869\n",
      "Epoch 2, iter 185, loss 2.353116035461426, acc 0.15000000596046448\n",
      "Epoch 2, iter 186, loss 2.437130928039551, acc 0.15000000596046448\n",
      "Epoch 2, iter 187, loss 2.457355499267578, acc 0.1599999964237213\n",
      "Epoch 2, iter 188, loss 2.4601480960845947, acc 0.11999999731779099\n",
      "Epoch 2, iter 189, loss 2.3628761768341064, acc 0.17000000178813934\n",
      "Epoch 2, iter 190, loss 2.519062042236328, acc 0.15000000596046448\n",
      "Epoch 2, iter 191, loss 2.290928602218628, acc 0.23000000417232513\n",
      "Epoch 2, iter 192, loss 2.5118892192840576, acc 0.10000000149011612\n",
      "Epoch 2, iter 193, loss 2.3618276119232178, acc 0.11999999731779099\n",
      "Epoch 2, iter 194, loss 2.3358664512634277, acc 0.12999999523162842\n",
      "Epoch 2, iter 195, loss 2.658968448638916, acc 0.10000000149011612\n",
      "Epoch 2, iter 196, loss 2.479112386703491, acc 0.09000000357627869\n",
      "Epoch 2, iter 197, loss 2.379260778427124, acc 0.11999999731779099\n",
      "Epoch 2, iter 198, loss 2.413605213165283, acc 0.10000000149011612\n",
      "Epoch 2, iter 199, loss 2.368105173110962, acc 0.14000000059604645\n",
      "Epoch 2, iter 200, loss 2.4677934646606445, acc 0.10999999940395355\n",
      "Epoch 2, iter 201, loss 2.518547773361206, acc 0.10000000149011612\n",
      "Epoch 2, iter 202, loss 2.487974166870117, acc 0.10999999940395355\n",
      "Epoch 2, iter 203, loss 2.5701260566711426, acc 0.10999999940395355\n",
      "Epoch 2, iter 204, loss 2.4542171955108643, acc 0.15000000596046448\n",
      "Epoch 2, iter 205, loss 2.3740010261535645, acc 0.11999999731779099\n",
      "Epoch 2, iter 206, loss 2.4127843379974365, acc 0.10999999940395355\n",
      "Epoch 2, iter 207, loss 2.3803818225860596, acc 0.18000000715255737\n",
      "Epoch 2, iter 208, loss 2.6005942821502686, acc 0.11999999731779099\n",
      "Epoch 2, iter 209, loss 2.557586431503296, acc 0.07999999821186066\n",
      "Epoch 2, iter 210, loss 2.5585319995880127, acc 0.11999999731779099\n",
      "Epoch 2, iter 211, loss 2.387617588043213, acc 0.17000000178813934\n",
      "Epoch 2, iter 212, loss 2.3311851024627686, acc 0.1599999964237213\n",
      "Epoch 2, iter 213, loss 2.4215738773345947, acc 0.14000000059604645\n",
      "Epoch 2, iter 214, loss 2.5453927516937256, acc 0.10000000149011612\n",
      "Epoch 2, iter 215, loss 2.4341750144958496, acc 0.11999999731779099\n",
      "Epoch 2, iter 216, loss 2.4617931842803955, acc 0.1599999964237213\n",
      "Epoch 2, iter 217, loss 2.2970588207244873, acc 0.1599999964237213\n",
      "Epoch 2, iter 218, loss 2.5416383743286133, acc 0.18000000715255737\n",
      "Epoch 2, iter 219, loss 2.4102225303649902, acc 0.18000000715255737\n",
      "Epoch 2, iter 220, loss 2.460141658782959, acc 0.07000000029802322\n",
      "Epoch 2, iter 221, loss 2.4371604919433594, acc 0.14000000059604645\n",
      "Epoch 2, iter 222, loss 2.4827699661254883, acc 0.11999999731779099\n",
      "Epoch 2, iter 223, loss 2.5408360958099365, acc 0.10999999940395355\n",
      "Epoch 2, iter 224, loss 2.446748971939087, acc 0.1599999964237213\n",
      "Epoch 2, iter 225, loss 2.3360462188720703, acc 0.20000000298023224\n",
      "Epoch 2, iter 226, loss 2.470118999481201, acc 0.09000000357627869\n",
      "Epoch 2, iter 227, loss 2.426947832107544, acc 0.15000000596046448\n",
      "Epoch 2, iter 228, loss 2.344907522201538, acc 0.2199999988079071\n",
      "Epoch 2, iter 229, loss 2.5389904975891113, acc 0.07999999821186066\n",
      "Epoch 2, iter 230, loss 2.461789608001709, acc 0.12999999523162842\n",
      "Epoch 2, iter 231, loss 2.412623882293701, acc 0.12999999523162842\n",
      "Epoch 2, iter 232, loss 2.467268228530884, acc 0.11999999731779099\n",
      "Epoch 2, iter 233, loss 2.4578826427459717, acc 0.14000000059604645\n",
      "Epoch 2, iter 234, loss 2.381103038787842, acc 0.07999999821186066\n",
      "Epoch 2, iter 235, loss 2.4753000736236572, acc 0.09000000357627869\n",
      "Epoch 2, iter 236, loss 2.456427574157715, acc 0.14000000059604645\n",
      "Epoch 2, iter 237, loss 2.5328476428985596, acc 0.11999999731779099\n",
      "Epoch 2, iter 238, loss 2.4141483306884766, acc 0.17000000178813934\n",
      "Epoch 2, iter 239, loss 2.5681488513946533, acc 0.05999999865889549\n",
      "Epoch 2, iter 240, loss 2.3872907161712646, acc 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, iter 241, loss 2.4606590270996094, acc 0.14000000059604645\n",
      "Epoch 2, iter 242, loss 2.5924019813537598, acc 0.07999999821186066\n",
      "Epoch 2, iter 243, loss 2.531423568725586, acc 0.17000000178813934\n",
      "Epoch 2, iter 244, loss 2.488921880722046, acc 0.14000000059604645\n",
      "Epoch 2, iter 245, loss 2.2994585037231445, acc 0.20000000298023224\n",
      "Epoch 2, iter 246, loss 2.370619773864746, acc 0.20000000298023224\n",
      "Epoch 2, iter 247, loss 2.4039626121520996, acc 0.11999999731779099\n",
      "Epoch 2, iter 248, loss 2.3345017433166504, acc 0.17000000178813934\n",
      "Epoch 2, iter 249, loss 2.4202828407287598, acc 0.14000000059604645\n",
      "Epoch 2, iter 250, loss 2.3786165714263916, acc 0.14000000059604645\n",
      "Epoch 2, iter 251, loss 2.4295928478240967, acc 0.1599999964237213\n",
      "Epoch 2, iter 252, loss 2.326082229614258, acc 0.15000000596046448\n",
      "Epoch 2, iter 253, loss 2.565126895904541, acc 0.1599999964237213\n",
      "Epoch 2, iter 254, loss 2.3198280334472656, acc 0.14000000059604645\n",
      "Epoch 2, iter 255, loss 2.5963590145111084, acc 0.12999999523162842\n",
      "Epoch 2, iter 256, loss 2.504455327987671, acc 0.10999999940395355\n",
      "Epoch 2, iter 257, loss 2.4132797718048096, acc 0.15000000596046448\n",
      "Epoch 2, iter 258, loss 2.5107836723327637, acc 0.14000000059604645\n",
      "Epoch 2, iter 259, loss 2.420290946960449, acc 0.14000000059604645\n",
      "Epoch 2, iter 260, loss 2.373018980026245, acc 0.12999999523162842\n",
      "Epoch 2, iter 261, loss 2.3466622829437256, acc 0.12999999523162842\n",
      "Epoch 2, iter 262, loss 2.581265926361084, acc 0.09000000357627869\n",
      "Epoch 2, iter 263, loss 2.3033008575439453, acc 0.12999999523162842\n",
      "Epoch 2, iter 264, loss 2.367906332015991, acc 0.17000000178813934\n",
      "Epoch 2, iter 265, loss 2.242020845413208, acc 0.2199999988079071\n",
      "Epoch 2, iter 266, loss 2.542813301086426, acc 0.11999999731779099\n",
      "Epoch 2, iter 267, loss 2.4741647243499756, acc 0.07000000029802322\n",
      "Epoch 2, iter 268, loss 2.408596992492676, acc 0.14000000059604645\n",
      "Epoch 2, iter 269, loss 2.3761281967163086, acc 0.1899999976158142\n",
      "Epoch 2, iter 270, loss 2.4853219985961914, acc 0.10999999940395355\n",
      "Epoch 2, iter 271, loss 2.359212875366211, acc 0.2199999988079071\n",
      "Epoch 2, iter 272, loss 2.3733956813812256, acc 0.14000000059604645\n",
      "Epoch 2, iter 273, loss 2.47016978263855, acc 0.11999999731779099\n",
      "Epoch 2, iter 274, loss 2.553785562515259, acc 0.05999999865889549\n",
      "Epoch 2, iter 275, loss 2.499681234359741, acc 0.10000000149011612\n",
      "Epoch 2, iter 276, loss 2.4503672122955322, acc 0.15000000596046448\n",
      "Epoch 2, iter 277, loss 2.3016371726989746, acc 0.14000000059604645\n",
      "Epoch 2, iter 278, loss 2.3389532566070557, acc 0.12999999523162842\n",
      "Epoch 2, iter 279, loss 2.5283401012420654, acc 0.12999999523162842\n",
      "Epoch 2, iter 280, loss 2.43154239654541, acc 0.10999999940395355\n",
      "Epoch 2, iter 281, loss 2.4274940490722656, acc 0.1599999964237213\n",
      "Epoch 2, iter 282, loss 2.287381410598755, acc 0.1899999976158142\n",
      "Epoch 2, iter 283, loss 2.4397051334381104, acc 0.17000000178813934\n",
      "Epoch 2, iter 284, loss 2.4009790420532227, acc 0.10000000149011612\n",
      "Epoch 2, iter 285, loss 2.420382022857666, acc 0.10999999940395355\n",
      "Epoch 2, iter 286, loss 2.380035877227783, acc 0.10000000149011612\n",
      "Epoch 2, iter 287, loss 2.363222122192383, acc 0.11999999731779099\n",
      "Epoch 2, iter 288, loss 2.5619499683380127, acc 0.07999999821186066\n",
      "Epoch 2, iter 289, loss 2.534186363220215, acc 0.09000000357627869\n",
      "Epoch 2, iter 290, loss 2.478400945663452, acc 0.10000000149011612\n",
      "Epoch 2, iter 291, loss 2.478412389755249, acc 0.11999999731779099\n",
      "Epoch 2, iter 292, loss 2.3542864322662354, acc 0.1599999964237213\n",
      "Epoch 2, iter 293, loss 2.388270139694214, acc 0.1599999964237213\n",
      "Epoch 2, iter 294, loss 2.2772774696350098, acc 0.20000000298023224\n",
      "Epoch 2, iter 295, loss 2.4514968395233154, acc 0.17000000178813934\n",
      "Epoch 2, iter 296, loss 2.3834269046783447, acc 0.09000000357627869\n",
      "Epoch 2, iter 297, loss 2.486194610595703, acc 0.1899999976158142\n",
      "Epoch 2, iter 298, loss 2.3353354930877686, acc 0.1599999964237213\n",
      "Epoch 2, iter 299, loss 2.6013965606689453, acc 0.10999999940395355\n",
      "Epoch 2, iter 300, loss 2.3983876705169678, acc 0.10999999940395355\n",
      "Epoch 2, iter 301, loss 2.4729692935943604, acc 0.10999999940395355\n",
      "Epoch 2, iter 302, loss 2.408419609069824, acc 0.14000000059604645\n",
      "Epoch 2, iter 303, loss 2.5218493938446045, acc 0.07999999821186066\n",
      "Epoch 2, iter 304, loss 2.5093882083892822, acc 0.15000000596046448\n",
      "Epoch 2, iter 305, loss 2.403640031814575, acc 0.18000000715255737\n",
      "Epoch 2, iter 306, loss 2.422945976257324, acc 0.10999999940395355\n",
      "Epoch 2, iter 307, loss 2.40726900100708, acc 0.14000000059604645\n",
      "Epoch 2, iter 308, loss 2.48685622215271, acc 0.12999999523162842\n",
      "Epoch 2, iter 309, loss 2.433079957962036, acc 0.12999999523162842\n",
      "Epoch 2, iter 310, loss 2.439551830291748, acc 0.09000000357627869\n",
      "Epoch 2, iter 311, loss 2.520627021789551, acc 0.11999999731779099\n",
      "Epoch 2, iter 312, loss 2.424389123916626, acc 0.14000000059604645\n",
      "Epoch 2, iter 313, loss 2.4194257259368896, acc 0.1899999976158142\n",
      "Epoch 2, iter 314, loss 2.2983083724975586, acc 0.1599999964237213\n",
      "Epoch 2, iter 315, loss 2.3524341583251953, acc 0.17000000178813934\n",
      "Epoch 2, iter 316, loss 2.4893953800201416, acc 0.10999999940395355\n",
      "Epoch 2, iter 317, loss 2.464832067489624, acc 0.18000000715255737\n",
      "Epoch 2, iter 318, loss 2.295865297317505, acc 0.1899999976158142\n",
      "Epoch 2, iter 319, loss 2.3664188385009766, acc 0.20000000298023224\n",
      "Epoch 2, iter 320, loss 2.4992246627807617, acc 0.1599999964237213\n",
      "Epoch 2, iter 321, loss 2.5246517658233643, acc 0.11999999731779099\n",
      "Epoch 2, iter 322, loss 2.493204116821289, acc 0.15000000596046448\n",
      "Epoch 2, iter 323, loss 2.332200050354004, acc 0.15000000596046448\n",
      "Epoch 2, iter 324, loss 2.3550078868865967, acc 0.14000000059604645\n",
      "Epoch 2, iter 325, loss 2.4716956615448, acc 0.17000000178813934\n",
      "Epoch 2, iter 326, loss 2.3545265197753906, acc 0.07999999821186066\n",
      "Epoch 2, iter 327, loss 2.3931970596313477, acc 0.14000000059604645\n",
      "Epoch 2, iter 328, loss 2.481837511062622, acc 0.07000000029802322\n",
      "Epoch 2, iter 329, loss 2.502354621887207, acc 0.10999999940395355\n",
      "Epoch 2, iter 330, loss 2.4198811054229736, acc 0.17000000178813934\n",
      "Epoch 2, iter 331, loss 2.3870036602020264, acc 0.18000000715255737\n",
      "Epoch 2, iter 332, loss 2.3069546222686768, acc 0.17000000178813934\n",
      "Epoch 2, iter 333, loss 2.3398399353027344, acc 0.15000000596046448\n",
      "Epoch 2, iter 334, loss 2.449087142944336, acc 0.15000000596046448\n",
      "Epoch 2, iter 335, loss 2.3511388301849365, acc 0.15000000596046448\n",
      "Epoch 2, iter 336, loss 2.3317372798919678, acc 0.14000000059604645\n",
      "Epoch 2, iter 337, loss 2.541623592376709, acc 0.10000000149011612\n",
      "Epoch 2, iter 338, loss 2.2850301265716553, acc 0.18000000715255737\n",
      "Epoch 2, iter 339, loss 2.2900917530059814, acc 0.18000000715255737\n",
      "Epoch 2, iter 340, loss 2.5165815353393555, acc 0.10999999940395355\n",
      "Epoch 2, iter 341, loss 2.3636574745178223, acc 0.12999999523162842\n",
      "Epoch 2, iter 342, loss 2.286456346511841, acc 0.20999999344348907\n",
      "Epoch 2, iter 343, loss 2.3786041736602783, acc 0.20000000298023224\n",
      "Epoch 2, iter 344, loss 2.413360357284546, acc 0.10000000149011612\n",
      "Epoch 2, iter 345, loss 2.4055347442626953, acc 0.14000000059604645\n",
      "Epoch 2, iter 346, loss 2.503080368041992, acc 0.09000000357627869\n",
      "Epoch 2, iter 347, loss 2.321789026260376, acc 0.1899999976158142\n",
      "Epoch 2, iter 348, loss 2.337261438369751, acc 0.14000000059604645\n",
      "Epoch 2, iter 349, loss 2.210585832595825, acc 0.1899999976158142\n",
      "Epoch 2, iter 350, loss 2.3864359855651855, acc 0.17000000178813934\n",
      "Epoch 2, iter 351, loss 2.4450204372406006, acc 0.14000000059604645\n",
      "Epoch 2, iter 352, loss 2.3687846660614014, acc 0.1599999964237213\n",
      "Epoch 2, iter 353, loss 2.4178435802459717, acc 0.10999999940395355\n",
      "Epoch 2, iter 354, loss 2.4166038036346436, acc 0.14000000059604645\n",
      "Epoch 2, iter 355, loss 2.463897943496704, acc 0.10999999940395355\n",
      "Epoch 2, iter 356, loss 2.3448894023895264, acc 0.18000000715255737\n",
      "Epoch 2, iter 357, loss 2.346323013305664, acc 0.1899999976158142\n",
      "Epoch 2, iter 358, loss 2.396376609802246, acc 0.1899999976158142\n",
      "Epoch 2, iter 359, loss 2.4178268909454346, acc 0.07999999821186066\n",
      "Epoch 2, iter 360, loss 2.3971712589263916, acc 0.15000000596046448\n",
      "Epoch 2, iter 361, loss 2.4342849254608154, acc 0.11999999731779099\n",
      "Epoch 2, iter 362, loss 2.4859578609466553, acc 0.15000000596046448\n",
      "Epoch 2, iter 363, loss 2.3460795879364014, acc 0.17000000178813934\n",
      "Epoch 2, iter 364, loss 2.3932721614837646, acc 0.17000000178813934\n",
      "Epoch 2, iter 365, loss 2.4247002601623535, acc 0.10999999940395355\n",
      "Epoch 2, iter 366, loss 2.284369707107544, acc 0.18000000715255737\n",
      "Epoch 2, iter 367, loss 2.433671474456787, acc 0.10000000149011612\n",
      "Epoch 2, iter 368, loss 2.3895440101623535, acc 0.1899999976158142\n",
      "Epoch 2, iter 369, loss 2.4675748348236084, acc 0.07999999821186066\n",
      "Epoch 2, iter 370, loss 2.4051599502563477, acc 0.12999999523162842\n",
      "Epoch 2, iter 371, loss 2.376753807067871, acc 0.11999999731779099\n",
      "Epoch 2, iter 372, loss 2.3553731441497803, acc 0.17000000178813934\n",
      "Epoch 2, iter 373, loss 2.46700382232666, acc 0.12999999523162842\n",
      "Epoch 2, iter 374, loss 2.3679449558258057, acc 0.14000000059604645\n",
      "Epoch 2, iter 375, loss 2.3807263374328613, acc 0.1599999964237213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, iter 376, loss 2.3313679695129395, acc 0.14000000059604645\n",
      "Epoch 2, iter 377, loss 2.4293127059936523, acc 0.10000000149011612\n",
      "Epoch 2, iter 378, loss 2.3655271530151367, acc 0.17000000178813934\n",
      "Epoch 2, iter 379, loss 2.4356648921966553, acc 0.15000000596046448\n",
      "Epoch 2, iter 380, loss 2.420717477798462, acc 0.14000000059604645\n",
      "Epoch 2, iter 381, loss 2.4577693939208984, acc 0.18000000715255737\n",
      "Epoch 2, iter 382, loss 2.281832456588745, acc 0.1899999976158142\n",
      "Epoch 2, iter 383, loss 2.4243807792663574, acc 0.17000000178813934\n",
      "Epoch 2, iter 384, loss 2.4190566539764404, acc 0.10000000149011612\n",
      "Epoch 2, iter 385, loss 2.5016112327575684, acc 0.09000000357627869\n",
      "Epoch 2, iter 386, loss 2.3484325408935547, acc 0.1599999964237213\n",
      "Epoch 2, iter 387, loss 2.363943576812744, acc 0.15000000596046448\n",
      "Epoch 2, iter 388, loss 2.383838176727295, acc 0.1899999976158142\n",
      "Epoch 2, iter 389, loss 2.373671054840088, acc 0.15000000596046448\n",
      "Epoch 2, iter 390, loss 2.4117934703826904, acc 0.15000000596046448\n",
      "Epoch 2, iter 391, loss 2.474940538406372, acc 0.15000000596046448\n",
      "Epoch 2, iter 392, loss 2.5331101417541504, acc 0.12999999523162842\n",
      "Epoch 2, iter 393, loss 2.3715786933898926, acc 0.11999999731779099\n",
      "Epoch 2, iter 394, loss 2.305286169052124, acc 0.17000000178813934\n",
      "Epoch 2, iter 395, loss 2.3611443042755127, acc 0.1599999964237213\n",
      "Epoch 2, iter 396, loss 2.5598669052124023, acc 0.14000000059604645\n",
      "Epoch 2, iter 397, loss 2.452930212020874, acc 0.10000000149011612\n",
      "Epoch 2, iter 398, loss 2.40651798248291, acc 0.12999999523162842\n",
      "Epoch 2, iter 399, loss 2.4528005123138428, acc 0.18000000715255737\n",
      "Epoch 2, iter 400, loss 2.3539984226226807, acc 0.09000000357627869\n",
      "Epoch 2, iter 401, loss 2.396451473236084, acc 0.15000000596046448\n",
      "Epoch 2, iter 402, loss 2.31687068939209, acc 0.15000000596046448\n",
      "Epoch 2, iter 403, loss 2.5627145767211914, acc 0.09000000357627869\n",
      "Epoch 2, iter 404, loss 2.5540056228637695, acc 0.07999999821186066\n",
      "Epoch 2, iter 405, loss 2.413069486618042, acc 0.12999999523162842\n",
      "Epoch 2, iter 406, loss 2.4059319496154785, acc 0.17000000178813934\n",
      "Epoch 2, iter 407, loss 2.347262382507324, acc 0.11999999731779099\n",
      "Epoch 2, iter 408, loss 2.357717990875244, acc 0.18000000715255737\n",
      "Epoch 2, iter 409, loss 2.4412453174591064, acc 0.10999999940395355\n",
      "Epoch 2, iter 410, loss 2.378331422805786, acc 0.10000000149011612\n",
      "Epoch 2, iter 411, loss 2.3877484798431396, acc 0.10999999940395355\n",
      "Epoch 2, iter 412, loss 2.3017704486846924, acc 0.1599999964237213\n",
      "Epoch 2, iter 413, loss 2.5147321224212646, acc 0.10999999940395355\n",
      "Epoch 2, iter 414, loss 2.4119105339050293, acc 0.12999999523162842\n",
      "Epoch 2, iter 415, loss 2.465977907180786, acc 0.12999999523162842\n",
      "Epoch 2, iter 416, loss 2.45760440826416, acc 0.09000000357627869\n",
      "Epoch 2, iter 417, loss 2.372220516204834, acc 0.10999999940395355\n",
      "Epoch 2, iter 418, loss 2.312190294265747, acc 0.18000000715255737\n",
      "Epoch 2, iter 419, loss 2.270188093185425, acc 0.11999999731779099\n",
      "Epoch 2, iter 420, loss 2.3722198009490967, acc 0.10999999940395355\n",
      "Epoch 3, iter 1, loss 2.3298256397247314, acc 0.12999999523162842\n",
      "Epoch 3, iter 2, loss 2.47092342376709, acc 0.10000000149011612\n",
      "Epoch 3, iter 3, loss 2.349700689315796, acc 0.09000000357627869\n",
      "Epoch 3, iter 4, loss 2.377798557281494, acc 0.1899999976158142\n",
      "Epoch 3, iter 5, loss 2.3334474563598633, acc 0.11999999731779099\n",
      "Epoch 3, iter 6, loss 2.3015928268432617, acc 0.18000000715255737\n",
      "Epoch 3, iter 7, loss 2.480719566345215, acc 0.09000000357627869\n",
      "Epoch 3, iter 8, loss 2.332704544067383, acc 0.17000000178813934\n",
      "Epoch 3, iter 9, loss 2.4099388122558594, acc 0.09000000357627869\n",
      "Epoch 3, iter 10, loss 2.434196949005127, acc 0.15000000596046448\n",
      "Epoch 3, iter 11, loss 2.5740134716033936, acc 0.10000000149011612\n",
      "Epoch 3, iter 12, loss 2.3905463218688965, acc 0.11999999731779099\n",
      "Epoch 3, iter 13, loss 2.3131914138793945, acc 0.14000000059604645\n",
      "Epoch 3, iter 14, loss 2.4632489681243896, acc 0.10000000149011612\n",
      "Epoch 3, iter 15, loss 2.3819048404693604, acc 0.07000000029802322\n",
      "Epoch 3, iter 16, loss 2.3649539947509766, acc 0.10000000149011612\n",
      "Epoch 3, iter 17, loss 2.3298346996307373, acc 0.15000000596046448\n",
      "Epoch 3, iter 18, loss 2.5260138511657715, acc 0.11999999731779099\n",
      "Epoch 3, iter 19, loss 2.3384711742401123, acc 0.14000000059604645\n",
      "Epoch 3, iter 20, loss 2.3921985626220703, acc 0.1599999964237213\n",
      "Epoch 3, iter 21, loss 2.372863531112671, acc 0.12999999523162842\n",
      "Epoch 3, iter 22, loss 2.4648592472076416, acc 0.09000000357627869\n",
      "Epoch 3, iter 23, loss 2.315021276473999, acc 0.18000000715255737\n",
      "Epoch 3, iter 24, loss 2.2866296768188477, acc 0.14000000059604645\n",
      "Epoch 3, iter 25, loss 2.2834970951080322, acc 0.20999999344348907\n",
      "Epoch 3, iter 26, loss 2.4392473697662354, acc 0.10999999940395355\n",
      "Epoch 3, iter 27, loss 2.2939271926879883, acc 0.18000000715255737\n",
      "Epoch 3, iter 28, loss 2.4357283115386963, acc 0.10000000149011612\n",
      "Epoch 3, iter 29, loss 2.4067296981811523, acc 0.14000000059604645\n",
      "Epoch 3, iter 30, loss 2.4203286170959473, acc 0.17000000178813934\n",
      "Epoch 3, iter 31, loss 2.4410905838012695, acc 0.14000000059604645\n",
      "Epoch 3, iter 32, loss 2.3736863136291504, acc 0.10999999940395355\n",
      "Epoch 3, iter 33, loss 2.4225549697875977, acc 0.15000000596046448\n",
      "Epoch 3, iter 34, loss 2.3657631874084473, acc 0.14000000059604645\n",
      "Epoch 3, iter 35, loss 2.4701225757598877, acc 0.09000000357627869\n",
      "Epoch 3, iter 36, loss 2.4716222286224365, acc 0.12999999523162842\n",
      "Epoch 3, iter 37, loss 2.401787281036377, acc 0.17000000178813934\n",
      "Epoch 3, iter 38, loss 2.3523623943328857, acc 0.1599999964237213\n",
      "Epoch 3, iter 39, loss 2.373307228088379, acc 0.11999999731779099\n",
      "Epoch 3, iter 40, loss 2.3557746410369873, acc 0.14000000059604645\n",
      "Epoch 3, iter 41, loss 2.42873215675354, acc 0.10999999940395355\n",
      "Epoch 3, iter 42, loss 2.3455560207366943, acc 0.10999999940395355\n",
      "Epoch 3, iter 43, loss 2.243450880050659, acc 0.1899999976158142\n",
      "Epoch 3, iter 44, loss 2.3160932064056396, acc 0.10999999940395355\n",
      "Epoch 3, iter 45, loss 2.3687684535980225, acc 0.15000000596046448\n",
      "Epoch 3, iter 46, loss 2.307448148727417, acc 0.15000000596046448\n",
      "Epoch 3, iter 47, loss 2.4302926063537598, acc 0.11999999731779099\n",
      "Epoch 3, iter 48, loss 2.2558233737945557, acc 0.12999999523162842\n",
      "Epoch 3, iter 49, loss 2.3512723445892334, acc 0.1599999964237213\n",
      "Epoch 3, iter 50, loss 2.3611409664154053, acc 0.20000000298023224\n",
      "Epoch 3, iter 51, loss 2.3563857078552246, acc 0.07999999821186066\n",
      "Epoch 3, iter 52, loss 2.3638417720794678, acc 0.1599999964237213\n",
      "Epoch 3, iter 53, loss 2.2955379486083984, acc 0.18000000715255737\n",
      "Epoch 3, iter 54, loss 2.2337229251861572, acc 0.10999999940395355\n",
      "Epoch 3, iter 55, loss 2.4584767818450928, acc 0.15000000596046448\n",
      "Epoch 3, iter 56, loss 2.3765268325805664, acc 0.12999999523162842\n",
      "Epoch 3, iter 57, loss 2.510607957839966, acc 0.15000000596046448\n",
      "Epoch 3, iter 58, loss 2.2767767906188965, acc 0.17000000178813934\n",
      "Epoch 3, iter 59, loss 2.4554946422576904, acc 0.11999999731779099\n",
      "Epoch 3, iter 60, loss 2.3242528438568115, acc 0.14000000059604645\n",
      "Epoch 3, iter 61, loss 2.490238904953003, acc 0.10999999940395355\n",
      "Epoch 3, iter 62, loss 2.3765792846679688, acc 0.12999999523162842\n",
      "Epoch 3, iter 63, loss 2.561387300491333, acc 0.07000000029802322\n",
      "Epoch 3, iter 64, loss 2.2697455883026123, acc 0.17000000178813934\n",
      "Epoch 3, iter 65, loss 2.5162453651428223, acc 0.10000000149011612\n",
      "Epoch 3, iter 66, loss 2.4077341556549072, acc 0.10000000149011612\n",
      "Epoch 3, iter 67, loss 2.3328025341033936, acc 0.1599999964237213\n",
      "Epoch 3, iter 68, loss 2.321049690246582, acc 0.12999999523162842\n",
      "Epoch 3, iter 69, loss 2.377164602279663, acc 0.12999999523162842\n",
      "Epoch 3, iter 70, loss 2.3378238677978516, acc 0.17000000178813934\n",
      "Epoch 3, iter 71, loss 2.446922540664673, acc 0.10999999940395355\n",
      "Epoch 3, iter 72, loss 2.330214738845825, acc 0.15000000596046448\n",
      "Epoch 3, iter 73, loss 2.370793581008911, acc 0.12999999523162842\n",
      "Epoch 3, iter 74, loss 2.334705114364624, acc 0.17000000178813934\n",
      "Epoch 3, iter 75, loss 2.363865613937378, acc 0.14000000059604645\n",
      "Epoch 3, iter 76, loss 2.393771171569824, acc 0.15000000596046448\n",
      "Epoch 3, iter 77, loss 2.352759599685669, acc 0.18000000715255737\n",
      "Epoch 3, iter 78, loss 2.411057710647583, acc 0.17000000178813934\n",
      "Epoch 3, iter 79, loss 2.393486976623535, acc 0.14000000059604645\n",
      "Epoch 3, iter 80, loss 2.4428811073303223, acc 0.10000000149011612\n",
      "Epoch 3, iter 81, loss 2.3435370922088623, acc 0.1599999964237213\n",
      "Epoch 3, iter 82, loss 2.3658766746520996, acc 0.15000000596046448\n",
      "Epoch 3, iter 83, loss 2.3691673278808594, acc 0.10000000149011612\n",
      "Epoch 3, iter 84, loss 2.4261720180511475, acc 0.1599999964237213\n",
      "Epoch 3, iter 85, loss 2.444287061691284, acc 0.1599999964237213\n",
      "Epoch 3, iter 86, loss 2.3933894634246826, acc 0.10000000149011612\n",
      "Epoch 3, iter 87, loss 2.3019485473632812, acc 0.27000001072883606\n",
      "Epoch 3, iter 88, loss 2.2916994094848633, acc 0.1599999964237213\n",
      "Epoch 3, iter 89, loss 2.4229724407196045, acc 0.10999999940395355\n",
      "Epoch 3, iter 90, loss 2.342665672302246, acc 0.10000000149011612\n",
      "Epoch 3, iter 91, loss 2.427644729614258, acc 0.10999999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 92, loss 2.4466898441314697, acc 0.15000000596046448\n",
      "Epoch 3, iter 93, loss 2.3815441131591797, acc 0.11999999731779099\n",
      "Epoch 3, iter 94, loss 2.338801622390747, acc 0.14000000059604645\n",
      "Epoch 3, iter 95, loss 2.4585177898406982, acc 0.09000000357627869\n",
      "Epoch 3, iter 96, loss 2.2686607837677, acc 0.2199999988079071\n",
      "Epoch 3, iter 97, loss 2.4154911041259766, acc 0.07000000029802322\n",
      "Epoch 3, iter 98, loss 2.326753616333008, acc 0.17000000178813934\n",
      "Epoch 3, iter 99, loss 2.4552347660064697, acc 0.17000000178813934\n",
      "Epoch 3, iter 100, loss 2.313383102416992, acc 0.15000000596046448\n",
      "Epoch 3, iter 101, loss 2.338291645050049, acc 0.15000000596046448\n",
      "Epoch 3, iter 102, loss 2.2779300212860107, acc 0.1599999964237213\n",
      "Epoch 3, iter 103, loss 2.3305575847625732, acc 0.18000000715255737\n",
      "Epoch 3, iter 104, loss 2.380129337310791, acc 0.14000000059604645\n",
      "Epoch 3, iter 105, loss 2.3354198932647705, acc 0.17000000178813934\n",
      "Epoch 3, iter 106, loss 2.3444931507110596, acc 0.17000000178813934\n",
      "Epoch 3, iter 107, loss 2.3287253379821777, acc 0.17000000178813934\n",
      "Epoch 3, iter 108, loss 2.2620959281921387, acc 0.18000000715255737\n",
      "Epoch 3, iter 109, loss 2.3571958541870117, acc 0.10000000149011612\n",
      "Epoch 3, iter 110, loss 2.4638149738311768, acc 0.11999999731779099\n",
      "Epoch 3, iter 111, loss 2.4298739433288574, acc 0.10000000149011612\n",
      "Epoch 3, iter 112, loss 2.372070550918579, acc 0.18000000715255737\n",
      "Epoch 3, iter 113, loss 2.3301210403442383, acc 0.11999999731779099\n",
      "Epoch 3, iter 114, loss 2.3280797004699707, acc 0.1599999964237213\n",
      "Epoch 3, iter 115, loss 2.3271472454071045, acc 0.14000000059604645\n",
      "Epoch 3, iter 116, loss 2.3423404693603516, acc 0.12999999523162842\n",
      "Epoch 3, iter 117, loss 2.3419811725616455, acc 0.18000000715255737\n",
      "Epoch 3, iter 118, loss 2.355903387069702, acc 0.17000000178813934\n",
      "Epoch 3, iter 119, loss 2.3324027061462402, acc 0.15000000596046448\n",
      "Epoch 3, iter 120, loss 2.350895881652832, acc 0.15000000596046448\n",
      "Epoch 3, iter 121, loss 2.401893377304077, acc 0.1599999964237213\n",
      "Epoch 3, iter 122, loss 2.335725784301758, acc 0.14000000059604645\n",
      "Epoch 3, iter 123, loss 2.338747978210449, acc 0.2199999988079071\n",
      "Epoch 3, iter 124, loss 2.318819046020508, acc 0.07999999821186066\n",
      "Epoch 3, iter 125, loss 2.3065450191497803, acc 0.12999999523162842\n",
      "Epoch 3, iter 126, loss 2.357914924621582, acc 0.14000000059604645\n",
      "Epoch 3, iter 127, loss 2.415076494216919, acc 0.07000000029802322\n",
      "Epoch 3, iter 128, loss 2.3381574153900146, acc 0.11999999731779099\n",
      "Epoch 3, iter 129, loss 2.4090969562530518, acc 0.1599999964237213\n",
      "Epoch 3, iter 130, loss 2.4021544456481934, acc 0.1599999964237213\n",
      "Epoch 3, iter 131, loss 2.365062952041626, acc 0.20999999344348907\n",
      "Epoch 3, iter 132, loss 2.2910544872283936, acc 0.1899999976158142\n",
      "Epoch 3, iter 133, loss 2.3316421508789062, acc 0.12999999523162842\n",
      "Epoch 3, iter 134, loss 2.48179292678833, acc 0.10999999940395355\n",
      "Epoch 3, iter 135, loss 2.264239549636841, acc 0.18000000715255737\n",
      "Epoch 3, iter 136, loss 2.3816587924957275, acc 0.11999999731779099\n",
      "Epoch 3, iter 137, loss 2.3797223567962646, acc 0.14000000059604645\n",
      "Epoch 3, iter 138, loss 2.282179117202759, acc 0.12999999523162842\n",
      "Epoch 3, iter 139, loss 2.4095051288604736, acc 0.11999999731779099\n",
      "Epoch 3, iter 140, loss 2.4605071544647217, acc 0.10999999940395355\n",
      "Epoch 3, iter 141, loss 2.4550368785858154, acc 0.05999999865889549\n",
      "Epoch 3, iter 142, loss 2.3505499362945557, acc 0.11999999731779099\n",
      "Epoch 3, iter 143, loss 2.3016374111175537, acc 0.11999999731779099\n",
      "Epoch 3, iter 144, loss 2.4405031204223633, acc 0.10000000149011612\n",
      "Epoch 3, iter 145, loss 2.406472682952881, acc 0.12999999523162842\n",
      "Epoch 3, iter 146, loss 2.3787314891815186, acc 0.12999999523162842\n",
      "Epoch 3, iter 147, loss 2.2793524265289307, acc 0.20999999344348907\n",
      "Epoch 3, iter 148, loss 2.3079967498779297, acc 0.12999999523162842\n",
      "Epoch 3, iter 149, loss 2.3862876892089844, acc 0.15000000596046448\n",
      "Epoch 3, iter 150, loss 2.199963092803955, acc 0.23000000417232513\n",
      "Epoch 3, iter 151, loss 2.2984731197357178, acc 0.12999999523162842\n",
      "Epoch 3, iter 152, loss 2.3478102684020996, acc 0.14000000059604645\n",
      "Epoch 3, iter 153, loss 2.275024652481079, acc 0.1899999976158142\n",
      "Epoch 3, iter 154, loss 2.3481054306030273, acc 0.14000000059604645\n",
      "Epoch 3, iter 155, loss 2.2692880630493164, acc 0.18000000715255737\n",
      "Epoch 3, iter 156, loss 2.326205253601074, acc 0.17000000178813934\n",
      "Epoch 3, iter 157, loss 2.5016086101531982, acc 0.05999999865889549\n",
      "Epoch 3, iter 158, loss 2.4121546745300293, acc 0.14000000059604645\n",
      "Epoch 3, iter 159, loss 2.3029446601867676, acc 0.15000000596046448\n",
      "Epoch 3, iter 160, loss 2.295609474182129, acc 0.20000000298023224\n",
      "Epoch 3, iter 161, loss 2.501534938812256, acc 0.09000000357627869\n",
      "Epoch 3, iter 162, loss 2.309727668762207, acc 0.15000000596046448\n",
      "Epoch 3, iter 163, loss 2.502887010574341, acc 0.07999999821186066\n",
      "Epoch 3, iter 164, loss 2.3779239654541016, acc 0.14000000059604645\n",
      "Epoch 3, iter 165, loss 2.380096435546875, acc 0.15000000596046448\n",
      "Epoch 3, iter 166, loss 2.423713207244873, acc 0.05000000074505806\n",
      "Epoch 3, iter 167, loss 2.355361223220825, acc 0.12999999523162842\n",
      "Epoch 3, iter 168, loss 2.3392269611358643, acc 0.10000000149011612\n",
      "Epoch 3, iter 169, loss 2.3574109077453613, acc 0.14000000059604645\n",
      "Epoch 3, iter 170, loss 2.390035390853882, acc 0.14000000059604645\n",
      "Epoch 3, iter 171, loss 2.375474214553833, acc 0.12999999523162842\n",
      "Epoch 3, iter 172, loss 2.3652524948120117, acc 0.10000000149011612\n",
      "Epoch 3, iter 173, loss 2.359339475631714, acc 0.1899999976158142\n",
      "Epoch 3, iter 174, loss 2.2962241172790527, acc 0.18000000715255737\n",
      "Epoch 3, iter 175, loss 2.347215414047241, acc 0.20999999344348907\n",
      "Epoch 3, iter 176, loss 2.3673131465911865, acc 0.1599999964237213\n",
      "Epoch 3, iter 177, loss 2.346696615219116, acc 0.20999999344348907\n",
      "Epoch 3, iter 178, loss 2.4083054065704346, acc 0.15000000596046448\n",
      "Epoch 3, iter 179, loss 2.4168858528137207, acc 0.17000000178813934\n",
      "Epoch 3, iter 180, loss 2.36761736869812, acc 0.1599999964237213\n",
      "Epoch 3, iter 181, loss 2.257512092590332, acc 0.1599999964237213\n",
      "Epoch 3, iter 182, loss 2.281052589416504, acc 0.14000000059604645\n",
      "Epoch 3, iter 183, loss 2.284315347671509, acc 0.18000000715255737\n",
      "Epoch 3, iter 184, loss 2.4011924266815186, acc 0.07999999821186066\n",
      "Epoch 3, iter 185, loss 2.278221607208252, acc 0.1599999964237213\n",
      "Epoch 3, iter 186, loss 2.351675033569336, acc 0.15000000596046448\n",
      "Epoch 3, iter 187, loss 2.306114435195923, acc 0.17000000178813934\n",
      "Epoch 3, iter 188, loss 2.3562123775482178, acc 0.11999999731779099\n",
      "Epoch 3, iter 189, loss 2.3033149242401123, acc 0.1599999964237213\n",
      "Epoch 3, iter 190, loss 2.421025037765503, acc 0.15000000596046448\n",
      "Epoch 3, iter 191, loss 2.227799892425537, acc 0.20999999344348907\n",
      "Epoch 3, iter 192, loss 2.4065709114074707, acc 0.10999999940395355\n",
      "Epoch 3, iter 193, loss 2.2779250144958496, acc 0.12999999523162842\n",
      "Epoch 3, iter 194, loss 2.270465135574341, acc 0.12999999523162842\n",
      "Epoch 3, iter 195, loss 2.547938585281372, acc 0.10000000149011612\n",
      "Epoch 3, iter 196, loss 2.3954110145568848, acc 0.10999999940395355\n",
      "Epoch 3, iter 197, loss 2.324606418609619, acc 0.11999999731779099\n",
      "Epoch 3, iter 198, loss 2.330152988433838, acc 0.10000000149011612\n",
      "Epoch 3, iter 199, loss 2.2786953449249268, acc 0.14000000059604645\n",
      "Epoch 3, iter 200, loss 2.380415916442871, acc 0.10999999940395355\n",
      "Epoch 3, iter 201, loss 2.399914503097534, acc 0.10000000149011612\n",
      "Epoch 3, iter 202, loss 2.38639760017395, acc 0.10999999940395355\n",
      "Epoch 3, iter 203, loss 2.4940686225891113, acc 0.10999999940395355\n",
      "Epoch 3, iter 204, loss 2.3244118690490723, acc 0.1599999964237213\n",
      "Epoch 3, iter 205, loss 2.297041177749634, acc 0.11999999731779099\n",
      "Epoch 3, iter 206, loss 2.3143486976623535, acc 0.14000000059604645\n",
      "Epoch 3, iter 207, loss 2.3091979026794434, acc 0.17000000178813934\n",
      "Epoch 3, iter 208, loss 2.4381649494171143, acc 0.12999999523162842\n",
      "Epoch 3, iter 209, loss 2.4824352264404297, acc 0.09000000357627869\n",
      "Epoch 3, iter 210, loss 2.4565370082855225, acc 0.11999999731779099\n",
      "Epoch 3, iter 211, loss 2.2744781970977783, acc 0.17000000178813934\n",
      "Epoch 3, iter 212, loss 2.2972466945648193, acc 0.15000000596046448\n",
      "Epoch 3, iter 213, loss 2.3468105792999268, acc 0.14000000059604645\n",
      "Epoch 3, iter 214, loss 2.420535087585449, acc 0.10999999940395355\n",
      "Epoch 3, iter 215, loss 2.3325769901275635, acc 0.11999999731779099\n",
      "Epoch 3, iter 216, loss 2.3814945220947266, acc 0.14000000059604645\n",
      "Epoch 3, iter 217, loss 2.2453653812408447, acc 0.1599999964237213\n",
      "Epoch 3, iter 218, loss 2.4251413345336914, acc 0.1899999976158142\n",
      "Epoch 3, iter 219, loss 2.3359994888305664, acc 0.18000000715255737\n",
      "Epoch 3, iter 220, loss 2.343125104904175, acc 0.07999999821186066\n",
      "Epoch 3, iter 221, loss 2.3238370418548584, acc 0.1599999964237213\n",
      "Epoch 3, iter 222, loss 2.4247372150421143, acc 0.10999999940395355\n",
      "Epoch 3, iter 223, loss 2.412104845046997, acc 0.11999999731779099\n",
      "Epoch 3, iter 224, loss 2.3624422550201416, acc 0.15000000596046448\n",
      "Epoch 3, iter 225, loss 2.240959644317627, acc 0.1899999976158142\n",
      "Epoch 3, iter 226, loss 2.3525657653808594, acc 0.10000000149011612\n",
      "Epoch 3, iter 227, loss 2.337475299835205, acc 0.15000000596046448\n",
      "Epoch 3, iter 228, loss 2.3027682304382324, acc 0.20999999344348907\n",
      "Epoch 3, iter 229, loss 2.3726508617401123, acc 0.10999999940395355\n",
      "Epoch 3, iter 230, loss 2.3761820793151855, acc 0.12999999523162842\n",
      "Epoch 3, iter 231, loss 2.3443124294281006, acc 0.11999999731779099\n",
      "Epoch 3, iter 232, loss 2.374878406524658, acc 0.11999999731779099\n",
      "Epoch 3, iter 233, loss 2.362363338470459, acc 0.15000000596046448\n",
      "Epoch 3, iter 234, loss 2.2950809001922607, acc 0.09000000357627869\n",
      "Epoch 3, iter 235, loss 2.385976791381836, acc 0.10000000149011612\n",
      "Epoch 3, iter 236, loss 2.3738274574279785, acc 0.1599999964237213\n",
      "Epoch 3, iter 237, loss 2.4314708709716797, acc 0.11999999731779099\n",
      "Epoch 3, iter 238, loss 2.3375349044799805, acc 0.17000000178813934\n",
      "Epoch 3, iter 239, loss 2.4413139820098877, acc 0.07000000029802322\n",
      "Epoch 3, iter 240, loss 2.3387274742126465, acc 0.20999999344348907\n",
      "Epoch 3, iter 241, loss 2.3568170070648193, acc 0.15000000596046448\n",
      "Epoch 3, iter 242, loss 2.525749921798706, acc 0.05999999865889549\n",
      "Epoch 3, iter 243, loss 2.4324936866760254, acc 0.20000000298023224\n",
      "Epoch 3, iter 244, loss 2.419483184814453, acc 0.15000000596046448\n",
      "Epoch 3, iter 245, loss 2.215482234954834, acc 0.20000000298023224\n",
      "Epoch 3, iter 246, loss 2.2921345233917236, acc 0.20000000298023224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 247, loss 2.3252904415130615, acc 0.10999999940395355\n",
      "Epoch 3, iter 248, loss 2.3025057315826416, acc 0.1599999964237213\n",
      "Epoch 3, iter 249, loss 2.3562142848968506, acc 0.11999999731779099\n",
      "Epoch 3, iter 250, loss 2.3162031173706055, acc 0.1599999964237213\n",
      "Epoch 3, iter 251, loss 2.330259323120117, acc 0.17000000178813934\n",
      "Epoch 3, iter 252, loss 2.2836074829101562, acc 0.12999999523162842\n",
      "Epoch 3, iter 253, loss 2.4888970851898193, acc 0.1599999964237213\n",
      "Epoch 3, iter 254, loss 2.274238109588623, acc 0.15000000596046448\n",
      "Epoch 3, iter 255, loss 2.431205987930298, acc 0.14000000059604645\n",
      "Epoch 3, iter 256, loss 2.394780397415161, acc 0.11999999731779099\n",
      "Epoch 3, iter 257, loss 2.2814769744873047, acc 0.17000000178813934\n",
      "Epoch 3, iter 258, loss 2.4158551692962646, acc 0.14000000059604645\n",
      "Epoch 3, iter 259, loss 2.3520429134368896, acc 0.15000000596046448\n",
      "Epoch 3, iter 260, loss 2.298330545425415, acc 0.12999999523162842\n",
      "Epoch 3, iter 261, loss 2.3000917434692383, acc 0.11999999731779099\n",
      "Epoch 3, iter 262, loss 2.468078851699829, acc 0.10000000149011612\n",
      "Epoch 3, iter 263, loss 2.2289040088653564, acc 0.12999999523162842\n",
      "Epoch 3, iter 264, loss 2.2953379154205322, acc 0.17000000178813934\n",
      "Epoch 3, iter 265, loss 2.2098662853240967, acc 0.2199999988079071\n",
      "Epoch 3, iter 266, loss 2.416466474533081, acc 0.14000000059604645\n",
      "Epoch 3, iter 267, loss 2.379040002822876, acc 0.07000000029802322\n",
      "Epoch 3, iter 268, loss 2.3135836124420166, acc 0.15000000596046448\n",
      "Epoch 3, iter 269, loss 2.278521776199341, acc 0.20999999344348907\n",
      "Epoch 3, iter 270, loss 2.42280912399292, acc 0.10000000149011612\n",
      "Epoch 3, iter 271, loss 2.2789628505706787, acc 0.20999999344348907\n",
      "Epoch 3, iter 272, loss 2.3013827800750732, acc 0.14000000059604645\n",
      "Epoch 3, iter 273, loss 2.3821706771850586, acc 0.11999999731779099\n",
      "Epoch 3, iter 274, loss 2.5037269592285156, acc 0.05999999865889549\n",
      "Epoch 3, iter 275, loss 2.418297529220581, acc 0.09000000357627869\n",
      "Epoch 3, iter 276, loss 2.3778231143951416, acc 0.15000000596046448\n",
      "Epoch 3, iter 277, loss 2.2141833305358887, acc 0.15000000596046448\n",
      "Epoch 3, iter 278, loss 2.254467248916626, acc 0.12999999523162842\n",
      "Epoch 3, iter 279, loss 2.4405078887939453, acc 0.14000000059604645\n",
      "Epoch 3, iter 280, loss 2.3419203758239746, acc 0.10999999940395355\n",
      "Epoch 3, iter 281, loss 2.384286880493164, acc 0.1599999964237213\n",
      "Epoch 3, iter 282, loss 2.2015879154205322, acc 0.1899999976158142\n",
      "Epoch 3, iter 283, loss 2.379540205001831, acc 0.1599999964237213\n",
      "Epoch 3, iter 284, loss 2.3322081565856934, acc 0.10999999940395355\n",
      "Epoch 3, iter 285, loss 2.363185405731201, acc 0.10000000149011612\n",
      "Epoch 3, iter 286, loss 2.316061019897461, acc 0.10999999940395355\n",
      "Epoch 3, iter 287, loss 2.325309991836548, acc 0.11999999731779099\n",
      "Epoch 3, iter 288, loss 2.4681618213653564, acc 0.07999999821186066\n",
      "Epoch 3, iter 289, loss 2.425396203994751, acc 0.07999999821186066\n",
      "Epoch 3, iter 290, loss 2.386974573135376, acc 0.10000000149011612\n",
      "Epoch 3, iter 291, loss 2.4095685482025146, acc 0.10000000149011612\n",
      "Epoch 3, iter 292, loss 2.3130457401275635, acc 0.1599999964237213\n",
      "Epoch 3, iter 293, loss 2.374270439147949, acc 0.14000000059604645\n",
      "Epoch 3, iter 294, loss 2.1900925636291504, acc 0.23000000417232513\n",
      "Epoch 3, iter 295, loss 2.4040486812591553, acc 0.1599999964237213\n",
      "Epoch 3, iter 296, loss 2.3147993087768555, acc 0.09000000357627869\n",
      "Epoch 3, iter 297, loss 2.4149084091186523, acc 0.1899999976158142\n",
      "Epoch 3, iter 298, loss 2.2733840942382812, acc 0.1599999964237213\n",
      "Epoch 3, iter 299, loss 2.503852605819702, acc 0.12999999523162842\n",
      "Epoch 3, iter 300, loss 2.3392527103424072, acc 0.10999999940395355\n",
      "Epoch 3, iter 301, loss 2.4056015014648438, acc 0.10999999940395355\n",
      "Epoch 3, iter 302, loss 2.354339361190796, acc 0.14000000059604645\n",
      "Epoch 3, iter 303, loss 2.3941762447357178, acc 0.10000000149011612\n",
      "Epoch 3, iter 304, loss 2.3554346561431885, acc 0.17000000178813934\n",
      "Epoch 3, iter 305, loss 2.343564510345459, acc 0.18000000715255737\n",
      "Epoch 3, iter 306, loss 2.339108943939209, acc 0.11999999731779099\n",
      "Epoch 3, iter 307, loss 2.3215956687927246, acc 0.15000000596046448\n",
      "Epoch 3, iter 308, loss 2.3578684329986572, acc 0.17000000178813934\n",
      "Epoch 3, iter 309, loss 2.2846603393554688, acc 0.14000000059604645\n",
      "Epoch 3, iter 310, loss 2.330815076828003, acc 0.12999999523162842\n",
      "Epoch 3, iter 311, loss 2.4154345989227295, acc 0.11999999731779099\n",
      "Epoch 3, iter 312, loss 2.305551052093506, acc 0.1599999964237213\n",
      "Epoch 3, iter 313, loss 2.344625949859619, acc 0.20000000298023224\n",
      "Epoch 3, iter 314, loss 2.257185220718384, acc 0.1599999964237213\n",
      "Epoch 3, iter 315, loss 2.2981600761413574, acc 0.1599999964237213\n",
      "Epoch 3, iter 316, loss 2.374159336090088, acc 0.11999999731779099\n",
      "Epoch 3, iter 317, loss 2.365680456161499, acc 0.1899999976158142\n",
      "Epoch 3, iter 318, loss 2.227597713470459, acc 0.20000000298023224\n",
      "Epoch 3, iter 319, loss 2.2745556831359863, acc 0.2199999988079071\n",
      "Epoch 3, iter 320, loss 2.372756004333496, acc 0.1599999964237213\n",
      "Epoch 3, iter 321, loss 2.4526314735412598, acc 0.11999999731779099\n",
      "Epoch 3, iter 322, loss 2.4038848876953125, acc 0.14000000059604645\n",
      "Epoch 3, iter 323, loss 2.2956197261810303, acc 0.1599999964237213\n",
      "Epoch 3, iter 324, loss 2.279038429260254, acc 0.15000000596046448\n",
      "Epoch 3, iter 325, loss 2.358067750930786, acc 0.18000000715255737\n",
      "Epoch 3, iter 326, loss 2.2919466495513916, acc 0.10000000149011612\n",
      "Epoch 3, iter 327, loss 2.31506609916687, acc 0.12999999523162842\n",
      "Epoch 3, iter 328, loss 2.4320852756500244, acc 0.07000000029802322\n",
      "Epoch 3, iter 329, loss 2.419015884399414, acc 0.11999999731779099\n",
      "Epoch 3, iter 330, loss 2.3147690296173096, acc 0.17000000178813934\n",
      "Epoch 3, iter 331, loss 2.2855277061462402, acc 0.1899999976158142\n",
      "Epoch 3, iter 332, loss 2.2501611709594727, acc 0.1599999964237213\n",
      "Epoch 3, iter 333, loss 2.2674684524536133, acc 0.14000000059604645\n",
      "Epoch 3, iter 334, loss 2.3121492862701416, acc 0.18000000715255737\n",
      "Epoch 3, iter 335, loss 2.2396905422210693, acc 0.17000000178813934\n",
      "Epoch 3, iter 336, loss 2.2566192150115967, acc 0.14000000059604645\n",
      "Epoch 3, iter 337, loss 2.446194648742676, acc 0.10000000149011612\n",
      "Epoch 3, iter 338, loss 2.235205888748169, acc 0.1899999976158142\n",
      "Epoch 3, iter 339, loss 2.1767680644989014, acc 0.17000000178813934\n",
      "Epoch 3, iter 340, loss 2.425771951675415, acc 0.10999999940395355\n",
      "Epoch 3, iter 341, loss 2.2978720664978027, acc 0.12999999523162842\n",
      "Epoch 3, iter 342, loss 2.218308448791504, acc 0.2199999988079071\n",
      "Epoch 3, iter 343, loss 2.3436338901519775, acc 0.20000000298023224\n",
      "Epoch 3, iter 344, loss 2.3523855209350586, acc 0.10000000149011612\n",
      "Epoch 3, iter 345, loss 2.3511931896209717, acc 0.15000000596046448\n",
      "Epoch 3, iter 346, loss 2.372568130493164, acc 0.11999999731779099\n",
      "Epoch 3, iter 347, loss 2.2589426040649414, acc 0.20999999344348907\n",
      "Epoch 3, iter 348, loss 2.2665584087371826, acc 0.14000000059604645\n",
      "Epoch 3, iter 349, loss 2.174651861190796, acc 0.20000000298023224\n",
      "Epoch 3, iter 350, loss 2.3190109729766846, acc 0.17000000178813934\n",
      "Epoch 3, iter 351, loss 2.365933656692505, acc 0.12999999523162842\n",
      "Epoch 3, iter 352, loss 2.327892780303955, acc 0.14000000059604645\n",
      "Epoch 3, iter 353, loss 2.3454434871673584, acc 0.10999999940395355\n",
      "Epoch 3, iter 354, loss 2.258974075317383, acc 0.15000000596046448\n",
      "Epoch 3, iter 355, loss 2.3751165866851807, acc 0.11999999731779099\n",
      "Epoch 3, iter 356, loss 2.3174445629119873, acc 0.1599999964237213\n",
      "Epoch 3, iter 357, loss 2.2492265701293945, acc 0.18000000715255737\n",
      "Epoch 3, iter 358, loss 2.337745428085327, acc 0.20000000298023224\n",
      "Epoch 3, iter 359, loss 2.3385918140411377, acc 0.07999999821186066\n",
      "Epoch 3, iter 360, loss 2.315932035446167, acc 0.1599999964237213\n",
      "Epoch 3, iter 361, loss 2.348701238632202, acc 0.10999999940395355\n",
      "Epoch 3, iter 362, loss 2.42680025100708, acc 0.14000000059604645\n",
      "Epoch 3, iter 363, loss 2.323643207550049, acc 0.1599999964237213\n",
      "Epoch 3, iter 364, loss 2.3578312397003174, acc 0.15000000596046448\n",
      "Epoch 3, iter 365, loss 2.358675956726074, acc 0.11999999731779099\n",
      "Epoch 3, iter 366, loss 2.237917423248291, acc 0.17000000178813934\n",
      "Epoch 3, iter 367, loss 2.3389241695404053, acc 0.10999999940395355\n",
      "Epoch 3, iter 368, loss 2.3309977054595947, acc 0.18000000715255737\n",
      "Epoch 3, iter 369, loss 2.348478078842163, acc 0.10000000149011612\n",
      "Epoch 3, iter 370, loss 2.3579800128936768, acc 0.12999999523162842\n",
      "Epoch 3, iter 371, loss 2.2937281131744385, acc 0.12999999523162842\n",
      "Epoch 3, iter 372, loss 2.2788753509521484, acc 0.18000000715255737\n",
      "Epoch 3, iter 373, loss 2.342747211456299, acc 0.14000000059604645\n",
      "Epoch 3, iter 374, loss 2.277444362640381, acc 0.1599999964237213\n",
      "Epoch 3, iter 375, loss 2.371352195739746, acc 0.14000000059604645\n",
      "Epoch 3, iter 376, loss 2.2852983474731445, acc 0.14000000059604645\n",
      "Epoch 3, iter 377, loss 2.362180471420288, acc 0.10000000149011612\n",
      "Epoch 3, iter 378, loss 2.2730112075805664, acc 0.18000000715255737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 379, loss 2.364205837249756, acc 0.1599999964237213\n",
      "Epoch 3, iter 380, loss 2.30241060256958, acc 0.17000000178813934\n",
      "Epoch 3, iter 381, loss 2.3910982608795166, acc 0.1899999976158142\n",
      "Epoch 3, iter 382, loss 2.189359426498413, acc 0.20000000298023224\n",
      "Epoch 3, iter 383, loss 2.320789098739624, acc 0.1899999976158142\n",
      "Epoch 3, iter 384, loss 2.348391056060791, acc 0.07999999821186066\n",
      "Epoch 3, iter 385, loss 2.410248041152954, acc 0.09000000357627869\n",
      "Epoch 3, iter 386, loss 2.3056905269622803, acc 0.1599999964237213\n",
      "Epoch 3, iter 387, loss 2.3130767345428467, acc 0.15000000596046448\n",
      "Epoch 3, iter 388, loss 2.240457534790039, acc 0.20999999344348907\n",
      "Epoch 3, iter 389, loss 2.295254945755005, acc 0.15000000596046448\n",
      "Epoch 3, iter 390, loss 2.2783186435699463, acc 0.17000000178813934\n",
      "Epoch 3, iter 391, loss 2.264514446258545, acc 0.1899999976158142\n",
      "Epoch 3, iter 392, loss 2.4509825706481934, acc 0.11999999731779099\n",
      "Epoch 3, iter 393, loss 2.3031530380249023, acc 0.11999999731779099\n",
      "Epoch 3, iter 394, loss 2.25447678565979, acc 0.18000000715255737\n",
      "Epoch 3, iter 395, loss 2.3332228660583496, acc 0.15000000596046448\n",
      "Epoch 3, iter 396, loss 2.4951982498168945, acc 0.12999999523162842\n",
      "Epoch 3, iter 397, loss 2.354527473449707, acc 0.10000000149011612\n",
      "Epoch 3, iter 398, loss 2.3484339714050293, acc 0.12999999523162842\n",
      "Epoch 3, iter 399, loss 2.365927219390869, acc 0.18000000715255737\n",
      "Epoch 3, iter 400, loss 2.276904821395874, acc 0.10999999940395355\n",
      "Epoch 3, iter 401, loss 2.3280043601989746, acc 0.15000000596046448\n",
      "Epoch 3, iter 402, loss 2.261950731277466, acc 0.1599999964237213\n",
      "Epoch 3, iter 403, loss 2.4479949474334717, acc 0.10000000149011612\n",
      "Epoch 3, iter 404, loss 2.4521210193634033, acc 0.09000000357627869\n",
      "Epoch 3, iter 405, loss 2.3314881324768066, acc 0.14000000059604645\n",
      "Epoch 3, iter 406, loss 2.350599765777588, acc 0.17000000178813934\n",
      "Epoch 3, iter 407, loss 2.320834159851074, acc 0.10000000149011612\n",
      "Epoch 3, iter 408, loss 2.280733108520508, acc 0.20000000298023224\n",
      "Epoch 3, iter 409, loss 2.394397020339966, acc 0.10999999940395355\n",
      "Epoch 3, iter 410, loss 2.295504570007324, acc 0.10999999940395355\n",
      "Epoch 3, iter 411, loss 2.31467866897583, acc 0.11999999731779099\n",
      "Epoch 3, iter 412, loss 2.275170087814331, acc 0.1599999964237213\n",
      "Epoch 3, iter 413, loss 2.4305503368377686, acc 0.10999999940395355\n",
      "Epoch 3, iter 414, loss 2.3724257946014404, acc 0.12999999523162842\n",
      "Epoch 3, iter 415, loss 2.4393668174743652, acc 0.10999999940395355\n",
      "Epoch 3, iter 416, loss 2.384424924850464, acc 0.10000000149011612\n",
      "Epoch 3, iter 417, loss 2.3059990406036377, acc 0.15000000596046448\n",
      "Epoch 3, iter 418, loss 2.2027580738067627, acc 0.20999999344348907\n",
      "Epoch 3, iter 419, loss 2.2256877422332764, acc 0.12999999523162842\n",
      "Epoch 3, iter 420, loss 2.3348124027252197, acc 0.11999999731779099\n",
      "Epoch 4, iter 1, loss 2.2729125022888184, acc 0.15000000596046448\n",
      "Epoch 4, iter 2, loss 2.3784759044647217, acc 0.10999999940395355\n",
      "Epoch 4, iter 3, loss 2.2777693271636963, acc 0.10999999940395355\n",
      "Epoch 4, iter 4, loss 2.3537404537200928, acc 0.20000000298023224\n",
      "Epoch 4, iter 5, loss 2.28139591217041, acc 0.11999999731779099\n",
      "Epoch 4, iter 6, loss 2.300273895263672, acc 0.15000000596046448\n",
      "Epoch 4, iter 7, loss 2.3606433868408203, acc 0.09000000357627869\n",
      "Epoch 4, iter 8, loss 2.2768495082855225, acc 0.17000000178813934\n",
      "Epoch 4, iter 9, loss 2.2678945064544678, acc 0.10999999940395355\n",
      "Epoch 4, iter 10, loss 2.3694345951080322, acc 0.15000000596046448\n",
      "Epoch 4, iter 11, loss 2.5198967456817627, acc 0.09000000357627869\n",
      "Epoch 4, iter 12, loss 2.3566107749938965, acc 0.11999999731779099\n",
      "Epoch 4, iter 13, loss 2.2409276962280273, acc 0.14000000059604645\n",
      "Epoch 4, iter 14, loss 2.3788955211639404, acc 0.10000000149011612\n",
      "Epoch 4, iter 15, loss 2.312458038330078, acc 0.05999999865889549\n",
      "Epoch 4, iter 16, loss 2.352273464202881, acc 0.10000000149011612\n",
      "Epoch 4, iter 17, loss 2.261857509613037, acc 0.1599999964237213\n",
      "Epoch 4, iter 18, loss 2.41166090965271, acc 0.14000000059604645\n",
      "Epoch 4, iter 19, loss 2.286278486251831, acc 0.17000000178813934\n",
      "Epoch 4, iter 20, loss 2.282212018966675, acc 0.1599999964237213\n",
      "Epoch 4, iter 21, loss 2.328134298324585, acc 0.11999999731779099\n",
      "Epoch 4, iter 22, loss 2.4115161895751953, acc 0.09000000357627869\n",
      "Epoch 4, iter 23, loss 2.2932825088500977, acc 0.17000000178813934\n",
      "Epoch 4, iter 24, loss 2.173253059387207, acc 0.17000000178813934\n",
      "Epoch 4, iter 25, loss 2.233973503112793, acc 0.20000000298023224\n",
      "Epoch 4, iter 26, loss 2.3457236289978027, acc 0.12999999523162842\n",
      "Epoch 4, iter 27, loss 2.2298405170440674, acc 0.20999999344348907\n",
      "Epoch 4, iter 28, loss 2.373382568359375, acc 0.10000000149011612\n",
      "Epoch 4, iter 29, loss 2.3484740257263184, acc 0.14000000059604645\n",
      "Epoch 4, iter 30, loss 2.3838741779327393, acc 0.17000000178813934\n",
      "Epoch 4, iter 31, loss 2.3365697860717773, acc 0.15000000596046448\n",
      "Epoch 4, iter 32, loss 2.3058385848999023, acc 0.10999999940395355\n",
      "Epoch 4, iter 33, loss 2.3096365928649902, acc 0.1899999976158142\n",
      "Epoch 4, iter 34, loss 2.2669785022735596, acc 0.1599999964237213\n",
      "Epoch 4, iter 35, loss 2.4265968799591064, acc 0.07999999821186066\n",
      "Epoch 4, iter 36, loss 2.3606152534484863, acc 0.15000000596046448\n",
      "Epoch 4, iter 37, loss 2.306936740875244, acc 0.18000000715255737\n",
      "Epoch 4, iter 38, loss 2.2731714248657227, acc 0.17000000178813934\n",
      "Epoch 4, iter 39, loss 2.310373306274414, acc 0.10999999940395355\n",
      "Epoch 4, iter 40, loss 2.2993290424346924, acc 0.14000000059604645\n",
      "Epoch 4, iter 41, loss 2.347468852996826, acc 0.10999999940395355\n",
      "Epoch 4, iter 42, loss 2.277468681335449, acc 0.10999999940395355\n",
      "Epoch 4, iter 43, loss 2.22703218460083, acc 0.17000000178813934\n",
      "Epoch 4, iter 44, loss 2.268454074859619, acc 0.12999999523162842\n",
      "Epoch 4, iter 45, loss 2.2807397842407227, acc 0.15000000596046448\n",
      "Epoch 4, iter 46, loss 2.2586326599121094, acc 0.1599999964237213\n",
      "Epoch 4, iter 47, loss 2.406294345855713, acc 0.10000000149011612\n",
      "Epoch 4, iter 48, loss 2.1937084197998047, acc 0.1599999964237213\n",
      "Epoch 4, iter 49, loss 2.2647335529327393, acc 0.1899999976158142\n",
      "Epoch 4, iter 50, loss 2.238504409790039, acc 0.20999999344348907\n",
      "Epoch 4, iter 51, loss 2.297337532043457, acc 0.07000000029802322\n",
      "Epoch 4, iter 52, loss 2.3300626277923584, acc 0.1599999964237213\n",
      "Epoch 4, iter 53, loss 2.2661101818084717, acc 0.1899999976158142\n",
      "Epoch 4, iter 54, loss 2.255506753921509, acc 0.09000000357627869\n",
      "Epoch 4, iter 55, loss 2.4016921520233154, acc 0.14000000059604645\n",
      "Epoch 4, iter 56, loss 2.3378591537475586, acc 0.10999999940395355\n",
      "Epoch 4, iter 57, loss 2.423668146133423, acc 0.1599999964237213\n",
      "Epoch 4, iter 58, loss 2.235665798187256, acc 0.17000000178813934\n",
      "Epoch 4, iter 59, loss 2.352778673171997, acc 0.14000000059604645\n",
      "Epoch 4, iter 60, loss 2.2484254837036133, acc 0.1599999964237213\n",
      "Epoch 4, iter 61, loss 2.3989267349243164, acc 0.10999999940395355\n",
      "Epoch 4, iter 62, loss 2.3475446701049805, acc 0.11999999731779099\n",
      "Epoch 4, iter 63, loss 2.437779426574707, acc 0.07000000029802322\n",
      "Epoch 4, iter 64, loss 2.204294204711914, acc 0.1899999976158142\n",
      "Epoch 4, iter 65, loss 2.3980677127838135, acc 0.10999999940395355\n",
      "Epoch 4, iter 66, loss 2.375823974609375, acc 0.10000000149011612\n",
      "Epoch 4, iter 67, loss 2.264974594116211, acc 0.18000000715255737\n",
      "Epoch 4, iter 68, loss 2.246973991394043, acc 0.14000000059604645\n",
      "Epoch 4, iter 69, loss 2.320643424987793, acc 0.12999999523162842\n",
      "Epoch 4, iter 70, loss 2.2439966201782227, acc 0.1899999976158142\n",
      "Epoch 4, iter 71, loss 2.363502025604248, acc 0.10999999940395355\n",
      "Epoch 4, iter 72, loss 2.2699596881866455, acc 0.15000000596046448\n",
      "Epoch 4, iter 73, loss 2.2545080184936523, acc 0.15000000596046448\n",
      "Epoch 4, iter 74, loss 2.3116531372070312, acc 0.17000000178813934\n",
      "Epoch 4, iter 75, loss 2.307366132736206, acc 0.15000000596046448\n",
      "Epoch 4, iter 76, loss 2.295448064804077, acc 0.1599999964237213\n",
      "Epoch 4, iter 77, loss 2.309410333633423, acc 0.18000000715255737\n",
      "Epoch 4, iter 78, loss 2.2989749908447266, acc 0.1599999964237213\n",
      "Epoch 4, iter 79, loss 2.2867302894592285, acc 0.15000000596046448\n",
      "Epoch 4, iter 80, loss 2.43523907661438, acc 0.07999999821186066\n",
      "Epoch 4, iter 81, loss 2.3216137886047363, acc 0.1599999964237213\n",
      "Epoch 4, iter 82, loss 2.3423502445220947, acc 0.1599999964237213\n",
      "Epoch 4, iter 83, loss 2.304586887359619, acc 0.10000000149011612\n",
      "Epoch 4, iter 84, loss 2.3151512145996094, acc 0.17000000178813934\n",
      "Epoch 4, iter 85, loss 2.4075119495391846, acc 0.15000000596046448\n",
      "Epoch 4, iter 86, loss 2.297800064086914, acc 0.07999999821186066\n",
      "Epoch 4, iter 87, loss 2.2466115951538086, acc 0.2800000011920929\n",
      "Epoch 4, iter 88, loss 2.2329909801483154, acc 0.15000000596046448\n",
      "Epoch 4, iter 89, loss 2.373612880706787, acc 0.10000000149011612\n",
      "Epoch 4, iter 90, loss 2.3152410984039307, acc 0.10999999940395355\n",
      "Epoch 4, iter 91, loss 2.3282229900360107, acc 0.14000000059604645\n",
      "Epoch 4, iter 92, loss 2.393130302429199, acc 0.15000000596046448\n",
      "Epoch 4, iter 93, loss 2.316521167755127, acc 0.11999999731779099\n",
      "Epoch 4, iter 94, loss 2.2734296321868896, acc 0.1599999964237213\n",
      "Epoch 4, iter 95, loss 2.4010865688323975, acc 0.10000000149011612\n",
      "Epoch 4, iter 96, loss 2.202763319015503, acc 0.2199999988079071\n",
      "Epoch 4, iter 97, loss 2.3531739711761475, acc 0.07999999821186066\n",
      "Epoch 4, iter 98, loss 2.2595269680023193, acc 0.17000000178813934\n",
      "Epoch 4, iter 99, loss 2.4271576404571533, acc 0.1599999964237213\n",
      "Epoch 4, iter 100, loss 2.3014345169067383, acc 0.15000000596046448\n",
      "Epoch 4, iter 101, loss 2.2602601051330566, acc 0.18000000715255737\n",
      "Epoch 4, iter 102, loss 2.223921775817871, acc 0.18000000715255737\n",
      "Epoch 4, iter 103, loss 2.2986385822296143, acc 0.1899999976158142\n",
      "Epoch 4, iter 104, loss 2.3835113048553467, acc 0.11999999731779099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 105, loss 2.241701602935791, acc 0.17000000178813934\n",
      "Epoch 4, iter 106, loss 2.3144047260284424, acc 0.15000000596046448\n",
      "Epoch 4, iter 107, loss 2.301898956298828, acc 0.18000000715255737\n",
      "Epoch 4, iter 108, loss 2.2145845890045166, acc 0.20000000298023224\n",
      "Epoch 4, iter 109, loss 2.28166127204895, acc 0.10000000149011612\n",
      "Epoch 4, iter 110, loss 2.4075498580932617, acc 0.11999999731779099\n",
      "Epoch 4, iter 111, loss 2.3384902477264404, acc 0.09000000357627869\n",
      "Epoch 4, iter 112, loss 2.3099236488342285, acc 0.17000000178813934\n",
      "Epoch 4, iter 113, loss 2.2530481815338135, acc 0.14000000059604645\n",
      "Epoch 4, iter 114, loss 2.2661540508270264, acc 0.18000000715255737\n",
      "Epoch 4, iter 115, loss 2.322129726409912, acc 0.11999999731779099\n",
      "Epoch 4, iter 116, loss 2.2932770252227783, acc 0.14000000059604645\n",
      "Epoch 4, iter 117, loss 2.2973742485046387, acc 0.1899999976158142\n",
      "Epoch 4, iter 118, loss 2.302682638168335, acc 0.17000000178813934\n",
      "Epoch 4, iter 119, loss 2.284005641937256, acc 0.15000000596046448\n",
      "Epoch 4, iter 120, loss 2.3045573234558105, acc 0.15000000596046448\n",
      "Epoch 4, iter 121, loss 2.3192663192749023, acc 0.17000000178813934\n",
      "Epoch 4, iter 122, loss 2.292140007019043, acc 0.14000000059604645\n",
      "Epoch 4, iter 123, loss 2.2523577213287354, acc 0.2199999988079071\n",
      "Epoch 4, iter 124, loss 2.255913734436035, acc 0.07999999821186066\n",
      "Epoch 4, iter 125, loss 2.2624449729919434, acc 0.12999999523162842\n",
      "Epoch 4, iter 126, loss 2.2580649852752686, acc 0.15000000596046448\n",
      "Epoch 4, iter 127, loss 2.3273537158966064, acc 0.09000000357627869\n",
      "Epoch 4, iter 128, loss 2.2940151691436768, acc 0.12999999523162842\n",
      "Epoch 4, iter 129, loss 2.335963249206543, acc 0.1599999964237213\n",
      "Epoch 4, iter 130, loss 2.310594081878662, acc 0.1899999976158142\n",
      "Epoch 4, iter 131, loss 2.244400978088379, acc 0.23000000417232513\n",
      "Epoch 4, iter 132, loss 2.259136438369751, acc 0.18000000715255737\n",
      "Epoch 4, iter 133, loss 2.2869956493377686, acc 0.11999999731779099\n",
      "Epoch 4, iter 134, loss 2.342160701751709, acc 0.1599999964237213\n",
      "Epoch 4, iter 135, loss 2.229797124862671, acc 0.18000000715255737\n",
      "Epoch 4, iter 136, loss 2.354018211364746, acc 0.11999999731779099\n",
      "Epoch 4, iter 137, loss 2.355457067489624, acc 0.11999999731779099\n",
      "Epoch 4, iter 138, loss 2.2435779571533203, acc 0.12999999523162842\n",
      "Epoch 4, iter 139, loss 2.374667167663574, acc 0.10999999940395355\n",
      "Epoch 4, iter 140, loss 2.3931686878204346, acc 0.10999999940395355\n",
      "Epoch 4, iter 141, loss 2.3841989040374756, acc 0.05999999865889549\n",
      "Epoch 4, iter 142, loss 2.308574676513672, acc 0.11999999731779099\n",
      "Epoch 4, iter 143, loss 2.2718822956085205, acc 0.11999999731779099\n",
      "Epoch 4, iter 144, loss 2.3982889652252197, acc 0.10000000149011612\n",
      "Epoch 4, iter 145, loss 2.346048593521118, acc 0.12999999523162842\n",
      "Epoch 4, iter 146, loss 2.3174684047698975, acc 0.14000000059604645\n",
      "Epoch 4, iter 147, loss 2.233661413192749, acc 0.20999999344348907\n",
      "Epoch 4, iter 148, loss 2.2462549209594727, acc 0.14000000059604645\n",
      "Epoch 4, iter 149, loss 2.3186049461364746, acc 0.1599999964237213\n",
      "Epoch 4, iter 150, loss 2.1589443683624268, acc 0.23999999463558197\n",
      "Epoch 4, iter 151, loss 2.2375481128692627, acc 0.14000000059604645\n",
      "Epoch 4, iter 152, loss 2.294586181640625, acc 0.14000000059604645\n",
      "Epoch 4, iter 153, loss 2.235884666442871, acc 0.1899999976158142\n",
      "Epoch 4, iter 154, loss 2.278621196746826, acc 0.1599999964237213\n",
      "Epoch 4, iter 155, loss 2.204289197921753, acc 0.20000000298023224\n",
      "Epoch 4, iter 156, loss 2.2827694416046143, acc 0.1599999964237213\n",
      "Epoch 4, iter 157, loss 2.391507625579834, acc 0.07999999821186066\n",
      "Epoch 4, iter 158, loss 2.3637096881866455, acc 0.12999999523162842\n",
      "Epoch 4, iter 159, loss 2.2594776153564453, acc 0.15000000596046448\n",
      "Epoch 4, iter 160, loss 2.242452383041382, acc 0.20000000298023224\n",
      "Epoch 4, iter 161, loss 2.426537275314331, acc 0.10000000149011612\n",
      "Epoch 4, iter 162, loss 2.2733147144317627, acc 0.1599999964237213\n",
      "Epoch 4, iter 163, loss 2.4174916744232178, acc 0.10999999940395355\n",
      "Epoch 4, iter 164, loss 2.3317160606384277, acc 0.14000000059604645\n",
      "Epoch 4, iter 165, loss 2.3211772441864014, acc 0.15000000596046448\n",
      "Epoch 4, iter 166, loss 2.3737878799438477, acc 0.03999999910593033\n",
      "Epoch 4, iter 167, loss 2.2880189418792725, acc 0.14000000059604645\n",
      "Epoch 4, iter 168, loss 2.2851576805114746, acc 0.10000000149011612\n",
      "Epoch 4, iter 169, loss 2.3071720600128174, acc 0.12999999523162842\n",
      "Epoch 4, iter 170, loss 2.3391916751861572, acc 0.14000000059604645\n",
      "Epoch 4, iter 171, loss 2.2957420349121094, acc 0.12999999523162842\n",
      "Epoch 4, iter 172, loss 2.2779457569122314, acc 0.10999999940395355\n",
      "Epoch 4, iter 173, loss 2.2817211151123047, acc 0.20000000298023224\n",
      "Epoch 4, iter 174, loss 2.2632083892822266, acc 0.18000000715255737\n",
      "Epoch 4, iter 175, loss 2.2498271465301514, acc 0.2199999988079071\n",
      "Epoch 4, iter 176, loss 2.303955554962158, acc 0.1599999964237213\n",
      "Epoch 4, iter 177, loss 2.335149049758911, acc 0.2199999988079071\n",
      "Epoch 4, iter 178, loss 2.3420848846435547, acc 0.17000000178813934\n",
      "Epoch 4, iter 179, loss 2.3412439823150635, acc 0.18000000715255737\n",
      "Epoch 4, iter 180, loss 2.2982823848724365, acc 0.17000000178813934\n",
      "Epoch 4, iter 181, loss 2.2068283557891846, acc 0.1599999964237213\n",
      "Epoch 4, iter 182, loss 2.236599922180176, acc 0.14000000059604645\n",
      "Epoch 4, iter 183, loss 2.265357494354248, acc 0.18000000715255737\n",
      "Epoch 4, iter 184, loss 2.284461259841919, acc 0.10000000149011612\n",
      "Epoch 4, iter 185, loss 2.196916341781616, acc 0.1599999964237213\n",
      "Epoch 4, iter 186, loss 2.285604476928711, acc 0.15000000596046448\n",
      "Epoch 4, iter 187, loss 2.2557051181793213, acc 0.17000000178813934\n",
      "Epoch 4, iter 188, loss 2.3096141815185547, acc 0.12999999523162842\n",
      "Epoch 4, iter 189, loss 2.261401653289795, acc 0.17000000178813934\n",
      "Epoch 4, iter 190, loss 2.3139524459838867, acc 0.1599999964237213\n",
      "Epoch 4, iter 191, loss 2.2191169261932373, acc 0.2199999988079071\n",
      "Epoch 4, iter 192, loss 2.3621714115142822, acc 0.11999999731779099\n",
      "Epoch 4, iter 193, loss 2.2389132976531982, acc 0.12999999523162842\n",
      "Epoch 4, iter 194, loss 2.2496209144592285, acc 0.12999999523162842\n",
      "Epoch 4, iter 195, loss 2.4687306880950928, acc 0.10000000149011612\n",
      "Epoch 4, iter 196, loss 2.347463607788086, acc 0.10000000149011612\n",
      "Epoch 4, iter 197, loss 2.2948997020721436, acc 0.11999999731779099\n",
      "Epoch 4, iter 198, loss 2.246904134750366, acc 0.11999999731779099\n",
      "Epoch 4, iter 199, loss 2.2778546810150146, acc 0.14000000059604645\n",
      "Epoch 4, iter 200, loss 2.3286631107330322, acc 0.10000000149011612\n",
      "Epoch 4, iter 201, loss 2.330995559692383, acc 0.10999999940395355\n",
      "Epoch 4, iter 202, loss 2.3129608631134033, acc 0.10999999940395355\n",
      "Epoch 4, iter 203, loss 2.423626184463501, acc 0.10999999940395355\n",
      "Epoch 4, iter 204, loss 2.294940233230591, acc 0.1599999964237213\n",
      "Epoch 4, iter 205, loss 2.2460684776306152, acc 0.11999999731779099\n",
      "Epoch 4, iter 206, loss 2.2704267501831055, acc 0.12999999523162842\n",
      "Epoch 4, iter 207, loss 2.2287354469299316, acc 0.18000000715255737\n",
      "Epoch 4, iter 208, loss 2.366199016571045, acc 0.14000000059604645\n",
      "Epoch 4, iter 209, loss 2.4412269592285156, acc 0.09000000357627869\n",
      "Epoch 4, iter 210, loss 2.3759403228759766, acc 0.15000000596046448\n",
      "Epoch 4, iter 211, loss 2.2208032608032227, acc 0.18000000715255737\n",
      "Epoch 4, iter 212, loss 2.2613649368286133, acc 0.15000000596046448\n",
      "Epoch 4, iter 213, loss 2.249699592590332, acc 0.1599999964237213\n",
      "Epoch 4, iter 214, loss 2.3582189083099365, acc 0.10999999940395355\n",
      "Epoch 4, iter 215, loss 2.2783403396606445, acc 0.12999999523162842\n",
      "Epoch 4, iter 216, loss 2.2987172603607178, acc 0.1599999964237213\n",
      "Epoch 4, iter 217, loss 2.2102506160736084, acc 0.17000000178813934\n",
      "Epoch 4, iter 218, loss 2.343580484390259, acc 0.1899999976158142\n",
      "Epoch 4, iter 219, loss 2.283510684967041, acc 0.18000000715255737\n",
      "Epoch 4, iter 220, loss 2.2878592014312744, acc 0.07999999821186066\n",
      "Epoch 4, iter 221, loss 2.230372428894043, acc 0.1599999964237213\n",
      "Epoch 4, iter 222, loss 2.376178741455078, acc 0.10999999940395355\n",
      "Epoch 4, iter 223, loss 2.326939582824707, acc 0.12999999523162842\n",
      "Epoch 4, iter 224, loss 2.282003879547119, acc 0.1599999964237213\n",
      "Epoch 4, iter 225, loss 2.219327926635742, acc 0.1899999976158142\n",
      "Epoch 4, iter 226, loss 2.2877390384674072, acc 0.11999999731779099\n",
      "Epoch 4, iter 227, loss 2.294548511505127, acc 0.15000000596046448\n",
      "Epoch 4, iter 228, loss 2.231213092803955, acc 0.2199999988079071\n",
      "Epoch 4, iter 229, loss 2.3178679943084717, acc 0.11999999731779099\n",
      "Epoch 4, iter 230, loss 2.3408048152923584, acc 0.14000000059604645\n",
      "Epoch 4, iter 231, loss 2.315059185028076, acc 0.12999999523162842\n",
      "Epoch 4, iter 232, loss 2.321432113647461, acc 0.11999999731779099\n",
      "Epoch 4, iter 233, loss 2.2640810012817383, acc 0.18000000715255737\n",
      "Epoch 4, iter 234, loss 2.275608777999878, acc 0.09000000357627869\n",
      "Epoch 4, iter 235, loss 2.3424859046936035, acc 0.10000000149011612\n",
      "Epoch 4, iter 236, loss 2.3106513023376465, acc 0.1599999964237213\n",
      "Epoch 4, iter 237, loss 2.34922456741333, acc 0.12999999523162842\n",
      "Epoch 4, iter 238, loss 2.284531354904175, acc 0.1599999964237213\n",
      "Epoch 4, iter 239, loss 2.377211093902588, acc 0.07000000029802322\n",
      "Epoch 4, iter 240, loss 2.319394588470459, acc 0.20999999344348907\n",
      "Epoch 4, iter 241, loss 2.3272271156311035, acc 0.15000000596046448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 242, loss 2.444988489151001, acc 0.05999999865889549\n",
      "Epoch 4, iter 243, loss 2.391697645187378, acc 0.1899999976158142\n",
      "Epoch 4, iter 244, loss 2.3490946292877197, acc 0.1599999964237213\n",
      "Epoch 4, iter 245, loss 2.210855007171631, acc 0.1899999976158142\n",
      "Epoch 4, iter 246, loss 2.2313976287841797, acc 0.20999999344348907\n",
      "Epoch 4, iter 247, loss 2.258147954940796, acc 0.11999999731779099\n",
      "Epoch 4, iter 248, loss 2.272153854370117, acc 0.1599999964237213\n",
      "Epoch 4, iter 249, loss 2.3261098861694336, acc 0.11999999731779099\n",
      "Epoch 4, iter 250, loss 2.292025327682495, acc 0.15000000596046448\n",
      "Epoch 4, iter 251, loss 2.31676983833313, acc 0.17000000178813934\n",
      "Epoch 4, iter 252, loss 2.2510149478912354, acc 0.12999999523162842\n",
      "Epoch 4, iter 253, loss 2.4560916423797607, acc 0.17000000178813934\n",
      "Epoch 4, iter 254, loss 2.2241086959838867, acc 0.15000000596046448\n",
      "Epoch 4, iter 255, loss 2.3772833347320557, acc 0.14000000059604645\n",
      "Epoch 4, iter 256, loss 2.320915937423706, acc 0.10999999940395355\n",
      "Epoch 4, iter 257, loss 2.231718063354492, acc 0.18000000715255737\n",
      "Epoch 4, iter 258, loss 2.381856679916382, acc 0.14000000059604645\n",
      "Epoch 4, iter 259, loss 2.3016719818115234, acc 0.17000000178813934\n",
      "Epoch 4, iter 260, loss 2.24503231048584, acc 0.10999999940395355\n",
      "Epoch 4, iter 261, loss 2.263744592666626, acc 0.11999999731779099\n",
      "Epoch 4, iter 262, loss 2.365664482116699, acc 0.10000000149011612\n",
      "Epoch 4, iter 263, loss 2.1958327293395996, acc 0.12999999523162842\n",
      "Epoch 4, iter 264, loss 2.260420322418213, acc 0.17000000178813934\n",
      "Epoch 4, iter 265, loss 2.1966207027435303, acc 0.20000000298023224\n",
      "Epoch 4, iter 266, loss 2.359720468521118, acc 0.15000000596046448\n",
      "Epoch 4, iter 267, loss 2.2997663021087646, acc 0.07000000029802322\n",
      "Epoch 4, iter 268, loss 2.282841444015503, acc 0.15000000596046448\n",
      "Epoch 4, iter 269, loss 2.2432284355163574, acc 0.20000000298023224\n",
      "Epoch 4, iter 270, loss 2.3364624977111816, acc 0.10000000149011612\n",
      "Epoch 4, iter 271, loss 2.199859857559204, acc 0.2199999988079071\n",
      "Epoch 4, iter 272, loss 2.2640650272369385, acc 0.15000000596046448\n",
      "Epoch 4, iter 273, loss 2.313469409942627, acc 0.11999999731779099\n",
      "Epoch 4, iter 274, loss 2.4272098541259766, acc 0.05999999865889549\n",
      "Epoch 4, iter 275, loss 2.3330726623535156, acc 0.10000000149011612\n",
      "Epoch 4, iter 276, loss 2.318438768386841, acc 0.14000000059604645\n",
      "Epoch 4, iter 277, loss 2.19357967376709, acc 0.15000000596046448\n",
      "Epoch 4, iter 278, loss 2.1888396739959717, acc 0.12999999523162842\n",
      "Epoch 4, iter 279, loss 2.3535141944885254, acc 0.14000000059604645\n",
      "Epoch 4, iter 280, loss 2.2740743160247803, acc 0.12999999523162842\n",
      "Epoch 4, iter 281, loss 2.280106544494629, acc 0.1599999964237213\n",
      "Epoch 4, iter 282, loss 2.155219793319702, acc 0.20000000298023224\n",
      "Epoch 4, iter 283, loss 2.3129868507385254, acc 0.17000000178813934\n",
      "Epoch 4, iter 284, loss 2.2553184032440186, acc 0.10999999940395355\n",
      "Epoch 4, iter 285, loss 2.315455675125122, acc 0.10999999940395355\n",
      "Epoch 4, iter 286, loss 2.2387404441833496, acc 0.10999999940395355\n",
      "Epoch 4, iter 287, loss 2.318951368331909, acc 0.10000000149011612\n",
      "Epoch 4, iter 288, loss 2.3989274501800537, acc 0.09000000357627869\n",
      "Epoch 4, iter 289, loss 2.342712879180908, acc 0.07999999821186066\n",
      "Epoch 4, iter 290, loss 2.3288848400115967, acc 0.10000000149011612\n",
      "Epoch 4, iter 291, loss 2.3460733890533447, acc 0.10000000149011612\n",
      "Epoch 4, iter 292, loss 2.2730677127838135, acc 0.1599999964237213\n",
      "Epoch 4, iter 293, loss 2.2909319400787354, acc 0.15000000596046448\n",
      "Epoch 4, iter 294, loss 2.176624298095703, acc 0.23000000417232513\n",
      "Epoch 4, iter 295, loss 2.3229615688323975, acc 0.18000000715255737\n",
      "Epoch 4, iter 296, loss 2.2678394317626953, acc 0.07999999821186066\n",
      "Epoch 4, iter 297, loss 2.342663526535034, acc 0.20000000298023224\n",
      "Epoch 4, iter 298, loss 2.2099573612213135, acc 0.1599999964237213\n",
      "Epoch 4, iter 299, loss 2.366603374481201, acc 0.15000000596046448\n",
      "Epoch 4, iter 300, loss 2.2342636585235596, acc 0.11999999731779099\n",
      "Epoch 4, iter 301, loss 2.355684280395508, acc 0.10999999940395355\n",
      "Epoch 4, iter 302, loss 2.3109312057495117, acc 0.15000000596046448\n",
      "Epoch 4, iter 303, loss 2.34360408782959, acc 0.10000000149011612\n",
      "Epoch 4, iter 304, loss 2.2796716690063477, acc 0.18000000715255737\n",
      "Epoch 4, iter 305, loss 2.3040223121643066, acc 0.18000000715255737\n",
      "Epoch 4, iter 306, loss 2.298470973968506, acc 0.11999999731779099\n",
      "Epoch 4, iter 307, loss 2.307478189468384, acc 0.14000000059604645\n",
      "Epoch 4, iter 308, loss 2.300119400024414, acc 0.18000000715255737\n",
      "Epoch 4, iter 309, loss 2.2400598526000977, acc 0.15000000596046448\n",
      "Epoch 4, iter 310, loss 2.3107094764709473, acc 0.10999999940395355\n",
      "Epoch 4, iter 311, loss 2.3451719284057617, acc 0.11999999731779099\n",
      "Epoch 4, iter 312, loss 2.271097183227539, acc 0.1599999964237213\n",
      "Epoch 4, iter 313, loss 2.2985239028930664, acc 0.20000000298023224\n",
      "Epoch 4, iter 314, loss 2.237813711166382, acc 0.1599999964237213\n",
      "Epoch 4, iter 315, loss 2.262657880783081, acc 0.1599999964237213\n",
      "Epoch 4, iter 316, loss 2.3209517002105713, acc 0.12999999523162842\n",
      "Epoch 4, iter 317, loss 2.310115098953247, acc 0.1899999976158142\n",
      "Epoch 4, iter 318, loss 2.165510416030884, acc 0.20000000298023224\n",
      "Epoch 4, iter 319, loss 2.2182016372680664, acc 0.2199999988079071\n",
      "Epoch 4, iter 320, loss 2.3201181888580322, acc 0.1599999964237213\n",
      "Epoch 4, iter 321, loss 2.3757164478302, acc 0.12999999523162842\n",
      "Epoch 4, iter 322, loss 2.348975419998169, acc 0.14000000059604645\n",
      "Epoch 4, iter 323, loss 2.282609701156616, acc 0.15000000596046448\n",
      "Epoch 4, iter 324, loss 2.257906436920166, acc 0.14000000059604645\n",
      "Epoch 4, iter 325, loss 2.3100411891937256, acc 0.18000000715255737\n",
      "Epoch 4, iter 326, loss 2.2624671459198, acc 0.10000000149011612\n",
      "Epoch 4, iter 327, loss 2.269235610961914, acc 0.14000000059604645\n",
      "Epoch 4, iter 328, loss 2.3796606063842773, acc 0.07999999821186066\n",
      "Epoch 4, iter 329, loss 2.372332811355591, acc 0.10999999940395355\n",
      "Epoch 4, iter 330, loss 2.289153814315796, acc 0.17000000178813934\n",
      "Epoch 4, iter 331, loss 2.2311272621154785, acc 0.20000000298023224\n",
      "Epoch 4, iter 332, loss 2.220797061920166, acc 0.17000000178813934\n",
      "Epoch 4, iter 333, loss 2.2293431758880615, acc 0.15000000596046448\n",
      "Epoch 4, iter 334, loss 2.269474983215332, acc 0.17000000178813934\n",
      "Epoch 4, iter 335, loss 2.232387065887451, acc 0.1599999964237213\n",
      "Epoch 4, iter 336, loss 2.2385408878326416, acc 0.14000000059604645\n",
      "Epoch 4, iter 337, loss 2.39174222946167, acc 0.10000000149011612\n",
      "Epoch 4, iter 338, loss 2.1816768646240234, acc 0.20000000298023224\n",
      "Epoch 4, iter 339, loss 2.1290884017944336, acc 0.17000000178813934\n",
      "Epoch 4, iter 340, loss 2.3823485374450684, acc 0.10999999940395355\n",
      "Epoch 4, iter 341, loss 2.234954595565796, acc 0.12999999523162842\n",
      "Epoch 4, iter 342, loss 2.1894800662994385, acc 0.2199999988079071\n",
      "Epoch 4, iter 343, loss 2.3230764865875244, acc 0.20000000298023224\n",
      "Epoch 4, iter 344, loss 2.3066437244415283, acc 0.10999999940395355\n",
      "Epoch 4, iter 345, loss 2.318892240524292, acc 0.15000000596046448\n",
      "Epoch 4, iter 346, loss 2.359029769897461, acc 0.10999999940395355\n",
      "Epoch 4, iter 347, loss 2.1666183471679688, acc 0.23000000417232513\n",
      "Epoch 4, iter 348, loss 2.2056937217712402, acc 0.15000000596046448\n",
      "Epoch 4, iter 349, loss 2.140526533126831, acc 0.20000000298023224\n",
      "Epoch 4, iter 350, loss 2.2967894077301025, acc 0.18000000715255737\n",
      "Epoch 4, iter 351, loss 2.3035714626312256, acc 0.14000000059604645\n",
      "Epoch 4, iter 352, loss 2.2394683361053467, acc 0.17000000178813934\n",
      "Epoch 4, iter 353, loss 2.307542324066162, acc 0.12999999523162842\n",
      "Epoch 4, iter 354, loss 2.214291572570801, acc 0.15000000596046448\n",
      "Epoch 4, iter 355, loss 2.3309340476989746, acc 0.11999999731779099\n",
      "Epoch 4, iter 356, loss 2.263261318206787, acc 0.1899999976158142\n",
      "Epoch 4, iter 357, loss 2.216573476791382, acc 0.18000000715255737\n",
      "Epoch 4, iter 358, loss 2.2649011611938477, acc 0.2199999988079071\n",
      "Epoch 4, iter 359, loss 2.306990385055542, acc 0.07999999821186066\n",
      "Epoch 4, iter 360, loss 2.3073410987854004, acc 0.1599999964237213\n",
      "Epoch 4, iter 361, loss 2.313951015472412, acc 0.11999999731779099\n",
      "Epoch 4, iter 362, loss 2.371821880340576, acc 0.15000000596046448\n",
      "Epoch 4, iter 363, loss 2.274010419845581, acc 0.17000000178813934\n",
      "Epoch 4, iter 364, loss 2.3017144203186035, acc 0.1599999964237213\n",
      "Epoch 4, iter 365, loss 2.2904303073883057, acc 0.11999999731779099\n",
      "Epoch 4, iter 366, loss 2.205143928527832, acc 0.18000000715255737\n",
      "Epoch 4, iter 367, loss 2.305905818939209, acc 0.10999999940395355\n",
      "Epoch 4, iter 368, loss 2.2967336177825928, acc 0.1899999976158142\n",
      "Epoch 4, iter 369, loss 2.332629442214966, acc 0.09000000357627869\n",
      "Epoch 4, iter 370, loss 2.2905173301696777, acc 0.12999999523162842\n",
      "Epoch 4, iter 371, loss 2.232663631439209, acc 0.12999999523162842\n",
      "Epoch 4, iter 372, loss 2.284233331680298, acc 0.17000000178813934\n",
      "Epoch 4, iter 373, loss 2.2795135974884033, acc 0.12999999523162842\n",
      "Epoch 4, iter 374, loss 2.2380926609039307, acc 0.1599999964237213\n",
      "Epoch 4, iter 375, loss 2.3140323162078857, acc 0.1599999964237213\n",
      "Epoch 4, iter 376, loss 2.2210800647735596, acc 0.14000000059604645\n",
      "Epoch 4, iter 377, loss 2.3224964141845703, acc 0.10000000149011612\n",
      "Epoch 4, iter 378, loss 2.2764408588409424, acc 0.17000000178813934\n",
      "Epoch 4, iter 379, loss 2.3073034286499023, acc 0.1599999964237213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 380, loss 2.2513320446014404, acc 0.17000000178813934\n",
      "Epoch 4, iter 381, loss 2.3404107093811035, acc 0.20000000298023224\n",
      "Epoch 4, iter 382, loss 2.127490758895874, acc 0.20999999344348907\n",
      "Epoch 4, iter 383, loss 2.2721033096313477, acc 0.17000000178813934\n",
      "Epoch 4, iter 384, loss 2.31583309173584, acc 0.07999999821186066\n",
      "Epoch 4, iter 385, loss 2.383204698562622, acc 0.09000000357627869\n",
      "Epoch 4, iter 386, loss 2.2561120986938477, acc 0.1599999964237213\n",
      "Epoch 4, iter 387, loss 2.2597711086273193, acc 0.17000000178813934\n",
      "Epoch 4, iter 388, loss 2.199169874191284, acc 0.20999999344348907\n",
      "Epoch 4, iter 389, loss 2.249182939529419, acc 0.15000000596046448\n",
      "Epoch 4, iter 390, loss 2.2605462074279785, acc 0.15000000596046448\n",
      "Epoch 4, iter 391, loss 2.2439515590667725, acc 0.18000000715255737\n",
      "Epoch 4, iter 392, loss 2.3967020511627197, acc 0.11999999731779099\n",
      "Epoch 4, iter 393, loss 2.2764711380004883, acc 0.11999999731779099\n",
      "Epoch 4, iter 394, loss 2.2125630378723145, acc 0.1899999976158142\n",
      "Epoch 4, iter 395, loss 2.2720999717712402, acc 0.17000000178813934\n",
      "Epoch 4, iter 396, loss 2.407949447631836, acc 0.15000000596046448\n",
      "Epoch 4, iter 397, loss 2.29665207862854, acc 0.10999999940395355\n",
      "Epoch 4, iter 398, loss 2.31259822845459, acc 0.12999999523162842\n",
      "Epoch 4, iter 399, loss 2.3371753692626953, acc 0.18000000715255737\n",
      "Epoch 4, iter 400, loss 2.2268152236938477, acc 0.10999999940395355\n",
      "Epoch 4, iter 401, loss 2.3169448375701904, acc 0.14000000059604645\n",
      "Epoch 4, iter 402, loss 2.233076810836792, acc 0.17000000178813934\n",
      "Epoch 4, iter 403, loss 2.3894898891448975, acc 0.10000000149011612\n",
      "Epoch 4, iter 404, loss 2.4113216400146484, acc 0.07999999821186066\n",
      "Epoch 4, iter 405, loss 2.312898635864258, acc 0.11999999731779099\n",
      "Epoch 4, iter 406, loss 2.3022639751434326, acc 0.18000000715255737\n",
      "Epoch 4, iter 407, loss 2.285797357559204, acc 0.10000000149011612\n",
      "Epoch 4, iter 408, loss 2.2403347492218018, acc 0.20000000298023224\n",
      "Epoch 4, iter 409, loss 2.3240349292755127, acc 0.10999999940395355\n",
      "Epoch 4, iter 410, loss 2.2404263019561768, acc 0.11999999731779099\n",
      "Epoch 4, iter 411, loss 2.291734218597412, acc 0.11999999731779099\n",
      "Epoch 4, iter 412, loss 2.2856733798980713, acc 0.15000000596046448\n",
      "Epoch 4, iter 413, loss 2.3206841945648193, acc 0.12999999523162842\n",
      "Epoch 4, iter 414, loss 2.333858013153076, acc 0.12999999523162842\n",
      "Epoch 4, iter 415, loss 2.396634578704834, acc 0.11999999731779099\n",
      "Epoch 4, iter 416, loss 2.350841522216797, acc 0.10000000149011612\n",
      "Epoch 4, iter 417, loss 2.2613401412963867, acc 0.14000000059604645\n",
      "Epoch 4, iter 418, loss 2.2036020755767822, acc 0.1899999976158142\n",
      "Epoch 4, iter 419, loss 2.2106494903564453, acc 0.11999999731779099\n",
      "Epoch 4, iter 420, loss 2.287067174911499, acc 0.12999999523162842\n",
      "Epoch 5, iter 1, loss 2.257411003112793, acc 0.14000000059604645\n",
      "Epoch 5, iter 2, loss 2.349168300628662, acc 0.10000000149011612\n",
      "Epoch 5, iter 3, loss 2.270382881164551, acc 0.10000000149011612\n",
      "Epoch 5, iter 4, loss 2.3024206161499023, acc 0.20000000298023224\n",
      "Epoch 5, iter 5, loss 2.2418859004974365, acc 0.11999999731779099\n",
      "Epoch 5, iter 6, loss 2.2448744773864746, acc 0.17000000178813934\n",
      "Epoch 5, iter 7, loss 2.3028831481933594, acc 0.09000000357627869\n",
      "Epoch 5, iter 8, loss 2.241637706756592, acc 0.18000000715255737\n",
      "Epoch 5, iter 9, loss 2.2561326026916504, acc 0.09000000357627869\n",
      "Epoch 5, iter 10, loss 2.3116464614868164, acc 0.14000000059604645\n",
      "Epoch 5, iter 11, loss 2.4686288833618164, acc 0.09000000357627869\n",
      "Epoch 5, iter 12, loss 2.325564384460449, acc 0.11999999731779099\n",
      "Epoch 5, iter 13, loss 2.202746868133545, acc 0.14000000059604645\n",
      "Epoch 5, iter 14, loss 2.3525643348693848, acc 0.10000000149011612\n",
      "Epoch 5, iter 15, loss 2.2595086097717285, acc 0.07999999821186066\n",
      "Epoch 5, iter 16, loss 2.2903592586517334, acc 0.10999999940395355\n",
      "Epoch 5, iter 17, loss 2.22763991355896, acc 0.1599999964237213\n",
      "Epoch 5, iter 18, loss 2.3735790252685547, acc 0.14000000059604645\n",
      "Epoch 5, iter 19, loss 2.2777962684631348, acc 0.15000000596046448\n",
      "Epoch 5, iter 20, loss 2.2333946228027344, acc 0.1599999964237213\n",
      "Epoch 5, iter 21, loss 2.2620880603790283, acc 0.11999999731779099\n",
      "Epoch 5, iter 22, loss 2.335581064224243, acc 0.09000000357627869\n",
      "Epoch 5, iter 23, loss 2.258281946182251, acc 0.17000000178813934\n",
      "Epoch 5, iter 24, loss 2.1541249752044678, acc 0.17000000178813934\n",
      "Epoch 5, iter 25, loss 2.2125966548919678, acc 0.20000000298023224\n",
      "Epoch 5, iter 26, loss 2.324265480041504, acc 0.12999999523162842\n",
      "Epoch 5, iter 27, loss 2.210523843765259, acc 0.20999999344348907\n",
      "Epoch 5, iter 28, loss 2.2983977794647217, acc 0.10000000149011612\n",
      "Epoch 5, iter 29, loss 2.3078043460845947, acc 0.14000000059604645\n",
      "Epoch 5, iter 30, loss 2.346889019012451, acc 0.17000000178813934\n",
      "Epoch 5, iter 31, loss 2.2887914180755615, acc 0.15000000596046448\n",
      "Epoch 5, iter 32, loss 2.271204710006714, acc 0.10999999940395355\n",
      "Epoch 5, iter 33, loss 2.2739624977111816, acc 0.1899999976158142\n",
      "Epoch 5, iter 34, loss 2.222480297088623, acc 0.1599999964237213\n",
      "Epoch 5, iter 35, loss 2.403524875640869, acc 0.07999999821186066\n",
      "Epoch 5, iter 36, loss 2.3361525535583496, acc 0.15000000596046448\n",
      "Epoch 5, iter 37, loss 2.2488880157470703, acc 0.18000000715255737\n",
      "Epoch 5, iter 38, loss 2.2375786304473877, acc 0.17000000178813934\n",
      "Epoch 5, iter 39, loss 2.2794923782348633, acc 0.10000000149011612\n",
      "Epoch 5, iter 40, loss 2.2294695377349854, acc 0.14000000059604645\n",
      "Epoch 5, iter 41, loss 2.3318915367126465, acc 0.10999999940395355\n",
      "Epoch 5, iter 42, loss 2.250272274017334, acc 0.10999999940395355\n",
      "Epoch 5, iter 43, loss 2.174455404281616, acc 0.18000000715255737\n",
      "Epoch 5, iter 44, loss 2.2499372959136963, acc 0.12999999523162842\n",
      "Epoch 5, iter 45, loss 2.264596939086914, acc 0.15000000596046448\n",
      "Epoch 5, iter 46, loss 2.2216684818267822, acc 0.1599999964237213\n",
      "Epoch 5, iter 47, loss 2.371541976928711, acc 0.10000000149011612\n",
      "Epoch 5, iter 48, loss 2.197601079940796, acc 0.15000000596046448\n",
      "Epoch 5, iter 49, loss 2.251953601837158, acc 0.18000000715255737\n",
      "Epoch 5, iter 50, loss 2.2002060413360596, acc 0.20999999344348907\n",
      "Epoch 5, iter 51, loss 2.2523438930511475, acc 0.07999999821186066\n",
      "Epoch 5, iter 52, loss 2.283658266067505, acc 0.1599999964237213\n",
      "Epoch 5, iter 53, loss 2.255006790161133, acc 0.18000000715255737\n",
      "Epoch 5, iter 54, loss 2.2012171745300293, acc 0.10000000149011612\n",
      "Epoch 5, iter 55, loss 2.3446204662323, acc 0.14000000059604645\n",
      "Epoch 5, iter 56, loss 2.29516863822937, acc 0.10999999940395355\n",
      "Epoch 5, iter 57, loss 2.344470262527466, acc 0.1599999964237213\n",
      "Epoch 5, iter 58, loss 2.1980063915252686, acc 0.17000000178813934\n",
      "Epoch 5, iter 59, loss 2.317040205001831, acc 0.15000000596046448\n",
      "Epoch 5, iter 60, loss 2.228024482727051, acc 0.15000000596046448\n",
      "Epoch 5, iter 61, loss 2.336768388748169, acc 0.11999999731779099\n",
      "Epoch 5, iter 62, loss 2.324770927429199, acc 0.11999999731779099\n",
      "Epoch 5, iter 63, loss 2.396339178085327, acc 0.07000000029802322\n",
      "Epoch 5, iter 64, loss 2.17808198928833, acc 0.18000000715255737\n",
      "Epoch 5, iter 65, loss 2.3499484062194824, acc 0.10999999940395355\n",
      "Epoch 5, iter 66, loss 2.3008174896240234, acc 0.10000000149011612\n",
      "Epoch 5, iter 67, loss 2.2534127235412598, acc 0.18000000715255737\n",
      "Epoch 5, iter 68, loss 2.2271249294281006, acc 0.14000000059604645\n",
      "Epoch 5, iter 69, loss 2.257843494415283, acc 0.12999999523162842\n",
      "Epoch 5, iter 70, loss 2.2324411869049072, acc 0.18000000715255737\n",
      "Epoch 5, iter 71, loss 2.352811336517334, acc 0.10999999940395355\n",
      "Epoch 5, iter 72, loss 2.2528584003448486, acc 0.15000000596046448\n",
      "Epoch 5, iter 73, loss 2.196000814437866, acc 0.14000000059604645\n",
      "Epoch 5, iter 74, loss 2.2546346187591553, acc 0.17000000178813934\n",
      "Epoch 5, iter 75, loss 2.273477077484131, acc 0.15000000596046448\n",
      "Epoch 5, iter 76, loss 2.2098021507263184, acc 0.1899999976158142\n",
      "Epoch 5, iter 77, loss 2.2977631092071533, acc 0.18000000715255737\n",
      "Epoch 5, iter 78, loss 2.260356903076172, acc 0.1599999964237213\n",
      "Epoch 5, iter 79, loss 2.252727746963501, acc 0.15000000596046448\n",
      "Epoch 5, iter 80, loss 2.381805658340454, acc 0.09000000357627869\n",
      "Epoch 5, iter 81, loss 2.29276704788208, acc 0.1599999964237213\n",
      "Epoch 5, iter 82, loss 2.289552927017212, acc 0.15000000596046448\n",
      "Epoch 5, iter 83, loss 2.278944730758667, acc 0.10000000149011612\n",
      "Epoch 5, iter 84, loss 2.2592499256134033, acc 0.17000000178813934\n",
      "Epoch 5, iter 85, loss 2.346756935119629, acc 0.15000000596046448\n",
      "Epoch 5, iter 86, loss 2.2540650367736816, acc 0.07999999821186066\n",
      "Epoch 5, iter 87, loss 2.195687770843506, acc 0.2800000011920929\n",
      "Epoch 5, iter 88, loss 2.196774959564209, acc 0.1599999964237213\n",
      "Epoch 5, iter 89, loss 2.288828134536743, acc 0.10000000149011612\n",
      "Epoch 5, iter 90, loss 2.2564609050750732, acc 0.10999999940395355\n",
      "Epoch 5, iter 91, loss 2.3018369674682617, acc 0.12999999523162842\n",
      "Epoch 5, iter 92, loss 2.3541457653045654, acc 0.12999999523162842\n",
      "Epoch 5, iter 93, loss 2.266117572784424, acc 0.11999999731779099\n",
      "Epoch 5, iter 94, loss 2.2481610774993896, acc 0.1599999964237213\n",
      "Epoch 5, iter 95, loss 2.375077724456787, acc 0.09000000357627869\n",
      "Epoch 5, iter 96, loss 2.1953577995300293, acc 0.20999999344348907\n",
      "Epoch 5, iter 97, loss 2.303300142288208, acc 0.07999999821186066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 98, loss 2.246044397354126, acc 0.17000000178813934\n",
      "Epoch 5, iter 99, loss 2.3496739864349365, acc 0.17000000178813934\n",
      "Epoch 5, iter 100, loss 2.271111249923706, acc 0.15000000596046448\n",
      "Epoch 5, iter 101, loss 2.2779760360717773, acc 0.1599999964237213\n",
      "Epoch 5, iter 102, loss 2.1914780139923096, acc 0.1899999976158142\n",
      "Epoch 5, iter 103, loss 2.2532968521118164, acc 0.18000000715255737\n",
      "Epoch 5, iter 104, loss 2.3134796619415283, acc 0.12999999523162842\n",
      "Epoch 5, iter 105, loss 2.212989568710327, acc 0.17000000178813934\n",
      "Epoch 5, iter 106, loss 2.2907347679138184, acc 0.17000000178813934\n",
      "Epoch 5, iter 107, loss 2.26946759223938, acc 0.17000000178813934\n",
      "Epoch 5, iter 108, loss 2.1964621543884277, acc 0.18000000715255737\n",
      "Epoch 5, iter 109, loss 2.2568814754486084, acc 0.10999999940395355\n",
      "Epoch 5, iter 110, loss 2.3681530952453613, acc 0.10999999940395355\n",
      "Epoch 5, iter 111, loss 2.308441400527954, acc 0.09000000357627869\n",
      "Epoch 5, iter 112, loss 2.2856228351593018, acc 0.18000000715255737\n",
      "Epoch 5, iter 113, loss 2.2241551876068115, acc 0.12999999523162842\n",
      "Epoch 5, iter 114, loss 2.24485182762146, acc 0.1599999964237213\n",
      "Epoch 5, iter 115, loss 2.3050451278686523, acc 0.11999999731779099\n",
      "Epoch 5, iter 116, loss 2.2851436138153076, acc 0.14000000059604645\n",
      "Epoch 5, iter 117, loss 2.2575793266296387, acc 0.18000000715255737\n",
      "Epoch 5, iter 118, loss 2.260952949523926, acc 0.17000000178813934\n",
      "Epoch 5, iter 119, loss 2.244910717010498, acc 0.15000000596046448\n",
      "Epoch 5, iter 120, loss 2.252166271209717, acc 0.1599999964237213\n",
      "Epoch 5, iter 121, loss 2.296755313873291, acc 0.17000000178813934\n",
      "Epoch 5, iter 122, loss 2.2707912921905518, acc 0.14000000059604645\n",
      "Epoch 5, iter 123, loss 2.2357733249664307, acc 0.2199999988079071\n",
      "Epoch 5, iter 124, loss 2.211341142654419, acc 0.07999999821186066\n",
      "Epoch 5, iter 125, loss 2.2425589561462402, acc 0.12999999523162842\n",
      "Epoch 5, iter 126, loss 2.2408881187438965, acc 0.12999999523162842\n",
      "Epoch 5, iter 127, loss 2.311509609222412, acc 0.09000000357627869\n",
      "Epoch 5, iter 128, loss 2.274963855743408, acc 0.11999999731779099\n",
      "Epoch 5, iter 129, loss 2.3102614879608154, acc 0.15000000596046448\n",
      "Epoch 5, iter 130, loss 2.2800800800323486, acc 0.18000000715255737\n",
      "Epoch 5, iter 131, loss 2.2293267250061035, acc 0.23000000417232513\n",
      "Epoch 5, iter 132, loss 2.2396352291107178, acc 0.17000000178813934\n",
      "Epoch 5, iter 133, loss 2.268667697906494, acc 0.12999999523162842\n",
      "Epoch 5, iter 134, loss 2.3266208171844482, acc 0.15000000596046448\n",
      "Epoch 5, iter 135, loss 2.1837823390960693, acc 0.20000000298023224\n",
      "Epoch 5, iter 136, loss 2.3191912174224854, acc 0.11999999731779099\n",
      "Epoch 5, iter 137, loss 2.3272392749786377, acc 0.12999999523162842\n",
      "Epoch 5, iter 138, loss 2.1985080242156982, acc 0.12999999523162842\n",
      "Epoch 5, iter 139, loss 2.3014566898345947, acc 0.10999999940395355\n",
      "Epoch 5, iter 140, loss 2.3505067825317383, acc 0.10000000149011612\n",
      "Epoch 5, iter 141, loss 2.3597769737243652, acc 0.05999999865889549\n",
      "Epoch 5, iter 142, loss 2.2219114303588867, acc 0.14000000059604645\n",
      "Epoch 5, iter 143, loss 2.2694497108459473, acc 0.11999999731779099\n",
      "Epoch 5, iter 144, loss 2.2941672801971436, acc 0.11999999731779099\n",
      "Epoch 5, iter 145, loss 2.2583518028259277, acc 0.14000000059604645\n",
      "Epoch 5, iter 146, loss 2.2676162719726562, acc 0.15000000596046448\n",
      "Epoch 5, iter 147, loss 2.2251739501953125, acc 0.20999999344348907\n",
      "Epoch 5, iter 148, loss 2.231849431991577, acc 0.11999999731779099\n",
      "Epoch 5, iter 149, loss 2.2848398685455322, acc 0.15000000596046448\n",
      "Epoch 5, iter 150, loss 2.1404387950897217, acc 0.23000000417232513\n",
      "Epoch 5, iter 151, loss 2.2314794063568115, acc 0.12999999523162842\n",
      "Epoch 5, iter 152, loss 2.2513458728790283, acc 0.14000000059604645\n",
      "Epoch 5, iter 153, loss 2.2323343753814697, acc 0.17000000178813934\n",
      "Epoch 5, iter 154, loss 2.2437381744384766, acc 0.14000000059604645\n",
      "Epoch 5, iter 155, loss 2.1979286670684814, acc 0.18000000715255737\n",
      "Epoch 5, iter 156, loss 2.2664449214935303, acc 0.1599999964237213\n",
      "Epoch 5, iter 157, loss 2.3253862857818604, acc 0.09000000357627869\n",
      "Epoch 5, iter 158, loss 2.3310585021972656, acc 0.12999999523162842\n",
      "Epoch 5, iter 159, loss 2.210510492324829, acc 0.1599999964237213\n",
      "Epoch 5, iter 160, loss 2.228048801422119, acc 0.20000000298023224\n",
      "Epoch 5, iter 161, loss 2.4034183025360107, acc 0.07999999821186066\n",
      "Epoch 5, iter 162, loss 2.256765365600586, acc 0.1599999964237213\n",
      "Epoch 5, iter 163, loss 2.3242008686065674, acc 0.10999999940395355\n",
      "Epoch 5, iter 164, loss 2.318657875061035, acc 0.11999999731779099\n",
      "Epoch 5, iter 165, loss 2.290614604949951, acc 0.15000000596046448\n",
      "Epoch 5, iter 166, loss 2.3383171558380127, acc 0.029999999329447746\n",
      "Epoch 5, iter 167, loss 2.274549961090088, acc 0.12999999523162842\n",
      "Epoch 5, iter 168, loss 2.263972759246826, acc 0.10000000149011612\n",
      "Epoch 5, iter 169, loss 2.2827329635620117, acc 0.14000000059604645\n",
      "Epoch 5, iter 170, loss 2.310983657836914, acc 0.14000000059604645\n",
      "Epoch 5, iter 171, loss 2.2494654655456543, acc 0.12999999523162842\n",
      "Epoch 5, iter 172, loss 2.2585456371307373, acc 0.10000000149011612\n",
      "Epoch 5, iter 173, loss 2.2695677280426025, acc 0.20000000298023224\n",
      "Epoch 5, iter 174, loss 2.246000289916992, acc 0.18000000715255737\n",
      "Epoch 5, iter 175, loss 2.234055519104004, acc 0.23000000417232513\n",
      "Epoch 5, iter 176, loss 2.266080379486084, acc 0.1599999964237213\n",
      "Epoch 5, iter 177, loss 2.2874057292938232, acc 0.2199999988079071\n",
      "Epoch 5, iter 178, loss 2.317619800567627, acc 0.1599999964237213\n",
      "Epoch 5, iter 179, loss 2.2913193702697754, acc 0.18000000715255737\n",
      "Epoch 5, iter 180, loss 2.2990596294403076, acc 0.1599999964237213\n",
      "Epoch 5, iter 181, loss 2.184884548187256, acc 0.1599999964237213\n",
      "Epoch 5, iter 182, loss 2.1886892318725586, acc 0.15000000596046448\n",
      "Epoch 5, iter 183, loss 2.2350385189056396, acc 0.1599999964237213\n",
      "Epoch 5, iter 184, loss 2.253833055496216, acc 0.09000000357627869\n",
      "Epoch 5, iter 185, loss 2.1698801517486572, acc 0.1599999964237213\n",
      "Epoch 5, iter 186, loss 2.219688892364502, acc 0.1599999964237213\n",
      "Epoch 5, iter 187, loss 2.2168636322021484, acc 0.18000000715255737\n",
      "Epoch 5, iter 188, loss 2.291200637817383, acc 0.10999999940395355\n",
      "Epoch 5, iter 189, loss 2.2112720012664795, acc 0.17000000178813934\n",
      "Epoch 5, iter 190, loss 2.273362159729004, acc 0.1599999964237213\n",
      "Epoch 5, iter 191, loss 2.166918992996216, acc 0.2199999988079071\n",
      "Epoch 5, iter 192, loss 2.340280055999756, acc 0.10999999940395355\n",
      "Epoch 5, iter 193, loss 2.2016820907592773, acc 0.12999999523162842\n",
      "Epoch 5, iter 194, loss 2.2262234687805176, acc 0.12999999523162842\n",
      "Epoch 5, iter 195, loss 2.416354179382324, acc 0.10000000149011612\n",
      "Epoch 5, iter 196, loss 2.3288230895996094, acc 0.10000000149011612\n",
      "Epoch 5, iter 197, loss 2.2601065635681152, acc 0.10999999940395355\n",
      "Epoch 5, iter 198, loss 2.20424222946167, acc 0.12999999523162842\n",
      "Epoch 5, iter 199, loss 2.2359747886657715, acc 0.14000000059604645\n",
      "Epoch 5, iter 200, loss 2.304272413253784, acc 0.09000000357627869\n",
      "Epoch 5, iter 201, loss 2.2810535430908203, acc 0.10999999940395355\n",
      "Epoch 5, iter 202, loss 2.285937786102295, acc 0.10000000149011612\n",
      "Epoch 5, iter 203, loss 2.387371063232422, acc 0.11999999731779099\n",
      "Epoch 5, iter 204, loss 2.254956007003784, acc 0.1599999964237213\n",
      "Epoch 5, iter 205, loss 2.2037572860717773, acc 0.11999999731779099\n",
      "Epoch 5, iter 206, loss 2.2614927291870117, acc 0.12999999523162842\n",
      "Epoch 5, iter 207, loss 2.209127902984619, acc 0.17000000178813934\n",
      "Epoch 5, iter 208, loss 2.3283638954162598, acc 0.14000000059604645\n",
      "Epoch 5, iter 209, loss 2.3917641639709473, acc 0.10000000149011612\n",
      "Epoch 5, iter 210, loss 2.336789608001709, acc 0.15000000596046448\n",
      "Epoch 5, iter 211, loss 2.1943907737731934, acc 0.18000000715255737\n",
      "Epoch 5, iter 212, loss 2.23957896232605, acc 0.15000000596046448\n",
      "Epoch 5, iter 213, loss 2.2265188694000244, acc 0.1599999964237213\n",
      "Epoch 5, iter 214, loss 2.3074066638946533, acc 0.10999999940395355\n",
      "Epoch 5, iter 215, loss 2.2554335594177246, acc 0.12999999523162842\n",
      "Epoch 5, iter 216, loss 2.261781930923462, acc 0.15000000596046448\n",
      "Epoch 5, iter 217, loss 2.1884822845458984, acc 0.1599999964237213\n",
      "Epoch 5, iter 218, loss 2.2988264560699463, acc 0.1899999976158142\n",
      "Epoch 5, iter 219, loss 2.248486042022705, acc 0.18000000715255737\n",
      "Epoch 5, iter 220, loss 2.2583107948303223, acc 0.07999999821186066\n",
      "Epoch 5, iter 221, loss 2.2143590450286865, acc 0.1599999964237213\n",
      "Epoch 5, iter 222, loss 2.3457248210906982, acc 0.10999999940395355\n",
      "Epoch 5, iter 223, loss 2.2662503719329834, acc 0.12999999523162842\n",
      "Epoch 5, iter 224, loss 2.2456743717193604, acc 0.15000000596046448\n",
      "Epoch 5, iter 225, loss 2.189221143722534, acc 0.20000000298023224\n",
      "Epoch 5, iter 226, loss 2.2677292823791504, acc 0.10999999940395355\n",
      "Epoch 5, iter 227, loss 2.2525575160980225, acc 0.15000000596046448\n",
      "Epoch 5, iter 228, loss 2.196120262145996, acc 0.2199999988079071\n",
      "Epoch 5, iter 229, loss 2.2765350341796875, acc 0.10000000149011612\n",
      "Epoch 5, iter 230, loss 2.2984681129455566, acc 0.15000000596046448\n",
      "Epoch 5, iter 231, loss 2.29784893989563, acc 0.10999999940395355\n",
      "Epoch 5, iter 232, loss 2.2765657901763916, acc 0.10999999940395355\n",
      "Epoch 5, iter 233, loss 2.2381882667541504, acc 0.18000000715255737\n",
      "Epoch 5, iter 234, loss 2.2418057918548584, acc 0.10000000149011612\n",
      "Epoch 5, iter 235, loss 2.3173866271972656, acc 0.10000000149011612\n",
      "Epoch 5, iter 236, loss 2.291403293609619, acc 0.1599999964237213\n",
      "Epoch 5, iter 237, loss 2.3028805255889893, acc 0.11999999731779099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 238, loss 2.25652813911438, acc 0.1599999964237213\n",
      "Epoch 5, iter 239, loss 2.323676824569702, acc 0.05999999865889549\n",
      "Epoch 5, iter 240, loss 2.2931389808654785, acc 0.20000000298023224\n",
      "Epoch 5, iter 241, loss 2.294700860977173, acc 0.15000000596046448\n",
      "Epoch 5, iter 242, loss 2.3927507400512695, acc 0.07000000029802322\n",
      "Epoch 5, iter 243, loss 2.3604576587677, acc 0.1899999976158142\n",
      "Epoch 5, iter 244, loss 2.3035080432891846, acc 0.1599999964237213\n",
      "Epoch 5, iter 245, loss 2.1856470108032227, acc 0.18000000715255737\n",
      "Epoch 5, iter 246, loss 2.240718126296997, acc 0.20000000298023224\n",
      "Epoch 5, iter 247, loss 2.213070869445801, acc 0.12999999523162842\n",
      "Epoch 5, iter 248, loss 2.2148385047912598, acc 0.1599999964237213\n",
      "Epoch 5, iter 249, loss 2.2467594146728516, acc 0.14000000059604645\n",
      "Epoch 5, iter 250, loss 2.260615110397339, acc 0.15000000596046448\n",
      "Epoch 5, iter 251, loss 2.225550889968872, acc 0.17000000178813934\n",
      "Epoch 5, iter 252, loss 2.2094199657440186, acc 0.1599999964237213\n",
      "Epoch 5, iter 253, loss 2.417504072189331, acc 0.17000000178813934\n",
      "Epoch 5, iter 254, loss 2.206563711166382, acc 0.14000000059604645\n",
      "Epoch 5, iter 255, loss 2.3407111167907715, acc 0.14000000059604645\n",
      "Epoch 5, iter 256, loss 2.280594825744629, acc 0.10999999940395355\n",
      "Epoch 5, iter 257, loss 2.191232681274414, acc 0.18000000715255737\n",
      "Epoch 5, iter 258, loss 2.3500349521636963, acc 0.12999999523162842\n",
      "Epoch 5, iter 259, loss 2.2880043983459473, acc 0.15000000596046448\n",
      "Epoch 5, iter 260, loss 2.2121243476867676, acc 0.10999999940395355\n",
      "Epoch 5, iter 261, loss 2.246068000793457, acc 0.10999999940395355\n",
      "Epoch 5, iter 262, loss 2.322079658508301, acc 0.10000000149011612\n",
      "Epoch 5, iter 263, loss 2.174375057220459, acc 0.12999999523162842\n",
      "Epoch 5, iter 264, loss 2.244540214538574, acc 0.1599999964237213\n",
      "Epoch 5, iter 265, loss 2.1813645362854004, acc 0.20000000298023224\n",
      "Epoch 5, iter 266, loss 2.3248260021209717, acc 0.15000000596046448\n",
      "Epoch 5, iter 267, loss 2.2994720935821533, acc 0.07000000029802322\n",
      "Epoch 5, iter 268, loss 2.2403249740600586, acc 0.15000000596046448\n",
      "Epoch 5, iter 269, loss 2.2214980125427246, acc 0.20000000298023224\n",
      "Epoch 5, iter 270, loss 2.297219753265381, acc 0.10000000149011612\n",
      "Epoch 5, iter 271, loss 2.174262523651123, acc 0.23000000417232513\n",
      "Epoch 5, iter 272, loss 2.2330150604248047, acc 0.14000000059604645\n",
      "Epoch 5, iter 273, loss 2.263272285461426, acc 0.11999999731779099\n",
      "Epoch 5, iter 274, loss 2.393620252609253, acc 0.05999999865889549\n",
      "Epoch 5, iter 275, loss 2.315838575363159, acc 0.09000000357627869\n",
      "Epoch 5, iter 276, loss 2.2663424015045166, acc 0.14000000059604645\n",
      "Epoch 5, iter 277, loss 2.1824023723602295, acc 0.15000000596046448\n",
      "Epoch 5, iter 278, loss 2.1555826663970947, acc 0.11999999731779099\n",
      "Epoch 5, iter 279, loss 2.335297107696533, acc 0.14000000059604645\n",
      "Epoch 5, iter 280, loss 2.252697229385376, acc 0.12999999523162842\n",
      "Epoch 5, iter 281, loss 2.280078649520874, acc 0.1599999964237213\n",
      "Epoch 5, iter 282, loss 2.1403238773345947, acc 0.1899999976158142\n",
      "Epoch 5, iter 283, loss 2.2908592224121094, acc 0.1599999964237213\n",
      "Epoch 5, iter 284, loss 2.2212090492248535, acc 0.10000000149011612\n",
      "Epoch 5, iter 285, loss 2.2814137935638428, acc 0.10999999940395355\n",
      "Epoch 5, iter 286, loss 2.2043557167053223, acc 0.10999999940395355\n",
      "Epoch 5, iter 287, loss 2.2860701084136963, acc 0.11999999731779099\n",
      "Epoch 5, iter 288, loss 2.340770959854126, acc 0.10000000149011612\n",
      "Epoch 5, iter 289, loss 2.281919002532959, acc 0.09000000357627869\n",
      "Epoch 5, iter 290, loss 2.292759656906128, acc 0.09000000357627869\n",
      "Epoch 5, iter 291, loss 2.308243989944458, acc 0.10000000149011612\n",
      "Epoch 5, iter 292, loss 2.241684675216675, acc 0.17000000178813934\n",
      "Epoch 5, iter 293, loss 2.252387762069702, acc 0.15000000596046448\n",
      "Epoch 5, iter 294, loss 2.165879964828491, acc 0.23000000417232513\n",
      "Epoch 5, iter 295, loss 2.2804079055786133, acc 0.17000000178813934\n",
      "Epoch 5, iter 296, loss 2.2407991886138916, acc 0.09000000357627869\n",
      "Epoch 5, iter 297, loss 2.2891931533813477, acc 0.20000000298023224\n",
      "Epoch 5, iter 298, loss 2.18215274810791, acc 0.1599999964237213\n",
      "Epoch 5, iter 299, loss 2.344700574874878, acc 0.15000000596046448\n",
      "Epoch 5, iter 300, loss 2.198651075363159, acc 0.12999999523162842\n",
      "Epoch 5, iter 301, loss 2.3116602897644043, acc 0.10999999940395355\n",
      "Epoch 5, iter 302, loss 2.297844648361206, acc 0.14000000059604645\n",
      "Epoch 5, iter 303, loss 2.3079612255096436, acc 0.10000000149011612\n",
      "Epoch 5, iter 304, loss 2.2523691654205322, acc 0.17000000178813934\n",
      "Epoch 5, iter 305, loss 2.25775408744812, acc 0.1899999976158142\n",
      "Epoch 5, iter 306, loss 2.2489895820617676, acc 0.12999999523162842\n",
      "Epoch 5, iter 307, loss 2.261423110961914, acc 0.12999999523162842\n",
      "Epoch 5, iter 308, loss 2.2870688438415527, acc 0.17000000178813934\n",
      "Epoch 5, iter 309, loss 2.202914237976074, acc 0.1599999964237213\n",
      "Epoch 5, iter 310, loss 2.3006157875061035, acc 0.10999999940395355\n",
      "Epoch 5, iter 311, loss 2.3231287002563477, acc 0.10999999940395355\n",
      "Epoch 5, iter 312, loss 2.205796241760254, acc 0.18000000715255737\n",
      "Epoch 5, iter 313, loss 2.2540087699890137, acc 0.20000000298023224\n",
      "Epoch 5, iter 314, loss 2.2209575176239014, acc 0.15000000596046448\n",
      "Epoch 5, iter 315, loss 2.218459367752075, acc 0.18000000715255737\n",
      "Epoch 5, iter 316, loss 2.30969500541687, acc 0.1899999976158142\n",
      "Epoch 5, iter 317, loss 2.2946019172668457, acc 0.1899999976158142\n",
      "Epoch 5, iter 318, loss 2.119905948638916, acc 0.20999999344348907\n",
      "Epoch 5, iter 319, loss 2.215378761291504, acc 0.18000000715255737\n",
      "Epoch 5, iter 320, loss 2.2789580821990967, acc 0.17000000178813934\n",
      "Epoch 5, iter 321, loss 2.339414596557617, acc 0.14000000059604645\n",
      "Epoch 5, iter 322, loss 2.319979190826416, acc 0.14000000059604645\n",
      "Epoch 5, iter 323, loss 2.2803127765655518, acc 0.11999999731779099\n",
      "Epoch 5, iter 324, loss 2.2539446353912354, acc 0.14000000059604645\n",
      "Epoch 5, iter 325, loss 2.2819130420684814, acc 0.17000000178813934\n",
      "Epoch 5, iter 326, loss 2.251373767852783, acc 0.10999999940395355\n",
      "Epoch 5, iter 327, loss 2.2482833862304688, acc 0.15000000596046448\n",
      "Epoch 5, iter 328, loss 2.346820592880249, acc 0.10000000149011612\n",
      "Epoch 5, iter 329, loss 2.3385653495788574, acc 0.11999999731779099\n",
      "Epoch 5, iter 330, loss 2.2499213218688965, acc 0.20000000298023224\n",
      "Epoch 5, iter 331, loss 2.1818594932556152, acc 0.23999999463558197\n",
      "Epoch 5, iter 332, loss 2.1896700859069824, acc 0.1899999976158142\n",
      "Epoch 5, iter 333, loss 2.2033660411834717, acc 0.15000000596046448\n",
      "Epoch 5, iter 334, loss 2.242269992828369, acc 0.20000000298023224\n",
      "Epoch 5, iter 335, loss 2.2055182456970215, acc 0.18000000715255737\n",
      "Epoch 5, iter 336, loss 2.2097785472869873, acc 0.15000000596046448\n",
      "Epoch 5, iter 337, loss 2.3445353507995605, acc 0.14000000059604645\n",
      "Epoch 5, iter 338, loss 2.168482780456543, acc 0.25\n",
      "Epoch 5, iter 339, loss 2.1155922412872314, acc 0.1599999964237213\n",
      "Epoch 5, iter 340, loss 2.3908112049102783, acc 0.10000000149011612\n",
      "Epoch 5, iter 341, loss 2.227672576904297, acc 0.15000000596046448\n",
      "Epoch 5, iter 342, loss 2.1810312271118164, acc 0.2199999988079071\n",
      "Epoch 5, iter 343, loss 2.3030683994293213, acc 0.20000000298023224\n",
      "Epoch 5, iter 344, loss 2.2864251136779785, acc 0.12999999523162842\n",
      "Epoch 5, iter 345, loss 2.328948736190796, acc 0.18000000715255737\n",
      "Epoch 5, iter 346, loss 2.313098192214966, acc 0.12999999523162842\n",
      "Epoch 5, iter 347, loss 2.169877529144287, acc 0.23999999463558197\n",
      "Epoch 5, iter 348, loss 2.18241286277771, acc 0.15000000596046448\n",
      "Epoch 5, iter 349, loss 2.1322035789489746, acc 0.1899999976158142\n",
      "Epoch 5, iter 350, loss 2.259368658065796, acc 0.1899999976158142\n",
      "Epoch 5, iter 351, loss 2.2642176151275635, acc 0.14000000059604645\n",
      "Epoch 5, iter 352, loss 2.220142364501953, acc 0.17000000178813934\n",
      "Epoch 5, iter 353, loss 2.290025472640991, acc 0.12999999523162842\n",
      "Epoch 5, iter 354, loss 2.208188056945801, acc 0.15000000596046448\n",
      "Epoch 5, iter 355, loss 2.2854819297790527, acc 0.14000000059604645\n",
      "Epoch 5, iter 356, loss 2.247429847717285, acc 0.20000000298023224\n",
      "Epoch 5, iter 357, loss 2.198732852935791, acc 0.18000000715255737\n",
      "Epoch 5, iter 358, loss 2.2328641414642334, acc 0.2199999988079071\n",
      "Epoch 5, iter 359, loss 2.2471702098846436, acc 0.07999999821186066\n",
      "Epoch 5, iter 360, loss 2.2769110202789307, acc 0.1599999964237213\n",
      "Epoch 5, iter 361, loss 2.2674572467803955, acc 0.11999999731779099\n",
      "Epoch 5, iter 362, loss 2.3433635234832764, acc 0.17000000178813934\n",
      "Epoch 5, iter 363, loss 2.265885353088379, acc 0.17000000178813934\n",
      "Epoch 5, iter 364, loss 2.2584381103515625, acc 0.1899999976158142\n",
      "Epoch 5, iter 365, loss 2.257150888442993, acc 0.14000000059604645\n",
      "Epoch 5, iter 366, loss 2.16374135017395, acc 0.20000000298023224\n",
      "Epoch 5, iter 367, loss 2.289088487625122, acc 0.10000000149011612\n",
      "Epoch 5, iter 368, loss 2.2600131034851074, acc 0.20000000298023224\n",
      "Epoch 5, iter 369, loss 2.2950737476348877, acc 0.12999999523162842\n",
      "Epoch 5, iter 370, loss 2.2729885578155518, acc 0.15000000596046448\n",
      "Epoch 5, iter 371, loss 2.191603899002075, acc 0.12999999523162842\n",
      "Epoch 5, iter 372, loss 2.254084348678589, acc 0.1599999964237213\n",
      "Epoch 5, iter 373, loss 2.212470054626465, acc 0.15000000596046448\n",
      "Epoch 5, iter 374, loss 2.2295644283294678, acc 0.1599999964237213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 375, loss 2.301130771636963, acc 0.1599999964237213\n",
      "Epoch 5, iter 376, loss 2.200725793838501, acc 0.1899999976158142\n",
      "Epoch 5, iter 377, loss 2.290236473083496, acc 0.12999999523162842\n",
      "Epoch 5, iter 378, loss 2.258211374282837, acc 0.20000000298023224\n",
      "Epoch 5, iter 379, loss 2.280423402786255, acc 0.14000000059604645\n",
      "Epoch 5, iter 380, loss 2.2478113174438477, acc 0.1899999976158142\n",
      "Epoch 5, iter 381, loss 2.3070437908172607, acc 0.18000000715255737\n",
      "Epoch 5, iter 382, loss 2.0982139110565186, acc 0.23000000417232513\n",
      "Epoch 5, iter 383, loss 2.233187675476074, acc 0.1599999964237213\n",
      "Epoch 5, iter 384, loss 2.273068904876709, acc 0.11999999731779099\n",
      "Epoch 5, iter 385, loss 2.353192090988159, acc 0.10000000149011612\n",
      "Epoch 5, iter 386, loss 2.2377817630767822, acc 0.20999999344348907\n",
      "Epoch 5, iter 387, loss 2.2444961071014404, acc 0.20999999344348907\n",
      "Epoch 5, iter 388, loss 2.213149070739746, acc 0.2199999988079071\n",
      "Epoch 5, iter 389, loss 2.2357330322265625, acc 0.17000000178813934\n",
      "Epoch 5, iter 390, loss 2.248704433441162, acc 0.20000000298023224\n",
      "Epoch 5, iter 391, loss 2.2108840942382812, acc 0.20999999344348907\n",
      "Epoch 5, iter 392, loss 2.366762161254883, acc 0.12999999523162842\n",
      "Epoch 5, iter 393, loss 2.246770143508911, acc 0.11999999731779099\n",
      "Epoch 5, iter 394, loss 2.179135799407959, acc 0.23000000417232513\n",
      "Epoch 5, iter 395, loss 2.232348918914795, acc 0.1599999964237213\n",
      "Epoch 5, iter 396, loss 2.3719570636749268, acc 0.12999999523162842\n",
      "Epoch 5, iter 397, loss 2.263901710510254, acc 0.14000000059604645\n",
      "Epoch 5, iter 398, loss 2.2629973888397217, acc 0.1599999964237213\n",
      "Epoch 5, iter 399, loss 2.29716157913208, acc 0.18000000715255737\n",
      "Epoch 5, iter 400, loss 2.208831310272217, acc 0.12999999523162842\n",
      "Epoch 5, iter 401, loss 2.2840397357940674, acc 0.15000000596046448\n",
      "Epoch 5, iter 402, loss 2.1924374103546143, acc 0.18000000715255737\n",
      "Epoch 5, iter 403, loss 2.3344175815582275, acc 0.12999999523162842\n",
      "Epoch 5, iter 404, loss 2.3810935020446777, acc 0.10999999940395355\n",
      "Epoch 5, iter 405, loss 2.2725181579589844, acc 0.15000000596046448\n",
      "Epoch 5, iter 406, loss 2.2739102840423584, acc 0.20000000298023224\n",
      "Epoch 5, iter 407, loss 2.2486302852630615, acc 0.10999999940395355\n",
      "Epoch 5, iter 408, loss 2.2139732837677, acc 0.20999999344348907\n",
      "Epoch 5, iter 409, loss 2.293438196182251, acc 0.11999999731779099\n",
      "Epoch 5, iter 410, loss 2.193302869796753, acc 0.18000000715255737\n",
      "Epoch 5, iter 411, loss 2.2712411880493164, acc 0.15000000596046448\n",
      "Epoch 5, iter 412, loss 2.254664421081543, acc 0.1899999976158142\n",
      "Epoch 5, iter 413, loss 2.3022329807281494, acc 0.14000000059604645\n",
      "Epoch 5, iter 414, loss 2.3193342685699463, acc 0.14000000059604645\n",
      "Epoch 5, iter 415, loss 2.3357088565826416, acc 0.1899999976158142\n",
      "Epoch 5, iter 416, loss 2.3117611408233643, acc 0.10999999940395355\n",
      "Epoch 5, iter 417, loss 2.229034185409546, acc 0.14000000059604645\n",
      "Epoch 5, iter 418, loss 2.1531877517700195, acc 0.23000000417232513\n",
      "Epoch 5, iter 419, loss 2.1778011322021484, acc 0.1599999964237213\n",
      "Epoch 5, iter 420, loss 2.278914451599121, acc 0.17000000178813934\n",
      "Epoch 6, iter 1, loss 2.223076105117798, acc 0.1899999976158142\n",
      "Epoch 6, iter 2, loss 2.309410333633423, acc 0.10000000149011612\n",
      "Epoch 6, iter 3, loss 2.2661969661712646, acc 0.07999999821186066\n",
      "Epoch 6, iter 4, loss 2.2812981605529785, acc 0.23999999463558197\n",
      "Epoch 6, iter 5, loss 2.2405126094818115, acc 0.15000000596046448\n",
      "Epoch 6, iter 6, loss 2.229133367538452, acc 0.1899999976158142\n",
      "Epoch 6, iter 7, loss 2.2930493354797363, acc 0.09000000357627869\n",
      "Epoch 6, iter 8, loss 2.2050294876098633, acc 0.1599999964237213\n",
      "Epoch 6, iter 9, loss 2.2183752059936523, acc 0.10999999940395355\n",
      "Epoch 6, iter 10, loss 2.281545400619507, acc 0.1599999964237213\n",
      "Epoch 6, iter 11, loss 2.4359915256500244, acc 0.11999999731779099\n",
      "Epoch 6, iter 12, loss 2.296351194381714, acc 0.12999999523162842\n",
      "Epoch 6, iter 13, loss 2.195863723754883, acc 0.17000000178813934\n",
      "Epoch 6, iter 14, loss 2.3404998779296875, acc 0.10000000149011612\n",
      "Epoch 6, iter 15, loss 2.2403922080993652, acc 0.09000000357627869\n",
      "Epoch 6, iter 16, loss 2.244793653488159, acc 0.14000000059604645\n",
      "Epoch 6, iter 17, loss 2.2043659687042236, acc 0.17000000178813934\n",
      "Epoch 6, iter 18, loss 2.357104539871216, acc 0.14000000059604645\n",
      "Epoch 6, iter 19, loss 2.2385153770446777, acc 0.1899999976158142\n",
      "Epoch 6, iter 20, loss 2.221987247467041, acc 0.17000000178813934\n",
      "Epoch 6, iter 21, loss 2.2361676692962646, acc 0.12999999523162842\n",
      "Epoch 6, iter 22, loss 2.297314167022705, acc 0.12999999523162842\n",
      "Epoch 6, iter 23, loss 2.2436225414276123, acc 0.20000000298023224\n",
      "Epoch 6, iter 24, loss 2.1499030590057373, acc 0.20000000298023224\n",
      "Epoch 6, iter 25, loss 2.204164505004883, acc 0.20000000298023224\n",
      "Epoch 6, iter 26, loss 2.308014392852783, acc 0.14000000059604645\n",
      "Epoch 6, iter 27, loss 2.1859679222106934, acc 0.20000000298023224\n",
      "Epoch 6, iter 28, loss 2.283574342727661, acc 0.10000000149011612\n",
      "Epoch 6, iter 29, loss 2.2889349460601807, acc 0.17000000178813934\n",
      "Epoch 6, iter 30, loss 2.292116165161133, acc 0.17000000178813934\n",
      "Epoch 6, iter 31, loss 2.271953821182251, acc 0.15000000596046448\n",
      "Epoch 6, iter 32, loss 2.2342793941497803, acc 0.11999999731779099\n",
      "Epoch 6, iter 33, loss 2.2644076347351074, acc 0.1899999976158142\n",
      "Epoch 6, iter 34, loss 2.2185657024383545, acc 0.1599999964237213\n",
      "Epoch 6, iter 35, loss 2.3837316036224365, acc 0.07999999821186066\n",
      "Epoch 6, iter 36, loss 2.2940802574157715, acc 0.1899999976158142\n",
      "Epoch 6, iter 37, loss 2.215043067932129, acc 0.17000000178813934\n",
      "Epoch 6, iter 38, loss 2.208545446395874, acc 0.20000000298023224\n",
      "Epoch 6, iter 39, loss 2.258866310119629, acc 0.12999999523162842\n",
      "Epoch 6, iter 40, loss 2.184044599533081, acc 0.11999999731779099\n",
      "Epoch 6, iter 41, loss 2.2766127586364746, acc 0.14000000059604645\n",
      "Epoch 6, iter 42, loss 2.2136640548706055, acc 0.10999999940395355\n",
      "Epoch 6, iter 43, loss 2.1341638565063477, acc 0.1899999976158142\n",
      "Epoch 6, iter 44, loss 2.2240819931030273, acc 0.15000000596046448\n",
      "Epoch 6, iter 45, loss 2.2346251010894775, acc 0.1599999964237213\n",
      "Epoch 6, iter 46, loss 2.211702585220337, acc 0.17000000178813934\n",
      "Epoch 6, iter 47, loss 2.351344585418701, acc 0.09000000357627869\n",
      "Epoch 6, iter 48, loss 2.173837184906006, acc 0.11999999731779099\n",
      "Epoch 6, iter 49, loss 2.2559142112731934, acc 0.17000000178813934\n",
      "Epoch 6, iter 50, loss 2.181800365447998, acc 0.18000000715255737\n",
      "Epoch 6, iter 51, loss 2.2141549587249756, acc 0.09000000357627869\n",
      "Epoch 6, iter 52, loss 2.249054193496704, acc 0.17000000178813934\n",
      "Epoch 6, iter 53, loss 2.243145704269409, acc 0.20999999344348907\n",
      "Epoch 6, iter 54, loss 2.1876912117004395, acc 0.14000000059604645\n",
      "Epoch 6, iter 55, loss 2.304248809814453, acc 0.25\n",
      "Epoch 6, iter 56, loss 2.260417938232422, acc 0.14000000059604645\n",
      "Epoch 6, iter 57, loss 2.2914986610412598, acc 0.1899999976158142\n",
      "Epoch 6, iter 58, loss 2.1598622798919678, acc 0.1899999976158142\n",
      "Epoch 6, iter 59, loss 2.2988805770874023, acc 0.1599999964237213\n",
      "Epoch 6, iter 60, loss 2.202775001525879, acc 0.1599999964237213\n",
      "Epoch 6, iter 61, loss 2.3136420249938965, acc 0.12999999523162842\n",
      "Epoch 6, iter 62, loss 2.294013261795044, acc 0.14000000059604645\n",
      "Epoch 6, iter 63, loss 2.3705484867095947, acc 0.07999999821186066\n",
      "Epoch 6, iter 64, loss 2.187056064605713, acc 0.1899999976158142\n",
      "Epoch 6, iter 65, loss 2.313627004623413, acc 0.12999999523162842\n",
      "Epoch 6, iter 66, loss 2.2949576377868652, acc 0.12999999523162842\n",
      "Epoch 6, iter 67, loss 2.2475063800811768, acc 0.18000000715255737\n",
      "Epoch 6, iter 68, loss 2.207502603530884, acc 0.1599999964237213\n",
      "Epoch 6, iter 69, loss 2.2079219818115234, acc 0.1899999976158142\n",
      "Epoch 6, iter 70, loss 2.2277708053588867, acc 0.1599999964237213\n",
      "Epoch 6, iter 71, loss 2.355309009552002, acc 0.10000000149011612\n",
      "Epoch 6, iter 72, loss 2.240846633911133, acc 0.15000000596046448\n",
      "Epoch 6, iter 73, loss 2.1945226192474365, acc 0.15000000596046448\n",
      "Epoch 6, iter 74, loss 2.239553213119507, acc 0.1899999976158142\n",
      "Epoch 6, iter 75, loss 2.1912713050842285, acc 0.18000000715255737\n",
      "Epoch 6, iter 76, loss 2.1977438926696777, acc 0.20000000298023224\n",
      "Epoch 6, iter 77, loss 2.2668159008026123, acc 0.18000000715255737\n",
      "Epoch 6, iter 78, loss 2.2574689388275146, acc 0.17000000178813934\n",
      "Epoch 6, iter 79, loss 2.261155128479004, acc 0.1599999964237213\n",
      "Epoch 6, iter 80, loss 2.35440731048584, acc 0.10999999940395355\n",
      "Epoch 6, iter 81, loss 2.2623355388641357, acc 0.1599999964237213\n",
      "Epoch 6, iter 82, loss 2.2619142532348633, acc 0.18000000715255737\n",
      "Epoch 6, iter 83, loss 2.2482378482818604, acc 0.10000000149011612\n",
      "Epoch 6, iter 84, loss 2.226966142654419, acc 0.20999999344348907\n",
      "Epoch 6, iter 85, loss 2.3080010414123535, acc 0.17000000178813934\n",
      "Epoch 6, iter 86, loss 2.2274582386016846, acc 0.14000000059604645\n",
      "Epoch 6, iter 87, loss 2.1383495330810547, acc 0.3100000023841858\n",
      "Epoch 6, iter 88, loss 2.1984221935272217, acc 0.18000000715255737\n",
      "Epoch 6, iter 89, loss 2.252728223800659, acc 0.15000000596046448\n",
      "Epoch 6, iter 90, loss 2.2135584354400635, acc 0.17000000178813934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 91, loss 2.2765119075775146, acc 0.14000000059604645\n",
      "Epoch 6, iter 92, loss 2.3014681339263916, acc 0.17000000178813934\n",
      "Epoch 6, iter 93, loss 2.23293399810791, acc 0.11999999731779099\n",
      "Epoch 6, iter 94, loss 2.2174437046051025, acc 0.1899999976158142\n",
      "Epoch 6, iter 95, loss 2.327946901321411, acc 0.10999999940395355\n",
      "Epoch 6, iter 96, loss 2.1624343395233154, acc 0.1899999976158142\n",
      "Epoch 6, iter 97, loss 2.2870147228240967, acc 0.07999999821186066\n",
      "Epoch 6, iter 98, loss 2.2213892936706543, acc 0.1599999964237213\n",
      "Epoch 6, iter 99, loss 2.303872585296631, acc 0.23000000417232513\n",
      "Epoch 6, iter 100, loss 2.2278060913085938, acc 0.18000000715255737\n",
      "Epoch 6, iter 101, loss 2.246781349182129, acc 0.18000000715255737\n",
      "Epoch 6, iter 102, loss 2.1643519401550293, acc 0.20000000298023224\n",
      "Epoch 6, iter 103, loss 2.2291207313537598, acc 0.1899999976158142\n",
      "Epoch 6, iter 104, loss 2.285010576248169, acc 0.15000000596046448\n",
      "Epoch 6, iter 105, loss 2.2238824367523193, acc 0.14000000059604645\n",
      "Epoch 6, iter 106, loss 2.272892713546753, acc 0.1599999964237213\n",
      "Epoch 6, iter 107, loss 2.2414205074310303, acc 0.1899999976158142\n",
      "Epoch 6, iter 108, loss 2.177372694015503, acc 0.25\n",
      "Epoch 6, iter 109, loss 2.2430291175842285, acc 0.12999999523162842\n",
      "Epoch 6, iter 110, loss 2.3287181854248047, acc 0.12999999523162842\n",
      "Epoch 6, iter 111, loss 2.2639029026031494, acc 0.12999999523162842\n",
      "Epoch 6, iter 112, loss 2.267559051513672, acc 0.20000000298023224\n",
      "Epoch 6, iter 113, loss 2.2030997276306152, acc 0.1599999964237213\n",
      "Epoch 6, iter 114, loss 2.189703941345215, acc 0.1599999964237213\n",
      "Epoch 6, iter 115, loss 2.2881548404693604, acc 0.1599999964237213\n",
      "Epoch 6, iter 116, loss 2.2496683597564697, acc 0.1599999964237213\n",
      "Epoch 6, iter 117, loss 2.2457845211029053, acc 0.1899999976158142\n",
      "Epoch 6, iter 118, loss 2.2586448192596436, acc 0.18000000715255737\n",
      "Epoch 6, iter 119, loss 2.2107062339782715, acc 0.18000000715255737\n",
      "Epoch 6, iter 120, loss 2.2030370235443115, acc 0.17000000178813934\n",
      "Epoch 6, iter 121, loss 2.2566542625427246, acc 0.18000000715255737\n",
      "Epoch 6, iter 122, loss 2.268812894821167, acc 0.1599999964237213\n",
      "Epoch 6, iter 123, loss 2.228478193283081, acc 0.20999999344348907\n",
      "Epoch 6, iter 124, loss 2.1891984939575195, acc 0.10000000149011612\n",
      "Epoch 6, iter 125, loss 2.224576473236084, acc 0.18000000715255737\n",
      "Epoch 6, iter 126, loss 2.2231173515319824, acc 0.12999999523162842\n",
      "Epoch 6, iter 127, loss 2.321261405944824, acc 0.10999999940395355\n",
      "Epoch 6, iter 128, loss 2.2656900882720947, acc 0.09000000357627869\n",
      "Epoch 6, iter 129, loss 2.304029941558838, acc 0.20000000298023224\n",
      "Epoch 6, iter 130, loss 2.2556121349334717, acc 0.18000000715255737\n",
      "Epoch 6, iter 131, loss 2.230086326599121, acc 0.23000000417232513\n",
      "Epoch 6, iter 132, loss 2.246274471282959, acc 0.1899999976158142\n",
      "Epoch 6, iter 133, loss 2.2510249614715576, acc 0.15000000596046448\n",
      "Epoch 6, iter 134, loss 2.301612615585327, acc 0.1599999964237213\n",
      "Epoch 6, iter 135, loss 2.1914942264556885, acc 0.20999999344348907\n",
      "Epoch 6, iter 136, loss 2.282940149307251, acc 0.14000000059604645\n",
      "Epoch 6, iter 137, loss 2.292268753051758, acc 0.1599999964237213\n",
      "Epoch 6, iter 138, loss 2.183117151260376, acc 0.15000000596046448\n",
      "Epoch 6, iter 139, loss 2.245896577835083, acc 0.15000000596046448\n",
      "Epoch 6, iter 140, loss 2.300220251083374, acc 0.11999999731779099\n",
      "Epoch 6, iter 141, loss 2.3525161743164062, acc 0.05999999865889549\n",
      "Epoch 6, iter 142, loss 2.1990747451782227, acc 0.1599999964237213\n",
      "Epoch 6, iter 143, loss 2.251185417175293, acc 0.14000000059604645\n",
      "Epoch 6, iter 144, loss 2.2802278995513916, acc 0.17000000178813934\n",
      "Epoch 6, iter 145, loss 2.2533791065216064, acc 0.18000000715255737\n",
      "Epoch 6, iter 146, loss 2.250976085662842, acc 0.14000000059604645\n",
      "Epoch 6, iter 147, loss 2.2058629989624023, acc 0.17000000178813934\n",
      "Epoch 6, iter 148, loss 2.1763455867767334, acc 0.1599999964237213\n",
      "Epoch 6, iter 149, loss 2.270397424697876, acc 0.17000000178813934\n",
      "Epoch 6, iter 150, loss 2.106795072555542, acc 0.23999999463558197\n",
      "Epoch 6, iter 151, loss 2.2089712619781494, acc 0.17000000178813934\n",
      "Epoch 6, iter 152, loss 2.2347214221954346, acc 0.15000000596046448\n",
      "Epoch 6, iter 153, loss 2.2060728073120117, acc 0.20999999344348907\n",
      "Epoch 6, iter 154, loss 2.2142579555511475, acc 0.17000000178813934\n",
      "Epoch 6, iter 155, loss 2.209212303161621, acc 0.18000000715255737\n",
      "Epoch 6, iter 156, loss 2.2344961166381836, acc 0.2199999988079071\n",
      "Epoch 6, iter 157, loss 2.298196792602539, acc 0.10999999940395355\n",
      "Epoch 6, iter 158, loss 2.318906784057617, acc 0.12999999523162842\n",
      "Epoch 6, iter 159, loss 2.207484245300293, acc 0.17000000178813934\n",
      "Epoch 6, iter 160, loss 2.212029457092285, acc 0.20000000298023224\n",
      "Epoch 6, iter 161, loss 2.3182032108306885, acc 0.11999999731779099\n",
      "Epoch 6, iter 162, loss 2.255363941192627, acc 0.1599999964237213\n",
      "Epoch 6, iter 163, loss 2.311947822570801, acc 0.17000000178813934\n",
      "Epoch 6, iter 164, loss 2.297487735748291, acc 0.15000000596046448\n",
      "Epoch 6, iter 165, loss 2.276395559310913, acc 0.17000000178813934\n",
      "Epoch 6, iter 166, loss 2.3091135025024414, acc 0.09000000357627869\n",
      "Epoch 6, iter 167, loss 2.2625839710235596, acc 0.15000000596046448\n",
      "Epoch 6, iter 168, loss 2.252964735031128, acc 0.10000000149011612\n",
      "Epoch 6, iter 169, loss 2.2488787174224854, acc 0.15000000596046448\n",
      "Epoch 6, iter 170, loss 2.285844326019287, acc 0.15000000596046448\n",
      "Epoch 6, iter 171, loss 2.246154308319092, acc 0.15000000596046448\n",
      "Epoch 6, iter 172, loss 2.2523744106292725, acc 0.10000000149011612\n",
      "Epoch 6, iter 173, loss 2.250497579574585, acc 0.20000000298023224\n",
      "Epoch 6, iter 174, loss 2.233349561691284, acc 0.20000000298023224\n",
      "Epoch 6, iter 175, loss 2.2366673946380615, acc 0.23000000417232513\n",
      "Epoch 6, iter 176, loss 2.247415065765381, acc 0.17000000178813934\n",
      "Epoch 6, iter 177, loss 2.242870569229126, acc 0.20000000298023224\n",
      "Epoch 6, iter 178, loss 2.2794737815856934, acc 0.17000000178813934\n",
      "Epoch 6, iter 179, loss 2.256462812423706, acc 0.17000000178813934\n",
      "Epoch 6, iter 180, loss 2.289942979812622, acc 0.1899999976158142\n",
      "Epoch 6, iter 181, loss 2.185004234313965, acc 0.17000000178813934\n",
      "Epoch 6, iter 182, loss 2.16658878326416, acc 0.1899999976158142\n",
      "Epoch 6, iter 183, loss 2.222529649734497, acc 0.1599999964237213\n",
      "Epoch 6, iter 184, loss 2.228817939758301, acc 0.14000000059604645\n",
      "Epoch 6, iter 185, loss 2.1714186668395996, acc 0.17000000178813934\n",
      "Epoch 6, iter 186, loss 2.203468084335327, acc 0.18000000715255737\n",
      "Epoch 6, iter 187, loss 2.2079176902770996, acc 0.23000000417232513\n",
      "Epoch 6, iter 188, loss 2.2692198753356934, acc 0.1599999964237213\n",
      "Epoch 6, iter 189, loss 2.1925549507141113, acc 0.17000000178813934\n",
      "Epoch 6, iter 190, loss 2.236818313598633, acc 0.18000000715255737\n",
      "Epoch 6, iter 191, loss 2.159393072128296, acc 0.23000000417232513\n",
      "Epoch 6, iter 192, loss 2.3077433109283447, acc 0.14000000059604645\n",
      "Epoch 6, iter 193, loss 2.1800711154937744, acc 0.12999999523162842\n",
      "Epoch 6, iter 194, loss 2.21926212310791, acc 0.18000000715255737\n",
      "Epoch 6, iter 195, loss 2.4009690284729004, acc 0.10000000149011612\n",
      "Epoch 6, iter 196, loss 2.2857658863067627, acc 0.12999999523162842\n",
      "Epoch 6, iter 197, loss 2.241503953933716, acc 0.14000000059604645\n",
      "Epoch 6, iter 198, loss 2.1880042552948, acc 0.14000000059604645\n",
      "Epoch 6, iter 199, loss 2.217196226119995, acc 0.12999999523162842\n",
      "Epoch 6, iter 200, loss 2.2767443656921387, acc 0.11999999731779099\n",
      "Epoch 6, iter 201, loss 2.2578532695770264, acc 0.10000000149011612\n",
      "Epoch 6, iter 202, loss 2.2639992237091064, acc 0.10999999940395355\n",
      "Epoch 6, iter 203, loss 2.3397531509399414, acc 0.10999999940395355\n",
      "Epoch 6, iter 204, loss 2.2353055477142334, acc 0.23999999463558197\n",
      "Epoch 6, iter 205, loss 2.191253423690796, acc 0.15000000596046448\n",
      "Epoch 6, iter 206, loss 2.229860305786133, acc 0.20000000298023224\n",
      "Epoch 6, iter 207, loss 2.195314407348633, acc 0.18000000715255737\n",
      "Epoch 6, iter 208, loss 2.284738302230835, acc 0.1599999964237213\n",
      "Epoch 6, iter 209, loss 2.3704023361206055, acc 0.12999999523162842\n",
      "Epoch 6, iter 210, loss 2.3038861751556396, acc 0.17000000178813934\n",
      "Epoch 6, iter 211, loss 2.1788177490234375, acc 0.18000000715255737\n",
      "Epoch 6, iter 212, loss 2.211852550506592, acc 0.17000000178813934\n",
      "Epoch 6, iter 213, loss 2.2066118717193604, acc 0.18000000715255737\n",
      "Epoch 6, iter 214, loss 2.274878978729248, acc 0.15000000596046448\n",
      "Epoch 6, iter 215, loss 2.213963031768799, acc 0.15000000596046448\n",
      "Epoch 6, iter 216, loss 2.2470710277557373, acc 0.1599999964237213\n",
      "Epoch 6, iter 217, loss 2.1766343116760254, acc 0.17000000178813934\n",
      "Epoch 6, iter 218, loss 2.2849082946777344, acc 0.1899999976158142\n",
      "Epoch 6, iter 219, loss 2.230306625366211, acc 0.18000000715255737\n",
      "Epoch 6, iter 220, loss 2.2472264766693115, acc 0.10000000149011612\n",
      "Epoch 6, iter 221, loss 2.176198720932007, acc 0.15000000596046448\n",
      "Epoch 6, iter 222, loss 2.3347132205963135, acc 0.10999999940395355\n",
      "Epoch 6, iter 223, loss 2.2476253509521484, acc 0.10999999940395355\n",
      "Epoch 6, iter 224, loss 2.2084362506866455, acc 0.12999999523162842\n",
      "Epoch 6, iter 225, loss 2.176917791366577, acc 0.20000000298023224\n",
      "Epoch 6, iter 226, loss 2.229818820953369, acc 0.15000000596046448\n",
      "Epoch 6, iter 227, loss 2.2215890884399414, acc 0.17000000178813934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 228, loss 2.184833288192749, acc 0.20999999344348907\n",
      "Epoch 6, iter 229, loss 2.2402689456939697, acc 0.12999999523162842\n",
      "Epoch 6, iter 230, loss 2.2810280323028564, acc 0.15000000596046448\n",
      "Epoch 6, iter 231, loss 2.275085210800171, acc 0.11999999731779099\n",
      "Epoch 6, iter 232, loss 2.255305290222168, acc 0.15000000596046448\n",
      "Epoch 6, iter 233, loss 2.2173027992248535, acc 0.20000000298023224\n",
      "Epoch 6, iter 234, loss 2.232135772705078, acc 0.11999999731779099\n",
      "Epoch 6, iter 235, loss 2.3037195205688477, acc 0.11999999731779099\n",
      "Epoch 6, iter 236, loss 2.268484354019165, acc 0.15000000596046448\n",
      "Epoch 6, iter 237, loss 2.2759385108947754, acc 0.1599999964237213\n",
      "Epoch 6, iter 238, loss 2.216193914413452, acc 0.17000000178813934\n",
      "Epoch 6, iter 239, loss 2.2930643558502197, acc 0.10000000149011612\n",
      "Epoch 6, iter 240, loss 2.2698378562927246, acc 0.15000000596046448\n",
      "Epoch 6, iter 241, loss 2.2875864505767822, acc 0.17000000178813934\n",
      "Epoch 6, iter 242, loss 2.3873636722564697, acc 0.07999999821186066\n",
      "Epoch 6, iter 243, loss 2.3279998302459717, acc 0.1899999976158142\n",
      "Epoch 6, iter 244, loss 2.303987503051758, acc 0.1599999964237213\n",
      "Epoch 6, iter 245, loss 2.155078172683716, acc 0.20000000298023224\n",
      "Epoch 6, iter 246, loss 2.222740411758423, acc 0.18000000715255737\n",
      "Epoch 6, iter 247, loss 2.199901580810547, acc 0.15000000596046448\n",
      "Epoch 6, iter 248, loss 2.203589916229248, acc 0.1599999964237213\n",
      "Epoch 6, iter 249, loss 2.2007057666778564, acc 0.14000000059604645\n",
      "Epoch 6, iter 250, loss 2.2642295360565186, acc 0.17000000178813934\n",
      "Epoch 6, iter 251, loss 2.226130485534668, acc 0.23000000417232513\n",
      "Epoch 6, iter 252, loss 2.19036865234375, acc 0.1599999964237213\n",
      "Epoch 6, iter 253, loss 2.406482219696045, acc 0.14000000059604645\n",
      "Epoch 6, iter 254, loss 2.1915862560272217, acc 0.1899999976158142\n",
      "Epoch 6, iter 255, loss 2.3022353649139404, acc 0.1599999964237213\n",
      "Epoch 6, iter 256, loss 2.221024513244629, acc 0.15000000596046448\n",
      "Epoch 6, iter 257, loss 2.1746926307678223, acc 0.20000000298023224\n",
      "Epoch 6, iter 258, loss 2.288266658782959, acc 0.17000000178813934\n",
      "Epoch 6, iter 259, loss 2.246882677078247, acc 0.1899999976158142\n",
      "Epoch 6, iter 260, loss 2.1936910152435303, acc 0.15000000596046448\n",
      "Epoch 6, iter 261, loss 2.2359578609466553, acc 0.15000000596046448\n",
      "Epoch 6, iter 262, loss 2.289137601852417, acc 0.11999999731779099\n",
      "Epoch 6, iter 263, loss 2.1672616004943848, acc 0.12999999523162842\n",
      "Epoch 6, iter 264, loss 2.227911949157715, acc 0.1899999976158142\n",
      "Epoch 6, iter 265, loss 2.178917646408081, acc 0.2199999988079071\n",
      "Epoch 6, iter 266, loss 2.2916064262390137, acc 0.15000000596046448\n",
      "Epoch 6, iter 267, loss 2.2627010345458984, acc 0.07000000029802322\n",
      "Epoch 6, iter 268, loss 2.219569206237793, acc 0.15000000596046448\n",
      "Epoch 6, iter 269, loss 2.188871383666992, acc 0.18000000715255737\n",
      "Epoch 6, iter 270, loss 2.2876758575439453, acc 0.10000000149011612\n",
      "Epoch 6, iter 271, loss 2.1593408584594727, acc 0.2800000011920929\n",
      "Epoch 6, iter 272, loss 2.2291011810302734, acc 0.1599999964237213\n",
      "Epoch 6, iter 273, loss 2.240065574645996, acc 0.15000000596046448\n",
      "Epoch 6, iter 274, loss 2.3557252883911133, acc 0.10999999940395355\n",
      "Epoch 6, iter 275, loss 2.248474597930908, acc 0.10000000149011612\n",
      "Epoch 6, iter 276, loss 2.2471256256103516, acc 0.17000000178813934\n",
      "Epoch 6, iter 277, loss 2.1664137840270996, acc 0.11999999731779099\n",
      "Epoch 6, iter 278, loss 2.117112636566162, acc 0.17000000178813934\n",
      "Epoch 6, iter 279, loss 2.3011417388916016, acc 0.15000000596046448\n",
      "Epoch 6, iter 280, loss 2.2357425689697266, acc 0.18000000715255737\n",
      "Epoch 6, iter 281, loss 2.259272575378418, acc 0.1599999964237213\n",
      "Epoch 6, iter 282, loss 2.1234946250915527, acc 0.2199999988079071\n",
      "Epoch 6, iter 283, loss 2.2688660621643066, acc 0.17000000178813934\n",
      "Epoch 6, iter 284, loss 2.2099428176879883, acc 0.11999999731779099\n",
      "Epoch 6, iter 285, loss 2.2570433616638184, acc 0.17000000178813934\n",
      "Epoch 6, iter 286, loss 2.1740996837615967, acc 0.14000000059604645\n",
      "Epoch 6, iter 287, loss 2.249606132507324, acc 0.15000000596046448\n",
      "Epoch 6, iter 288, loss 2.3266830444335938, acc 0.10999999940395355\n",
      "Epoch 6, iter 289, loss 2.2845358848571777, acc 0.11999999731779099\n",
      "Epoch 6, iter 290, loss 2.2721035480499268, acc 0.10000000149011612\n",
      "Epoch 6, iter 291, loss 2.287910223007202, acc 0.11999999731779099\n",
      "Epoch 6, iter 292, loss 2.222491979598999, acc 0.20000000298023224\n",
      "Epoch 6, iter 293, loss 2.2461600303649902, acc 0.17000000178813934\n",
      "Epoch 6, iter 294, loss 2.139620542526245, acc 0.28999999165534973\n",
      "Epoch 6, iter 295, loss 2.2703685760498047, acc 0.18000000715255737\n",
      "Epoch 6, iter 296, loss 2.2361130714416504, acc 0.09000000357627869\n",
      "Epoch 6, iter 297, loss 2.2699246406555176, acc 0.20000000298023224\n",
      "Epoch 6, iter 298, loss 2.155832052230835, acc 0.17000000178813934\n",
      "Epoch 6, iter 299, loss 2.3166568279266357, acc 0.17000000178813934\n",
      "Epoch 6, iter 300, loss 2.1757009029388428, acc 0.1599999964237213\n",
      "Epoch 6, iter 301, loss 2.27874493598938, acc 0.15000000596046448\n",
      "Epoch 6, iter 302, loss 2.2744529247283936, acc 0.15000000596046448\n",
      "Epoch 6, iter 303, loss 2.277034282684326, acc 0.14000000059604645\n",
      "Epoch 6, iter 304, loss 2.2022547721862793, acc 0.20000000298023224\n",
      "Epoch 6, iter 305, loss 2.236278772354126, acc 0.20000000298023224\n",
      "Epoch 6, iter 306, loss 2.240309000015259, acc 0.15000000596046448\n",
      "Epoch 6, iter 307, loss 2.2523999214172363, acc 0.14000000059604645\n",
      "Epoch 6, iter 308, loss 2.258558988571167, acc 0.1899999976158142\n",
      "Epoch 6, iter 309, loss 2.1788532733917236, acc 0.1599999964237213\n",
      "Epoch 6, iter 310, loss 2.2728943824768066, acc 0.10000000149011612\n",
      "Epoch 6, iter 311, loss 2.267214298248291, acc 0.17000000178813934\n",
      "Epoch 6, iter 312, loss 2.183946132659912, acc 0.17000000178813934\n",
      "Epoch 6, iter 313, loss 2.2437543869018555, acc 0.20000000298023224\n",
      "Epoch 6, iter 314, loss 2.185757637023926, acc 0.1599999964237213\n",
      "Epoch 6, iter 315, loss 2.2117865085601807, acc 0.1599999964237213\n",
      "Epoch 6, iter 316, loss 2.2776782512664795, acc 0.1899999976158142\n",
      "Epoch 6, iter 317, loss 2.2733821868896484, acc 0.1899999976158142\n",
      "Epoch 6, iter 318, loss 2.1000492572784424, acc 0.2199999988079071\n",
      "Epoch 6, iter 319, loss 2.168790102005005, acc 0.20000000298023224\n",
      "Epoch 6, iter 320, loss 2.2545859813690186, acc 0.18000000715255737\n",
      "Epoch 6, iter 321, loss 2.3323116302490234, acc 0.12999999523162842\n",
      "Epoch 6, iter 322, loss 2.2937734127044678, acc 0.14000000059604645\n",
      "Epoch 6, iter 323, loss 2.261932134628296, acc 0.14000000059604645\n",
      "Epoch 6, iter 324, loss 2.223217725753784, acc 0.12999999523162842\n",
      "Epoch 6, iter 325, loss 2.2697527408599854, acc 0.1599999964237213\n",
      "Epoch 6, iter 326, loss 2.2068707942962646, acc 0.11999999731779099\n",
      "Epoch 6, iter 327, loss 2.2205677032470703, acc 0.15000000596046448\n",
      "Epoch 6, iter 328, loss 2.3175437450408936, acc 0.10999999940395355\n",
      "Epoch 6, iter 329, loss 2.3027050495147705, acc 0.14000000059604645\n",
      "Epoch 6, iter 330, loss 2.227924346923828, acc 0.20000000298023224\n",
      "Epoch 6, iter 331, loss 2.176816463470459, acc 0.2199999988079071\n",
      "Epoch 6, iter 332, loss 2.19903826713562, acc 0.18000000715255737\n",
      "Epoch 6, iter 333, loss 2.2005703449249268, acc 0.14000000059604645\n",
      "Epoch 6, iter 334, loss 2.224602460861206, acc 0.20999999344348907\n",
      "Epoch 6, iter 335, loss 2.139040946960449, acc 0.20999999344348907\n",
      "Epoch 6, iter 336, loss 2.2075583934783936, acc 0.14000000059604645\n",
      "Epoch 6, iter 337, loss 2.303079605102539, acc 0.14000000059604645\n",
      "Epoch 6, iter 338, loss 2.146477699279785, acc 0.27000001072883606\n",
      "Epoch 6, iter 339, loss 2.097917318344116, acc 0.15000000596046448\n",
      "Epoch 6, iter 340, loss 2.3020071983337402, acc 0.10999999940395355\n",
      "Epoch 6, iter 341, loss 2.185507297515869, acc 0.14000000059604645\n",
      "Epoch 6, iter 342, loss 2.153545379638672, acc 0.23000000417232513\n",
      "Epoch 6, iter 343, loss 2.2927095890045166, acc 0.20000000298023224\n",
      "Epoch 6, iter 344, loss 2.282902479171753, acc 0.12999999523162842\n",
      "Epoch 6, iter 345, loss 2.3002209663391113, acc 0.18000000715255737\n",
      "Epoch 6, iter 346, loss 2.267484188079834, acc 0.1599999964237213\n",
      "Epoch 6, iter 347, loss 2.160994529724121, acc 0.23000000417232513\n",
      "Epoch 6, iter 348, loss 2.170889377593994, acc 0.15000000596046448\n",
      "Epoch 6, iter 349, loss 2.1456515789031982, acc 0.1899999976158142\n",
      "Epoch 6, iter 350, loss 2.2499570846557617, acc 0.1599999964237213\n",
      "Epoch 6, iter 351, loss 2.255060911178589, acc 0.14000000059604645\n",
      "Epoch 6, iter 352, loss 2.2123281955718994, acc 0.18000000715255737\n",
      "Epoch 6, iter 353, loss 2.2627692222595215, acc 0.1599999964237213\n",
      "Epoch 6, iter 354, loss 2.2034707069396973, acc 0.14000000059604645\n",
      "Epoch 6, iter 355, loss 2.246145009994507, acc 0.14000000059604645\n",
      "Epoch 6, iter 356, loss 2.1991147994995117, acc 0.20999999344348907\n",
      "Epoch 6, iter 357, loss 2.181715488433838, acc 0.18000000715255737\n",
      "Epoch 6, iter 358, loss 2.227879524230957, acc 0.25\n",
      "Epoch 6, iter 359, loss 2.232175350189209, acc 0.09000000357627869\n",
      "Epoch 6, iter 360, loss 2.250509738922119, acc 0.1599999964237213\n",
      "Epoch 6, iter 361, loss 2.2606050968170166, acc 0.15000000596046448\n",
      "Epoch 6, iter 362, loss 2.298696994781494, acc 0.18000000715255737\n",
      "Epoch 6, iter 363, loss 2.2258434295654297, acc 0.18000000715255737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 364, loss 2.254333734512329, acc 0.1899999976158142\n",
      "Epoch 6, iter 365, loss 2.2465009689331055, acc 0.14000000059604645\n",
      "Epoch 6, iter 366, loss 2.1777803897857666, acc 0.20000000298023224\n",
      "Epoch 6, iter 367, loss 2.2775635719299316, acc 0.10000000149011612\n",
      "Epoch 6, iter 368, loss 2.2619788646698, acc 0.20000000298023224\n",
      "Epoch 6, iter 369, loss 2.2674179077148438, acc 0.12999999523162842\n",
      "Epoch 6, iter 370, loss 2.241583824157715, acc 0.1599999964237213\n",
      "Epoch 6, iter 371, loss 2.192704916000366, acc 0.12999999523162842\n",
      "Epoch 6, iter 372, loss 2.2143867015838623, acc 0.17000000178813934\n",
      "Epoch 6, iter 373, loss 2.179309129714966, acc 0.14000000059604645\n",
      "Epoch 6, iter 374, loss 2.209231376647949, acc 0.1599999964237213\n",
      "Epoch 6, iter 375, loss 2.265761613845825, acc 0.1599999964237213\n",
      "Epoch 6, iter 376, loss 2.1626522541046143, acc 0.1899999976158142\n",
      "Epoch 6, iter 377, loss 2.273179054260254, acc 0.12999999523162842\n",
      "Epoch 6, iter 378, loss 2.232968807220459, acc 0.18000000715255737\n",
      "Epoch 6, iter 379, loss 2.2616665363311768, acc 0.14000000059604645\n",
      "Epoch 6, iter 380, loss 2.2287817001342773, acc 0.20000000298023224\n",
      "Epoch 6, iter 381, loss 2.2898929119110107, acc 0.18000000715255737\n",
      "Epoch 6, iter 382, loss 2.067404270172119, acc 0.2199999988079071\n",
      "Epoch 6, iter 383, loss 2.1993024349212646, acc 0.1599999964237213\n",
      "Epoch 6, iter 384, loss 2.249925374984741, acc 0.12999999523162842\n",
      "Epoch 6, iter 385, loss 2.3198440074920654, acc 0.10000000149011612\n",
      "Epoch 6, iter 386, loss 2.2193825244903564, acc 0.20999999344348907\n",
      "Epoch 6, iter 387, loss 2.212271213531494, acc 0.2199999988079071\n",
      "Epoch 6, iter 388, loss 2.176705837249756, acc 0.25\n",
      "Epoch 6, iter 389, loss 2.1884708404541016, acc 0.1899999976158142\n",
      "Epoch 6, iter 390, loss 2.2368884086608887, acc 0.1899999976158142\n",
      "Epoch 6, iter 391, loss 2.185284376144409, acc 0.20000000298023224\n",
      "Epoch 6, iter 392, loss 2.320843458175659, acc 0.12999999523162842\n",
      "Epoch 6, iter 393, loss 2.237473964691162, acc 0.10999999940395355\n",
      "Epoch 6, iter 394, loss 2.162554979324341, acc 0.23000000417232513\n",
      "Epoch 6, iter 395, loss 2.234450340270996, acc 0.15000000596046448\n",
      "Epoch 6, iter 396, loss 2.360954761505127, acc 0.11999999731779099\n",
      "Epoch 6, iter 397, loss 2.2195725440979004, acc 0.14000000059604645\n",
      "Epoch 6, iter 398, loss 2.2366068363189697, acc 0.25\n",
      "Epoch 6, iter 399, loss 2.2829995155334473, acc 0.20999999344348907\n",
      "Epoch 6, iter 400, loss 2.2079415321350098, acc 0.20999999344348907\n",
      "Epoch 6, iter 401, loss 2.2724084854125977, acc 0.17000000178813934\n",
      "Epoch 6, iter 402, loss 2.19708251953125, acc 0.25\n",
      "Epoch 6, iter 403, loss 2.282961845397949, acc 0.23000000417232513\n",
      "Epoch 6, iter 404, loss 2.3629279136657715, acc 0.14000000059604645\n",
      "Epoch 6, iter 405, loss 2.275444269180298, acc 0.20999999344348907\n",
      "Epoch 6, iter 406, loss 2.2423391342163086, acc 0.1899999976158142\n",
      "Epoch 6, iter 407, loss 2.217513084411621, acc 0.12999999523162842\n",
      "Epoch 6, iter 408, loss 2.1507067680358887, acc 0.23000000417232513\n",
      "Epoch 6, iter 409, loss 2.258204460144043, acc 0.20999999344348907\n",
      "Epoch 6, iter 410, loss 2.1807050704956055, acc 0.3100000023841858\n",
      "Epoch 6, iter 411, loss 2.2623698711395264, acc 0.1899999976158142\n",
      "Epoch 6, iter 412, loss 2.221008539199829, acc 0.25999999046325684\n",
      "Epoch 6, iter 413, loss 2.293041229248047, acc 0.17000000178813934\n",
      "Epoch 6, iter 414, loss 2.31514048576355, acc 0.12999999523162842\n",
      "Epoch 6, iter 415, loss 2.3437929153442383, acc 0.18000000715255737\n",
      "Epoch 6, iter 416, loss 2.278080940246582, acc 0.20000000298023224\n",
      "Epoch 6, iter 417, loss 2.212562322616577, acc 0.17000000178813934\n",
      "Epoch 6, iter 418, loss 2.1355350017547607, acc 0.2800000011920929\n",
      "Epoch 6, iter 419, loss 2.1554880142211914, acc 0.20999999344348907\n",
      "Epoch 6, iter 420, loss 2.2564165592193604, acc 0.14000000059604645\n",
      "Epoch 7, iter 1, loss 2.1916825771331787, acc 0.2199999988079071\n",
      "Epoch 7, iter 2, loss 2.2719202041625977, acc 0.1899999976158142\n",
      "Epoch 7, iter 3, loss 2.2162811756134033, acc 0.2199999988079071\n",
      "Epoch 7, iter 4, loss 2.27089786529541, acc 0.20999999344348907\n",
      "Epoch 7, iter 5, loss 2.176711320877075, acc 0.18000000715255737\n",
      "Epoch 7, iter 6, loss 2.206815719604492, acc 0.1899999976158142\n",
      "Epoch 7, iter 7, loss 2.2889440059661865, acc 0.15000000596046448\n",
      "Epoch 7, iter 8, loss 2.22129225730896, acc 0.23000000417232513\n",
      "Epoch 7, iter 9, loss 2.185105562210083, acc 0.20999999344348907\n",
      "Epoch 7, iter 10, loss 2.2549917697906494, acc 0.2199999988079071\n",
      "Epoch 7, iter 11, loss 2.418240547180176, acc 0.11999999731779099\n",
      "Epoch 7, iter 12, loss 2.30167818069458, acc 0.14000000059604645\n",
      "Epoch 7, iter 13, loss 2.1949081420898438, acc 0.18000000715255737\n",
      "Epoch 7, iter 14, loss 2.325827121734619, acc 0.10999999940395355\n",
      "Epoch 7, iter 15, loss 2.230353593826294, acc 0.1599999964237213\n",
      "Epoch 7, iter 16, loss 2.1975111961364746, acc 0.17000000178813934\n",
      "Epoch 7, iter 17, loss 2.1840903759002686, acc 0.23999999463558197\n",
      "Epoch 7, iter 18, loss 2.3413245677948, acc 0.18000000715255737\n",
      "Epoch 7, iter 19, loss 2.200979232788086, acc 0.20000000298023224\n",
      "Epoch 7, iter 20, loss 2.2057688236236572, acc 0.17000000178813934\n",
      "Epoch 7, iter 21, loss 2.236318588256836, acc 0.2199999988079071\n",
      "Epoch 7, iter 22, loss 2.2852730751037598, acc 0.17000000178813934\n",
      "Epoch 7, iter 23, loss 2.197847366333008, acc 0.20000000298023224\n",
      "Epoch 7, iter 24, loss 2.1391658782958984, acc 0.25999999046325684\n",
      "Epoch 7, iter 25, loss 2.206085205078125, acc 0.1899999976158142\n",
      "Epoch 7, iter 26, loss 2.2819714546203613, acc 0.20999999344348907\n",
      "Epoch 7, iter 27, loss 2.2062549591064453, acc 0.1899999976158142\n",
      "Epoch 7, iter 28, loss 2.2762346267700195, acc 0.1599999964237213\n",
      "Epoch 7, iter 29, loss 2.266517162322998, acc 0.23000000417232513\n",
      "Epoch 7, iter 30, loss 2.2509560585021973, acc 0.18000000715255737\n",
      "Epoch 7, iter 31, loss 2.259455442428589, acc 0.20000000298023224\n",
      "Epoch 7, iter 32, loss 2.224550724029541, acc 0.23999999463558197\n",
      "Epoch 7, iter 33, loss 2.24983811378479, acc 0.17000000178813934\n",
      "Epoch 7, iter 34, loss 2.199568510055542, acc 0.23999999463558197\n",
      "Epoch 7, iter 35, loss 2.3168632984161377, acc 0.15000000596046448\n",
      "Epoch 7, iter 36, loss 2.30539608001709, acc 0.1899999976158142\n",
      "Epoch 7, iter 37, loss 2.182532548904419, acc 0.17000000178813934\n",
      "Epoch 7, iter 38, loss 2.2039601802825928, acc 0.20000000298023224\n",
      "Epoch 7, iter 39, loss 2.264921188354492, acc 0.17000000178813934\n",
      "Epoch 7, iter 40, loss 2.1784064769744873, acc 0.23999999463558197\n",
      "Epoch 7, iter 41, loss 2.2870616912841797, acc 0.1899999976158142\n",
      "Epoch 7, iter 42, loss 2.178150177001953, acc 0.23999999463558197\n",
      "Epoch 7, iter 43, loss 2.143033027648926, acc 0.20999999344348907\n",
      "Epoch 7, iter 44, loss 2.206719160079956, acc 0.2199999988079071\n",
      "Epoch 7, iter 45, loss 2.2459115982055664, acc 0.20999999344348907\n",
      "Epoch 7, iter 46, loss 2.17499041557312, acc 0.18000000715255737\n",
      "Epoch 7, iter 47, loss 2.3002939224243164, acc 0.14000000059604645\n",
      "Epoch 7, iter 48, loss 2.1601343154907227, acc 0.2199999988079071\n",
      "Epoch 7, iter 49, loss 2.1834030151367188, acc 0.1899999976158142\n",
      "Epoch 7, iter 50, loss 2.170703649520874, acc 0.2199999988079071\n",
      "Epoch 7, iter 51, loss 2.181025505065918, acc 0.1899999976158142\n",
      "Epoch 7, iter 52, loss 2.2221105098724365, acc 0.15000000596046448\n",
      "Epoch 7, iter 53, loss 2.231276035308838, acc 0.10000000149011612\n",
      "Epoch 7, iter 54, loss 2.16530704498291, acc 0.2800000011920929\n",
      "Epoch 7, iter 55, loss 2.2949724197387695, acc 0.23999999463558197\n",
      "Epoch 7, iter 56, loss 2.2164626121520996, acc 0.25\n",
      "Epoch 7, iter 57, loss 2.2726876735687256, acc 0.23000000417232513\n",
      "Epoch 7, iter 58, loss 2.142298460006714, acc 0.28999999165534973\n",
      "Epoch 7, iter 59, loss 2.2971553802490234, acc 0.1899999976158142\n",
      "Epoch 7, iter 60, loss 2.1863646507263184, acc 0.23000000417232513\n",
      "Epoch 7, iter 61, loss 2.24501633644104, acc 0.25\n",
      "Epoch 7, iter 62, loss 2.2835772037506104, acc 0.20999999344348907\n",
      "Epoch 7, iter 63, loss 2.3145875930786133, acc 0.11999999731779099\n",
      "Epoch 7, iter 64, loss 2.1667158603668213, acc 0.20000000298023224\n",
      "Epoch 7, iter 65, loss 2.3051984310150146, acc 0.1599999964237213\n",
      "Epoch 7, iter 66, loss 2.261364221572876, acc 0.17000000178813934\n",
      "Epoch 7, iter 67, loss 2.263901710510254, acc 0.15000000596046448\n",
      "Epoch 7, iter 68, loss 2.1744253635406494, acc 0.23000000417232513\n",
      "Epoch 7, iter 69, loss 2.1963465213775635, acc 0.2199999988079071\n",
      "Epoch 7, iter 70, loss 2.2195000648498535, acc 0.15000000596046448\n",
      "Epoch 7, iter 71, loss 2.3195626735687256, acc 0.1599999964237213\n",
      "Epoch 7, iter 72, loss 2.183589458465576, acc 0.25\n",
      "Epoch 7, iter 73, loss 2.196211814880371, acc 0.18000000715255737\n",
      "Epoch 7, iter 74, loss 2.2199649810791016, acc 0.2199999988079071\n",
      "Epoch 7, iter 75, loss 2.1907503604888916, acc 0.25\n",
      "Epoch 7, iter 76, loss 2.1490726470947266, acc 0.27000001072883606\n",
      "Epoch 7, iter 77, loss 2.2670130729675293, acc 0.10999999940395355\n",
      "Epoch 7, iter 78, loss 2.233262538909912, acc 0.17000000178813934\n",
      "Epoch 7, iter 79, loss 2.2168283462524414, acc 0.20999999344348907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 80, loss 2.343080997467041, acc 0.1599999964237213\n",
      "Epoch 7, iter 81, loss 2.2128288745880127, acc 0.18000000715255737\n",
      "Epoch 7, iter 82, loss 2.2183985710144043, acc 0.18000000715255737\n",
      "Epoch 7, iter 83, loss 2.214787244796753, acc 0.23000000417232513\n",
      "Epoch 7, iter 84, loss 2.236175298690796, acc 0.2800000011920929\n",
      "Epoch 7, iter 85, loss 2.3027782440185547, acc 0.23000000417232513\n",
      "Epoch 7, iter 86, loss 2.2080113887786865, acc 0.20999999344348907\n",
      "Epoch 7, iter 87, loss 2.15787410736084, acc 0.23999999463558197\n",
      "Epoch 7, iter 88, loss 2.170772075653076, acc 0.2199999988079071\n",
      "Epoch 7, iter 89, loss 2.259007692337036, acc 0.17000000178813934\n",
      "Epoch 7, iter 90, loss 2.216714859008789, acc 0.25\n",
      "Epoch 7, iter 91, loss 2.247619867324829, acc 0.2199999988079071\n",
      "Epoch 7, iter 92, loss 2.2706708908081055, acc 0.20999999344348907\n",
      "Epoch 7, iter 93, loss 2.239143133163452, acc 0.2199999988079071\n",
      "Epoch 7, iter 94, loss 2.201531410217285, acc 0.20000000298023224\n",
      "Epoch 7, iter 95, loss 2.2631325721740723, acc 0.17000000178813934\n",
      "Epoch 7, iter 96, loss 2.177903175354004, acc 0.20000000298023224\n",
      "Epoch 7, iter 97, loss 2.266148805618286, acc 0.18000000715255737\n",
      "Epoch 7, iter 98, loss 2.201667070388794, acc 0.2199999988079071\n",
      "Epoch 7, iter 99, loss 2.316455364227295, acc 0.20000000298023224\n",
      "Epoch 7, iter 100, loss 2.217688798904419, acc 0.17000000178813934\n",
      "Epoch 7, iter 101, loss 2.208380937576294, acc 0.23999999463558197\n",
      "Epoch 7, iter 102, loss 2.130282402038574, acc 0.20000000298023224\n",
      "Epoch 7, iter 103, loss 2.2127153873443604, acc 0.20000000298023224\n",
      "Epoch 7, iter 104, loss 2.285313606262207, acc 0.17000000178813934\n",
      "Epoch 7, iter 105, loss 2.2290923595428467, acc 0.2199999988079071\n",
      "Epoch 7, iter 106, loss 2.257222890853882, acc 0.10999999940395355\n",
      "Epoch 7, iter 107, loss 2.2224271297454834, acc 0.1899999976158142\n",
      "Epoch 7, iter 108, loss 2.1133852005004883, acc 0.25999999046325684\n",
      "Epoch 7, iter 109, loss 2.244037389755249, acc 0.17000000178813934\n",
      "Epoch 7, iter 110, loss 2.2848403453826904, acc 0.20000000298023224\n",
      "Epoch 7, iter 111, loss 2.24796724319458, acc 0.1899999976158142\n",
      "Epoch 7, iter 112, loss 2.2617084980010986, acc 0.11999999731779099\n",
      "Epoch 7, iter 113, loss 2.1847574710845947, acc 0.25999999046325684\n",
      "Epoch 7, iter 114, loss 2.2230031490325928, acc 0.17000000178813934\n",
      "Epoch 7, iter 115, loss 2.279930591583252, acc 0.17000000178813934\n",
      "Epoch 7, iter 116, loss 2.2518703937530518, acc 0.1899999976158142\n",
      "Epoch 7, iter 117, loss 2.2455480098724365, acc 0.17000000178813934\n",
      "Epoch 7, iter 118, loss 2.221982479095459, acc 0.23999999463558197\n",
      "Epoch 7, iter 119, loss 2.204026937484741, acc 0.20000000298023224\n",
      "Epoch 7, iter 120, loss 2.2039215564727783, acc 0.15000000596046448\n",
      "Epoch 7, iter 121, loss 2.266221284866333, acc 0.1899999976158142\n",
      "Epoch 7, iter 122, loss 2.2448248863220215, acc 0.20000000298023224\n",
      "Epoch 7, iter 123, loss 2.204293727874756, acc 0.2199999988079071\n",
      "Epoch 7, iter 124, loss 2.1910343170166016, acc 0.25999999046325684\n",
      "Epoch 7, iter 125, loss 2.2199184894561768, acc 0.20999999344348907\n",
      "Epoch 7, iter 126, loss 2.225539207458496, acc 0.20000000298023224\n",
      "Epoch 7, iter 127, loss 2.2516775131225586, acc 0.20000000298023224\n",
      "Epoch 7, iter 128, loss 2.2079100608825684, acc 0.18000000715255737\n",
      "Epoch 7, iter 129, loss 2.270491123199463, acc 0.20999999344348907\n",
      "Epoch 7, iter 130, loss 2.245668411254883, acc 0.1899999976158142\n",
      "Epoch 7, iter 131, loss 2.201605796813965, acc 0.20999999344348907\n",
      "Epoch 7, iter 132, loss 2.2143421173095703, acc 0.17000000178813934\n",
      "Epoch 7, iter 133, loss 2.215546131134033, acc 0.20000000298023224\n",
      "Epoch 7, iter 134, loss 2.234236240386963, acc 0.23999999463558197\n",
      "Epoch 7, iter 135, loss 2.201139450073242, acc 0.20000000298023224\n",
      "Epoch 7, iter 136, loss 2.281463861465454, acc 0.1599999964237213\n",
      "Epoch 7, iter 137, loss 2.2797813415527344, acc 0.1599999964237213\n",
      "Epoch 7, iter 138, loss 2.1707513332366943, acc 0.23000000417232513\n",
      "Epoch 7, iter 139, loss 2.244236946105957, acc 0.1599999964237213\n",
      "Epoch 7, iter 140, loss 2.2803549766540527, acc 0.1899999976158142\n",
      "Epoch 7, iter 141, loss 2.319021701812744, acc 0.15000000596046448\n",
      "Epoch 7, iter 142, loss 2.1716408729553223, acc 0.18000000715255737\n",
      "Epoch 7, iter 143, loss 2.2458159923553467, acc 0.17000000178813934\n",
      "Epoch 7, iter 144, loss 2.241534471511841, acc 0.20000000298023224\n",
      "Epoch 7, iter 145, loss 2.2099661827087402, acc 0.20999999344348907\n",
      "Epoch 7, iter 146, loss 2.2514259815216064, acc 0.15000000596046448\n",
      "Epoch 7, iter 147, loss 2.169058322906494, acc 0.20000000298023224\n",
      "Epoch 7, iter 148, loss 2.1380507946014404, acc 0.2199999988079071\n",
      "Epoch 7, iter 149, loss 2.21701717376709, acc 0.20000000298023224\n",
      "Epoch 7, iter 150, loss 2.0823655128479004, acc 0.25\n",
      "Epoch 7, iter 151, loss 2.184502601623535, acc 0.20000000298023224\n",
      "Epoch 7, iter 152, loss 2.209799289703369, acc 0.1899999976158142\n",
      "Epoch 7, iter 153, loss 2.2120964527130127, acc 0.2199999988079071\n",
      "Epoch 7, iter 154, loss 2.1826255321502686, acc 0.20999999344348907\n",
      "Epoch 7, iter 155, loss 2.1502699851989746, acc 0.1899999976158142\n",
      "Epoch 7, iter 156, loss 2.2229344844818115, acc 0.30000001192092896\n",
      "Epoch 7, iter 157, loss 2.3003242015838623, acc 0.10999999940395355\n",
      "Epoch 7, iter 158, loss 2.3276870250701904, acc 0.12999999523162842\n",
      "Epoch 7, iter 159, loss 2.1691131591796875, acc 0.1899999976158142\n",
      "Epoch 7, iter 160, loss 2.196143627166748, acc 0.20000000298023224\n",
      "Epoch 7, iter 161, loss 2.2463347911834717, acc 0.17000000178813934\n",
      "Epoch 7, iter 162, loss 2.2163689136505127, acc 0.23000000417232513\n",
      "Epoch 7, iter 163, loss 2.2736847400665283, acc 0.23000000417232513\n",
      "Epoch 7, iter 164, loss 2.2508938312530518, acc 0.23000000417232513\n",
      "Epoch 7, iter 165, loss 2.232867479324341, acc 0.14000000059604645\n",
      "Epoch 7, iter 166, loss 2.2777512073516846, acc 0.1899999976158142\n",
      "Epoch 7, iter 167, loss 2.247588634490967, acc 0.17000000178813934\n",
      "Epoch 7, iter 168, loss 2.2193965911865234, acc 0.18000000715255737\n",
      "Epoch 7, iter 169, loss 2.223107099533081, acc 0.18000000715255737\n",
      "Epoch 7, iter 170, loss 2.213871479034424, acc 0.25999999046325684\n",
      "Epoch 7, iter 171, loss 2.228544235229492, acc 0.25999999046325684\n",
      "Epoch 7, iter 172, loss 2.2462120056152344, acc 0.18000000715255737\n",
      "Epoch 7, iter 173, loss 2.2211484909057617, acc 0.1899999976158142\n",
      "Epoch 7, iter 174, loss 2.1948511600494385, acc 0.27000001072883606\n",
      "Epoch 7, iter 175, loss 2.2325010299682617, acc 0.20000000298023224\n",
      "Epoch 7, iter 176, loss 2.2116334438323975, acc 0.23000000417232513\n",
      "Epoch 7, iter 177, loss 2.2641353607177734, acc 0.1599999964237213\n",
      "Epoch 7, iter 178, loss 2.2552711963653564, acc 0.20000000298023224\n",
      "Epoch 7, iter 179, loss 2.2349140644073486, acc 0.20999999344348907\n",
      "Epoch 7, iter 180, loss 2.2031478881835938, acc 0.20999999344348907\n",
      "Epoch 7, iter 181, loss 2.15370512008667, acc 0.25\n",
      "Epoch 7, iter 182, loss 2.137061357498169, acc 0.25999999046325684\n",
      "Epoch 7, iter 183, loss 2.189148187637329, acc 0.2199999988079071\n",
      "Epoch 7, iter 184, loss 2.201932430267334, acc 0.2199999988079071\n",
      "Epoch 7, iter 185, loss 2.161411762237549, acc 0.20000000298023224\n",
      "Epoch 7, iter 186, loss 2.209709882736206, acc 0.1599999964237213\n",
      "Epoch 7, iter 187, loss 2.1690011024475098, acc 0.25999999046325684\n",
      "Epoch 7, iter 188, loss 2.2464990615844727, acc 0.1899999976158142\n",
      "Epoch 7, iter 189, loss 2.1597673892974854, acc 0.20999999344348907\n",
      "Epoch 7, iter 190, loss 2.2364957332611084, acc 0.20999999344348907\n",
      "Epoch 7, iter 191, loss 2.1728086471557617, acc 0.20000000298023224\n",
      "Epoch 7, iter 192, loss 2.2769906520843506, acc 0.1899999976158142\n",
      "Epoch 7, iter 193, loss 2.151658058166504, acc 0.23000000417232513\n",
      "Epoch 7, iter 194, loss 2.227025032043457, acc 0.2199999988079071\n",
      "Epoch 7, iter 195, loss 2.3746368885040283, acc 0.10999999940395355\n",
      "Epoch 7, iter 196, loss 2.2232587337493896, acc 0.20999999344348907\n",
      "Epoch 7, iter 197, loss 2.2425429821014404, acc 0.20999999344348907\n",
      "Epoch 7, iter 198, loss 2.193117618560791, acc 0.14000000059604645\n",
      "Epoch 7, iter 199, loss 2.243574619293213, acc 0.10999999940395355\n",
      "Epoch 7, iter 200, loss 2.26743221282959, acc 0.14000000059604645\n",
      "Epoch 7, iter 201, loss 2.2262325286865234, acc 0.23000000417232513\n",
      "Epoch 7, iter 202, loss 2.2148070335388184, acc 0.23000000417232513\n",
      "Epoch 7, iter 203, loss 2.3148016929626465, acc 0.18000000715255737\n",
      "Epoch 7, iter 204, loss 2.2406461238861084, acc 0.23999999463558197\n",
      "Epoch 7, iter 205, loss 2.162769079208374, acc 0.27000001072883606\n",
      "Epoch 7, iter 206, loss 2.2265851497650146, acc 0.18000000715255737\n",
      "Epoch 7, iter 207, loss 2.186021327972412, acc 0.23999999463558197\n",
      "Epoch 7, iter 208, loss 2.254154682159424, acc 0.23999999463558197\n",
      "Epoch 7, iter 209, loss 2.342423439025879, acc 0.17000000178813934\n",
      "Epoch 7, iter 210, loss 2.29846453666687, acc 0.12999999523162842\n",
      "Epoch 7, iter 211, loss 2.170289993286133, acc 0.23999999463558197\n",
      "Epoch 7, iter 212, loss 2.194708824157715, acc 0.2199999988079071\n",
      "Epoch 7, iter 213, loss 2.187525749206543, acc 0.25\n",
      "Epoch 7, iter 214, loss 2.2775466442108154, acc 0.2199999988079071\n",
      "Epoch 7, iter 215, loss 2.202847957611084, acc 0.2199999988079071\n",
      "Epoch 7, iter 216, loss 2.193427801132202, acc 0.2199999988079071\n",
      "Epoch 7, iter 217, loss 2.189617395401001, acc 0.15000000596046448\n",
      "Epoch 7, iter 218, loss 2.2688612937927246, acc 0.20000000298023224\n",
      "Epoch 7, iter 219, loss 2.1883068084716797, acc 0.23000000417232513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 220, loss 2.2539026737213135, acc 0.15000000596046448\n",
      "Epoch 7, iter 221, loss 2.175318717956543, acc 0.25999999046325684\n",
      "Epoch 7, iter 222, loss 2.277254104614258, acc 0.12999999523162842\n",
      "Epoch 7, iter 223, loss 2.21662974357605, acc 0.20000000298023224\n",
      "Epoch 7, iter 224, loss 2.222107172012329, acc 0.1899999976158142\n",
      "Epoch 7, iter 225, loss 2.1690988540649414, acc 0.20000000298023224\n",
      "Epoch 7, iter 226, loss 2.1994543075561523, acc 0.18000000715255737\n",
      "Epoch 7, iter 227, loss 2.2295994758605957, acc 0.14000000059604645\n",
      "Epoch 7, iter 228, loss 2.148674964904785, acc 0.23000000417232513\n",
      "Epoch 7, iter 229, loss 2.1989376544952393, acc 0.1899999976158142\n",
      "Epoch 7, iter 230, loss 2.2591047286987305, acc 0.10999999940395355\n",
      "Epoch 7, iter 231, loss 2.2221693992614746, acc 0.17000000178813934\n",
      "Epoch 7, iter 232, loss 2.2412805557250977, acc 0.2199999988079071\n",
      "Epoch 7, iter 233, loss 2.1881368160247803, acc 0.27000001072883606\n",
      "Epoch 7, iter 234, loss 2.1895432472229004, acc 0.2199999988079071\n",
      "Epoch 7, iter 235, loss 2.26269268989563, acc 0.15000000596046448\n",
      "Epoch 7, iter 236, loss 2.264997959136963, acc 0.18000000715255737\n",
      "Epoch 7, iter 237, loss 2.2342910766601562, acc 0.2199999988079071\n",
      "Epoch 7, iter 238, loss 2.187732696533203, acc 0.23000000417232513\n",
      "Epoch 7, iter 239, loss 2.2603633403778076, acc 0.23999999463558197\n",
      "Epoch 7, iter 240, loss 2.2461397647857666, acc 0.1599999964237213\n",
      "Epoch 7, iter 241, loss 2.2372963428497314, acc 0.23000000417232513\n",
      "Epoch 7, iter 242, loss 2.388807535171509, acc 0.12999999523162842\n",
      "Epoch 7, iter 243, loss 2.2877607345581055, acc 0.18000000715255737\n",
      "Epoch 7, iter 244, loss 2.2776572704315186, acc 0.20000000298023224\n",
      "Epoch 7, iter 245, loss 2.1518287658691406, acc 0.25\n",
      "Epoch 7, iter 246, loss 2.1823694705963135, acc 0.1899999976158142\n",
      "Epoch 7, iter 247, loss 2.1968436241149902, acc 0.20000000298023224\n",
      "Epoch 7, iter 248, loss 2.20829701423645, acc 0.1899999976158142\n",
      "Epoch 7, iter 249, loss 2.1974408626556396, acc 0.2199999988079071\n",
      "Epoch 7, iter 250, loss 2.2363178730010986, acc 0.20000000298023224\n",
      "Epoch 7, iter 251, loss 2.2278103828430176, acc 0.23000000417232513\n",
      "Epoch 7, iter 252, loss 2.169583797454834, acc 0.23999999463558197\n",
      "Epoch 7, iter 253, loss 2.3540213108062744, acc 0.1599999964237213\n",
      "Epoch 7, iter 254, loss 2.209979772567749, acc 0.2199999988079071\n",
      "Epoch 7, iter 255, loss 2.2421653270721436, acc 0.2199999988079071\n",
      "Epoch 7, iter 256, loss 2.1932730674743652, acc 0.25999999046325684\n",
      "Epoch 7, iter 257, loss 2.154562473297119, acc 0.20999999344348907\n",
      "Epoch 7, iter 258, loss 2.2648823261260986, acc 0.2199999988079071\n",
      "Epoch 7, iter 259, loss 2.259287118911743, acc 0.1899999976158142\n",
      "Epoch 7, iter 260, loss 2.172525405883789, acc 0.20000000298023224\n",
      "Epoch 7, iter 261, loss 2.2185261249542236, acc 0.25\n",
      "Epoch 7, iter 262, loss 2.2167649269104004, acc 0.23999999463558197\n",
      "Epoch 7, iter 263, loss 2.1748721599578857, acc 0.23999999463558197\n",
      "Epoch 7, iter 264, loss 2.2075634002685547, acc 0.15000000596046448\n",
      "Epoch 7, iter 265, loss 2.150808572769165, acc 0.18000000715255737\n",
      "Epoch 7, iter 266, loss 2.3063814640045166, acc 0.15000000596046448\n",
      "Epoch 7, iter 267, loss 2.2544708251953125, acc 0.12999999523162842\n",
      "Epoch 7, iter 268, loss 2.2009031772613525, acc 0.2199999988079071\n",
      "Epoch 7, iter 269, loss 2.1812448501586914, acc 0.25\n",
      "Epoch 7, iter 270, loss 2.2466607093811035, acc 0.18000000715255737\n",
      "Epoch 7, iter 271, loss 2.161996364593506, acc 0.2800000011920929\n",
      "Epoch 7, iter 272, loss 2.219236135482788, acc 0.1899999976158142\n",
      "Epoch 7, iter 273, loss 2.224947929382324, acc 0.1899999976158142\n",
      "Epoch 7, iter 274, loss 2.313046932220459, acc 0.18000000715255737\n",
      "Epoch 7, iter 275, loss 2.2430524826049805, acc 0.17000000178813934\n",
      "Epoch 7, iter 276, loss 2.2456891536712646, acc 0.20000000298023224\n",
      "Epoch 7, iter 277, loss 2.116447687149048, acc 0.1899999976158142\n",
      "Epoch 7, iter 278, loss 2.119643449783325, acc 0.3400000035762787\n",
      "Epoch 7, iter 279, loss 2.278427839279175, acc 0.14000000059604645\n",
      "Epoch 7, iter 280, loss 2.234232187271118, acc 0.20999999344348907\n",
      "Epoch 7, iter 281, loss 2.2168965339660645, acc 0.14000000059604645\n",
      "Epoch 7, iter 282, loss 2.1314189434051514, acc 0.28999999165534973\n",
      "Epoch 7, iter 283, loss 2.2481656074523926, acc 0.17000000178813934\n",
      "Epoch 7, iter 284, loss 2.2039144039154053, acc 0.20999999344348907\n",
      "Epoch 7, iter 285, loss 2.2664806842803955, acc 0.18000000715255737\n",
      "Epoch 7, iter 286, loss 2.1376256942749023, acc 0.23999999463558197\n",
      "Epoch 7, iter 287, loss 2.210939884185791, acc 0.23000000417232513\n",
      "Epoch 7, iter 288, loss 2.356520891189575, acc 0.12999999523162842\n",
      "Epoch 7, iter 289, loss 2.2542431354522705, acc 0.17000000178813934\n",
      "Epoch 7, iter 290, loss 2.2357537746429443, acc 0.18000000715255737\n",
      "Epoch 7, iter 291, loss 2.2977025508880615, acc 0.1899999976158142\n",
      "Epoch 7, iter 292, loss 2.2255280017852783, acc 0.2199999988079071\n",
      "Epoch 7, iter 293, loss 2.264415979385376, acc 0.1899999976158142\n",
      "Epoch 7, iter 294, loss 2.1327414512634277, acc 0.23000000417232513\n",
      "Epoch 7, iter 295, loss 2.2484006881713867, acc 0.1899999976158142\n",
      "Epoch 7, iter 296, loss 2.196671485900879, acc 0.23999999463558197\n",
      "Epoch 7, iter 297, loss 2.2437753677368164, acc 0.1599999964237213\n",
      "Epoch 7, iter 298, loss 2.1786844730377197, acc 0.2199999988079071\n",
      "Epoch 7, iter 299, loss 2.3111677169799805, acc 0.20000000298023224\n",
      "Epoch 7, iter 300, loss 2.1650390625, acc 0.2199999988079071\n",
      "Epoch 7, iter 301, loss 2.2155699729919434, acc 0.23000000417232513\n",
      "Epoch 7, iter 302, loss 2.2490835189819336, acc 0.12999999523162842\n",
      "Epoch 7, iter 303, loss 2.2525975704193115, acc 0.1899999976158142\n",
      "Epoch 7, iter 304, loss 2.1669347286224365, acc 0.25999999046325684\n",
      "Epoch 7, iter 305, loss 2.1935651302337646, acc 0.1899999976158142\n",
      "Epoch 7, iter 306, loss 2.191295623779297, acc 0.23000000417232513\n",
      "Epoch 7, iter 307, loss 2.2192132472991943, acc 0.14000000059604645\n",
      "Epoch 7, iter 308, loss 2.229867696762085, acc 0.15000000596046448\n",
      "Epoch 7, iter 309, loss 2.1458468437194824, acc 0.2199999988079071\n",
      "Epoch 7, iter 310, loss 2.2177915573120117, acc 0.18000000715255737\n",
      "Epoch 7, iter 311, loss 2.2414908409118652, acc 0.18000000715255737\n",
      "Epoch 7, iter 312, loss 2.184708595275879, acc 0.18000000715255737\n",
      "Epoch 7, iter 313, loss 2.2172605991363525, acc 0.1599999964237213\n",
      "Epoch 7, iter 314, loss 2.1939642429351807, acc 0.17000000178813934\n",
      "Epoch 7, iter 315, loss 2.2082338333129883, acc 0.18000000715255737\n",
      "Epoch 7, iter 316, loss 2.2631642818450928, acc 0.27000001072883606\n",
      "Epoch 7, iter 317, loss 2.2513797283172607, acc 0.15000000596046448\n",
      "Epoch 7, iter 318, loss 2.150327205657959, acc 0.25\n",
      "Epoch 7, iter 319, loss 2.1324851512908936, acc 0.20999999344348907\n",
      "Epoch 7, iter 320, loss 2.211738348007202, acc 0.2199999988079071\n",
      "Epoch 7, iter 321, loss 2.2840356826782227, acc 0.1599999964237213\n",
      "Epoch 7, iter 322, loss 2.2685182094573975, acc 0.15000000596046448\n",
      "Epoch 7, iter 323, loss 2.226135492324829, acc 0.17000000178813934\n",
      "Epoch 7, iter 324, loss 2.1887259483337402, acc 0.23000000417232513\n",
      "Epoch 7, iter 325, loss 2.245288133621216, acc 0.15000000596046448\n",
      "Epoch 7, iter 326, loss 2.177116632461548, acc 0.20999999344348907\n",
      "Epoch 7, iter 327, loss 2.207535743713379, acc 0.27000001072883606\n",
      "Epoch 7, iter 328, loss 2.323857307434082, acc 0.17000000178813934\n",
      "Epoch 7, iter 329, loss 2.260331630706787, acc 0.17000000178813934\n",
      "Epoch 7, iter 330, loss 2.2163901329040527, acc 0.20000000298023224\n",
      "Epoch 7, iter 331, loss 2.163478136062622, acc 0.2199999988079071\n",
      "Epoch 7, iter 332, loss 2.158582925796509, acc 0.17000000178813934\n",
      "Epoch 7, iter 333, loss 2.1819255352020264, acc 0.20999999344348907\n",
      "Epoch 7, iter 334, loss 2.199604034423828, acc 0.18000000715255737\n",
      "Epoch 7, iter 335, loss 2.1234548091888428, acc 0.25\n",
      "Epoch 7, iter 336, loss 2.1624300479888916, acc 0.18000000715255737\n",
      "Epoch 7, iter 337, loss 2.305180549621582, acc 0.20999999344348907\n",
      "Epoch 7, iter 338, loss 2.155001640319824, acc 0.1899999976158142\n",
      "Epoch 7, iter 339, loss 2.1066412925720215, acc 0.2199999988079071\n",
      "Epoch 7, iter 340, loss 2.2692463397979736, acc 0.17000000178813934\n",
      "Epoch 7, iter 341, loss 2.160388231277466, acc 0.25999999046325684\n",
      "Epoch 7, iter 342, loss 2.1332664489746094, acc 0.20000000298023224\n",
      "Epoch 7, iter 343, loss 2.2627649307250977, acc 0.1899999976158142\n",
      "Epoch 7, iter 344, loss 2.289736747741699, acc 0.14000000059604645\n",
      "Epoch 7, iter 345, loss 2.291111469268799, acc 0.18000000715255737\n",
      "Epoch 7, iter 346, loss 2.2825193405151367, acc 0.20999999344348907\n",
      "Epoch 7, iter 347, loss 2.16141414642334, acc 0.2199999988079071\n",
      "Epoch 7, iter 348, loss 2.1796927452087402, acc 0.1899999976158142\n",
      "Epoch 7, iter 349, loss 2.1456236839294434, acc 0.17000000178813934\n",
      "Epoch 7, iter 350, loss 2.2333381175994873, acc 0.23999999463558197\n",
      "Epoch 7, iter 351, loss 2.216113567352295, acc 0.23999999463558197\n",
      "Epoch 7, iter 352, loss 2.206071376800537, acc 0.20000000298023224\n",
      "Epoch 7, iter 353, loss 2.2587029933929443, acc 0.15000000596046448\n",
      "Epoch 7, iter 354, loss 2.185042381286621, acc 0.18000000715255737\n",
      "Epoch 7, iter 355, loss 2.2404584884643555, acc 0.2199999988079071\n",
      "Epoch 7, iter 356, loss 2.1704354286193848, acc 0.25\n",
      "Epoch 7, iter 357, loss 2.168222188949585, acc 0.20000000298023224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 358, loss 2.239581823348999, acc 0.25\n",
      "Epoch 7, iter 359, loss 2.214905023574829, acc 0.15000000596046448\n",
      "Epoch 7, iter 360, loss 2.228153944015503, acc 0.20000000298023224\n",
      "Epoch 7, iter 361, loss 2.2478249073028564, acc 0.20000000298023224\n",
      "Epoch 7, iter 362, loss 2.238377809524536, acc 0.1599999964237213\n",
      "Epoch 7, iter 363, loss 2.230520248413086, acc 0.1599999964237213\n",
      "Epoch 7, iter 364, loss 2.2455193996429443, acc 0.18000000715255737\n",
      "Epoch 7, iter 365, loss 2.2316551208496094, acc 0.18000000715255737\n",
      "Epoch 7, iter 366, loss 2.154873847961426, acc 0.23000000417232513\n",
      "Epoch 7, iter 367, loss 2.2115464210510254, acc 0.2199999988079071\n",
      "Epoch 7, iter 368, loss 2.246058702468872, acc 0.17000000178813934\n",
      "Epoch 7, iter 369, loss 2.2604079246520996, acc 0.20999999344348907\n",
      "Epoch 7, iter 370, loss 2.2475745677948, acc 0.23000000417232513\n",
      "Epoch 7, iter 371, loss 2.1882338523864746, acc 0.1899999976158142\n",
      "Epoch 7, iter 372, loss 2.191096782684326, acc 0.2199999988079071\n",
      "Epoch 7, iter 373, loss 2.172085762023926, acc 0.23000000417232513\n",
      "Epoch 7, iter 374, loss 2.195222854614258, acc 0.23000000417232513\n",
      "Epoch 7, iter 375, loss 2.2653298377990723, acc 0.09000000357627869\n",
      "Epoch 7, iter 376, loss 2.1358888149261475, acc 0.27000001072883606\n",
      "Epoch 7, iter 377, loss 2.246772527694702, acc 0.12999999523162842\n",
      "Epoch 7, iter 378, loss 2.212909698486328, acc 0.20000000298023224\n",
      "Epoch 7, iter 379, loss 2.2674643993377686, acc 0.20000000298023224\n",
      "Epoch 7, iter 380, loss 2.210892677307129, acc 0.25\n",
      "Epoch 7, iter 381, loss 2.249443292617798, acc 0.1599999964237213\n",
      "Epoch 7, iter 382, loss 2.048860549926758, acc 0.2800000011920929\n",
      "Epoch 7, iter 383, loss 2.195571184158325, acc 0.20999999344348907\n",
      "Epoch 7, iter 384, loss 2.239940643310547, acc 0.20999999344348907\n",
      "Epoch 7, iter 385, loss 2.2943437099456787, acc 0.17000000178813934\n",
      "Epoch 7, iter 386, loss 2.175238847732544, acc 0.23000000417232513\n",
      "Epoch 7, iter 387, loss 2.2084221839904785, acc 0.20000000298023224\n",
      "Epoch 7, iter 388, loss 2.1314103603363037, acc 0.27000001072883606\n",
      "Epoch 7, iter 389, loss 2.177006959915161, acc 0.2199999988079071\n",
      "Epoch 7, iter 390, loss 2.228224277496338, acc 0.27000001072883606\n",
      "Epoch 7, iter 391, loss 2.1344025135040283, acc 0.2800000011920929\n",
      "Epoch 7, iter 392, loss 2.2929277420043945, acc 0.2199999988079071\n",
      "Epoch 7, iter 393, loss 2.1641781330108643, acc 0.2800000011920929\n",
      "Epoch 7, iter 394, loss 2.1550650596618652, acc 0.27000001072883606\n",
      "Epoch 7, iter 395, loss 2.217414140701294, acc 0.1899999976158142\n",
      "Epoch 7, iter 396, loss 2.3463943004608154, acc 0.1899999976158142\n",
      "Epoch 7, iter 397, loss 2.1917858123779297, acc 0.23000000417232513\n",
      "Epoch 7, iter 398, loss 2.231006622314453, acc 0.25\n",
      "Epoch 7, iter 399, loss 2.263320207595825, acc 0.1899999976158142\n",
      "Epoch 7, iter 400, loss 2.1803808212280273, acc 0.1899999976158142\n",
      "Epoch 7, iter 401, loss 2.239330291748047, acc 0.25\n",
      "Epoch 7, iter 402, loss 2.1540393829345703, acc 0.25999999046325684\n",
      "Epoch 7, iter 403, loss 2.2667391300201416, acc 0.23999999463558197\n",
      "Epoch 7, iter 404, loss 2.310826063156128, acc 0.14000000059604645\n",
      "Epoch 7, iter 405, loss 2.247016668319702, acc 0.20000000298023224\n",
      "Epoch 7, iter 406, loss 2.2414848804473877, acc 0.1899999976158142\n",
      "Epoch 7, iter 407, loss 2.1876273155212402, acc 0.1599999964237213\n",
      "Epoch 7, iter 408, loss 2.1656439304351807, acc 0.1899999976158142\n",
      "Epoch 7, iter 409, loss 2.2673230171203613, acc 0.2199999988079071\n",
      "Epoch 7, iter 410, loss 2.1436493396759033, acc 0.3700000047683716\n",
      "Epoch 7, iter 411, loss 2.2214081287384033, acc 0.1599999964237213\n",
      "Epoch 7, iter 412, loss 2.2014591693878174, acc 0.23000000417232513\n",
      "Epoch 7, iter 413, loss 2.264446496963501, acc 0.2199999988079071\n",
      "Epoch 7, iter 414, loss 2.298250675201416, acc 0.12999999523162842\n",
      "Epoch 7, iter 415, loss 2.306691884994507, acc 0.18000000715255737\n",
      "Epoch 7, iter 416, loss 2.2512853145599365, acc 0.20000000298023224\n",
      "Epoch 7, iter 417, loss 2.193079948425293, acc 0.1599999964237213\n",
      "Epoch 7, iter 418, loss 2.084975481033325, acc 0.3400000035762787\n",
      "Epoch 7, iter 419, loss 2.1293630599975586, acc 0.23000000417232513\n",
      "Epoch 7, iter 420, loss 2.2568907737731934, acc 0.14000000059604645\n",
      "Epoch 8, iter 1, loss 2.1969423294067383, acc 0.23999999463558197\n",
      "Epoch 8, iter 2, loss 2.263988733291626, acc 0.20000000298023224\n",
      "Epoch 8, iter 3, loss 2.186404228210449, acc 0.23000000417232513\n",
      "Epoch 8, iter 4, loss 2.2517263889312744, acc 0.20000000298023224\n",
      "Epoch 8, iter 5, loss 2.1538822650909424, acc 0.20999999344348907\n",
      "Epoch 8, iter 6, loss 2.1873180866241455, acc 0.20999999344348907\n",
      "Epoch 8, iter 7, loss 2.2882015705108643, acc 0.1599999964237213\n",
      "Epoch 8, iter 8, loss 2.1963798999786377, acc 0.23999999463558197\n",
      "Epoch 8, iter 9, loss 2.158045768737793, acc 0.23999999463558197\n",
      "Epoch 8, iter 10, loss 2.2233245372772217, acc 0.18000000715255737\n",
      "Epoch 8, iter 11, loss 2.3724958896636963, acc 0.11999999731779099\n",
      "Epoch 8, iter 12, loss 2.2802531719207764, acc 0.14000000059604645\n",
      "Epoch 8, iter 13, loss 2.17856764793396, acc 0.17000000178813934\n",
      "Epoch 8, iter 14, loss 2.2995383739471436, acc 0.15000000596046448\n",
      "Epoch 8, iter 15, loss 2.220095157623291, acc 0.15000000596046448\n",
      "Epoch 8, iter 16, loss 2.1861073970794678, acc 0.1899999976158142\n",
      "Epoch 8, iter 17, loss 2.179608106613159, acc 0.23999999463558197\n",
      "Epoch 8, iter 18, loss 2.3089520931243896, acc 0.18000000715255737\n",
      "Epoch 8, iter 19, loss 2.192747116088867, acc 0.20000000298023224\n",
      "Epoch 8, iter 20, loss 2.2228405475616455, acc 0.1599999964237213\n",
      "Epoch 8, iter 21, loss 2.212312698364258, acc 0.23000000417232513\n",
      "Epoch 8, iter 22, loss 2.2502925395965576, acc 0.1599999964237213\n",
      "Epoch 8, iter 23, loss 2.198341131210327, acc 0.1899999976158142\n",
      "Epoch 8, iter 24, loss 2.1189162731170654, acc 0.2800000011920929\n",
      "Epoch 8, iter 25, loss 2.1997439861297607, acc 0.1899999976158142\n",
      "Epoch 8, iter 26, loss 2.2565793991088867, acc 0.23000000417232513\n",
      "Epoch 8, iter 27, loss 2.1785614490509033, acc 0.20000000298023224\n",
      "Epoch 8, iter 28, loss 2.261730432510376, acc 0.18000000715255737\n",
      "Epoch 8, iter 29, loss 2.208387613296509, acc 0.23000000417232513\n",
      "Epoch 8, iter 30, loss 2.234086513519287, acc 0.20000000298023224\n",
      "Epoch 8, iter 31, loss 2.2411587238311768, acc 0.20000000298023224\n",
      "Epoch 8, iter 32, loss 2.2013204097747803, acc 0.23000000417232513\n",
      "Epoch 8, iter 33, loss 2.2489278316497803, acc 0.1599999964237213\n",
      "Epoch 8, iter 34, loss 2.1783554553985596, acc 0.25\n",
      "Epoch 8, iter 35, loss 2.2748727798461914, acc 0.1599999964237213\n",
      "Epoch 8, iter 36, loss 2.262892961502075, acc 0.20000000298023224\n",
      "Epoch 8, iter 37, loss 2.173494338989258, acc 0.1599999964237213\n",
      "Epoch 8, iter 38, loss 2.1727311611175537, acc 0.20999999344348907\n",
      "Epoch 8, iter 39, loss 2.212578535079956, acc 0.18000000715255737\n",
      "Epoch 8, iter 40, loss 2.1381001472473145, acc 0.25999999046325684\n",
      "Epoch 8, iter 41, loss 2.287666082382202, acc 0.1899999976158142\n",
      "Epoch 8, iter 42, loss 2.204652786254883, acc 0.23999999463558197\n",
      "Epoch 8, iter 43, loss 2.1202969551086426, acc 0.20999999344348907\n",
      "Epoch 8, iter 44, loss 2.1842217445373535, acc 0.23000000417232513\n",
      "Epoch 8, iter 45, loss 2.226325511932373, acc 0.2199999988079071\n",
      "Epoch 8, iter 46, loss 2.1815176010131836, acc 0.17000000178813934\n",
      "Epoch 8, iter 47, loss 2.2803781032562256, acc 0.15000000596046448\n",
      "Epoch 8, iter 48, loss 2.144495964050293, acc 0.20999999344348907\n",
      "Epoch 8, iter 49, loss 2.182724952697754, acc 0.20000000298023224\n",
      "Epoch 8, iter 50, loss 2.151113510131836, acc 0.20999999344348907\n",
      "Epoch 8, iter 51, loss 2.1800217628479004, acc 0.1899999976158142\n",
      "Epoch 8, iter 52, loss 2.2106480598449707, acc 0.1599999964237213\n",
      "Epoch 8, iter 53, loss 2.2107174396514893, acc 0.10000000149011612\n",
      "Epoch 8, iter 54, loss 2.1174378395080566, acc 0.28999999165534973\n",
      "Epoch 8, iter 55, loss 2.2825276851654053, acc 0.23999999463558197\n",
      "Epoch 8, iter 56, loss 2.206012725830078, acc 0.25999999046325684\n",
      "Epoch 8, iter 57, loss 2.219557285308838, acc 0.25\n",
      "Epoch 8, iter 58, loss 2.1394684314727783, acc 0.30000001192092896\n",
      "Epoch 8, iter 59, loss 2.2580459117889404, acc 0.20999999344348907\n",
      "Epoch 8, iter 60, loss 2.1715874671936035, acc 0.23000000417232513\n",
      "Epoch 8, iter 61, loss 2.2293577194213867, acc 0.25\n",
      "Epoch 8, iter 62, loss 2.2442502975463867, acc 0.2199999988079071\n",
      "Epoch 8, iter 63, loss 2.2897770404815674, acc 0.14000000059604645\n",
      "Epoch 8, iter 64, loss 2.152484655380249, acc 0.20000000298023224\n",
      "Epoch 8, iter 65, loss 2.255920648574829, acc 0.17000000178813934\n",
      "Epoch 8, iter 66, loss 2.2295749187469482, acc 0.17000000178813934\n",
      "Epoch 8, iter 67, loss 2.2388901710510254, acc 0.17000000178813934\n",
      "Epoch 8, iter 68, loss 2.166736125946045, acc 0.23000000417232513\n",
      "Epoch 8, iter 69, loss 2.1917600631713867, acc 0.20999999344348907\n",
      "Epoch 8, iter 70, loss 2.211901903152466, acc 0.15000000596046448\n",
      "Epoch 8, iter 71, loss 2.2441232204437256, acc 0.1599999964237213\n",
      "Epoch 8, iter 72, loss 2.1795942783355713, acc 0.23999999463558197\n",
      "Epoch 8, iter 73, loss 2.190124750137329, acc 0.20999999344348907\n",
      "Epoch 8, iter 74, loss 2.1987478733062744, acc 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 75, loss 2.180565118789673, acc 0.23999999463558197\n",
      "Epoch 8, iter 76, loss 2.1354784965515137, acc 0.27000001072883606\n",
      "Epoch 8, iter 77, loss 2.244471311569214, acc 0.11999999731779099\n",
      "Epoch 8, iter 78, loss 2.223135471343994, acc 0.17000000178813934\n",
      "Epoch 8, iter 79, loss 2.1882026195526123, acc 0.20999999344348907\n",
      "Epoch 8, iter 80, loss 2.3159239292144775, acc 0.17000000178813934\n",
      "Epoch 8, iter 81, loss 2.2024810314178467, acc 0.18000000715255737\n",
      "Epoch 8, iter 82, loss 2.2093019485473633, acc 0.18000000715255737\n",
      "Epoch 8, iter 83, loss 2.191845178604126, acc 0.23999999463558197\n",
      "Epoch 8, iter 84, loss 2.224459648132324, acc 0.27000001072883606\n",
      "Epoch 8, iter 85, loss 2.281921625137329, acc 0.2199999988079071\n",
      "Epoch 8, iter 86, loss 2.196033239364624, acc 0.20999999344348907\n",
      "Epoch 8, iter 87, loss 2.121131658554077, acc 0.25999999046325684\n",
      "Epoch 8, iter 88, loss 2.167243719100952, acc 0.20000000298023224\n",
      "Epoch 8, iter 89, loss 2.235476016998291, acc 0.17000000178813934\n",
      "Epoch 8, iter 90, loss 2.1857917308807373, acc 0.25999999046325684\n",
      "Epoch 8, iter 91, loss 2.2369813919067383, acc 0.2199999988079071\n",
      "Epoch 8, iter 92, loss 2.24371337890625, acc 0.20999999344348907\n",
      "Epoch 8, iter 93, loss 2.2140560150146484, acc 0.2199999988079071\n",
      "Epoch 8, iter 94, loss 2.182159423828125, acc 0.20999999344348907\n",
      "Epoch 8, iter 95, loss 2.2560479640960693, acc 0.1599999964237213\n",
      "Epoch 8, iter 96, loss 2.1601526737213135, acc 0.20999999344348907\n",
      "Epoch 8, iter 97, loss 2.2483432292938232, acc 0.18000000715255737\n",
      "Epoch 8, iter 98, loss 2.205841302871704, acc 0.20999999344348907\n",
      "Epoch 8, iter 99, loss 2.2999091148376465, acc 0.20000000298023224\n",
      "Epoch 8, iter 100, loss 2.2083756923675537, acc 0.17000000178813934\n",
      "Epoch 8, iter 101, loss 2.1975793838500977, acc 0.23999999463558197\n",
      "Epoch 8, iter 102, loss 2.1340341567993164, acc 0.1899999976158142\n",
      "Epoch 8, iter 103, loss 2.1791563034057617, acc 0.20999999344348907\n",
      "Epoch 8, iter 104, loss 2.2513771057128906, acc 0.17000000178813934\n",
      "Epoch 8, iter 105, loss 2.2053632736206055, acc 0.23000000417232513\n",
      "Epoch 8, iter 106, loss 2.2486319541931152, acc 0.10999999940395355\n",
      "Epoch 8, iter 107, loss 2.2164323329925537, acc 0.18000000715255737\n",
      "Epoch 8, iter 108, loss 2.0865399837493896, acc 0.25999999046325684\n",
      "Epoch 8, iter 109, loss 2.234285593032837, acc 0.17000000178813934\n",
      "Epoch 8, iter 110, loss 2.2727243900299072, acc 0.20000000298023224\n",
      "Epoch 8, iter 111, loss 2.2287752628326416, acc 0.1899999976158142\n",
      "Epoch 8, iter 112, loss 2.2507810592651367, acc 0.11999999731779099\n",
      "Epoch 8, iter 113, loss 2.1635255813598633, acc 0.25999999046325684\n",
      "Epoch 8, iter 114, loss 2.19221830368042, acc 0.1899999976158142\n",
      "Epoch 8, iter 115, loss 2.260174512863159, acc 0.18000000715255737\n",
      "Epoch 8, iter 116, loss 2.2397401332855225, acc 0.20000000298023224\n",
      "Epoch 8, iter 117, loss 2.22611927986145, acc 0.17000000178813934\n",
      "Epoch 8, iter 118, loss 2.1938092708587646, acc 0.23999999463558197\n",
      "Epoch 8, iter 119, loss 2.187899112701416, acc 0.20000000298023224\n",
      "Epoch 8, iter 120, loss 2.206301689147949, acc 0.12999999523162842\n",
      "Epoch 8, iter 121, loss 2.2338569164276123, acc 0.1899999976158142\n",
      "Epoch 8, iter 122, loss 2.229546308517456, acc 0.20000000298023224\n",
      "Epoch 8, iter 123, loss 2.1939594745635986, acc 0.20999999344348907\n",
      "Epoch 8, iter 124, loss 2.179255485534668, acc 0.25\n",
      "Epoch 8, iter 125, loss 2.212024450302124, acc 0.20999999344348907\n",
      "Epoch 8, iter 126, loss 2.201874017715454, acc 0.20999999344348907\n",
      "Epoch 8, iter 127, loss 2.234375238418579, acc 0.20000000298023224\n",
      "Epoch 8, iter 128, loss 2.181755304336548, acc 0.18000000715255737\n",
      "Epoch 8, iter 129, loss 2.262430191040039, acc 0.20999999344348907\n",
      "Epoch 8, iter 130, loss 2.226391077041626, acc 0.1899999976158142\n",
      "Epoch 8, iter 131, loss 2.1940643787384033, acc 0.20999999344348907\n",
      "Epoch 8, iter 132, loss 2.1739838123321533, acc 0.17000000178813934\n",
      "Epoch 8, iter 133, loss 2.1919806003570557, acc 0.20000000298023224\n",
      "Epoch 8, iter 134, loss 2.1796250343322754, acc 0.25\n",
      "Epoch 8, iter 135, loss 2.2070889472961426, acc 0.1899999976158142\n",
      "Epoch 8, iter 136, loss 2.253760814666748, acc 0.17000000178813934\n",
      "Epoch 8, iter 137, loss 2.2745959758758545, acc 0.1599999964237213\n",
      "Epoch 8, iter 138, loss 2.1612203121185303, acc 0.23000000417232513\n",
      "Epoch 8, iter 139, loss 2.220752000808716, acc 0.17000000178813934\n",
      "Epoch 8, iter 140, loss 2.239609718322754, acc 0.1899999976158142\n",
      "Epoch 8, iter 141, loss 2.306119441986084, acc 0.15000000596046448\n",
      "Epoch 8, iter 142, loss 2.1469485759735107, acc 0.1899999976158142\n",
      "Epoch 8, iter 143, loss 2.2188403606414795, acc 0.17000000178813934\n",
      "Epoch 8, iter 144, loss 2.214207887649536, acc 0.20000000298023224\n",
      "Epoch 8, iter 145, loss 2.2025628089904785, acc 0.20999999344348907\n",
      "Epoch 8, iter 146, loss 2.237555742263794, acc 0.1599999964237213\n",
      "Epoch 8, iter 147, loss 2.173341751098633, acc 0.1899999976158142\n",
      "Epoch 8, iter 148, loss 2.1309423446655273, acc 0.2199999988079071\n",
      "Epoch 8, iter 149, loss 2.208446979522705, acc 0.1899999976158142\n",
      "Epoch 8, iter 150, loss 2.067568063735962, acc 0.25\n",
      "Epoch 8, iter 151, loss 2.166520357131958, acc 0.20000000298023224\n",
      "Epoch 8, iter 152, loss 2.187605381011963, acc 0.18000000715255737\n",
      "Epoch 8, iter 153, loss 2.2054386138916016, acc 0.2199999988079071\n",
      "Epoch 8, iter 154, loss 2.1684916019439697, acc 0.20999999344348907\n",
      "Epoch 8, iter 155, loss 2.151482582092285, acc 0.1899999976158142\n",
      "Epoch 8, iter 156, loss 2.18972110748291, acc 0.3199999928474426\n",
      "Epoch 8, iter 157, loss 2.2629029750823975, acc 0.12999999523162842\n",
      "Epoch 8, iter 158, loss 2.314772129058838, acc 0.14000000059604645\n",
      "Epoch 8, iter 159, loss 2.147521734237671, acc 0.20000000298023224\n",
      "Epoch 8, iter 160, loss 2.1846818923950195, acc 0.20999999344348907\n",
      "Epoch 8, iter 161, loss 2.2501108646392822, acc 0.1599999964237213\n",
      "Epoch 8, iter 162, loss 2.210151433944702, acc 0.2199999988079071\n",
      "Epoch 8, iter 163, loss 2.2440881729125977, acc 0.23000000417232513\n",
      "Epoch 8, iter 164, loss 2.2398955821990967, acc 0.23000000417232513\n",
      "Epoch 8, iter 165, loss 2.211374282836914, acc 0.15000000596046448\n",
      "Epoch 8, iter 166, loss 2.2459146976470947, acc 0.1899999976158142\n",
      "Epoch 8, iter 167, loss 2.2415730953216553, acc 0.17000000178813934\n",
      "Epoch 8, iter 168, loss 2.200735569000244, acc 0.18000000715255737\n",
      "Epoch 8, iter 169, loss 2.2296411991119385, acc 0.1599999964237213\n",
      "Epoch 8, iter 170, loss 2.202866792678833, acc 0.25\n",
      "Epoch 8, iter 171, loss 2.2002413272857666, acc 0.2800000011920929\n",
      "Epoch 8, iter 172, loss 2.2295994758605957, acc 0.18000000715255737\n",
      "Epoch 8, iter 173, loss 2.2150232791900635, acc 0.1899999976158142\n",
      "Epoch 8, iter 174, loss 2.1939985752105713, acc 0.2800000011920929\n",
      "Epoch 8, iter 175, loss 2.2344374656677246, acc 0.1899999976158142\n",
      "Epoch 8, iter 176, loss 2.2090249061584473, acc 0.23000000417232513\n",
      "Epoch 8, iter 177, loss 2.245950222015381, acc 0.1599999964237213\n",
      "Epoch 8, iter 178, loss 2.2429001331329346, acc 0.20000000298023224\n",
      "Epoch 8, iter 179, loss 2.2081851959228516, acc 0.20999999344348907\n",
      "Epoch 8, iter 180, loss 2.1973416805267334, acc 0.20000000298023224\n",
      "Epoch 8, iter 181, loss 2.1384634971618652, acc 0.25\n",
      "Epoch 8, iter 182, loss 2.1467065811157227, acc 0.25\n",
      "Epoch 8, iter 183, loss 2.1624345779418945, acc 0.20999999344348907\n",
      "Epoch 8, iter 184, loss 2.1879992485046387, acc 0.2199999988079071\n",
      "Epoch 8, iter 185, loss 2.140437364578247, acc 0.20999999344348907\n",
      "Epoch 8, iter 186, loss 2.1548147201538086, acc 0.1899999976158142\n",
      "Epoch 8, iter 187, loss 2.153792381286621, acc 0.25999999046325684\n",
      "Epoch 8, iter 188, loss 2.2380988597869873, acc 0.1899999976158142\n",
      "Epoch 8, iter 189, loss 2.155331611633301, acc 0.20999999344348907\n",
      "Epoch 8, iter 190, loss 2.2096285820007324, acc 0.20000000298023224\n",
      "Epoch 8, iter 191, loss 2.1485610008239746, acc 0.20000000298023224\n",
      "Epoch 8, iter 192, loss 2.2323966026306152, acc 0.20999999344348907\n",
      "Epoch 8, iter 193, loss 2.145038366317749, acc 0.23999999463558197\n",
      "Epoch 8, iter 194, loss 2.18796968460083, acc 0.23000000417232513\n",
      "Epoch 8, iter 195, loss 2.3528754711151123, acc 0.11999999731779099\n",
      "Epoch 8, iter 196, loss 2.2035722732543945, acc 0.20999999344348907\n",
      "Epoch 8, iter 197, loss 2.2322771549224854, acc 0.20000000298023224\n",
      "Epoch 8, iter 198, loss 2.1633541584014893, acc 0.15000000596046448\n",
      "Epoch 8, iter 199, loss 2.2214853763580322, acc 0.12999999523162842\n",
      "Epoch 8, iter 200, loss 2.2478864192962646, acc 0.15000000596046448\n",
      "Epoch 8, iter 201, loss 2.198364496231079, acc 0.23999999463558197\n",
      "Epoch 8, iter 202, loss 2.230576753616333, acc 0.20999999344348907\n",
      "Epoch 8, iter 203, loss 2.280604600906372, acc 0.20000000298023224\n",
      "Epoch 8, iter 204, loss 2.1724634170532227, acc 0.25999999046325684\n",
      "Epoch 8, iter 205, loss 2.132478713989258, acc 0.2800000011920929\n",
      "Epoch 8, iter 206, loss 2.2161381244659424, acc 0.18000000715255737\n",
      "Epoch 8, iter 207, loss 2.161797285079956, acc 0.25\n",
      "Epoch 8, iter 208, loss 2.233914852142334, acc 0.23999999463558197\n",
      "Epoch 8, iter 209, loss 2.3341360092163086, acc 0.17000000178813934\n",
      "Epoch 8, iter 210, loss 2.2895772457122803, acc 0.14000000059604645\n",
      "Epoch 8, iter 211, loss 2.1604108810424805, acc 0.23999999463558197\n",
      "Epoch 8, iter 212, loss 2.1970903873443604, acc 0.1899999976158142\n",
      "Epoch 8, iter 213, loss 2.1652143001556396, acc 0.25999999046325684\n",
      "Epoch 8, iter 214, loss 2.24467396736145, acc 0.2199999988079071\n",
      "Epoch 8, iter 215, loss 2.195582151412964, acc 0.2199999988079071\n",
      "Epoch 8, iter 216, loss 2.156341791152954, acc 0.2199999988079071\n",
      "Epoch 8, iter 217, loss 2.156342029571533, acc 0.1599999964237213\n",
      "Epoch 8, iter 218, loss 2.234593629837036, acc 0.20999999344348907\n",
      "Epoch 8, iter 219, loss 2.1875388622283936, acc 0.2199999988079071\n",
      "Epoch 8, iter 220, loss 2.2114417552948, acc 0.18000000715255737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 221, loss 2.1594576835632324, acc 0.25\n",
      "Epoch 8, iter 222, loss 2.2734341621398926, acc 0.11999999731779099\n",
      "Epoch 8, iter 223, loss 2.1956300735473633, acc 0.20999999344348907\n",
      "Epoch 8, iter 224, loss 2.1638565063476562, acc 0.2199999988079071\n",
      "Epoch 8, iter 225, loss 2.156912326812744, acc 0.20999999344348907\n",
      "Epoch 8, iter 226, loss 2.190753221511841, acc 0.18000000715255737\n",
      "Epoch 8, iter 227, loss 2.1945340633392334, acc 0.15000000596046448\n",
      "Epoch 8, iter 228, loss 2.1331303119659424, acc 0.2199999988079071\n",
      "Epoch 8, iter 229, loss 2.185842990875244, acc 0.20000000298023224\n",
      "Epoch 8, iter 230, loss 2.231578826904297, acc 0.10999999940395355\n",
      "Epoch 8, iter 231, loss 2.2088263034820557, acc 0.1599999964237213\n",
      "Epoch 8, iter 232, loss 2.227454900741577, acc 0.2199999988079071\n",
      "Epoch 8, iter 233, loss 2.181694269180298, acc 0.25999999046325684\n",
      "Epoch 8, iter 234, loss 2.176691770553589, acc 0.2199999988079071\n",
      "Epoch 8, iter 235, loss 2.2492029666900635, acc 0.1599999964237213\n",
      "Epoch 8, iter 236, loss 2.2291033267974854, acc 0.18000000715255737\n",
      "Epoch 8, iter 237, loss 2.2015581130981445, acc 0.23000000417232513\n",
      "Epoch 8, iter 238, loss 2.169818639755249, acc 0.23000000417232513\n",
      "Epoch 8, iter 239, loss 2.2308831214904785, acc 0.25\n",
      "Epoch 8, iter 240, loss 2.215721845626831, acc 0.18000000715255737\n",
      "Epoch 8, iter 241, loss 2.231916904449463, acc 0.2199999988079071\n",
      "Epoch 8, iter 242, loss 2.3451240062713623, acc 0.15000000596046448\n",
      "Epoch 8, iter 243, loss 2.2687790393829346, acc 0.18000000715255737\n",
      "Epoch 8, iter 244, loss 2.2423648834228516, acc 0.20000000298023224\n",
      "Epoch 8, iter 245, loss 2.1490638256073, acc 0.25\n",
      "Epoch 8, iter 246, loss 2.1746160984039307, acc 0.20000000298023224\n",
      "Epoch 8, iter 247, loss 2.1779842376708984, acc 0.20999999344348907\n",
      "Epoch 8, iter 248, loss 2.177734851837158, acc 0.20999999344348907\n",
      "Epoch 8, iter 249, loss 2.170283317565918, acc 0.2199999988079071\n",
      "Epoch 8, iter 250, loss 2.21502685546875, acc 0.20999999344348907\n",
      "Epoch 8, iter 251, loss 2.218402147293091, acc 0.23000000417232513\n",
      "Epoch 8, iter 252, loss 2.1593871116638184, acc 0.23000000417232513\n",
      "Epoch 8, iter 253, loss 2.3101770877838135, acc 0.18000000715255737\n",
      "Epoch 8, iter 254, loss 2.208592176437378, acc 0.23000000417232513\n",
      "Epoch 8, iter 255, loss 2.245448350906372, acc 0.20999999344348907\n",
      "Epoch 8, iter 256, loss 2.1700356006622314, acc 0.27000001072883606\n",
      "Epoch 8, iter 257, loss 2.1445302963256836, acc 0.2199999988079071\n",
      "Epoch 8, iter 258, loss 2.2665882110595703, acc 0.20000000298023224\n",
      "Epoch 8, iter 259, loss 2.246246099472046, acc 0.20000000298023224\n",
      "Epoch 8, iter 260, loss 2.153085708618164, acc 0.20000000298023224\n",
      "Epoch 8, iter 261, loss 2.1946287155151367, acc 0.25\n",
      "Epoch 8, iter 262, loss 2.2145094871520996, acc 0.23000000417232513\n",
      "Epoch 8, iter 263, loss 2.154170036315918, acc 0.23000000417232513\n",
      "Epoch 8, iter 264, loss 2.1858227252960205, acc 0.15000000596046448\n",
      "Epoch 8, iter 265, loss 2.148545503616333, acc 0.18000000715255737\n",
      "Epoch 8, iter 266, loss 2.2672507762908936, acc 0.18000000715255737\n",
      "Epoch 8, iter 267, loss 2.2337639331817627, acc 0.12999999523162842\n",
      "Epoch 8, iter 268, loss 2.1691973209381104, acc 0.23000000417232513\n",
      "Epoch 8, iter 269, loss 2.165530204772949, acc 0.25\n",
      "Epoch 8, iter 270, loss 2.2265987396240234, acc 0.17000000178813934\n",
      "Epoch 8, iter 271, loss 2.134902000427246, acc 0.28999999165534973\n",
      "Epoch 8, iter 272, loss 2.210120916366577, acc 0.18000000715255737\n",
      "Epoch 8, iter 273, loss 2.211189031600952, acc 0.1899999976158142\n",
      "Epoch 8, iter 274, loss 2.2978899478912354, acc 0.1899999976158142\n",
      "Epoch 8, iter 275, loss 2.222015380859375, acc 0.18000000715255737\n",
      "Epoch 8, iter 276, loss 2.2139580249786377, acc 0.23000000417232513\n",
      "Epoch 8, iter 277, loss 2.1177728176116943, acc 0.1899999976158142\n",
      "Epoch 8, iter 278, loss 2.0718626976013184, acc 0.36000001430511475\n",
      "Epoch 8, iter 279, loss 2.252417802810669, acc 0.15000000596046448\n",
      "Epoch 8, iter 280, loss 2.200613498687744, acc 0.20999999344348907\n",
      "Epoch 8, iter 281, loss 2.2138304710388184, acc 0.14000000059604645\n",
      "Epoch 8, iter 282, loss 2.1119229793548584, acc 0.30000001192092896\n",
      "Epoch 8, iter 283, loss 2.2294352054595947, acc 0.17000000178813934\n",
      "Epoch 8, iter 284, loss 2.1804516315460205, acc 0.20999999344348907\n",
      "Epoch 8, iter 285, loss 2.2404184341430664, acc 0.1899999976158142\n",
      "Epoch 8, iter 286, loss 2.123723030090332, acc 0.25999999046325684\n",
      "Epoch 8, iter 287, loss 2.216993808746338, acc 0.2199999988079071\n",
      "Epoch 8, iter 288, loss 2.321960210800171, acc 0.12999999523162842\n",
      "Epoch 8, iter 289, loss 2.248215913772583, acc 0.17000000178813934\n",
      "Epoch 8, iter 290, loss 2.2229607105255127, acc 0.18000000715255737\n",
      "Epoch 8, iter 291, loss 2.2752022743225098, acc 0.18000000715255737\n",
      "Epoch 8, iter 292, loss 2.1891424655914307, acc 0.2199999988079071\n",
      "Epoch 8, iter 293, loss 2.245695114135742, acc 0.1899999976158142\n",
      "Epoch 8, iter 294, loss 2.155055046081543, acc 0.23000000417232513\n",
      "Epoch 8, iter 295, loss 2.2249279022216797, acc 0.20000000298023224\n",
      "Epoch 8, iter 296, loss 2.1986730098724365, acc 0.2199999988079071\n",
      "Epoch 8, iter 297, loss 2.227919816970825, acc 0.17000000178813934\n",
      "Epoch 8, iter 298, loss 2.1164817810058594, acc 0.23999999463558197\n",
      "Epoch 8, iter 299, loss 2.295058250427246, acc 0.20000000298023224\n",
      "Epoch 8, iter 300, loss 2.134096145629883, acc 0.23000000417232513\n",
      "Epoch 8, iter 301, loss 2.2160654067993164, acc 0.20999999344348907\n",
      "Epoch 8, iter 302, loss 2.229779005050659, acc 0.12999999523162842\n",
      "Epoch 8, iter 303, loss 2.2216267585754395, acc 0.20999999344348907\n",
      "Epoch 8, iter 304, loss 2.137575626373291, acc 0.25999999046325684\n",
      "Epoch 8, iter 305, loss 2.1861722469329834, acc 0.1899999976158142\n",
      "Epoch 8, iter 306, loss 2.1841366291046143, acc 0.2199999988079071\n",
      "Epoch 8, iter 307, loss 2.2255184650421143, acc 0.14000000059604645\n",
      "Epoch 8, iter 308, loss 2.217167854309082, acc 0.15000000596046448\n",
      "Epoch 8, iter 309, loss 2.1086411476135254, acc 0.2199999988079071\n",
      "Epoch 8, iter 310, loss 2.1969146728515625, acc 0.1899999976158142\n",
      "Epoch 8, iter 311, loss 2.234825372695923, acc 0.18000000715255737\n",
      "Epoch 8, iter 312, loss 2.166264533996582, acc 0.18000000715255737\n",
      "Epoch 8, iter 313, loss 2.2157387733459473, acc 0.17000000178813934\n",
      "Epoch 8, iter 314, loss 2.1843903064727783, acc 0.18000000715255737\n",
      "Epoch 8, iter 315, loss 2.17529559135437, acc 0.1899999976158142\n",
      "Epoch 8, iter 316, loss 2.2492220401763916, acc 0.2800000011920929\n",
      "Epoch 8, iter 317, loss 2.232189416885376, acc 0.15000000596046448\n",
      "Epoch 8, iter 318, loss 2.1096367835998535, acc 0.25999999046325684\n",
      "Epoch 8, iter 319, loss 2.115938901901245, acc 0.2199999988079071\n",
      "Epoch 8, iter 320, loss 2.195892333984375, acc 0.20999999344348907\n",
      "Epoch 8, iter 321, loss 2.2690389156341553, acc 0.1599999964237213\n",
      "Epoch 8, iter 322, loss 2.250906467437744, acc 0.15000000596046448\n",
      "Epoch 8, iter 323, loss 2.214132070541382, acc 0.1599999964237213\n",
      "Epoch 8, iter 324, loss 2.1653354167938232, acc 0.23000000417232513\n",
      "Epoch 8, iter 325, loss 2.2472479343414307, acc 0.15000000596046448\n",
      "Epoch 8, iter 326, loss 2.1704232692718506, acc 0.20999999344348907\n",
      "Epoch 8, iter 327, loss 2.1963067054748535, acc 0.27000001072883606\n",
      "Epoch 8, iter 328, loss 2.290382146835327, acc 0.17000000178813934\n",
      "Epoch 8, iter 329, loss 2.2494163513183594, acc 0.1599999964237213\n",
      "Epoch 8, iter 330, loss 2.204740047454834, acc 0.20999999344348907\n",
      "Epoch 8, iter 331, loss 2.1725716590881348, acc 0.23000000417232513\n",
      "Epoch 8, iter 332, loss 2.146888017654419, acc 0.17000000178813934\n",
      "Epoch 8, iter 333, loss 2.1566011905670166, acc 0.2199999988079071\n",
      "Epoch 8, iter 334, loss 2.1814658641815186, acc 0.1899999976158142\n",
      "Epoch 8, iter 335, loss 2.1130478382110596, acc 0.25\n",
      "Epoch 8, iter 336, loss 2.179995536804199, acc 0.1599999964237213\n",
      "Epoch 8, iter 337, loss 2.2615761756896973, acc 0.2199999988079071\n",
      "Epoch 8, iter 338, loss 2.1147615909576416, acc 0.20999999344348907\n",
      "Epoch 8, iter 339, loss 2.0725133419036865, acc 0.23999999463558197\n",
      "Epoch 8, iter 340, loss 2.260956048965454, acc 0.18000000715255737\n",
      "Epoch 8, iter 341, loss 2.1426637172698975, acc 0.25999999046325684\n",
      "Epoch 8, iter 342, loss 2.120659112930298, acc 0.20000000298023224\n",
      "Epoch 8, iter 343, loss 2.2431561946868896, acc 0.1899999976158142\n",
      "Epoch 8, iter 344, loss 2.278701066970825, acc 0.14000000059604645\n",
      "Epoch 8, iter 345, loss 2.277353286743164, acc 0.18000000715255737\n",
      "Epoch 8, iter 346, loss 2.2248458862304688, acc 0.2199999988079071\n",
      "Epoch 8, iter 347, loss 2.153388261795044, acc 0.2199999988079071\n",
      "Epoch 8, iter 348, loss 2.1445152759552, acc 0.20000000298023224\n",
      "Epoch 8, iter 349, loss 2.1411948204040527, acc 0.2199999988079071\n",
      "Epoch 8, iter 350, loss 2.2103803157806396, acc 0.20999999344348907\n",
      "Epoch 8, iter 351, loss 2.1946702003479004, acc 0.25\n",
      "Epoch 8, iter 352, loss 2.1856415271759033, acc 0.20000000298023224\n",
      "Epoch 8, iter 353, loss 2.238452434539795, acc 0.15000000596046448\n",
      "Epoch 8, iter 354, loss 2.1808338165283203, acc 0.2199999988079071\n",
      "Epoch 8, iter 355, loss 2.2303452491760254, acc 0.20999999344348907\n",
      "Epoch 8, iter 356, loss 2.1569454669952393, acc 0.27000001072883606\n",
      "Epoch 8, iter 357, loss 2.160383462905884, acc 0.20999999344348907\n",
      "Epoch 8, iter 358, loss 2.205165147781372, acc 0.2199999988079071\n",
      "Epoch 8, iter 359, loss 2.202601671218872, acc 0.20999999344348907\n",
      "Epoch 8, iter 360, loss 2.1826000213623047, acc 0.17000000178813934\n",
      "Epoch 8, iter 361, loss 2.2205147743225098, acc 0.20999999344348907\n",
      "Epoch 8, iter 362, loss 2.2202494144439697, acc 0.15000000596046448\n",
      "Epoch 8, iter 363, loss 2.2032594680786133, acc 0.1599999964237213\n",
      "Epoch 8, iter 364, loss 2.2242207527160645, acc 0.1899999976158142\n",
      "Epoch 8, iter 365, loss 2.2140395641326904, acc 0.1899999976158142\n",
      "Epoch 8, iter 366, loss 2.1298208236694336, acc 0.23000000417232513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 367, loss 2.1940910816192627, acc 0.2199999988079071\n",
      "Epoch 8, iter 368, loss 2.2384488582611084, acc 0.17000000178813934\n",
      "Epoch 8, iter 369, loss 2.2402539253234863, acc 0.2199999988079071\n",
      "Epoch 8, iter 370, loss 2.224026918411255, acc 0.23999999463558197\n",
      "Epoch 8, iter 371, loss 2.1882503032684326, acc 0.1899999976158142\n",
      "Epoch 8, iter 372, loss 2.17972993850708, acc 0.2199999988079071\n",
      "Epoch 8, iter 373, loss 2.14288330078125, acc 0.25\n",
      "Epoch 8, iter 374, loss 2.17354679107666, acc 0.23000000417232513\n",
      "Epoch 8, iter 375, loss 2.234262466430664, acc 0.09000000357627869\n",
      "Epoch 8, iter 376, loss 2.133052349090576, acc 0.25999999046325684\n",
      "Epoch 8, iter 377, loss 2.226982831954956, acc 0.12999999523162842\n",
      "Epoch 8, iter 378, loss 2.2184736728668213, acc 0.20000000298023224\n",
      "Epoch 8, iter 379, loss 2.2449276447296143, acc 0.20999999344348907\n",
      "Epoch 8, iter 380, loss 2.1835899353027344, acc 0.25999999046325684\n",
      "Epoch 8, iter 381, loss 2.229844808578491, acc 0.17000000178813934\n",
      "Epoch 8, iter 382, loss 2.046430826187134, acc 0.27000001072883606\n",
      "Epoch 8, iter 383, loss 2.1571145057678223, acc 0.23999999463558197\n",
      "Epoch 8, iter 384, loss 2.2080259323120117, acc 0.20999999344348907\n",
      "Epoch 8, iter 385, loss 2.2723453044891357, acc 0.18000000715255737\n",
      "Epoch 8, iter 386, loss 2.165009021759033, acc 0.23000000417232513\n",
      "Epoch 8, iter 387, loss 2.194791316986084, acc 0.1899999976158142\n",
      "Epoch 8, iter 388, loss 2.0976431369781494, acc 0.25999999046325684\n",
      "Epoch 8, iter 389, loss 2.1757631301879883, acc 0.2199999988079071\n",
      "Epoch 8, iter 390, loss 2.21468448638916, acc 0.27000001072883606\n",
      "Epoch 8, iter 391, loss 2.1223855018615723, acc 0.2800000011920929\n",
      "Epoch 8, iter 392, loss 2.2775862216949463, acc 0.2199999988079071\n",
      "Epoch 8, iter 393, loss 2.16519832611084, acc 0.27000001072883606\n",
      "Epoch 8, iter 394, loss 2.1450510025024414, acc 0.27000001072883606\n",
      "Epoch 8, iter 395, loss 2.1992340087890625, acc 0.20000000298023224\n",
      "Epoch 8, iter 396, loss 2.2695672512054443, acc 0.20000000298023224\n",
      "Epoch 8, iter 397, loss 2.1607983112335205, acc 0.23999999463558197\n",
      "Epoch 8, iter 398, loss 2.1909844875335693, acc 0.27000001072883606\n",
      "Epoch 8, iter 399, loss 2.2246832847595215, acc 0.20000000298023224\n",
      "Epoch 8, iter 400, loss 2.1712050437927246, acc 0.1899999976158142\n",
      "Epoch 8, iter 401, loss 2.2126898765563965, acc 0.25999999046325684\n",
      "Epoch 8, iter 402, loss 2.1442110538482666, acc 0.25999999046325684\n",
      "Epoch 8, iter 403, loss 2.2305960655212402, acc 0.23999999463558197\n",
      "Epoch 8, iter 404, loss 2.2843329906463623, acc 0.15000000596046448\n",
      "Epoch 8, iter 405, loss 2.2376503944396973, acc 0.20000000298023224\n",
      "Epoch 8, iter 406, loss 2.230203628540039, acc 0.1899999976158142\n",
      "Epoch 8, iter 407, loss 2.174140691757202, acc 0.17000000178813934\n",
      "Epoch 8, iter 408, loss 2.133328676223755, acc 0.20999999344348907\n",
      "Epoch 8, iter 409, loss 2.233660936355591, acc 0.23999999463558197\n",
      "Epoch 8, iter 410, loss 2.1212639808654785, acc 0.3700000047683716\n",
      "Epoch 8, iter 411, loss 2.218860387802124, acc 0.15000000596046448\n",
      "Epoch 8, iter 412, loss 2.1544058322906494, acc 0.25\n",
      "Epoch 8, iter 413, loss 2.2617015838623047, acc 0.20999999344348907\n",
      "Epoch 8, iter 414, loss 2.2896385192871094, acc 0.12999999523162842\n",
      "Epoch 8, iter 415, loss 2.2950360774993896, acc 0.18000000715255737\n",
      "Epoch 8, iter 416, loss 2.2262580394744873, acc 0.2199999988079071\n",
      "Epoch 8, iter 417, loss 2.1634316444396973, acc 0.18000000715255737\n",
      "Epoch 8, iter 418, loss 2.076638698577881, acc 0.33000001311302185\n",
      "Epoch 8, iter 419, loss 2.1274776458740234, acc 0.23000000417232513\n",
      "Epoch 8, iter 420, loss 2.2375307083129883, acc 0.14000000059604645\n",
      "Epoch 9, iter 1, loss 2.179335594177246, acc 0.23000000417232513\n",
      "Epoch 9, iter 2, loss 2.221137285232544, acc 0.20999999344348907\n",
      "Epoch 9, iter 3, loss 2.188004493713379, acc 0.2199999988079071\n",
      "Epoch 9, iter 4, loss 2.2385435104370117, acc 0.20000000298023224\n",
      "Epoch 9, iter 5, loss 2.1534829139709473, acc 0.20000000298023224\n",
      "Epoch 9, iter 6, loss 2.1654508113861084, acc 0.20999999344348907\n",
      "Epoch 9, iter 7, loss 2.2616236209869385, acc 0.17000000178813934\n",
      "Epoch 9, iter 8, loss 2.179706335067749, acc 0.23000000417232513\n",
      "Epoch 9, iter 9, loss 2.1455419063568115, acc 0.23999999463558197\n",
      "Epoch 9, iter 10, loss 2.225738286972046, acc 0.18000000715255737\n",
      "Epoch 9, iter 11, loss 2.335520029067993, acc 0.12999999523162842\n",
      "Epoch 9, iter 12, loss 2.258802890777588, acc 0.14000000059604645\n",
      "Epoch 9, iter 13, loss 2.1423795223236084, acc 0.1899999976158142\n",
      "Epoch 9, iter 14, loss 2.2782247066497803, acc 0.17000000178813934\n",
      "Epoch 9, iter 15, loss 2.200167655944824, acc 0.15000000596046448\n",
      "Epoch 9, iter 16, loss 2.1634743213653564, acc 0.20000000298023224\n",
      "Epoch 9, iter 17, loss 2.1597824096679688, acc 0.25\n",
      "Epoch 9, iter 18, loss 2.298280715942383, acc 0.18000000715255737\n",
      "Epoch 9, iter 19, loss 2.1675562858581543, acc 0.20999999344348907\n",
      "Epoch 9, iter 20, loss 2.2021067142486572, acc 0.1599999964237213\n",
      "Epoch 9, iter 21, loss 2.2096266746520996, acc 0.20999999344348907\n",
      "Epoch 9, iter 22, loss 2.22664737701416, acc 0.17000000178813934\n",
      "Epoch 9, iter 23, loss 2.1882071495056152, acc 0.1899999976158142\n",
      "Epoch 9, iter 24, loss 2.107743263244629, acc 0.27000001072883606\n",
      "Epoch 9, iter 25, loss 2.1849639415740967, acc 0.1899999976158142\n",
      "Epoch 9, iter 26, loss 2.237974166870117, acc 0.23999999463558197\n",
      "Epoch 9, iter 27, loss 2.1668131351470947, acc 0.20000000298023224\n",
      "Epoch 9, iter 28, loss 2.235893726348877, acc 0.1899999976158142\n",
      "Epoch 9, iter 29, loss 2.2243332862854004, acc 0.20999999344348907\n",
      "Epoch 9, iter 30, loss 2.226468324661255, acc 0.1899999976158142\n",
      "Epoch 9, iter 31, loss 2.2246475219726562, acc 0.20999999344348907\n",
      "Epoch 9, iter 32, loss 2.1786975860595703, acc 0.25\n",
      "Epoch 9, iter 33, loss 2.2360544204711914, acc 0.1599999964237213\n",
      "Epoch 9, iter 34, loss 2.1520614624023438, acc 0.25\n",
      "Epoch 9, iter 35, loss 2.2536725997924805, acc 0.1599999964237213\n",
      "Epoch 9, iter 36, loss 2.2513318061828613, acc 0.20000000298023224\n",
      "Epoch 9, iter 37, loss 2.1495816707611084, acc 0.18000000715255737\n",
      "Epoch 9, iter 38, loss 2.164019823074341, acc 0.2199999988079071\n",
      "Epoch 9, iter 39, loss 2.2015838623046875, acc 0.18000000715255737\n",
      "Epoch 9, iter 40, loss 2.1279544830322266, acc 0.25\n",
      "Epoch 9, iter 41, loss 2.2756597995758057, acc 0.1899999976158142\n",
      "Epoch 9, iter 42, loss 2.1352076530456543, acc 0.23999999463558197\n",
      "Epoch 9, iter 43, loss 2.0996484756469727, acc 0.23000000417232513\n",
      "Epoch 9, iter 44, loss 2.159728527069092, acc 0.2199999988079071\n",
      "Epoch 9, iter 45, loss 2.2213971614837646, acc 0.2199999988079071\n",
      "Epoch 9, iter 46, loss 2.1689865589141846, acc 0.18000000715255737\n",
      "Epoch 9, iter 47, loss 2.2683231830596924, acc 0.15000000596046448\n",
      "Epoch 9, iter 48, loss 2.137594223022461, acc 0.20999999344348907\n",
      "Epoch 9, iter 49, loss 2.1625423431396484, acc 0.20999999344348907\n",
      "Epoch 9, iter 50, loss 2.1344082355499268, acc 0.2199999988079071\n",
      "Epoch 9, iter 51, loss 2.170164108276367, acc 0.20000000298023224\n",
      "Epoch 9, iter 52, loss 2.1907126903533936, acc 0.1599999964237213\n",
      "Epoch 9, iter 53, loss 2.217639207839966, acc 0.09000000357627869\n",
      "Epoch 9, iter 54, loss 2.116880416870117, acc 0.2800000011920929\n",
      "Epoch 9, iter 55, loss 2.2610952854156494, acc 0.23999999463558197\n",
      "Epoch 9, iter 56, loss 2.1749444007873535, acc 0.27000001072883606\n",
      "Epoch 9, iter 57, loss 2.2287027835845947, acc 0.23999999463558197\n",
      "Epoch 9, iter 58, loss 2.1065852642059326, acc 0.30000001192092896\n",
      "Epoch 9, iter 59, loss 2.258957624435425, acc 0.20999999344348907\n",
      "Epoch 9, iter 60, loss 2.1556880474090576, acc 0.23000000417232513\n",
      "Epoch 9, iter 61, loss 2.196432590484619, acc 0.25999999046325684\n",
      "Epoch 9, iter 62, loss 2.231527328491211, acc 0.2199999988079071\n",
      "Epoch 9, iter 63, loss 2.288792133331299, acc 0.12999999523162842\n",
      "Epoch 9, iter 64, loss 2.1571474075317383, acc 0.1899999976158142\n",
      "Epoch 9, iter 65, loss 2.2372779846191406, acc 0.17000000178813934\n",
      "Epoch 9, iter 66, loss 2.2217257022857666, acc 0.17000000178813934\n",
      "Epoch 9, iter 67, loss 2.2284820079803467, acc 0.17000000178813934\n",
      "Epoch 9, iter 68, loss 2.161073684692383, acc 0.23000000417232513\n",
      "Epoch 9, iter 69, loss 2.177605628967285, acc 0.20999999344348907\n",
      "Epoch 9, iter 70, loss 2.181478977203369, acc 0.1599999964237213\n",
      "Epoch 9, iter 71, loss 2.228224754333496, acc 0.1599999964237213\n",
      "Epoch 9, iter 72, loss 2.1768417358398438, acc 0.23999999463558197\n",
      "Epoch 9, iter 73, loss 2.1651511192321777, acc 0.20000000298023224\n",
      "Epoch 9, iter 74, loss 2.1770849227905273, acc 0.23000000417232513\n",
      "Epoch 9, iter 75, loss 2.1651713848114014, acc 0.25\n",
      "Epoch 9, iter 76, loss 2.1311516761779785, acc 0.27000001072883606\n",
      "Epoch 9, iter 77, loss 2.2333178520202637, acc 0.11999999731779099\n",
      "Epoch 9, iter 78, loss 2.176560878753662, acc 0.17000000178813934\n",
      "Epoch 9, iter 79, loss 2.1492652893066406, acc 0.23000000417232513\n",
      "Epoch 9, iter 80, loss 2.3121464252471924, acc 0.1599999964237213\n",
      "Epoch 9, iter 81, loss 2.1897974014282227, acc 0.1899999976158142\n",
      "Epoch 9, iter 82, loss 2.2026662826538086, acc 0.1899999976158142\n",
      "Epoch 9, iter 83, loss 2.1830620765686035, acc 0.23000000417232513\n",
      "Epoch 9, iter 84, loss 2.1976754665374756, acc 0.2800000011920929\n",
      "Epoch 9, iter 85, loss 2.2690393924713135, acc 0.23000000417232513\n",
      "Epoch 9, iter 86, loss 2.1750261783599854, acc 0.20999999344348907\n",
      "Epoch 9, iter 87, loss 2.0969460010528564, acc 0.2800000011920929\n",
      "Epoch 9, iter 88, loss 2.1369261741638184, acc 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 89, loss 2.189652681350708, acc 0.1899999976158142\n",
      "Epoch 9, iter 90, loss 2.196418046951294, acc 0.25\n",
      "Epoch 9, iter 91, loss 2.2133870124816895, acc 0.20999999344348907\n",
      "Epoch 9, iter 92, loss 2.190908908843994, acc 0.23000000417232513\n",
      "Epoch 9, iter 93, loss 2.1805953979492188, acc 0.25\n",
      "Epoch 9, iter 94, loss 2.173666000366211, acc 0.20999999344348907\n",
      "Epoch 9, iter 95, loss 2.2307889461517334, acc 0.18000000715255737\n",
      "Epoch 9, iter 96, loss 2.1478185653686523, acc 0.20999999344348907\n",
      "Epoch 9, iter 97, loss 2.230729341506958, acc 0.18000000715255737\n",
      "Epoch 9, iter 98, loss 2.199179172515869, acc 0.20999999344348907\n",
      "Epoch 9, iter 99, loss 2.246906042098999, acc 0.23000000417232513\n",
      "Epoch 9, iter 100, loss 2.1991333961486816, acc 0.17000000178813934\n",
      "Epoch 9, iter 101, loss 2.1928577423095703, acc 0.23999999463558197\n",
      "Epoch 9, iter 102, loss 2.0906295776367188, acc 0.20000000298023224\n",
      "Epoch 9, iter 103, loss 2.167435884475708, acc 0.20999999344348907\n",
      "Epoch 9, iter 104, loss 2.2409861087799072, acc 0.18000000715255737\n",
      "Epoch 9, iter 105, loss 2.2007172107696533, acc 0.2199999988079071\n",
      "Epoch 9, iter 106, loss 2.2392022609710693, acc 0.10999999940395355\n",
      "Epoch 9, iter 107, loss 2.1878914833068848, acc 0.1899999976158142\n",
      "Epoch 9, iter 108, loss 2.0990188121795654, acc 0.25\n",
      "Epoch 9, iter 109, loss 2.1849918365478516, acc 0.18000000715255737\n",
      "Epoch 9, iter 110, loss 2.2530837059020996, acc 0.20000000298023224\n",
      "Epoch 9, iter 111, loss 2.182931661605835, acc 0.2199999988079071\n",
      "Epoch 9, iter 112, loss 2.2316458225250244, acc 0.11999999731779099\n",
      "Epoch 9, iter 113, loss 2.1527254581451416, acc 0.25999999046325684\n",
      "Epoch 9, iter 114, loss 2.1933090686798096, acc 0.18000000715255737\n",
      "Epoch 9, iter 115, loss 2.245565414428711, acc 0.1599999964237213\n",
      "Epoch 9, iter 116, loss 2.2212116718292236, acc 0.20000000298023224\n",
      "Epoch 9, iter 117, loss 2.2150979042053223, acc 0.18000000715255737\n",
      "Epoch 9, iter 118, loss 2.2040462493896484, acc 0.23999999463558197\n",
      "Epoch 9, iter 119, loss 2.1671152114868164, acc 0.20000000298023224\n",
      "Epoch 9, iter 120, loss 2.19154691696167, acc 0.14000000059604645\n",
      "Epoch 9, iter 121, loss 2.2128679752349854, acc 0.1899999976158142\n",
      "Epoch 9, iter 122, loss 2.21663761138916, acc 0.20000000298023224\n",
      "Epoch 9, iter 123, loss 2.1610686779022217, acc 0.23000000417232513\n",
      "Epoch 9, iter 124, loss 2.1706998348236084, acc 0.25999999046325684\n",
      "Epoch 9, iter 125, loss 2.1767704486846924, acc 0.23000000417232513\n",
      "Epoch 9, iter 126, loss 2.164738655090332, acc 0.23999999463558197\n",
      "Epoch 9, iter 127, loss 2.206514835357666, acc 0.20000000298023224\n",
      "Epoch 9, iter 128, loss 2.180701971054077, acc 0.17000000178813934\n",
      "Epoch 9, iter 129, loss 2.2547640800476074, acc 0.20000000298023224\n",
      "Epoch 9, iter 130, loss 2.214837074279785, acc 0.18000000715255737\n",
      "Epoch 9, iter 131, loss 2.189480781555176, acc 0.20999999344348907\n",
      "Epoch 9, iter 132, loss 2.1505603790283203, acc 0.18000000715255737\n",
      "Epoch 9, iter 133, loss 2.1734578609466553, acc 0.20000000298023224\n",
      "Epoch 9, iter 134, loss 2.162489891052246, acc 0.25\n",
      "Epoch 9, iter 135, loss 2.196162223815918, acc 0.20000000298023224\n",
      "Epoch 9, iter 136, loss 2.2477200031280518, acc 0.17000000178813934\n",
      "Epoch 9, iter 137, loss 2.255526304244995, acc 0.1599999964237213\n",
      "Epoch 9, iter 138, loss 2.1416289806365967, acc 0.23000000417232513\n",
      "Epoch 9, iter 139, loss 2.2041189670562744, acc 0.17000000178813934\n",
      "Epoch 9, iter 140, loss 2.244274854660034, acc 0.1899999976158142\n",
      "Epoch 9, iter 141, loss 2.27923321723938, acc 0.15000000596046448\n",
      "Epoch 9, iter 142, loss 2.15447998046875, acc 0.1899999976158142\n",
      "Epoch 9, iter 143, loss 2.214855432510376, acc 0.17000000178813934\n",
      "Epoch 9, iter 144, loss 2.2082767486572266, acc 0.20000000298023224\n",
      "Epoch 9, iter 145, loss 2.186305284500122, acc 0.20999999344348907\n",
      "Epoch 9, iter 146, loss 2.210418462753296, acc 0.18000000715255737\n",
      "Epoch 9, iter 147, loss 2.1587066650390625, acc 0.20000000298023224\n",
      "Epoch 9, iter 148, loss 2.1227729320526123, acc 0.2199999988079071\n",
      "Epoch 9, iter 149, loss 2.1998636722564697, acc 0.20000000298023224\n",
      "Epoch 9, iter 150, loss 2.0683786869049072, acc 0.25\n",
      "Epoch 9, iter 151, loss 2.156984329223633, acc 0.20000000298023224\n",
      "Epoch 9, iter 152, loss 2.1808254718780518, acc 0.20000000298023224\n",
      "Epoch 9, iter 153, loss 2.1936798095703125, acc 0.2199999988079071\n",
      "Epoch 9, iter 154, loss 2.156189203262329, acc 0.2199999988079071\n",
      "Epoch 9, iter 155, loss 2.1416196823120117, acc 0.1899999976158142\n",
      "Epoch 9, iter 156, loss 2.178530216217041, acc 0.3199999928474426\n",
      "Epoch 9, iter 157, loss 2.250042676925659, acc 0.12999999523162842\n",
      "Epoch 9, iter 158, loss 2.2781989574432373, acc 0.1599999964237213\n",
      "Epoch 9, iter 159, loss 2.143098831176758, acc 0.20000000298023224\n",
      "Epoch 9, iter 160, loss 2.1920690536499023, acc 0.20000000298023224\n",
      "Epoch 9, iter 161, loss 2.238391876220703, acc 0.1599999964237213\n",
      "Epoch 9, iter 162, loss 2.1801726818084717, acc 0.23999999463558197\n",
      "Epoch 9, iter 163, loss 2.219679117202759, acc 0.23000000417232513\n",
      "Epoch 9, iter 164, loss 2.2204482555389404, acc 0.23000000417232513\n",
      "Epoch 9, iter 165, loss 2.1970338821411133, acc 0.15000000596046448\n",
      "Epoch 9, iter 166, loss 2.2381539344787598, acc 0.1899999976158142\n",
      "Epoch 9, iter 167, loss 2.240663766860962, acc 0.17000000178813934\n",
      "Epoch 9, iter 168, loss 2.1911704540252686, acc 0.18000000715255737\n",
      "Epoch 9, iter 169, loss 2.1753666400909424, acc 0.18000000715255737\n",
      "Epoch 9, iter 170, loss 2.1998138427734375, acc 0.25\n",
      "Epoch 9, iter 171, loss 2.1918954849243164, acc 0.2800000011920929\n",
      "Epoch 9, iter 172, loss 2.2222392559051514, acc 0.18000000715255737\n",
      "Epoch 9, iter 173, loss 2.1959636211395264, acc 0.1899999976158142\n",
      "Epoch 9, iter 174, loss 2.1805739402770996, acc 0.27000001072883606\n",
      "Epoch 9, iter 175, loss 2.2212774753570557, acc 0.20000000298023224\n",
      "Epoch 9, iter 176, loss 2.192410469055176, acc 0.23000000417232513\n",
      "Epoch 9, iter 177, loss 2.240182876586914, acc 0.17000000178813934\n",
      "Epoch 9, iter 178, loss 2.2311630249023438, acc 0.20000000298023224\n",
      "Epoch 9, iter 179, loss 2.1761722564697266, acc 0.23000000417232513\n",
      "Epoch 9, iter 180, loss 2.1907646656036377, acc 0.20000000298023224\n",
      "Epoch 9, iter 181, loss 2.1450812816619873, acc 0.23999999463558197\n",
      "Epoch 9, iter 182, loss 2.1191208362579346, acc 0.25999999046325684\n",
      "Epoch 9, iter 183, loss 2.1497671604156494, acc 0.20999999344348907\n",
      "Epoch 9, iter 184, loss 2.169633626937866, acc 0.2199999988079071\n",
      "Epoch 9, iter 185, loss 2.1215779781341553, acc 0.20999999344348907\n",
      "Epoch 9, iter 186, loss 2.157007932662964, acc 0.1899999976158142\n",
      "Epoch 9, iter 187, loss 2.144634246826172, acc 0.25999999046325684\n",
      "Epoch 9, iter 188, loss 2.22436261177063, acc 0.1899999976158142\n",
      "Epoch 9, iter 189, loss 2.1417760848999023, acc 0.20999999344348907\n",
      "Epoch 9, iter 190, loss 2.2054145336151123, acc 0.20000000298023224\n",
      "Epoch 9, iter 191, loss 2.1399810314178467, acc 0.20999999344348907\n",
      "Epoch 9, iter 192, loss 2.221464157104492, acc 0.20999999344348907\n",
      "Epoch 9, iter 193, loss 2.1363959312438965, acc 0.23000000417232513\n",
      "Epoch 9, iter 194, loss 2.184931993484497, acc 0.23000000417232513\n",
      "Epoch 9, iter 195, loss 2.3131606578826904, acc 0.12999999523162842\n",
      "Epoch 9, iter 196, loss 2.1998209953308105, acc 0.20999999344348907\n",
      "Epoch 9, iter 197, loss 2.215332269668579, acc 0.1899999976158142\n",
      "Epoch 9, iter 198, loss 2.1593527793884277, acc 0.15000000596046448\n",
      "Epoch 9, iter 199, loss 2.2120678424835205, acc 0.12999999523162842\n",
      "Epoch 9, iter 200, loss 2.2512214183807373, acc 0.14000000059604645\n",
      "Epoch 9, iter 201, loss 2.1802189350128174, acc 0.23999999463558197\n",
      "Epoch 9, iter 202, loss 2.1680850982666016, acc 0.25\n",
      "Epoch 9, iter 203, loss 2.275681734085083, acc 0.1899999976158142\n",
      "Epoch 9, iter 204, loss 2.1627254486083984, acc 0.25\n",
      "Epoch 9, iter 205, loss 2.113163948059082, acc 0.2800000011920929\n",
      "Epoch 9, iter 206, loss 2.1903903484344482, acc 0.1899999976158142\n",
      "Epoch 9, iter 207, loss 2.1582064628601074, acc 0.25\n",
      "Epoch 9, iter 208, loss 2.2329764366149902, acc 0.23999999463558197\n",
      "Epoch 9, iter 209, loss 2.3043758869171143, acc 0.17000000178813934\n",
      "Epoch 9, iter 210, loss 2.247809648513794, acc 0.14000000059604645\n",
      "Epoch 9, iter 211, loss 2.1483144760131836, acc 0.23999999463558197\n",
      "Epoch 9, iter 212, loss 2.165175676345825, acc 0.2199999988079071\n",
      "Epoch 9, iter 213, loss 2.1609129905700684, acc 0.27000001072883606\n",
      "Epoch 9, iter 214, loss 2.214799642562866, acc 0.23000000417232513\n",
      "Epoch 9, iter 215, loss 2.1888084411621094, acc 0.2199999988079071\n",
      "Epoch 9, iter 216, loss 2.1471786499023438, acc 0.2199999988079071\n",
      "Epoch 9, iter 217, loss 2.1425857543945312, acc 0.18000000715255737\n",
      "Epoch 9, iter 218, loss 2.2066686153411865, acc 0.2199999988079071\n",
      "Epoch 9, iter 219, loss 2.1445131301879883, acc 0.25\n",
      "Epoch 9, iter 220, loss 2.1837594509124756, acc 0.18000000715255737\n",
      "Epoch 9, iter 221, loss 2.1179518699645996, acc 0.27000001072883606\n",
      "Epoch 9, iter 222, loss 2.241231918334961, acc 0.12999999523162842\n",
      "Epoch 9, iter 223, loss 2.174875020980835, acc 0.20000000298023224\n",
      "Epoch 9, iter 224, loss 2.1306354999542236, acc 0.23000000417232513\n",
      "Epoch 9, iter 225, loss 2.129103899002075, acc 0.20999999344348907\n",
      "Epoch 9, iter 226, loss 2.191439390182495, acc 0.18000000715255737\n",
      "Epoch 9, iter 227, loss 2.172240972518921, acc 0.15000000596046448\n",
      "Epoch 9, iter 228, loss 2.129887104034424, acc 0.2199999988079071\n",
      "Epoch 9, iter 229, loss 2.1738839149475098, acc 0.20000000298023224\n",
      "Epoch 9, iter 230, loss 2.2247393131256104, acc 0.10999999940395355\n",
      "Epoch 9, iter 231, loss 2.1957156658172607, acc 0.1599999964237213\n",
      "Epoch 9, iter 232, loss 2.214007616043091, acc 0.2199999988079071\n",
      "Epoch 9, iter 233, loss 2.16534686088562, acc 0.25999999046325684\n",
      "Epoch 9, iter 234, loss 2.1722605228424072, acc 0.2199999988079071\n",
      "Epoch 9, iter 235, loss 2.2318532466888428, acc 0.1599999964237213\n",
      "Epoch 9, iter 236, loss 2.2331137657165527, acc 0.18000000715255737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 237, loss 2.184458017349243, acc 0.23000000417232513\n",
      "Epoch 9, iter 238, loss 2.1654553413391113, acc 0.2199999988079071\n",
      "Epoch 9, iter 239, loss 2.205139398574829, acc 0.25\n",
      "Epoch 9, iter 240, loss 2.219977617263794, acc 0.17000000178813934\n",
      "Epoch 9, iter 241, loss 2.2237582206726074, acc 0.2199999988079071\n",
      "Epoch 9, iter 242, loss 2.3413641452789307, acc 0.14000000059604645\n",
      "Epoch 9, iter 243, loss 2.2629055976867676, acc 0.18000000715255737\n",
      "Epoch 9, iter 244, loss 2.225907802581787, acc 0.20000000298023224\n",
      "Epoch 9, iter 245, loss 2.129108190536499, acc 0.25\n",
      "Epoch 9, iter 246, loss 2.17036771774292, acc 0.20000000298023224\n",
      "Epoch 9, iter 247, loss 2.1621451377868652, acc 0.2199999988079071\n",
      "Epoch 9, iter 248, loss 2.170044422149658, acc 0.20999999344348907\n",
      "Epoch 9, iter 249, loss 2.1803884506225586, acc 0.2199999988079071\n",
      "Epoch 9, iter 250, loss 2.2139580249786377, acc 0.1899999976158142\n",
      "Epoch 9, iter 251, loss 2.189157724380493, acc 0.23999999463558197\n",
      "Epoch 9, iter 252, loss 2.1433451175689697, acc 0.23000000417232513\n",
      "Epoch 9, iter 253, loss 2.309234619140625, acc 0.18000000715255737\n",
      "Epoch 9, iter 254, loss 2.207244634628296, acc 0.20999999344348907\n",
      "Epoch 9, iter 255, loss 2.236544609069824, acc 0.20999999344348907\n",
      "Epoch 9, iter 256, loss 2.145540475845337, acc 0.27000001072883606\n",
      "Epoch 9, iter 257, loss 2.128481388092041, acc 0.2199999988079071\n",
      "Epoch 9, iter 258, loss 2.2208869457244873, acc 0.20999999344348907\n",
      "Epoch 9, iter 259, loss 2.2478997707366943, acc 0.1899999976158142\n",
      "Epoch 9, iter 260, loss 2.149092674255371, acc 0.20000000298023224\n",
      "Epoch 9, iter 261, loss 2.181597948074341, acc 0.25\n",
      "Epoch 9, iter 262, loss 2.1884279251098633, acc 0.23999999463558197\n",
      "Epoch 9, iter 263, loss 2.123603105545044, acc 0.25\n",
      "Epoch 9, iter 264, loss 2.17163348197937, acc 0.15000000596046448\n",
      "Epoch 9, iter 265, loss 2.137457847595215, acc 0.18000000715255737\n",
      "Epoch 9, iter 266, loss 2.2475900650024414, acc 0.1899999976158142\n",
      "Epoch 9, iter 267, loss 2.228008508682251, acc 0.12999999523162842\n",
      "Epoch 9, iter 268, loss 2.1663124561309814, acc 0.2199999988079071\n",
      "Epoch 9, iter 269, loss 2.160676956176758, acc 0.25\n",
      "Epoch 9, iter 270, loss 2.217968463897705, acc 0.17000000178813934\n",
      "Epoch 9, iter 271, loss 2.114635467529297, acc 0.30000001192092896\n",
      "Epoch 9, iter 272, loss 2.2059051990509033, acc 0.18000000715255737\n",
      "Epoch 9, iter 273, loss 2.1821250915527344, acc 0.1899999976158142\n",
      "Epoch 9, iter 274, loss 2.275989294052124, acc 0.1899999976158142\n",
      "Epoch 9, iter 275, loss 2.201204776763916, acc 0.17000000178813934\n",
      "Epoch 9, iter 276, loss 2.205958604812622, acc 0.23000000417232513\n",
      "Epoch 9, iter 277, loss 2.0962836742401123, acc 0.20000000298023224\n",
      "Epoch 9, iter 278, loss 2.059746742248535, acc 0.36000001430511475\n",
      "Epoch 9, iter 279, loss 2.2536864280700684, acc 0.1599999964237213\n",
      "Epoch 9, iter 280, loss 2.187270164489746, acc 0.2199999988079071\n",
      "Epoch 9, iter 281, loss 2.1895902156829834, acc 0.14000000059604645\n",
      "Epoch 9, iter 282, loss 2.093961715698242, acc 0.30000001192092896\n",
      "Epoch 9, iter 283, loss 2.209911823272705, acc 0.17000000178813934\n",
      "Epoch 9, iter 284, loss 2.143223762512207, acc 0.20999999344348907\n",
      "Epoch 9, iter 285, loss 2.254335403442383, acc 0.18000000715255737\n",
      "Epoch 9, iter 286, loss 2.116562604904175, acc 0.25\n",
      "Epoch 9, iter 287, loss 2.1806480884552, acc 0.23999999463558197\n",
      "Epoch 9, iter 288, loss 2.3102338314056396, acc 0.15000000596046448\n",
      "Epoch 9, iter 289, loss 2.2232913970947266, acc 0.18000000715255737\n",
      "Epoch 9, iter 290, loss 2.194798231124878, acc 0.18000000715255737\n",
      "Epoch 9, iter 291, loss 2.2625949382781982, acc 0.18000000715255737\n",
      "Epoch 9, iter 292, loss 2.1874539852142334, acc 0.2199999988079071\n",
      "Epoch 9, iter 293, loss 2.2138190269470215, acc 0.20999999344348907\n",
      "Epoch 9, iter 294, loss 2.1213066577911377, acc 0.25\n",
      "Epoch 9, iter 295, loss 2.215545177459717, acc 0.20000000298023224\n",
      "Epoch 9, iter 296, loss 2.153747797012329, acc 0.23999999463558197\n",
      "Epoch 9, iter 297, loss 2.202436923980713, acc 0.18000000715255737\n",
      "Epoch 9, iter 298, loss 2.1418561935424805, acc 0.23000000417232513\n",
      "Epoch 9, iter 299, loss 2.2781989574432373, acc 0.20999999344348907\n",
      "Epoch 9, iter 300, loss 2.1230483055114746, acc 0.23000000417232513\n",
      "Epoch 9, iter 301, loss 2.1776626110076904, acc 0.25\n",
      "Epoch 9, iter 302, loss 2.2155890464782715, acc 0.12999999523162842\n",
      "Epoch 9, iter 303, loss 2.2053258419036865, acc 0.20999999344348907\n",
      "Epoch 9, iter 304, loss 2.1380248069763184, acc 0.25999999046325684\n",
      "Epoch 9, iter 305, loss 2.1853487491607666, acc 0.1899999976158142\n",
      "Epoch 9, iter 306, loss 2.175117254257202, acc 0.23000000417232513\n",
      "Epoch 9, iter 307, loss 2.189340591430664, acc 0.1599999964237213\n",
      "Epoch 9, iter 308, loss 2.1990370750427246, acc 0.1599999964237213\n",
      "Epoch 9, iter 309, loss 2.106208086013794, acc 0.2199999988079071\n",
      "Epoch 9, iter 310, loss 2.2065224647521973, acc 0.18000000715255737\n",
      "Epoch 9, iter 311, loss 2.205683946609497, acc 0.1899999976158142\n",
      "Epoch 9, iter 312, loss 2.1556997299194336, acc 0.20000000298023224\n",
      "Epoch 9, iter 313, loss 2.2189133167266846, acc 0.1599999964237213\n",
      "Epoch 9, iter 314, loss 2.1605119705200195, acc 0.17000000178813934\n",
      "Epoch 9, iter 315, loss 2.1676087379455566, acc 0.1899999976158142\n",
      "Epoch 9, iter 316, loss 2.2102837562561035, acc 0.2800000011920929\n",
      "Epoch 9, iter 317, loss 2.2137179374694824, acc 0.1599999964237213\n",
      "Epoch 9, iter 318, loss 2.101377010345459, acc 0.27000001072883606\n",
      "Epoch 9, iter 319, loss 2.109344482421875, acc 0.2199999988079071\n",
      "Epoch 9, iter 320, loss 2.1896555423736572, acc 0.20999999344348907\n",
      "Epoch 9, iter 321, loss 2.255979061126709, acc 0.1599999964237213\n",
      "Epoch 9, iter 322, loss 2.2354912757873535, acc 0.1599999964237213\n",
      "Epoch 9, iter 323, loss 2.190213441848755, acc 0.18000000715255737\n",
      "Epoch 9, iter 324, loss 2.162567615509033, acc 0.23999999463558197\n",
      "Epoch 9, iter 325, loss 2.224168300628662, acc 0.15000000596046448\n",
      "Epoch 9, iter 326, loss 2.163193464279175, acc 0.2199999988079071\n",
      "Epoch 9, iter 327, loss 2.1885383129119873, acc 0.27000001072883606\n",
      "Epoch 9, iter 328, loss 2.266831874847412, acc 0.17000000178813934\n",
      "Epoch 9, iter 329, loss 2.248551607131958, acc 0.1599999964237213\n",
      "Epoch 9, iter 330, loss 2.1709771156311035, acc 0.2199999988079071\n",
      "Epoch 9, iter 331, loss 2.147080183029175, acc 0.23999999463558197\n",
      "Epoch 9, iter 332, loss 2.1282784938812256, acc 0.1899999976158142\n",
      "Epoch 9, iter 333, loss 2.138143301010132, acc 0.23000000417232513\n",
      "Epoch 9, iter 334, loss 2.1821107864379883, acc 0.1899999976158142\n",
      "Epoch 9, iter 335, loss 2.077828884124756, acc 0.27000001072883606\n",
      "Epoch 9, iter 336, loss 2.1594862937927246, acc 0.17000000178813934\n",
      "Epoch 9, iter 337, loss 2.2612714767456055, acc 0.2199999988079071\n",
      "Epoch 9, iter 338, loss 2.114670515060425, acc 0.20999999344348907\n",
      "Epoch 9, iter 339, loss 2.062567710876465, acc 0.23000000417232513\n",
      "Epoch 9, iter 340, loss 2.2399232387542725, acc 0.18000000715255737\n",
      "Epoch 9, iter 341, loss 2.1279706954956055, acc 0.27000001072883606\n",
      "Epoch 9, iter 342, loss 2.130674362182617, acc 0.1899999976158142\n",
      "Epoch 9, iter 343, loss 2.2658743858337402, acc 0.18000000715255737\n",
      "Epoch 9, iter 344, loss 2.2747106552124023, acc 0.14000000059604645\n",
      "Epoch 9, iter 345, loss 2.2920262813568115, acc 0.18000000715255737\n",
      "Epoch 9, iter 346, loss 2.2008728981018066, acc 0.2199999988079071\n",
      "Epoch 9, iter 347, loss 2.1345860958099365, acc 0.23000000417232513\n",
      "Epoch 9, iter 348, loss 2.127361297607422, acc 0.20999999344348907\n",
      "Epoch 9, iter 349, loss 2.1431024074554443, acc 0.20999999344348907\n",
      "Epoch 9, iter 350, loss 2.1745071411132812, acc 0.2199999988079071\n",
      "Epoch 9, iter 351, loss 2.168060064315796, acc 0.25\n",
      "Epoch 9, iter 352, loss 2.174452066421509, acc 0.20999999344348907\n",
      "Epoch 9, iter 353, loss 2.207704544067383, acc 0.1599999964237213\n",
      "Epoch 9, iter 354, loss 2.172776699066162, acc 0.2199999988079071\n",
      "Epoch 9, iter 355, loss 2.2037127017974854, acc 0.2199999988079071\n",
      "Epoch 9, iter 356, loss 2.1519622802734375, acc 0.27000001072883606\n",
      "Epoch 9, iter 357, loss 2.1487960815429688, acc 0.20999999344348907\n",
      "Epoch 9, iter 358, loss 2.1961116790771484, acc 0.2199999988079071\n",
      "Epoch 9, iter 359, loss 2.1716349124908447, acc 0.2199999988079071\n",
      "Epoch 9, iter 360, loss 2.1649231910705566, acc 0.17000000178813934\n",
      "Epoch 9, iter 361, loss 2.194039821624756, acc 0.20999999344348907\n",
      "Epoch 9, iter 362, loss 2.227661371231079, acc 0.1599999964237213\n",
      "Epoch 9, iter 363, loss 2.208871364593506, acc 0.1599999964237213\n",
      "Epoch 9, iter 364, loss 2.2135605812072754, acc 0.20000000298023224\n",
      "Epoch 9, iter 365, loss 2.201627254486084, acc 0.1899999976158142\n",
      "Epoch 9, iter 366, loss 2.1209585666656494, acc 0.25\n",
      "Epoch 9, iter 367, loss 2.2023062705993652, acc 0.20999999344348907\n",
      "Epoch 9, iter 368, loss 2.2115862369537354, acc 0.1899999976158142\n",
      "Epoch 9, iter 369, loss 2.2158937454223633, acc 0.23000000417232513\n",
      "Epoch 9, iter 370, loss 2.209768533706665, acc 0.23999999463558197\n",
      "Epoch 9, iter 371, loss 2.1860225200653076, acc 0.17000000178813934\n",
      "Epoch 9, iter 372, loss 2.164306879043579, acc 0.2199999988079071\n",
      "Epoch 9, iter 373, loss 2.1407573223114014, acc 0.23999999463558197\n",
      "Epoch 9, iter 374, loss 2.151639938354492, acc 0.23000000417232513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 375, loss 2.224868059158325, acc 0.09000000357627869\n",
      "Epoch 9, iter 376, loss 2.125481367111206, acc 0.25\n",
      "Epoch 9, iter 377, loss 2.219168186187744, acc 0.14000000059604645\n",
      "Epoch 9, iter 378, loss 2.187406063079834, acc 0.2199999988079071\n",
      "Epoch 9, iter 379, loss 2.2246930599212646, acc 0.2199999988079071\n",
      "Epoch 9, iter 380, loss 2.18098783493042, acc 0.25999999046325684\n",
      "Epoch 9, iter 381, loss 2.2358646392822266, acc 0.17000000178813934\n",
      "Epoch 9, iter 382, loss 2.0453853607177734, acc 0.28999999165534973\n",
      "Epoch 9, iter 383, loss 2.145141363143921, acc 0.23999999463558197\n",
      "Epoch 9, iter 384, loss 2.193441152572632, acc 0.2199999988079071\n",
      "Epoch 9, iter 385, loss 2.2691891193389893, acc 0.18000000715255737\n",
      "Epoch 9, iter 386, loss 2.148254632949829, acc 0.23000000417232513\n",
      "Epoch 9, iter 387, loss 2.1892735958099365, acc 0.18000000715255737\n",
      "Epoch 9, iter 388, loss 2.062462091445923, acc 0.25999999046325684\n",
      "Epoch 9, iter 389, loss 2.1705949306488037, acc 0.2199999988079071\n",
      "Epoch 9, iter 390, loss 2.2144806385040283, acc 0.27000001072883606\n",
      "Epoch 9, iter 391, loss 2.1027729511260986, acc 0.28999999165534973\n",
      "Epoch 9, iter 392, loss 2.251688241958618, acc 0.2199999988079071\n",
      "Epoch 9, iter 393, loss 2.1579582691192627, acc 0.27000001072883606\n",
      "Epoch 9, iter 394, loss 2.1076042652130127, acc 0.2800000011920929\n",
      "Epoch 9, iter 395, loss 2.1773061752319336, acc 0.20999999344348907\n",
      "Epoch 9, iter 396, loss 2.265700578689575, acc 0.20000000298023224\n",
      "Epoch 9, iter 397, loss 2.142852783203125, acc 0.23999999463558197\n",
      "Epoch 9, iter 398, loss 2.165700912475586, acc 0.28999999165534973\n",
      "Epoch 9, iter 399, loss 2.217423439025879, acc 0.1899999976158142\n",
      "Epoch 9, iter 400, loss 2.150996208190918, acc 0.20000000298023224\n",
      "Epoch 9, iter 401, loss 2.211289167404175, acc 0.25\n",
      "Epoch 9, iter 402, loss 2.117706298828125, acc 0.27000001072883606\n",
      "Epoch 9, iter 403, loss 2.210634231567383, acc 0.25\n",
      "Epoch 9, iter 404, loss 2.2863969802856445, acc 0.14000000059604645\n",
      "Epoch 9, iter 405, loss 2.202920913696289, acc 0.2199999988079071\n",
      "Epoch 9, iter 406, loss 2.2276439666748047, acc 0.1899999976158142\n",
      "Epoch 9, iter 407, loss 2.182903289794922, acc 0.17000000178813934\n",
      "Epoch 9, iter 408, loss 2.1028640270233154, acc 0.20999999344348907\n",
      "Epoch 9, iter 409, loss 2.2217299938201904, acc 0.23000000417232513\n",
      "Epoch 9, iter 410, loss 2.078845500946045, acc 0.4099999964237213\n",
      "Epoch 9, iter 411, loss 2.1910622119903564, acc 0.15000000596046448\n",
      "Epoch 9, iter 412, loss 2.132181406021118, acc 0.27000001072883606\n",
      "Epoch 9, iter 413, loss 2.2254297733306885, acc 0.2199999988079071\n",
      "Epoch 9, iter 414, loss 2.2708239555358887, acc 0.12999999523162842\n",
      "Epoch 9, iter 415, loss 2.2552976608276367, acc 0.1899999976158142\n",
      "Epoch 9, iter 416, loss 2.1745047569274902, acc 0.23000000417232513\n",
      "Epoch 9, iter 417, loss 2.1280012130737305, acc 0.1899999976158142\n",
      "Epoch 9, iter 418, loss 2.0536348819732666, acc 0.3499999940395355\n",
      "Epoch 9, iter 419, loss 2.123284101486206, acc 0.23000000417232513\n",
      "Epoch 9, iter 420, loss 2.2236034870147705, acc 0.14000000059604645\n",
      "Epoch 10, iter 1, loss 2.1772758960723877, acc 0.23000000417232513\n",
      "Epoch 10, iter 2, loss 2.202986478805542, acc 0.2199999988079071\n",
      "Epoch 10, iter 3, loss 2.184997797012329, acc 0.20999999344348907\n",
      "Epoch 10, iter 4, loss 2.2187716960906982, acc 0.20999999344348907\n",
      "Epoch 10, iter 5, loss 2.1543383598327637, acc 0.20000000298023224\n",
      "Epoch 10, iter 6, loss 2.1409599781036377, acc 0.2199999988079071\n",
      "Epoch 10, iter 7, loss 2.2456769943237305, acc 0.17000000178813934\n",
      "Epoch 10, iter 8, loss 2.1529934406280518, acc 0.25\n",
      "Epoch 10, iter 9, loss 2.1424155235290527, acc 0.23999999463558197\n",
      "Epoch 10, iter 10, loss 2.2073628902435303, acc 0.17000000178813934\n",
      "Epoch 10, iter 11, loss 2.29571533203125, acc 0.11999999731779099\n",
      "Epoch 10, iter 12, loss 2.229440689086914, acc 0.15000000596046448\n",
      "Epoch 10, iter 13, loss 2.1413984298706055, acc 0.18000000715255737\n",
      "Epoch 10, iter 14, loss 2.260972261428833, acc 0.17000000178813934\n",
      "Epoch 10, iter 15, loss 2.182435989379883, acc 0.1599999964237213\n",
      "Epoch 10, iter 16, loss 2.1535654067993164, acc 0.20000000298023224\n",
      "Epoch 10, iter 17, loss 2.152360677719116, acc 0.25999999046325684\n",
      "Epoch 10, iter 18, loss 2.2467784881591797, acc 0.1899999976158142\n",
      "Epoch 10, iter 19, loss 2.173402786254883, acc 0.20000000298023224\n",
      "Epoch 10, iter 20, loss 2.1510934829711914, acc 0.18000000715255737\n",
      "Epoch 10, iter 21, loss 2.186833620071411, acc 0.2199999988079071\n",
      "Epoch 10, iter 22, loss 2.219944715499878, acc 0.17000000178813934\n",
      "Epoch 10, iter 23, loss 2.166106939315796, acc 0.20000000298023224\n",
      "Epoch 10, iter 24, loss 2.0917396545410156, acc 0.2800000011920929\n",
      "Epoch 10, iter 25, loss 2.1520214080810547, acc 0.20999999344348907\n",
      "Epoch 10, iter 26, loss 2.239067316055298, acc 0.23000000417232513\n",
      "Epoch 10, iter 27, loss 2.1521761417388916, acc 0.20000000298023224\n",
      "Epoch 10, iter 28, loss 2.2178795337677, acc 0.20000000298023224\n",
      "Epoch 10, iter 29, loss 2.212876558303833, acc 0.20999999344348907\n",
      "Epoch 10, iter 30, loss 2.174853801727295, acc 0.23999999463558197\n",
      "Epoch 10, iter 31, loss 2.217024564743042, acc 0.20999999344348907\n",
      "Epoch 10, iter 32, loss 2.1576414108276367, acc 0.25\n",
      "Epoch 10, iter 33, loss 2.2173781394958496, acc 0.17000000178813934\n",
      "Epoch 10, iter 34, loss 2.1365153789520264, acc 0.25\n",
      "Epoch 10, iter 35, loss 2.270763635635376, acc 0.15000000596046448\n",
      "Epoch 10, iter 36, loss 2.2079334259033203, acc 0.20999999344348907\n",
      "Epoch 10, iter 37, loss 2.114858865737915, acc 0.20000000298023224\n",
      "Epoch 10, iter 38, loss 2.1384713649749756, acc 0.23000000417232513\n",
      "Epoch 10, iter 39, loss 2.207247734069824, acc 0.18000000715255737\n",
      "Epoch 10, iter 40, loss 2.097266912460327, acc 0.2800000011920929\n",
      "Epoch 10, iter 41, loss 2.249249219894409, acc 0.20999999344348907\n",
      "Epoch 10, iter 42, loss 2.1501476764678955, acc 0.23999999463558197\n",
      "Epoch 10, iter 43, loss 2.100813388824463, acc 0.2199999988079071\n",
      "Epoch 10, iter 44, loss 2.130749464035034, acc 0.23999999463558197\n",
      "Epoch 10, iter 45, loss 2.1954410076141357, acc 0.23000000417232513\n",
      "Epoch 10, iter 46, loss 2.1609106063842773, acc 0.18000000715255737\n",
      "Epoch 10, iter 47, loss 2.2530548572540283, acc 0.1599999964237213\n",
      "Epoch 10, iter 48, loss 2.1320226192474365, acc 0.2199999988079071\n",
      "Epoch 10, iter 49, loss 2.1607842445373535, acc 0.20999999344348907\n",
      "Epoch 10, iter 50, loss 2.1079838275909424, acc 0.23000000417232513\n",
      "Epoch 10, iter 51, loss 2.161701202392578, acc 0.18000000715255737\n",
      "Epoch 10, iter 52, loss 2.1805505752563477, acc 0.1599999964237213\n",
      "Epoch 10, iter 53, loss 2.1974666118621826, acc 0.09000000357627869\n",
      "Epoch 10, iter 54, loss 2.100710868835449, acc 0.27000001072883606\n",
      "Epoch 10, iter 55, loss 2.2637157440185547, acc 0.23999999463558197\n",
      "Epoch 10, iter 56, loss 2.1596555709838867, acc 0.27000001072883606\n",
      "Epoch 10, iter 57, loss 2.1837077140808105, acc 0.25\n",
      "Epoch 10, iter 58, loss 2.082399606704712, acc 0.33000001311302185\n",
      "Epoch 10, iter 59, loss 2.278862714767456, acc 0.20000000298023224\n",
      "Epoch 10, iter 60, loss 2.1325275897979736, acc 0.23999999463558197\n",
      "Epoch 10, iter 61, loss 2.1582846641540527, acc 0.2800000011920929\n",
      "Epoch 10, iter 62, loss 2.1959950923919678, acc 0.2199999988079071\n",
      "Epoch 10, iter 63, loss 2.2933411598205566, acc 0.12999999523162842\n",
      "Epoch 10, iter 64, loss 2.1507692337036133, acc 0.18000000715255737\n",
      "Epoch 10, iter 65, loss 2.218698024749756, acc 0.18000000715255737\n",
      "Epoch 10, iter 66, loss 2.2282702922821045, acc 0.17000000178813934\n",
      "Epoch 10, iter 67, loss 2.218707323074341, acc 0.18000000715255737\n",
      "Epoch 10, iter 68, loss 2.148439884185791, acc 0.2199999988079071\n",
      "Epoch 10, iter 69, loss 2.140611171722412, acc 0.2199999988079071\n",
      "Epoch 10, iter 70, loss 2.1890881061553955, acc 0.1599999964237213\n",
      "Epoch 10, iter 71, loss 2.2090096473693848, acc 0.20000000298023224\n",
      "Epoch 10, iter 72, loss 2.178035020828247, acc 0.25\n",
      "Epoch 10, iter 73, loss 2.1544415950775146, acc 0.20000000298023224\n",
      "Epoch 10, iter 74, loss 2.168617010116577, acc 0.23999999463558197\n",
      "Epoch 10, iter 75, loss 2.100687026977539, acc 0.2800000011920929\n",
      "Epoch 10, iter 76, loss 2.1126363277435303, acc 0.28999999165534973\n",
      "Epoch 10, iter 77, loss 2.2028348445892334, acc 0.15000000596046448\n",
      "Epoch 10, iter 78, loss 2.1687886714935303, acc 0.18000000715255737\n",
      "Epoch 10, iter 79, loss 2.1739540100097656, acc 0.20000000298023224\n",
      "Epoch 10, iter 80, loss 2.2917356491088867, acc 0.18000000715255737\n",
      "Epoch 10, iter 81, loss 2.1876418590545654, acc 0.18000000715255737\n",
      "Epoch 10, iter 82, loss 2.2090303897857666, acc 0.1899999976158142\n",
      "Epoch 10, iter 83, loss 2.164553165435791, acc 0.23000000417232513\n",
      "Epoch 10, iter 84, loss 2.2010250091552734, acc 0.28999999165534973\n",
      "Epoch 10, iter 85, loss 2.262594699859619, acc 0.23000000417232513\n",
      "Epoch 10, iter 86, loss 2.16506290435791, acc 0.20999999344348907\n",
      "Epoch 10, iter 87, loss 2.091137647628784, acc 0.2800000011920929\n",
      "Epoch 10, iter 88, loss 2.147747278213501, acc 0.20999999344348907\n",
      "Epoch 10, iter 89, loss 2.1882145404815674, acc 0.18000000715255737\n",
      "Epoch 10, iter 90, loss 2.144050359725952, acc 0.30000001192092896\n",
      "Epoch 10, iter 91, loss 2.1841471195220947, acc 0.23000000417232513\n",
      "Epoch 10, iter 92, loss 2.170166492462158, acc 0.23000000417232513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 93, loss 2.1679975986480713, acc 0.23000000417232513\n",
      "Epoch 10, iter 94, loss 2.1502649784088135, acc 0.2199999988079071\n",
      "Epoch 10, iter 95, loss 2.2234537601470947, acc 0.18000000715255737\n",
      "Epoch 10, iter 96, loss 2.1434366703033447, acc 0.2199999988079071\n",
      "Epoch 10, iter 97, loss 2.22461199760437, acc 0.18000000715255737\n",
      "Epoch 10, iter 98, loss 2.1468214988708496, acc 0.23000000417232513\n",
      "Epoch 10, iter 99, loss 2.242908239364624, acc 0.2199999988079071\n",
      "Epoch 10, iter 100, loss 2.1781821250915527, acc 0.18000000715255737\n",
      "Epoch 10, iter 101, loss 2.15535831451416, acc 0.25\n",
      "Epoch 10, iter 102, loss 2.1005425453186035, acc 0.20999999344348907\n",
      "Epoch 10, iter 103, loss 2.143484592437744, acc 0.23000000417232513\n",
      "Epoch 10, iter 104, loss 2.2143912315368652, acc 0.20000000298023224\n",
      "Epoch 10, iter 105, loss 2.1654324531555176, acc 0.23999999463558197\n",
      "Epoch 10, iter 106, loss 2.205932855606079, acc 0.12999999523162842\n",
      "Epoch 10, iter 107, loss 2.1792633533477783, acc 0.20000000298023224\n",
      "Epoch 10, iter 108, loss 2.1245076656341553, acc 0.20000000298023224\n",
      "Epoch 10, iter 109, loss 2.1758100986480713, acc 0.20000000298023224\n",
      "Epoch 10, iter 110, loss 2.234872341156006, acc 0.20000000298023224\n",
      "Epoch 10, iter 111, loss 2.2167158126831055, acc 0.20999999344348907\n",
      "Epoch 10, iter 112, loss 2.2257416248321533, acc 0.14000000059604645\n",
      "Epoch 10, iter 113, loss 2.1246895790100098, acc 0.2800000011920929\n",
      "Epoch 10, iter 114, loss 2.1554269790649414, acc 0.1899999976158142\n",
      "Epoch 10, iter 115, loss 2.23040509223938, acc 0.18000000715255737\n",
      "Epoch 10, iter 116, loss 2.1866517066955566, acc 0.23000000417232513\n",
      "Epoch 10, iter 117, loss 2.18170166015625, acc 0.2199999988079071\n",
      "Epoch 10, iter 118, loss 2.187817335128784, acc 0.25\n",
      "Epoch 10, iter 119, loss 2.1504294872283936, acc 0.20000000298023224\n",
      "Epoch 10, iter 120, loss 2.1880903244018555, acc 0.14000000059604645\n",
      "Epoch 10, iter 121, loss 2.164604902267456, acc 0.20999999344348907\n",
      "Epoch 10, iter 122, loss 2.2082602977752686, acc 0.1899999976158142\n",
      "Epoch 10, iter 123, loss 2.1404905319213867, acc 0.23000000417232513\n",
      "Epoch 10, iter 124, loss 2.147681713104248, acc 0.25999999046325684\n",
      "Epoch 10, iter 125, loss 2.1497397422790527, acc 0.25\n",
      "Epoch 10, iter 126, loss 2.1337661743164062, acc 0.27000001072883606\n",
      "Epoch 10, iter 127, loss 2.223444700241089, acc 0.20000000298023224\n",
      "Epoch 10, iter 128, loss 2.167111873626709, acc 0.18000000715255737\n",
      "Epoch 10, iter 129, loss 2.2199690341949463, acc 0.2199999988079071\n",
      "Epoch 10, iter 130, loss 2.1862142086029053, acc 0.20000000298023224\n",
      "Epoch 10, iter 131, loss 2.172034978866577, acc 0.20999999344348907\n",
      "Epoch 10, iter 132, loss 2.178171157836914, acc 0.18000000715255737\n",
      "Epoch 10, iter 133, loss 2.1683349609375, acc 0.20999999344348907\n",
      "Epoch 10, iter 134, loss 2.1666769981384277, acc 0.25\n",
      "Epoch 10, iter 135, loss 2.195103645324707, acc 0.20000000298023224\n",
      "Epoch 10, iter 136, loss 2.221583843231201, acc 0.17000000178813934\n",
      "Epoch 10, iter 137, loss 2.289036512374878, acc 0.15000000596046448\n",
      "Epoch 10, iter 138, loss 2.152764081954956, acc 0.20999999344348907\n",
      "Epoch 10, iter 139, loss 2.197709798812866, acc 0.1599999964237213\n",
      "Epoch 10, iter 140, loss 2.205228090286255, acc 0.2199999988079071\n",
      "Epoch 10, iter 141, loss 2.2651102542877197, acc 0.15000000596046448\n",
      "Epoch 10, iter 142, loss 2.166882276535034, acc 0.1899999976158142\n",
      "Epoch 10, iter 143, loss 2.188246965408325, acc 0.18000000715255737\n",
      "Epoch 10, iter 144, loss 2.207169532775879, acc 0.1899999976158142\n",
      "Epoch 10, iter 145, loss 2.1904592514038086, acc 0.2199999988079071\n",
      "Epoch 10, iter 146, loss 2.179750680923462, acc 0.20000000298023224\n",
      "Epoch 10, iter 147, loss 2.1574695110321045, acc 0.20000000298023224\n",
      "Epoch 10, iter 148, loss 2.108992099761963, acc 0.2199999988079071\n",
      "Epoch 10, iter 149, loss 2.1773154735565186, acc 0.23000000417232513\n",
      "Epoch 10, iter 150, loss 2.0736591815948486, acc 0.23999999463558197\n",
      "Epoch 10, iter 151, loss 2.1267154216766357, acc 0.23999999463558197\n",
      "Epoch 10, iter 152, loss 2.1392412185668945, acc 0.23000000417232513\n",
      "Epoch 10, iter 153, loss 2.174001693725586, acc 0.20999999344348907\n",
      "Epoch 10, iter 154, loss 2.153655529022217, acc 0.2199999988079071\n",
      "Epoch 10, iter 155, loss 2.125190258026123, acc 0.20999999344348907\n",
      "Epoch 10, iter 156, loss 2.163384199142456, acc 0.30000001192092896\n",
      "Epoch 10, iter 157, loss 2.2342424392700195, acc 0.14000000059604645\n",
      "Epoch 10, iter 158, loss 2.261435031890869, acc 0.1599999964237213\n",
      "Epoch 10, iter 159, loss 2.132413625717163, acc 0.20000000298023224\n",
      "Epoch 10, iter 160, loss 2.19389271736145, acc 0.20000000298023224\n",
      "Epoch 10, iter 161, loss 2.2598204612731934, acc 0.15000000596046448\n",
      "Epoch 10, iter 162, loss 2.156313419342041, acc 0.25999999046325684\n",
      "Epoch 10, iter 163, loss 2.192193031311035, acc 0.25999999046325684\n",
      "Epoch 10, iter 164, loss 2.2098886966705322, acc 0.23000000417232513\n",
      "Epoch 10, iter 165, loss 2.19614315032959, acc 0.1599999964237213\n",
      "Epoch 10, iter 166, loss 2.216066360473633, acc 0.1899999976158142\n",
      "Epoch 10, iter 167, loss 2.192661762237549, acc 0.1899999976158142\n",
      "Epoch 10, iter 168, loss 2.178658962249756, acc 0.1899999976158142\n",
      "Epoch 10, iter 169, loss 2.1646459102630615, acc 0.1899999976158142\n",
      "Epoch 10, iter 170, loss 2.1772732734680176, acc 0.23999999463558197\n",
      "Epoch 10, iter 171, loss 2.2012970447540283, acc 0.25999999046325684\n",
      "Epoch 10, iter 172, loss 2.214024305343628, acc 0.1899999976158142\n",
      "Epoch 10, iter 173, loss 2.1990163326263428, acc 0.20999999344348907\n",
      "Epoch 10, iter 174, loss 2.154949426651001, acc 0.30000001192092896\n",
      "Epoch 10, iter 175, loss 2.1915433406829834, acc 0.2199999988079071\n",
      "Epoch 10, iter 176, loss 2.1890921592712402, acc 0.25\n",
      "Epoch 10, iter 177, loss 2.1964523792266846, acc 0.17000000178813934\n",
      "Epoch 10, iter 178, loss 2.2211430072784424, acc 0.20000000298023224\n",
      "Epoch 10, iter 179, loss 2.1633214950561523, acc 0.23999999463558197\n",
      "Epoch 10, iter 180, loss 2.226865291595459, acc 0.1899999976158142\n",
      "Epoch 10, iter 181, loss 2.1218934059143066, acc 0.25999999046325684\n",
      "Epoch 10, iter 182, loss 2.109182357788086, acc 0.27000001072883606\n",
      "Epoch 10, iter 183, loss 2.1227540969848633, acc 0.23999999463558197\n",
      "Epoch 10, iter 184, loss 2.155534029006958, acc 0.23000000417232513\n",
      "Epoch 10, iter 185, loss 2.1283814907073975, acc 0.20999999344348907\n",
      "Epoch 10, iter 186, loss 2.1727182865142822, acc 0.20000000298023224\n",
      "Epoch 10, iter 187, loss 2.1370155811309814, acc 0.27000001072883606\n",
      "Epoch 10, iter 188, loss 2.199711561203003, acc 0.20000000298023224\n",
      "Epoch 10, iter 189, loss 2.1463654041290283, acc 0.20999999344348907\n",
      "Epoch 10, iter 190, loss 2.133653163909912, acc 0.25\n",
      "Epoch 10, iter 191, loss 2.1438722610473633, acc 0.20999999344348907\n",
      "Epoch 10, iter 192, loss 2.211242914199829, acc 0.23000000417232513\n",
      "Epoch 10, iter 193, loss 2.1243844032287598, acc 0.23999999463558197\n",
      "Epoch 10, iter 194, loss 2.1800453662872314, acc 0.2199999988079071\n",
      "Epoch 10, iter 195, loss 2.3314616680145264, acc 0.11999999731779099\n",
      "Epoch 10, iter 196, loss 2.192392110824585, acc 0.23000000417232513\n",
      "Epoch 10, iter 197, loss 2.210254430770874, acc 0.1899999976158142\n",
      "Epoch 10, iter 198, loss 2.1440324783325195, acc 0.1599999964237213\n",
      "Epoch 10, iter 199, loss 2.1872365474700928, acc 0.15000000596046448\n",
      "Epoch 10, iter 200, loss 2.2188451290130615, acc 0.17000000178813934\n",
      "Epoch 10, iter 201, loss 2.18011474609375, acc 0.25\n",
      "Epoch 10, iter 202, loss 2.235762357711792, acc 0.20000000298023224\n",
      "Epoch 10, iter 203, loss 2.2526795864105225, acc 0.20000000298023224\n",
      "Epoch 10, iter 204, loss 2.124985456466675, acc 0.25999999046325684\n",
      "Epoch 10, iter 205, loss 2.0883359909057617, acc 0.28999999165534973\n",
      "Epoch 10, iter 206, loss 2.1992104053497314, acc 0.1899999976158142\n",
      "Epoch 10, iter 207, loss 2.112515449523926, acc 0.2800000011920929\n",
      "Epoch 10, iter 208, loss 2.1956043243408203, acc 0.23000000417232513\n",
      "Epoch 10, iter 209, loss 2.2878808975219727, acc 0.17000000178813934\n",
      "Epoch 10, iter 210, loss 2.253636121749878, acc 0.1599999964237213\n",
      "Epoch 10, iter 211, loss 2.117600440979004, acc 0.25\n",
      "Epoch 10, iter 212, loss 2.1434853076934814, acc 0.20999999344348907\n",
      "Epoch 10, iter 213, loss 2.1371028423309326, acc 0.25999999046325684\n",
      "Epoch 10, iter 214, loss 2.1900362968444824, acc 0.20999999344348907\n",
      "Epoch 10, iter 215, loss 2.1739635467529297, acc 0.23999999463558197\n",
      "Epoch 10, iter 216, loss 2.150195598602295, acc 0.20999999344348907\n",
      "Epoch 10, iter 217, loss 2.129631280899048, acc 0.17000000178813934\n",
      "Epoch 10, iter 218, loss 2.2175519466400146, acc 0.2199999988079071\n",
      "Epoch 10, iter 219, loss 2.165451765060425, acc 0.23000000417232513\n",
      "Epoch 10, iter 220, loss 2.1524667739868164, acc 0.20999999344348907\n",
      "Epoch 10, iter 221, loss 2.1234915256500244, acc 0.2800000011920929\n",
      "Epoch 10, iter 222, loss 2.2412126064300537, acc 0.12999999523162842\n",
      "Epoch 10, iter 223, loss 2.1801953315734863, acc 0.20999999344348907\n",
      "Epoch 10, iter 224, loss 2.1435916423797607, acc 0.2199999988079071\n",
      "Epoch 10, iter 225, loss 2.098100423812866, acc 0.23000000417232513\n",
      "Epoch 10, iter 226, loss 2.200270652770996, acc 0.17000000178813934\n",
      "Epoch 10, iter 227, loss 2.1801764965057373, acc 0.1599999964237213\n",
      "Epoch 10, iter 228, loss 2.140012502670288, acc 0.20999999344348907\n",
      "Epoch 10, iter 229, loss 2.1952011585235596, acc 0.1899999976158142\n",
      "Epoch 10, iter 230, loss 2.202334403991699, acc 0.11999999731779099\n",
      "Epoch 10, iter 231, loss 2.2129294872283936, acc 0.15000000596046448\n",
      "Epoch 10, iter 232, loss 2.200786590576172, acc 0.20999999344348907\n",
      "Epoch 10, iter 233, loss 2.162982225418091, acc 0.27000001072883606\n",
      "Epoch 10, iter 234, loss 2.149247407913208, acc 0.23000000417232513\n",
      "Epoch 10, iter 235, loss 2.2051520347595215, acc 0.1899999976158142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 236, loss 2.262378692626953, acc 0.1899999976158142\n",
      "Epoch 10, iter 237, loss 2.2014877796173096, acc 0.20999999344348907\n",
      "Epoch 10, iter 238, loss 2.1037802696228027, acc 0.27000001072883606\n",
      "Epoch 10, iter 239, loss 2.174349069595337, acc 0.25999999046325684\n",
      "Epoch 10, iter 240, loss 2.201342821121216, acc 0.1899999976158142\n",
      "Epoch 10, iter 241, loss 2.1888022422790527, acc 0.23999999463558197\n",
      "Epoch 10, iter 242, loss 2.291778802871704, acc 0.1599999964237213\n",
      "Epoch 10, iter 243, loss 2.2448344230651855, acc 0.18000000715255737\n",
      "Epoch 10, iter 244, loss 2.218754529953003, acc 0.1899999976158142\n",
      "Epoch 10, iter 245, loss 2.107320785522461, acc 0.27000001072883606\n",
      "Epoch 10, iter 246, loss 2.1788976192474365, acc 0.1899999976158142\n",
      "Epoch 10, iter 247, loss 2.1166393756866455, acc 0.23000000417232513\n",
      "Epoch 10, iter 248, loss 2.146834373474121, acc 0.20000000298023224\n",
      "Epoch 10, iter 249, loss 2.1405439376831055, acc 0.23000000417232513\n",
      "Epoch 10, iter 250, loss 2.2152717113494873, acc 0.1899999976158142\n",
      "Epoch 10, iter 251, loss 2.1676642894744873, acc 0.25\n",
      "Epoch 10, iter 252, loss 2.1327459812164307, acc 0.23000000417232513\n",
      "Epoch 10, iter 253, loss 2.3087236881256104, acc 0.18000000715255737\n",
      "Epoch 10, iter 254, loss 2.175370454788208, acc 0.2199999988079071\n",
      "Epoch 10, iter 255, loss 2.237744092941284, acc 0.20999999344348907\n",
      "Epoch 10, iter 256, loss 2.136239528656006, acc 0.2800000011920929\n",
      "Epoch 10, iter 257, loss 2.114816188812256, acc 0.2199999988079071\n",
      "Epoch 10, iter 258, loss 2.222707986831665, acc 0.20999999344348907\n",
      "Epoch 10, iter 259, loss 2.248522996902466, acc 0.1899999976158142\n",
      "Epoch 10, iter 260, loss 2.1353132724761963, acc 0.23000000417232513\n",
      "Epoch 10, iter 261, loss 2.1555569171905518, acc 0.25\n",
      "Epoch 10, iter 262, loss 2.1846797466278076, acc 0.23999999463558197\n",
      "Epoch 10, iter 263, loss 2.1278417110443115, acc 0.25\n",
      "Epoch 10, iter 264, loss 2.169285774230957, acc 0.15000000596046448\n",
      "Epoch 10, iter 265, loss 2.1548218727111816, acc 0.18000000715255737\n",
      "Epoch 10, iter 266, loss 2.237105369567871, acc 0.20999999344348907\n",
      "Epoch 10, iter 267, loss 2.228233575820923, acc 0.10999999940395355\n",
      "Epoch 10, iter 268, loss 2.152961492538452, acc 0.2199999988079071\n",
      "Epoch 10, iter 269, loss 2.1455276012420654, acc 0.23999999463558197\n",
      "Epoch 10, iter 270, loss 2.2060458660125732, acc 0.1899999976158142\n",
      "Epoch 10, iter 271, loss 2.0736451148986816, acc 0.3100000023841858\n",
      "Epoch 10, iter 272, loss 2.1834282875061035, acc 0.1899999976158142\n",
      "Epoch 10, iter 273, loss 2.170377254486084, acc 0.20000000298023224\n",
      "Epoch 10, iter 274, loss 2.259979486465454, acc 0.1899999976158142\n",
      "Epoch 10, iter 275, loss 2.1771059036254883, acc 0.20999999344348907\n",
      "Epoch 10, iter 276, loss 2.1818456649780273, acc 0.23000000417232513\n",
      "Epoch 10, iter 277, loss 2.0826802253723145, acc 0.23000000417232513\n",
      "Epoch 10, iter 278, loss 2.0565123558044434, acc 0.3700000047683716\n",
      "Epoch 10, iter 279, loss 2.2296042442321777, acc 0.1599999964237213\n",
      "Epoch 10, iter 280, loss 2.1716463565826416, acc 0.2199999988079071\n",
      "Epoch 10, iter 281, loss 2.1882779598236084, acc 0.14000000059604645\n",
      "Epoch 10, iter 282, loss 2.0805275440216064, acc 0.3100000023841858\n",
      "Epoch 10, iter 283, loss 2.16732120513916, acc 0.20000000298023224\n",
      "Epoch 10, iter 284, loss 2.134556531906128, acc 0.2199999988079071\n",
      "Epoch 10, iter 285, loss 2.206155300140381, acc 0.20999999344348907\n",
      "Epoch 10, iter 286, loss 2.1070303916931152, acc 0.25999999046325684\n",
      "Epoch 10, iter 287, loss 2.186467170715332, acc 0.23999999463558197\n",
      "Epoch 10, iter 288, loss 2.2856268882751465, acc 0.1599999964237213\n",
      "Epoch 10, iter 289, loss 2.2137610912323, acc 0.18000000715255737\n",
      "Epoch 10, iter 290, loss 2.189617156982422, acc 0.18000000715255737\n",
      "Epoch 10, iter 291, loss 2.2346184253692627, acc 0.1899999976158142\n",
      "Epoch 10, iter 292, loss 2.172464370727539, acc 0.23000000417232513\n",
      "Epoch 10, iter 293, loss 2.222421646118164, acc 0.20000000298023224\n",
      "Epoch 10, iter 294, loss 2.1202003955841064, acc 0.25\n",
      "Epoch 10, iter 295, loss 2.167301893234253, acc 0.2199999988079071\n",
      "Epoch 10, iter 296, loss 2.130441427230835, acc 0.23000000417232513\n",
      "Epoch 10, iter 297, loss 2.1782779693603516, acc 0.18000000715255737\n",
      "Epoch 10, iter 298, loss 2.0935444831848145, acc 0.25999999046325684\n",
      "Epoch 10, iter 299, loss 2.2612669467926025, acc 0.20000000298023224\n",
      "Epoch 10, iter 300, loss 2.1135849952697754, acc 0.2199999988079071\n",
      "Epoch 10, iter 301, loss 2.209012031555176, acc 0.23000000417232513\n",
      "Epoch 10, iter 302, loss 2.192190170288086, acc 0.14000000059604645\n",
      "Epoch 10, iter 303, loss 2.1839170455932617, acc 0.20999999344348907\n",
      "Epoch 10, iter 304, loss 2.127706289291382, acc 0.25999999046325684\n",
      "Epoch 10, iter 305, loss 2.184079170227051, acc 0.1899999976158142\n",
      "Epoch 10, iter 306, loss 2.150890827178955, acc 0.23999999463558197\n",
      "Epoch 10, iter 307, loss 2.2028565406799316, acc 0.15000000596046448\n",
      "Epoch 10, iter 308, loss 2.205810546875, acc 0.15000000596046448\n",
      "Epoch 10, iter 309, loss 2.0909109115600586, acc 0.23000000417232513\n",
      "Epoch 10, iter 310, loss 2.2090609073638916, acc 0.17000000178813934\n",
      "Epoch 10, iter 311, loss 2.1969406604766846, acc 0.1899999976158142\n",
      "Epoch 10, iter 312, loss 2.1260993480682373, acc 0.1899999976158142\n",
      "Epoch 10, iter 313, loss 2.2248809337615967, acc 0.17000000178813934\n",
      "Epoch 10, iter 314, loss 2.1613099575042725, acc 0.17000000178813934\n",
      "Epoch 10, iter 315, loss 2.159261703491211, acc 0.18000000715255737\n",
      "Epoch 10, iter 316, loss 2.1982243061065674, acc 0.30000001192092896\n",
      "Epoch 10, iter 317, loss 2.21378231048584, acc 0.1599999964237213\n",
      "Epoch 10, iter 318, loss 2.0684168338775635, acc 0.2800000011920929\n",
      "Epoch 10, iter 319, loss 2.105398654937744, acc 0.2199999988079071\n",
      "Epoch 10, iter 320, loss 2.189452886581421, acc 0.20999999344348907\n",
      "Epoch 10, iter 321, loss 2.242814064025879, acc 0.17000000178813934\n",
      "Epoch 10, iter 322, loss 2.233102321624756, acc 0.15000000596046448\n",
      "Epoch 10, iter 323, loss 2.193852186203003, acc 0.17000000178813934\n",
      "Epoch 10, iter 324, loss 2.160691022872925, acc 0.23999999463558197\n",
      "Epoch 10, iter 325, loss 2.216031551361084, acc 0.14000000059604645\n",
      "Epoch 10, iter 326, loss 2.1673848628997803, acc 0.2199999988079071\n",
      "Epoch 10, iter 327, loss 2.181349039077759, acc 0.2800000011920929\n",
      "Epoch 10, iter 328, loss 2.243830919265747, acc 0.17000000178813934\n",
      "Epoch 10, iter 329, loss 2.203495740890503, acc 0.18000000715255737\n",
      "Epoch 10, iter 330, loss 2.1609599590301514, acc 0.2199999988079071\n",
      "Epoch 10, iter 331, loss 2.1231322288513184, acc 0.25\n",
      "Epoch 10, iter 332, loss 2.1102025508880615, acc 0.1899999976158142\n",
      "Epoch 10, iter 333, loss 2.135793685913086, acc 0.2199999988079071\n",
      "Epoch 10, iter 334, loss 2.1480002403259277, acc 0.20000000298023224\n",
      "Epoch 10, iter 335, loss 2.0567495822906494, acc 0.2800000011920929\n",
      "Epoch 10, iter 336, loss 2.1631991863250732, acc 0.17000000178813934\n",
      "Epoch 10, iter 337, loss 2.231672763824463, acc 0.23000000417232513\n",
      "Epoch 10, iter 338, loss 2.117893695831299, acc 0.20999999344348907\n",
      "Epoch 10, iter 339, loss 2.0428624153137207, acc 0.23999999463558197\n",
      "Epoch 10, iter 340, loss 2.24121356010437, acc 0.18000000715255737\n",
      "Epoch 10, iter 341, loss 2.1192688941955566, acc 0.27000001072883606\n",
      "Epoch 10, iter 342, loss 2.1187009811401367, acc 0.1899999976158142\n",
      "Epoch 10, iter 343, loss 2.225999355316162, acc 0.18000000715255737\n",
      "Epoch 10, iter 344, loss 2.2584526538848877, acc 0.15000000596046448\n",
      "Epoch 10, iter 345, loss 2.277637481689453, acc 0.1899999976158142\n",
      "Epoch 10, iter 346, loss 2.1890506744384766, acc 0.23000000417232513\n",
      "Epoch 10, iter 347, loss 2.1388065814971924, acc 0.23999999463558197\n",
      "Epoch 10, iter 348, loss 2.1082072257995605, acc 0.20999999344348907\n",
      "Epoch 10, iter 349, loss 2.128967523574829, acc 0.23000000417232513\n",
      "Epoch 10, iter 350, loss 2.1205155849456787, acc 0.23999999463558197\n",
      "Epoch 10, iter 351, loss 2.1446588039398193, acc 0.27000001072883606\n",
      "Epoch 10, iter 352, loss 2.162977695465088, acc 0.2199999988079071\n",
      "Epoch 10, iter 353, loss 2.193387985229492, acc 0.17000000178813934\n",
      "Epoch 10, iter 354, loss 2.1681745052337646, acc 0.2199999988079071\n",
      "Epoch 10, iter 355, loss 2.194911479949951, acc 0.2199999988079071\n",
      "Epoch 10, iter 356, loss 2.137042284011841, acc 0.2800000011920929\n",
      "Epoch 10, iter 357, loss 2.1424920558929443, acc 0.20999999344348907\n",
      "Epoch 10, iter 358, loss 2.179558753967285, acc 0.2199999988079071\n",
      "Epoch 10, iter 359, loss 2.1605608463287354, acc 0.23999999463558197\n",
      "Epoch 10, iter 360, loss 2.1418654918670654, acc 0.1899999976158142\n",
      "Epoch 10, iter 361, loss 2.1701695919036865, acc 0.2199999988079071\n",
      "Epoch 10, iter 362, loss 2.2059571743011475, acc 0.17000000178813934\n",
      "Epoch 10, iter 363, loss 2.2110676765441895, acc 0.15000000596046448\n",
      "Epoch 10, iter 364, loss 2.2029573917388916, acc 0.20000000298023224\n",
      "Epoch 10, iter 365, loss 2.1727402210235596, acc 0.20000000298023224\n",
      "Epoch 10, iter 366, loss 2.0714638233184814, acc 0.25999999046325684\n",
      "Epoch 10, iter 367, loss 2.1908257007598877, acc 0.20999999344348907\n",
      "Epoch 10, iter 368, loss 2.210909843444824, acc 0.18000000715255737\n",
      "Epoch 10, iter 369, loss 2.203444480895996, acc 0.23000000417232513\n",
      "Epoch 10, iter 370, loss 2.196107864379883, acc 0.23999999463558197\n",
      "Epoch 10, iter 371, loss 2.1487646102905273, acc 0.20000000298023224\n",
      "Epoch 10, iter 372, loss 2.1555609703063965, acc 0.20999999344348907\n",
      "Epoch 10, iter 373, loss 2.1193490028381348, acc 0.25\n",
      "Epoch 10, iter 374, loss 2.141646385192871, acc 0.23000000417232513\n",
      "Epoch 10, iter 375, loss 2.1909961700439453, acc 0.10000000149011612\n",
      "Epoch 10, iter 376, loss 2.1076433658599854, acc 0.25999999046325684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 377, loss 2.2055068016052246, acc 0.14000000059604645\n",
      "Epoch 10, iter 378, loss 2.16641902923584, acc 0.2199999988079071\n",
      "Epoch 10, iter 379, loss 2.2151401042938232, acc 0.2199999988079071\n",
      "Epoch 10, iter 380, loss 2.171442985534668, acc 0.25999999046325684\n",
      "Epoch 10, iter 381, loss 2.2275848388671875, acc 0.17000000178813934\n",
      "Epoch 10, iter 382, loss 2.0345559120178223, acc 0.2800000011920929\n",
      "Epoch 10, iter 383, loss 2.118654251098633, acc 0.25\n",
      "Epoch 10, iter 384, loss 2.165942430496216, acc 0.23000000417232513\n",
      "Epoch 10, iter 385, loss 2.2283437252044678, acc 0.1899999976158142\n",
      "Epoch 10, iter 386, loss 2.137420177459717, acc 0.23000000417232513\n",
      "Epoch 10, iter 387, loss 2.173823356628418, acc 0.1899999976158142\n",
      "Epoch 10, iter 388, loss 2.06024169921875, acc 0.2800000011920929\n",
      "Epoch 10, iter 389, loss 2.159045934677124, acc 0.23000000417232513\n",
      "Epoch 10, iter 390, loss 2.175185203552246, acc 0.2800000011920929\n",
      "Epoch 10, iter 391, loss 2.0834341049194336, acc 0.30000001192092896\n",
      "Epoch 10, iter 392, loss 2.242462158203125, acc 0.23000000417232513\n",
      "Epoch 10, iter 393, loss 2.1365883350372314, acc 0.27000001072883606\n",
      "Epoch 10, iter 394, loss 2.1061182022094727, acc 0.2800000011920929\n",
      "Epoch 10, iter 395, loss 2.1842246055603027, acc 0.20000000298023224\n",
      "Epoch 10, iter 396, loss 2.2569141387939453, acc 0.20000000298023224\n",
      "Epoch 10, iter 397, loss 2.125530958175659, acc 0.23999999463558197\n",
      "Epoch 10, iter 398, loss 2.158848285675049, acc 0.28999999165534973\n",
      "Epoch 10, iter 399, loss 2.176333427429199, acc 0.2199999988079071\n",
      "Epoch 10, iter 400, loss 2.1224260330200195, acc 0.20000000298023224\n",
      "Epoch 10, iter 401, loss 2.193054437637329, acc 0.25999999046325684\n",
      "Epoch 10, iter 402, loss 2.1152231693267822, acc 0.27000001072883606\n",
      "Epoch 10, iter 403, loss 2.1824703216552734, acc 0.25999999046325684\n",
      "Epoch 10, iter 404, loss 2.2754900455474854, acc 0.14000000059604645\n",
      "Epoch 10, iter 405, loss 2.1901535987854004, acc 0.2199999988079071\n",
      "Epoch 10, iter 406, loss 2.1825826168060303, acc 0.1899999976158142\n",
      "Epoch 10, iter 407, loss 2.1753287315368652, acc 0.17000000178813934\n",
      "Epoch 10, iter 408, loss 2.1066925525665283, acc 0.20000000298023224\n",
      "Epoch 10, iter 409, loss 2.2012109756469727, acc 0.23999999463558197\n",
      "Epoch 10, iter 410, loss 2.0953309535980225, acc 0.38999998569488525\n",
      "Epoch 10, iter 411, loss 2.1814301013946533, acc 0.15000000596046448\n",
      "Epoch 10, iter 412, loss 2.1327178478240967, acc 0.27000001072883606\n",
      "Epoch 10, iter 413, loss 2.212374687194824, acc 0.2199999988079071\n",
      "Epoch 10, iter 414, loss 2.266495704650879, acc 0.12999999523162842\n",
      "Epoch 10, iter 415, loss 2.250213146209717, acc 0.1899999976158142\n",
      "Epoch 10, iter 416, loss 2.1665921211242676, acc 0.23000000417232513\n",
      "Epoch 10, iter 417, loss 2.111130475997925, acc 0.20000000298023224\n",
      "Epoch 10, iter 418, loss 2.0476737022399902, acc 0.3499999940395355\n",
      "Epoch 10, iter 419, loss 2.125859498977661, acc 0.23000000417232513\n",
      "Epoch 10, iter 420, loss 2.2148773670196533, acc 0.14000000059604645\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "Loss=[]\n",
    "num_epoch=10\n",
    "for i in range(num_epoch):\n",
    "    for j,batch in enumerate(mnist_batched):\n",
    "        x=batch['X']\n",
    "        Y=batch['y']\n",
    "        p=mod(x)\n",
    "        loss=CE(p,Y)\n",
    "        loss.backward()\n",
    "        Loss.append(loss.item())\n",
    "        acc=(p.argmax(axis=1)==Y).float().mean().item()\n",
    "        print(f\"Epoch {i+1}, iter {j+1}, loss {loss.item()}, acc {acc}\")\n",
    "        with torch.no_grad():\n",
    "            for p in mod.parameters():\n",
    "                p-=lr*p.grad\n",
    "            mod.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1288c6f10>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(Loss)),Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Can we improve this further, should we be declaring parameters? Shouldn't there be abstractions for layers?\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1=nn.Linear(784,3)\n",
    "        self.sig=nn.Sigmoid()\n",
    "        self.lin2=nn.Linear(3,10)\n",
    "        self.softmax=nn.Softmax()\n",
    "    def forward(self,X):\n",
    "        x=self.lin1(X)\n",
    "        x=self.sig(x)\n",
    "        x=self.lin2(x)\n",
    "        x=self.softmax(x)\n",
    "        return x                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=optim.SGD(mod.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gunnvantsaini/miniconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 1, loss 2.463615655899048, acc 0.07000000029802322\n",
      "Epoch 1, iter 2, loss 2.345031499862671, acc 0.15000000596046448\n",
      "Epoch 1, iter 3, loss 2.3293352127075195, acc 0.11999999731779099\n",
      "Epoch 1, iter 4, loss 2.3531954288482666, acc 0.18000000715255737\n",
      "Epoch 1, iter 5, loss 2.3207666873931885, acc 0.20000000298023224\n",
      "Epoch 1, iter 6, loss 2.3387107849121094, acc 0.15000000596046448\n",
      "Epoch 1, iter 7, loss 2.3709189891815186, acc 0.10999999940395355\n",
      "Epoch 1, iter 8, loss 2.2999656200408936, acc 0.11999999731779099\n",
      "Epoch 1, iter 9, loss 2.328460931777954, acc 0.11999999731779099\n",
      "Epoch 1, iter 10, loss 2.3569610118865967, acc 0.11999999731779099\n",
      "Epoch 1, iter 11, loss 2.337036371231079, acc 0.12999999523162842\n",
      "Epoch 1, iter 12, loss 2.349637508392334, acc 0.10999999940395355\n",
      "Epoch 1, iter 13, loss 2.325228691101074, acc 0.12999999523162842\n",
      "Epoch 1, iter 14, loss 2.3155064582824707, acc 0.10000000149011612\n",
      "Epoch 1, iter 15, loss 2.290046453475952, acc 0.12999999523162842\n",
      "Epoch 1, iter 16, loss 2.2563369274139404, acc 0.10999999940395355\n",
      "Epoch 1, iter 17, loss 2.3085553646087646, acc 0.12999999523162842\n",
      "Epoch 1, iter 18, loss 2.2395436763763428, acc 0.15000000596046448\n",
      "Epoch 1, iter 19, loss 2.248089551925659, acc 0.1899999976158142\n",
      "Epoch 1, iter 20, loss 2.1949915885925293, acc 0.18000000715255737\n",
      "Epoch 1, iter 21, loss 2.2409181594848633, acc 0.12999999523162842\n",
      "Epoch 1, iter 22, loss 2.2280776500701904, acc 0.12999999523162842\n",
      "Epoch 1, iter 23, loss 2.1981687545776367, acc 0.20000000298023224\n",
      "Epoch 1, iter 24, loss 2.2768378257751465, acc 0.14000000059604645\n",
      "Epoch 1, iter 25, loss 2.2699692249298096, acc 0.14000000059604645\n",
      "Epoch 1, iter 26, loss 2.271594762802124, acc 0.17000000178813934\n",
      "Epoch 1, iter 27, loss 2.280708074569702, acc 0.09000000357627869\n",
      "Epoch 1, iter 28, loss 2.2098352909088135, acc 0.07000000029802322\n",
      "Epoch 1, iter 29, loss 2.2495832443237305, acc 0.15000000596046448\n",
      "Epoch 1, iter 30, loss 2.314729928970337, acc 0.07999999821186066\n",
      "Epoch 1, iter 31, loss 2.299640417098999, acc 0.12999999523162842\n",
      "Epoch 1, iter 32, loss 2.257725238800049, acc 0.11999999731779099\n",
      "Epoch 1, iter 33, loss 2.2722678184509277, acc 0.07000000029802322\n",
      "Epoch 1, iter 34, loss 2.242506980895996, acc 0.07999999821186066\n",
      "Epoch 1, iter 35, loss 2.194401741027832, acc 0.14000000059604645\n",
      "Epoch 1, iter 36, loss 2.2020578384399414, acc 0.18000000715255737\n",
      "Epoch 1, iter 37, loss 2.3245935440063477, acc 0.10000000149011612\n",
      "Epoch 1, iter 38, loss 2.2596845626831055, acc 0.10000000149011612\n",
      "Epoch 1, iter 39, loss 2.229898452758789, acc 0.10999999940395355\n",
      "Epoch 1, iter 40, loss 2.2282896041870117, acc 0.12999999523162842\n",
      "Epoch 1, iter 41, loss 2.2196316719055176, acc 0.20000000298023224\n",
      "Epoch 1, iter 42, loss 2.22920823097229, acc 0.20000000298023224\n",
      "Epoch 1, iter 43, loss 2.221940279006958, acc 0.23999999463558197\n",
      "Epoch 1, iter 44, loss 2.2200510501861572, acc 0.1899999976158142\n",
      "Epoch 1, iter 45, loss 2.257733106613159, acc 0.17000000178813934\n",
      "Epoch 1, iter 46, loss 2.2975013256073, acc 0.11999999731779099\n",
      "Epoch 1, iter 47, loss 2.315199375152588, acc 0.10999999940395355\n",
      "Epoch 1, iter 48, loss 2.258585214614868, acc 0.15000000596046448\n",
      "Epoch 1, iter 49, loss 2.2933619022369385, acc 0.15000000596046448\n",
      "Epoch 1, iter 50, loss 2.319000005722046, acc 0.10000000149011612\n",
      "Epoch 1, iter 51, loss 2.245654344558716, acc 0.23000000417232513\n",
      "Epoch 1, iter 52, loss 2.278637647628784, acc 0.11999999731779099\n",
      "Epoch 1, iter 53, loss 2.2795543670654297, acc 0.07999999821186066\n",
      "Epoch 1, iter 54, loss 2.2789440155029297, acc 0.17000000178813934\n",
      "Epoch 1, iter 55, loss 2.284390926361084, acc 0.20999999344348907\n",
      "Epoch 1, iter 56, loss 2.2739741802215576, acc 0.1899999976158142\n",
      "Epoch 1, iter 57, loss 2.2571287155151367, acc 0.15000000596046448\n",
      "Epoch 1, iter 58, loss 2.23993182182312, acc 0.18000000715255737\n",
      "Epoch 1, iter 59, loss 2.240750312805176, acc 0.12999999523162842\n",
      "Epoch 1, iter 60, loss 2.231236457824707, acc 0.14000000059604645\n",
      "Epoch 1, iter 61, loss 2.19696307182312, acc 0.23999999463558197\n",
      "Epoch 1, iter 62, loss 2.2383339405059814, acc 0.12999999523162842\n",
      "Epoch 1, iter 63, loss 2.210505723953247, acc 0.11999999731779099\n",
      "Epoch 1, iter 64, loss 2.247257947921753, acc 0.14000000059604645\n",
      "Epoch 1, iter 65, loss 2.2110037803649902, acc 0.20000000298023224\n",
      "Epoch 1, iter 66, loss 2.2153351306915283, acc 0.23000000417232513\n",
      "Epoch 1, iter 67, loss 2.2545294761657715, acc 0.12999999523162842\n",
      "Epoch 1, iter 68, loss 2.2093148231506348, acc 0.25999999046325684\n",
      "Epoch 1, iter 69, loss 2.18302059173584, acc 0.23000000417232513\n",
      "Epoch 1, iter 70, loss 2.1991829872131348, acc 0.20999999344348907\n",
      "Epoch 1, iter 71, loss 2.230534553527832, acc 0.11999999731779099\n",
      "Epoch 1, iter 72, loss 2.216564416885376, acc 0.20999999344348907\n",
      "Epoch 1, iter 73, loss 2.1813547611236572, acc 0.23999999463558197\n",
      "Epoch 1, iter 74, loss 2.1895833015441895, acc 0.23999999463558197\n",
      "Epoch 1, iter 75, loss 2.194568395614624, acc 0.20000000298023224\n",
      "Epoch 1, iter 76, loss 2.1775429248809814, acc 0.23000000417232513\n",
      "Epoch 1, iter 77, loss 2.250591993331909, acc 0.11999999731779099\n",
      "Epoch 1, iter 78, loss 2.2063732147216797, acc 0.20999999344348907\n",
      "Epoch 1, iter 79, loss 2.20292067527771, acc 0.2199999988079071\n",
      "Epoch 1, iter 80, loss 2.177799701690674, acc 0.25\n",
      "Epoch 1, iter 81, loss 2.205157995223999, acc 0.17000000178813934\n",
      "Epoch 1, iter 82, loss 2.220883369445801, acc 0.1899999976158142\n",
      "Epoch 1, iter 83, loss 2.1440441608428955, acc 0.20000000298023224\n",
      "Epoch 1, iter 84, loss 2.1682238578796387, acc 0.17000000178813934\n",
      "Epoch 1, iter 85, loss 2.1942427158355713, acc 0.17000000178813934\n",
      "Epoch 1, iter 86, loss 2.1691815853118896, acc 0.2199999988079071\n",
      "Epoch 1, iter 87, loss 2.1885123252868652, acc 0.20999999344348907\n",
      "Epoch 1, iter 88, loss 2.175381898880005, acc 0.23000000417232513\n",
      "Epoch 1, iter 89, loss 2.1750075817108154, acc 0.2199999988079071\n",
      "Epoch 1, iter 90, loss 2.172905206680298, acc 0.25\n",
      "Epoch 1, iter 91, loss 2.202111005783081, acc 0.1899999976158142\n",
      "Epoch 1, iter 92, loss 2.1685092449188232, acc 0.1599999964237213\n",
      "Epoch 1, iter 93, loss 2.172346591949463, acc 0.14000000059604645\n",
      "Epoch 1, iter 94, loss 2.1674187183380127, acc 0.20999999344348907\n",
      "Epoch 1, iter 95, loss 2.165851593017578, acc 0.1899999976158142\n",
      "Epoch 1, iter 96, loss 2.2076921463012695, acc 0.12999999523162842\n",
      "Epoch 1, iter 97, loss 2.2454068660736084, acc 0.14000000059604645\n",
      "Epoch 1, iter 98, loss 2.228076219558716, acc 0.1599999964237213\n",
      "Epoch 1, iter 99, loss 2.1636369228363037, acc 0.20999999344348907\n",
      "Epoch 1, iter 100, loss 2.197805404663086, acc 0.20000000298023224\n",
      "Epoch 1, iter 101, loss 2.1365606784820557, acc 0.23999999463558197\n",
      "Epoch 1, iter 102, loss 2.206369400024414, acc 0.15000000596046448\n",
      "Epoch 1, iter 103, loss 2.18975830078125, acc 0.20000000298023224\n",
      "Epoch 1, iter 104, loss 2.178488254547119, acc 0.23999999463558197\n",
      "Epoch 1, iter 105, loss 2.1196930408477783, acc 0.27000001072883606\n",
      "Epoch 1, iter 106, loss 2.1376864910125732, acc 0.2199999988079071\n",
      "Epoch 1, iter 107, loss 2.172667980194092, acc 0.2199999988079071\n",
      "Epoch 1, iter 108, loss 2.176913261413574, acc 0.23000000417232513\n",
      "Epoch 1, iter 109, loss 2.168771743774414, acc 0.18000000715255737\n",
      "Epoch 1, iter 110, loss 2.1749277114868164, acc 0.20000000298023224\n",
      "Epoch 1, iter 111, loss 2.181436538696289, acc 0.1899999976158142\n",
      "Epoch 1, iter 112, loss 2.1669881343841553, acc 0.23999999463558197\n",
      "Epoch 1, iter 113, loss 2.1731467247009277, acc 0.23000000417232513\n",
      "Epoch 1, iter 114, loss 2.183652877807617, acc 0.20000000298023224\n",
      "Epoch 1, iter 115, loss 2.11299467086792, acc 0.2800000011920929\n",
      "Epoch 1, iter 116, loss 2.1644127368927, acc 0.23999999463558197\n",
      "Epoch 1, iter 117, loss 2.1690587997436523, acc 0.15000000596046448\n",
      "Epoch 1, iter 118, loss 2.1744472980499268, acc 0.1899999976158142\n",
      "Epoch 1, iter 119, loss 2.131519317626953, acc 0.25\n",
      "Epoch 1, iter 120, loss 2.158874988555908, acc 0.20999999344348907\n",
      "Epoch 1, iter 121, loss 2.159745693206787, acc 0.18000000715255737\n",
      "Epoch 1, iter 122, loss 2.1415305137634277, acc 0.23000000417232513\n",
      "Epoch 1, iter 123, loss 2.1429784297943115, acc 0.23000000417232513\n",
      "Epoch 1, iter 124, loss 2.111952066421509, acc 0.20000000298023224\n",
      "Epoch 1, iter 125, loss 2.167142391204834, acc 0.1899999976158142\n",
      "Epoch 1, iter 126, loss 2.1338820457458496, acc 0.25\n",
      "Epoch 1, iter 127, loss 2.168041229248047, acc 0.2199999988079071\n",
      "Epoch 1, iter 128, loss 2.1455931663513184, acc 0.1899999976158142\n",
      "Epoch 1, iter 129, loss 2.182363510131836, acc 0.20000000298023224\n",
      "Epoch 1, iter 130, loss 2.1483917236328125, acc 0.20999999344348907\n",
      "Epoch 1, iter 131, loss 2.187798023223877, acc 0.12999999523162842\n",
      "Epoch 1, iter 132, loss 2.119133710861206, acc 0.25\n",
      "Epoch 1, iter 133, loss 2.185821294784546, acc 0.15000000596046448\n",
      "Epoch 1, iter 134, loss 2.12992787361145, acc 0.17000000178813934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 135, loss 2.1499390602111816, acc 0.2199999988079071\n",
      "Epoch 1, iter 136, loss 2.106266975402832, acc 0.30000001192092896\n",
      "Epoch 1, iter 137, loss 2.1454198360443115, acc 0.25999999046325684\n",
      "Epoch 1, iter 138, loss 2.1108155250549316, acc 0.20000000298023224\n",
      "Epoch 1, iter 139, loss 2.1719255447387695, acc 0.1599999964237213\n",
      "Epoch 1, iter 140, loss 2.130707025527954, acc 0.27000001072883606\n",
      "Epoch 1, iter 141, loss 2.158613920211792, acc 0.17000000178813934\n",
      "Epoch 1, iter 142, loss 2.199760913848877, acc 0.18000000715255737\n",
      "Epoch 1, iter 143, loss 2.1636910438537598, acc 0.20000000298023224\n",
      "Epoch 1, iter 144, loss 2.239800214767456, acc 0.18000000715255737\n",
      "Epoch 1, iter 145, loss 2.1984145641326904, acc 0.20000000298023224\n",
      "Epoch 1, iter 146, loss 2.2254364490509033, acc 0.20999999344348907\n",
      "Epoch 1, iter 147, loss 2.208102226257324, acc 0.18000000715255737\n",
      "Epoch 1, iter 148, loss 2.1782021522521973, acc 0.25\n",
      "Epoch 1, iter 149, loss 2.1058247089385986, acc 0.27000001072883606\n",
      "Epoch 1, iter 150, loss 2.1260557174682617, acc 0.2199999988079071\n",
      "Epoch 1, iter 151, loss 2.1114501953125, acc 0.2199999988079071\n",
      "Epoch 1, iter 152, loss 2.13604998588562, acc 0.20000000298023224\n",
      "Epoch 1, iter 153, loss 2.1504933834075928, acc 0.20000000298023224\n",
      "Epoch 1, iter 154, loss 2.1527297496795654, acc 0.20000000298023224\n",
      "Epoch 1, iter 155, loss 2.135803461074829, acc 0.1599999964237213\n",
      "Epoch 1, iter 156, loss 2.113633632659912, acc 0.20999999344348907\n",
      "Epoch 1, iter 157, loss 2.2135684490203857, acc 0.17000000178813934\n",
      "Epoch 1, iter 158, loss 2.1330318450927734, acc 0.18000000715255737\n",
      "Epoch 1, iter 159, loss 2.1270601749420166, acc 0.2199999988079071\n",
      "Epoch 1, iter 160, loss 2.154231071472168, acc 0.20999999344348907\n",
      "Epoch 1, iter 161, loss 2.117502212524414, acc 0.30000001192092896\n",
      "Epoch 1, iter 162, loss 2.0790905952453613, acc 0.25\n",
      "Epoch 1, iter 163, loss 2.1507740020751953, acc 0.20000000298023224\n",
      "Epoch 1, iter 164, loss 2.1599233150482178, acc 0.1899999976158142\n",
      "Epoch 1, iter 165, loss 2.1607666015625, acc 0.18000000715255737\n",
      "Epoch 1, iter 166, loss 2.165231227874756, acc 0.23999999463558197\n",
      "Epoch 1, iter 167, loss 2.180711269378662, acc 0.20000000298023224\n",
      "Epoch 1, iter 168, loss 2.146216630935669, acc 0.18000000715255737\n",
      "Epoch 1, iter 169, loss 2.127837657928467, acc 0.20999999344348907\n",
      "Epoch 1, iter 170, loss 2.15153431892395, acc 0.20000000298023224\n",
      "Epoch 1, iter 171, loss 2.1907002925872803, acc 0.18000000715255737\n",
      "Epoch 1, iter 172, loss 2.1541881561279297, acc 0.1599999964237213\n",
      "Epoch 1, iter 173, loss 2.1434013843536377, acc 0.1599999964237213\n",
      "Epoch 1, iter 174, loss 2.1777749061584473, acc 0.17000000178813934\n",
      "Epoch 1, iter 175, loss 2.1054656505584717, acc 0.23999999463558197\n",
      "Epoch 1, iter 176, loss 2.2061588764190674, acc 0.14000000059604645\n",
      "Epoch 1, iter 177, loss 2.137930154800415, acc 0.1599999964237213\n",
      "Epoch 1, iter 178, loss 2.171093702316284, acc 0.15000000596046448\n",
      "Epoch 1, iter 179, loss 2.125187635421753, acc 0.1599999964237213\n",
      "Epoch 1, iter 180, loss 2.1080517768859863, acc 0.1899999976158142\n",
      "Epoch 1, iter 181, loss 2.1043989658355713, acc 0.1899999976158142\n",
      "Epoch 1, iter 182, loss 2.1323723793029785, acc 0.20000000298023224\n",
      "Epoch 1, iter 183, loss 2.1333184242248535, acc 0.18000000715255737\n",
      "Epoch 1, iter 184, loss 2.163236618041992, acc 0.23000000417232513\n",
      "Epoch 1, iter 185, loss 2.114929437637329, acc 0.1899999976158142\n",
      "Epoch 1, iter 186, loss 2.1325523853302, acc 0.2199999988079071\n",
      "Epoch 1, iter 187, loss 2.106499433517456, acc 0.25999999046325684\n",
      "Epoch 1, iter 188, loss 2.1590704917907715, acc 0.20000000298023224\n",
      "Epoch 1, iter 189, loss 2.1938767433166504, acc 0.12999999523162842\n",
      "Epoch 1, iter 190, loss 2.08284854888916, acc 0.17000000178813934\n",
      "Epoch 1, iter 191, loss 2.1250405311584473, acc 0.20999999344348907\n",
      "Epoch 1, iter 192, loss 2.1424753665924072, acc 0.2199999988079071\n",
      "Epoch 1, iter 193, loss 2.1110994815826416, acc 0.20000000298023224\n",
      "Epoch 1, iter 194, loss 2.1023812294006348, acc 0.18000000715255737\n",
      "Epoch 1, iter 195, loss 2.1083426475524902, acc 0.23999999463558197\n",
      "Epoch 1, iter 196, loss 2.1557672023773193, acc 0.1599999964237213\n",
      "Epoch 1, iter 197, loss 2.1369521617889404, acc 0.20999999344348907\n",
      "Epoch 1, iter 198, loss 2.0793259143829346, acc 0.28999999165534973\n",
      "Epoch 1, iter 199, loss 2.111083745956421, acc 0.20000000298023224\n",
      "Epoch 1, iter 200, loss 2.139084577560425, acc 0.20999999344348907\n",
      "Epoch 1, iter 201, loss 2.155932903289795, acc 0.20999999344348907\n",
      "Epoch 1, iter 202, loss 2.179020643234253, acc 0.20000000298023224\n",
      "Epoch 1, iter 203, loss 2.142584800720215, acc 0.15000000596046448\n",
      "Epoch 1, iter 204, loss 2.115765333175659, acc 0.25999999046325684\n",
      "Epoch 1, iter 205, loss 2.0845940113067627, acc 0.20999999344348907\n",
      "Epoch 1, iter 206, loss 2.140549421310425, acc 0.23999999463558197\n",
      "Epoch 1, iter 207, loss 2.112438917160034, acc 0.20000000298023224\n",
      "Epoch 1, iter 208, loss 2.1492490768432617, acc 0.12999999523162842\n",
      "Epoch 1, iter 209, loss 2.1430487632751465, acc 0.18000000715255737\n",
      "Epoch 1, iter 210, loss 2.143322229385376, acc 0.2199999988079071\n",
      "Epoch 1, iter 211, loss 2.1308677196502686, acc 0.1899999976158142\n",
      "Epoch 1, iter 212, loss 2.1339211463928223, acc 0.20000000298023224\n",
      "Epoch 1, iter 213, loss 2.1304445266723633, acc 0.14000000059604645\n",
      "Epoch 1, iter 214, loss 2.146620035171509, acc 0.17000000178813934\n",
      "Epoch 1, iter 215, loss 2.1410906314849854, acc 0.18000000715255737\n",
      "Epoch 1, iter 216, loss 2.1532351970672607, acc 0.1899999976158142\n",
      "Epoch 1, iter 217, loss 2.126429796218872, acc 0.20000000298023224\n",
      "Epoch 1, iter 218, loss 2.2015671730041504, acc 0.10000000149011612\n",
      "Epoch 1, iter 219, loss 2.135474443435669, acc 0.25\n",
      "Epoch 1, iter 220, loss 2.1367781162261963, acc 0.1599999964237213\n",
      "Epoch 1, iter 221, loss 2.0833897590637207, acc 0.20000000298023224\n",
      "Epoch 1, iter 222, loss 2.1303112506866455, acc 0.15000000596046448\n",
      "Epoch 1, iter 223, loss 2.0775234699249268, acc 0.2199999988079071\n",
      "Epoch 1, iter 224, loss 2.0943543910980225, acc 0.1899999976158142\n",
      "Epoch 1, iter 225, loss 2.118117570877075, acc 0.25\n",
      "Epoch 1, iter 226, loss 2.155430793762207, acc 0.25\n",
      "Epoch 1, iter 227, loss 2.137049674987793, acc 0.1899999976158142\n",
      "Epoch 1, iter 228, loss 2.140835762023926, acc 0.25\n",
      "Epoch 1, iter 229, loss 2.1326053142547607, acc 0.1899999976158142\n",
      "Epoch 1, iter 230, loss 2.1263480186462402, acc 0.20999999344348907\n",
      "Epoch 1, iter 231, loss 2.1274209022521973, acc 0.17000000178813934\n",
      "Epoch 1, iter 232, loss 2.1725664138793945, acc 0.1599999964237213\n",
      "Epoch 1, iter 233, loss 2.2473361492156982, acc 0.20000000298023224\n",
      "Epoch 1, iter 234, loss 2.1880669593811035, acc 0.17000000178813934\n",
      "Epoch 1, iter 235, loss 2.1951074600219727, acc 0.18000000715255737\n",
      "Epoch 1, iter 236, loss 2.143975257873535, acc 0.15000000596046448\n",
      "Epoch 1, iter 237, loss 2.165437698364258, acc 0.20000000298023224\n",
      "Epoch 1, iter 238, loss 2.197305679321289, acc 0.15000000596046448\n",
      "Epoch 1, iter 239, loss 2.110436201095581, acc 0.1599999964237213\n",
      "Epoch 1, iter 240, loss 2.12617564201355, acc 0.12999999523162842\n",
      "Epoch 1, iter 241, loss 2.083224058151245, acc 0.1599999964237213\n",
      "Epoch 1, iter 242, loss 2.1357104778289795, acc 0.10999999940395355\n",
      "Epoch 1, iter 243, loss 2.122114658355713, acc 0.17000000178813934\n",
      "Epoch 1, iter 244, loss 2.1037259101867676, acc 0.2800000011920929\n",
      "Epoch 1, iter 245, loss 2.103177070617676, acc 0.20999999344348907\n",
      "Epoch 1, iter 246, loss 2.1142232418060303, acc 0.1599999964237213\n",
      "Epoch 1, iter 247, loss 2.064307928085327, acc 0.25\n",
      "Epoch 1, iter 248, loss 2.1497232913970947, acc 0.18000000715255737\n",
      "Epoch 1, iter 249, loss 2.1026670932769775, acc 0.12999999523162842\n",
      "Epoch 1, iter 250, loss 2.081503391265869, acc 0.28999999165534973\n",
      "Epoch 1, iter 251, loss 2.1290650367736816, acc 0.1899999976158142\n",
      "Epoch 1, iter 252, loss 2.071359395980835, acc 0.23999999463558197\n",
      "Epoch 1, iter 253, loss 2.15604305267334, acc 0.15000000596046448\n",
      "Epoch 1, iter 254, loss 2.086533546447754, acc 0.20999999344348907\n",
      "Epoch 1, iter 255, loss 2.0820491313934326, acc 0.18000000715255737\n",
      "Epoch 1, iter 256, loss 2.090308427810669, acc 0.23000000417232513\n",
      "Epoch 1, iter 257, loss 2.1004464626312256, acc 0.17000000178813934\n",
      "Epoch 1, iter 258, loss 2.1242117881774902, acc 0.23999999463558197\n",
      "Epoch 1, iter 259, loss 2.1200063228607178, acc 0.23000000417232513\n",
      "Epoch 1, iter 260, loss 2.071518659591675, acc 0.1899999976158142\n",
      "Epoch 1, iter 261, loss 2.058058977127075, acc 0.23000000417232513\n",
      "Epoch 1, iter 262, loss 2.1073379516601562, acc 0.1599999964237213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 263, loss 2.0507280826568604, acc 0.23000000417232513\n",
      "Epoch 1, iter 264, loss 2.0821681022644043, acc 0.23999999463558197\n",
      "Epoch 1, iter 265, loss 2.1005218029022217, acc 0.23000000417232513\n",
      "Epoch 1, iter 266, loss 2.0964393615722656, acc 0.17000000178813934\n",
      "Epoch 1, iter 267, loss 2.09212589263916, acc 0.2800000011920929\n",
      "Epoch 1, iter 268, loss 2.1033411026000977, acc 0.12999999523162842\n",
      "Epoch 1, iter 269, loss 2.073439598083496, acc 0.1899999976158142\n",
      "Epoch 1, iter 270, loss 2.114832878112793, acc 0.1599999964237213\n",
      "Epoch 1, iter 271, loss 2.0914759635925293, acc 0.20000000298023224\n",
      "Epoch 1, iter 272, loss 2.1002118587493896, acc 0.2199999988079071\n",
      "Epoch 1, iter 273, loss 2.077376365661621, acc 0.20999999344348907\n",
      "Epoch 1, iter 274, loss 2.069223642349243, acc 0.20999999344348907\n",
      "Epoch 1, iter 275, loss 2.1091721057891846, acc 0.18000000715255737\n",
      "Epoch 1, iter 276, loss 2.089747428894043, acc 0.20000000298023224\n",
      "Epoch 1, iter 277, loss 2.105959892272949, acc 0.20000000298023224\n",
      "Epoch 1, iter 278, loss 2.070114850997925, acc 0.17000000178813934\n",
      "Epoch 1, iter 279, loss 2.106471300125122, acc 0.2800000011920929\n",
      "Epoch 1, iter 280, loss 2.092984914779663, acc 0.1899999976158142\n",
      "Epoch 1, iter 281, loss 2.082371234893799, acc 0.30000001192092896\n",
      "Epoch 1, iter 282, loss 2.1066761016845703, acc 0.18000000715255737\n",
      "Epoch 1, iter 283, loss 2.158830404281616, acc 0.17000000178813934\n",
      "Epoch 1, iter 284, loss 2.1305506229400635, acc 0.25\n",
      "Epoch 1, iter 285, loss 2.118725061416626, acc 0.1899999976158142\n",
      "Epoch 1, iter 286, loss 2.140151262283325, acc 0.23999999463558197\n",
      "Epoch 1, iter 287, loss 2.095869541168213, acc 0.20000000298023224\n",
      "Epoch 1, iter 288, loss 2.150073766708374, acc 0.20999999344348907\n",
      "Epoch 1, iter 289, loss 2.0975401401519775, acc 0.23999999463558197\n",
      "Epoch 1, iter 290, loss 2.0986361503601074, acc 0.23000000417232513\n",
      "Epoch 1, iter 291, loss 2.182774782180786, acc 0.20000000298023224\n",
      "Epoch 1, iter 292, loss 2.1309165954589844, acc 0.23999999463558197\n",
      "Epoch 1, iter 293, loss 2.1162052154541016, acc 0.20000000298023224\n",
      "Epoch 1, iter 294, loss 2.1405937671661377, acc 0.1599999964237213\n",
      "Epoch 1, iter 295, loss 2.1088457107543945, acc 0.1899999976158142\n",
      "Epoch 1, iter 296, loss 2.1158483028411865, acc 0.20999999344348907\n",
      "Epoch 1, iter 297, loss 2.0799732208251953, acc 0.23999999463558197\n",
      "Epoch 1, iter 298, loss 2.0786256790161133, acc 0.25\n",
      "Epoch 1, iter 299, loss 2.1239919662475586, acc 0.11999999731779099\n",
      "Epoch 1, iter 300, loss 2.108004570007324, acc 0.18000000715255737\n",
      "Epoch 1, iter 301, loss 2.087096929550171, acc 0.20999999344348907\n",
      "Epoch 1, iter 302, loss 2.105098009109497, acc 0.2800000011920929\n",
      "Epoch 1, iter 303, loss 2.087606430053711, acc 0.20000000298023224\n",
      "Epoch 1, iter 304, loss 2.0947864055633545, acc 0.17000000178813934\n",
      "Epoch 1, iter 305, loss 2.1415464878082275, acc 0.1599999964237213\n",
      "Epoch 1, iter 306, loss 2.0647406578063965, acc 0.20000000298023224\n",
      "Epoch 1, iter 307, loss 2.05617356300354, acc 0.23999999463558197\n",
      "Epoch 1, iter 308, loss 2.107729434967041, acc 0.2199999988079071\n",
      "Epoch 1, iter 309, loss 2.0733015537261963, acc 0.20000000298023224\n",
      "Epoch 1, iter 310, loss 2.1129202842712402, acc 0.18000000715255737\n",
      "Epoch 1, iter 311, loss 2.0777978897094727, acc 0.23000000417232513\n",
      "Epoch 1, iter 312, loss 2.125525712966919, acc 0.25\n",
      "Epoch 1, iter 313, loss 2.1234896183013916, acc 0.11999999731779099\n",
      "Epoch 1, iter 314, loss 2.0805981159210205, acc 0.25999999046325684\n",
      "Epoch 1, iter 315, loss 2.077388048171997, acc 0.25\n",
      "Epoch 1, iter 316, loss 2.1116364002227783, acc 0.12999999523162842\n",
      "Epoch 1, iter 317, loss 2.10701847076416, acc 0.2199999988079071\n",
      "Epoch 1, iter 318, loss 2.068103313446045, acc 0.2199999988079071\n",
      "Epoch 1, iter 319, loss 2.086536169052124, acc 0.18000000715255737\n",
      "Epoch 1, iter 320, loss 2.1216557025909424, acc 0.20000000298023224\n",
      "Epoch 1, iter 321, loss 2.104400157928467, acc 0.1899999976158142\n",
      "Epoch 1, iter 322, loss 2.0972466468811035, acc 0.23999999463558197\n",
      "Epoch 1, iter 323, loss 2.093837022781372, acc 0.20000000298023224\n",
      "Epoch 1, iter 324, loss 2.044110059738159, acc 0.25\n",
      "Epoch 1, iter 325, loss 2.11853289604187, acc 0.25\n",
      "Epoch 1, iter 326, loss 2.094581127166748, acc 0.20999999344348907\n",
      "Epoch 1, iter 327, loss 2.038076877593994, acc 0.17000000178813934\n",
      "Epoch 1, iter 328, loss 2.0910284519195557, acc 0.25\n",
      "Epoch 1, iter 329, loss 2.0800750255584717, acc 0.2199999988079071\n",
      "Epoch 1, iter 330, loss 2.1109366416931152, acc 0.20999999344348907\n",
      "Epoch 1, iter 331, loss 2.0558226108551025, acc 0.1899999976158142\n",
      "Epoch 1, iter 332, loss 2.109196424484253, acc 0.23000000417232513\n",
      "Epoch 1, iter 333, loss 2.1190683841705322, acc 0.23000000417232513\n",
      "Epoch 1, iter 334, loss 2.0687525272369385, acc 0.2199999988079071\n",
      "Epoch 1, iter 335, loss 2.0724401473999023, acc 0.25\n",
      "Epoch 1, iter 336, loss 2.0671164989471436, acc 0.23999999463558197\n",
      "Epoch 1, iter 337, loss 2.0964858531951904, acc 0.20999999344348907\n",
      "Epoch 1, iter 338, loss 2.1392791271209717, acc 0.2199999988079071\n",
      "Epoch 1, iter 339, loss 2.0604186058044434, acc 0.23000000417232513\n",
      "Epoch 1, iter 340, loss 2.0886950492858887, acc 0.2199999988079071\n",
      "Epoch 1, iter 341, loss 2.0338294506073, acc 0.25\n",
      "Epoch 1, iter 342, loss 2.086747884750366, acc 0.23000000417232513\n",
      "Epoch 1, iter 343, loss 2.0665130615234375, acc 0.1899999976158142\n",
      "Epoch 1, iter 344, loss 2.058176040649414, acc 0.23999999463558197\n",
      "Epoch 1, iter 345, loss 2.0870769023895264, acc 0.1899999976158142\n",
      "Epoch 1, iter 346, loss 2.072634220123291, acc 0.25\n",
      "Epoch 1, iter 347, loss 2.100119113922119, acc 0.20000000298023224\n",
      "Epoch 1, iter 348, loss 2.098849296569824, acc 0.3199999928474426\n",
      "Epoch 1, iter 349, loss 2.1350858211517334, acc 0.25\n",
      "Epoch 1, iter 350, loss 2.16568922996521, acc 0.23999999463558197\n",
      "Epoch 1, iter 351, loss 2.1132924556732178, acc 0.15000000596046448\n",
      "Epoch 1, iter 352, loss 2.077885150909424, acc 0.18000000715255737\n",
      "Epoch 1, iter 353, loss 2.048816442489624, acc 0.25999999046325684\n",
      "Epoch 1, iter 354, loss 2.0517776012420654, acc 0.25\n",
      "Epoch 1, iter 355, loss 2.093310594558716, acc 0.20999999344348907\n",
      "Epoch 1, iter 356, loss 2.1135928630828857, acc 0.23999999463558197\n",
      "Epoch 1, iter 357, loss 2.0627686977386475, acc 0.2199999988079071\n",
      "Epoch 1, iter 358, loss 2.0926902294158936, acc 0.1899999976158142\n",
      "Epoch 1, iter 359, loss 2.082005500793457, acc 0.12999999523162842\n",
      "Epoch 1, iter 360, loss 2.110137462615967, acc 0.23999999463558197\n",
      "Epoch 1, iter 361, loss 2.1258652210235596, acc 0.20000000298023224\n",
      "Epoch 1, iter 362, loss 2.1111979484558105, acc 0.17000000178813934\n",
      "Epoch 1, iter 363, loss 2.051910877227783, acc 0.28999999165534973\n",
      "Epoch 1, iter 364, loss 2.162738084793091, acc 0.12999999523162842\n",
      "Epoch 1, iter 365, loss 2.091594696044922, acc 0.20999999344348907\n",
      "Epoch 1, iter 366, loss 2.076531410217285, acc 0.23999999463558197\n",
      "Epoch 1, iter 367, loss 2.043463945388794, acc 0.23000000417232513\n",
      "Epoch 1, iter 368, loss 2.067600727081299, acc 0.23000000417232513\n",
      "Epoch 1, iter 369, loss 2.041529893875122, acc 0.23999999463558197\n",
      "Epoch 1, iter 370, loss 2.0121543407440186, acc 0.2199999988079071\n",
      "Epoch 1, iter 371, loss 2.0787155628204346, acc 0.23000000417232513\n",
      "Epoch 1, iter 372, loss 2.0549609661102295, acc 0.23000000417232513\n",
      "Epoch 1, iter 373, loss 2.091574192047119, acc 0.17000000178813934\n",
      "Epoch 1, iter 374, loss 2.1120011806488037, acc 0.20999999344348907\n",
      "Epoch 1, iter 375, loss 2.0471298694610596, acc 0.30000001192092896\n",
      "Epoch 1, iter 376, loss 2.0709807872772217, acc 0.15000000596046448\n",
      "Epoch 1, iter 377, loss 2.0436432361602783, acc 0.27000001072883606\n",
      "Epoch 1, iter 378, loss 2.053480386734009, acc 0.25999999046325684\n",
      "Epoch 1, iter 379, loss 2.1012766361236572, acc 0.18000000715255737\n",
      "Epoch 1, iter 380, loss 2.1026883125305176, acc 0.17000000178813934\n",
      "Epoch 1, iter 381, loss 2.080655574798584, acc 0.1599999964237213\n",
      "Epoch 1, iter 382, loss 2.0281028747558594, acc 0.25\n",
      "Epoch 1, iter 383, loss 2.048576831817627, acc 0.2800000011920929\n",
      "Epoch 1, iter 384, loss 2.0660173892974854, acc 0.18000000715255737\n",
      "Epoch 1, iter 385, loss 2.029001235961914, acc 0.23999999463558197\n",
      "Epoch 1, iter 386, loss 2.082246780395508, acc 0.20999999344348907\n",
      "Epoch 1, iter 387, loss 2.0978190898895264, acc 0.2199999988079071\n",
      "Epoch 1, iter 388, loss 2.0524117946624756, acc 0.20000000298023224\n",
      "Epoch 1, iter 389, loss 2.0937302112579346, acc 0.20999999344348907\n",
      "Epoch 1, iter 390, loss 2.154693603515625, acc 0.10000000149011612\n",
      "Epoch 1, iter 391, loss 2.0687263011932373, acc 0.1899999976158142\n",
      "Epoch 1, iter 392, loss 2.1037793159484863, acc 0.18000000715255737\n",
      "Epoch 1, iter 393, loss 2.0790724754333496, acc 0.15000000596046448\n",
      "Epoch 1, iter 394, loss 2.0746424198150635, acc 0.23999999463558197\n",
      "Epoch 1, iter 395, loss 2.096292018890381, acc 0.25999999046325684\n",
      "Epoch 1, iter 396, loss 2.1161062717437744, acc 0.1599999964237213\n",
      "Epoch 1, iter 397, loss 2.101738214492798, acc 0.20000000298023224\n",
      "Epoch 1, iter 398, loss 2.186389446258545, acc 0.12999999523162842\n",
      "Epoch 1, iter 399, loss 2.1820666790008545, acc 0.2199999988079071\n",
      "Epoch 1, iter 400, loss 2.1402106285095215, acc 0.28999999165534973\n",
      "Epoch 1, iter 401, loss 2.196075439453125, acc 0.1899999976158142\n",
      "Epoch 1, iter 402, loss 2.125683307647705, acc 0.20999999344348907\n",
      "Epoch 1, iter 403, loss 2.091590166091919, acc 0.20000000298023224\n",
      "Epoch 1, iter 404, loss 2.1603004932403564, acc 0.17000000178813934\n",
      "Epoch 1, iter 405, loss 2.1238226890563965, acc 0.25\n",
      "Epoch 1, iter 406, loss 2.209129571914673, acc 0.11999999731779099\n",
      "Epoch 1, iter 407, loss 2.154716730117798, acc 0.12999999523162842\n",
      "Epoch 1, iter 408, loss 2.2049193382263184, acc 0.23000000417232513\n",
      "Epoch 1, iter 409, loss 2.1186563968658447, acc 0.25\n",
      "Epoch 1, iter 410, loss 2.1727607250213623, acc 0.1599999964237213\n",
      "Epoch 1, iter 411, loss 2.128030300140381, acc 0.27000001072883606\n",
      "Epoch 1, iter 412, loss 2.137240171432495, acc 0.27000001072883606\n",
      "Epoch 1, iter 413, loss 2.263578414916992, acc 0.12999999523162842\n",
      "Epoch 1, iter 414, loss 2.1767046451568604, acc 0.15000000596046448\n",
      "Epoch 1, iter 415, loss 2.1520140171051025, acc 0.20000000298023224\n",
      "Epoch 1, iter 416, loss 2.115049362182617, acc 0.20999999344348907\n",
      "Epoch 1, iter 417, loss 2.070157766342163, acc 0.30000001192092896\n",
      "Epoch 1, iter 418, loss 2.184096574783325, acc 0.15000000596046448\n",
      "Epoch 1, iter 419, loss 2.1419756412506104, acc 0.25999999046325684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 420, loss 2.0964696407318115, acc 0.23999999463558197\n",
      "Epoch 2, iter 1, loss 2.1032614707946777, acc 0.2199999988079071\n",
      "Epoch 2, iter 2, loss 2.166931390762329, acc 0.18000000715255737\n",
      "Epoch 2, iter 3, loss 2.0977513790130615, acc 0.1899999976158142\n",
      "Epoch 2, iter 4, loss 2.1719160079956055, acc 0.17000000178813934\n",
      "Epoch 2, iter 5, loss 2.1323583126068115, acc 0.17000000178813934\n",
      "Epoch 2, iter 6, loss 2.142025947570801, acc 0.17000000178813934\n",
      "Epoch 2, iter 7, loss 2.114553451538086, acc 0.25\n",
      "Epoch 2, iter 8, loss 2.151906967163086, acc 0.17000000178813934\n",
      "Epoch 2, iter 9, loss 2.1055104732513428, acc 0.2199999988079071\n",
      "Epoch 2, iter 10, loss 2.1528453826904297, acc 0.18000000715255737\n",
      "Epoch 2, iter 11, loss 2.124600887298584, acc 0.20999999344348907\n",
      "Epoch 2, iter 12, loss 2.0966243743896484, acc 0.20000000298023224\n",
      "Epoch 2, iter 13, loss 2.0641205310821533, acc 0.18000000715255737\n",
      "Epoch 2, iter 14, loss 2.090857982635498, acc 0.20999999344348907\n",
      "Epoch 2, iter 15, loss 1.976487398147583, acc 0.2800000011920929\n",
      "Epoch 2, iter 16, loss 2.072218418121338, acc 0.20999999344348907\n",
      "Epoch 2, iter 17, loss 2.0493345260620117, acc 0.1599999964237213\n",
      "Epoch 2, iter 18, loss 2.0891213417053223, acc 0.20000000298023224\n",
      "Epoch 2, iter 19, loss 2.057248830795288, acc 0.18000000715255737\n",
      "Epoch 2, iter 20, loss 2.0554115772247314, acc 0.25\n",
      "Epoch 2, iter 21, loss 2.0437703132629395, acc 0.23000000417232513\n",
      "Epoch 2, iter 22, loss 2.0743019580841064, acc 0.18000000715255737\n",
      "Epoch 2, iter 23, loss 2.0501558780670166, acc 0.27000001072883606\n",
      "Epoch 2, iter 24, loss 2.0821292400360107, acc 0.18000000715255737\n",
      "Epoch 2, iter 25, loss 2.080418348312378, acc 0.20999999344348907\n",
      "Epoch 2, iter 26, loss 2.099395751953125, acc 0.20000000298023224\n",
      "Epoch 2, iter 27, loss 2.008073329925537, acc 0.2800000011920929\n",
      "Epoch 2, iter 28, loss 2.0134479999542236, acc 0.25999999046325684\n",
      "Epoch 2, iter 29, loss 2.0466322898864746, acc 0.23999999463558197\n",
      "Epoch 2, iter 30, loss 2.134860038757324, acc 0.1899999976158142\n",
      "Epoch 2, iter 31, loss 2.132826328277588, acc 0.11999999731779099\n",
      "Epoch 2, iter 32, loss 2.0056536197662354, acc 0.18000000715255737\n",
      "Epoch 2, iter 33, loss 2.064016819000244, acc 0.23999999463558197\n",
      "Epoch 2, iter 34, loss 2.0562872886657715, acc 0.20000000298023224\n",
      "Epoch 2, iter 35, loss 2.0437209606170654, acc 0.23999999463558197\n",
      "Epoch 2, iter 36, loss 2.0884039402008057, acc 0.18000000715255737\n",
      "Epoch 2, iter 37, loss 2.0309183597564697, acc 0.18000000715255737\n",
      "Epoch 2, iter 38, loss 2.04679012298584, acc 0.25\n",
      "Epoch 2, iter 39, loss 2.059237480163574, acc 0.2199999988079071\n",
      "Epoch 2, iter 40, loss 2.0447633266448975, acc 0.20999999344348907\n",
      "Epoch 2, iter 41, loss 2.1589417457580566, acc 0.14000000059604645\n",
      "Epoch 2, iter 42, loss 2.0780909061431885, acc 0.1599999964237213\n",
      "Epoch 2, iter 43, loss 1.9947248697280884, acc 0.20000000298023224\n",
      "Epoch 2, iter 44, loss 2.028938055038452, acc 0.1899999976158142\n",
      "Epoch 2, iter 45, loss 2.096625804901123, acc 0.20999999344348907\n",
      "Epoch 2, iter 46, loss 2.0687732696533203, acc 0.27000001072883606\n",
      "Epoch 2, iter 47, loss 2.143075942993164, acc 0.1599999964237213\n",
      "Epoch 2, iter 48, loss 2.065548896789551, acc 0.1899999976158142\n",
      "Epoch 2, iter 49, loss 2.107020616531372, acc 0.20999999344348907\n",
      "Epoch 2, iter 50, loss 2.0524702072143555, acc 0.23999999463558197\n",
      "Epoch 2, iter 51, loss 1.9574666023254395, acc 0.25999999046325684\n",
      "Epoch 2, iter 52, loss 2.0657942295074463, acc 0.20000000298023224\n",
      "Epoch 2, iter 53, loss 2.0307726860046387, acc 0.3199999928474426\n",
      "Epoch 2, iter 54, loss 2.0891878604888916, acc 0.11999999731779099\n",
      "Epoch 2, iter 55, loss 2.1556665897369385, acc 0.09000000357627869\n",
      "Epoch 2, iter 56, loss 2.0594282150268555, acc 0.18000000715255737\n",
      "Epoch 2, iter 57, loss 2.079768180847168, acc 0.1899999976158142\n",
      "Epoch 2, iter 58, loss 2.035953998565674, acc 0.1899999976158142\n",
      "Epoch 2, iter 59, loss 2.0535802841186523, acc 0.25\n",
      "Epoch 2, iter 60, loss 2.052302598953247, acc 0.2199999988079071\n",
      "Epoch 2, iter 61, loss 2.0225391387939453, acc 0.18000000715255737\n",
      "Epoch 2, iter 62, loss 2.013124704360962, acc 0.20999999344348907\n",
      "Epoch 2, iter 63, loss 2.0095977783203125, acc 0.25\n",
      "Epoch 2, iter 64, loss 2.013791799545288, acc 0.20999999344348907\n",
      "Epoch 2, iter 65, loss 2.01932430267334, acc 0.2800000011920929\n",
      "Epoch 2, iter 66, loss 2.0397696495056152, acc 0.23000000417232513\n",
      "Epoch 2, iter 67, loss 2.0599758625030518, acc 0.17000000178813934\n",
      "Epoch 2, iter 68, loss 2.0112085342407227, acc 0.3100000023841858\n",
      "Epoch 2, iter 69, loss 2.0456786155700684, acc 0.1899999976158142\n",
      "Epoch 2, iter 70, loss 2.0240817070007324, acc 0.2800000011920929\n",
      "Epoch 2, iter 71, loss 2.053567886352539, acc 0.18000000715255737\n",
      "Epoch 2, iter 72, loss 2.0451722145080566, acc 0.14000000059604645\n",
      "Epoch 2, iter 73, loss 2.017725706100464, acc 0.25\n",
      "Epoch 2, iter 74, loss 2.009103298187256, acc 0.2199999988079071\n",
      "Epoch 2, iter 75, loss 2.032106876373291, acc 0.12999999523162842\n",
      "Epoch 2, iter 76, loss 2.070740222930908, acc 0.20000000298023224\n",
      "Epoch 2, iter 77, loss 2.1484627723693848, acc 0.17000000178813934\n",
      "Epoch 2, iter 78, loss 2.052102565765381, acc 0.28999999165534973\n",
      "Epoch 2, iter 79, loss 2.0535852909088135, acc 0.2199999988079071\n",
      "Epoch 2, iter 80, loss 2.030513048171997, acc 0.20000000298023224\n",
      "Epoch 2, iter 81, loss 2.0222251415252686, acc 0.1599999964237213\n",
      "Epoch 2, iter 82, loss 2.0738577842712402, acc 0.1599999964237213\n",
      "Epoch 2, iter 83, loss 1.9965075254440308, acc 0.2199999988079071\n",
      "Epoch 2, iter 84, loss 2.046351432800293, acc 0.15000000596046448\n",
      "Epoch 2, iter 85, loss 2.0952768325805664, acc 0.15000000596046448\n",
      "Epoch 2, iter 86, loss 2.007132053375244, acc 0.20999999344348907\n",
      "Epoch 2, iter 87, loss 2.058037281036377, acc 0.23999999463558197\n",
      "Epoch 2, iter 88, loss 2.004185199737549, acc 0.25999999046325684\n",
      "Epoch 2, iter 89, loss 2.0466201305389404, acc 0.20000000298023224\n",
      "Epoch 2, iter 90, loss 2.039458751678467, acc 0.1899999976158142\n",
      "Epoch 2, iter 91, loss 2.0461525917053223, acc 0.1899999976158142\n",
      "Epoch 2, iter 92, loss 2.0544393062591553, acc 0.20999999344348907\n",
      "Epoch 2, iter 93, loss 2.0226125717163086, acc 0.2199999988079071\n",
      "Epoch 2, iter 94, loss 2.059713840484619, acc 0.1599999964237213\n",
      "Epoch 2, iter 95, loss 2.0600993633270264, acc 0.20999999344348907\n",
      "Epoch 2, iter 96, loss 2.0276732444763184, acc 0.23999999463558197\n",
      "Epoch 2, iter 97, loss 2.0767908096313477, acc 0.10000000149011612\n",
      "Epoch 2, iter 98, loss 2.104722738265991, acc 0.1599999964237213\n",
      "Epoch 2, iter 99, loss 2.0947577953338623, acc 0.20999999344348907\n",
      "Epoch 2, iter 100, loss 2.04343843460083, acc 0.23999999463558197\n",
      "Epoch 2, iter 101, loss 2.1580541133880615, acc 0.17000000178813934\n",
      "Epoch 2, iter 102, loss 2.1649744510650635, acc 0.20000000298023224\n",
      "Epoch 2, iter 103, loss 2.106475353240967, acc 0.25\n",
      "Epoch 2, iter 104, loss 2.1295409202575684, acc 0.25\n",
      "Epoch 2, iter 105, loss 2.119908094406128, acc 0.14000000059604645\n",
      "Epoch 2, iter 106, loss 2.023627758026123, acc 0.25999999046325684\n",
      "Epoch 2, iter 107, loss 2.0649378299713135, acc 0.2199999988079071\n",
      "Epoch 2, iter 108, loss 2.0431973934173584, acc 0.12999999523162842\n",
      "Epoch 2, iter 109, loss 2.0846612453460693, acc 0.20999999344348907\n",
      "Epoch 2, iter 110, loss 2.0770974159240723, acc 0.12999999523162842\n",
      "Epoch 2, iter 111, loss 2.072540044784546, acc 0.17000000178813934\n",
      "Epoch 2, iter 112, loss 2.088535785675049, acc 0.23000000417232513\n",
      "Epoch 2, iter 113, loss 2.0427663326263428, acc 0.25\n",
      "Epoch 2, iter 114, loss 2.0031158924102783, acc 0.2199999988079071\n",
      "Epoch 2, iter 115, loss 1.9832018613815308, acc 0.25999999046325684\n",
      "Epoch 2, iter 116, loss 2.0853097438812256, acc 0.20999999344348907\n",
      "Epoch 2, iter 117, loss 2.069672107696533, acc 0.2199999988079071\n",
      "Epoch 2, iter 118, loss 2.063955783843994, acc 0.14000000059604645\n",
      "Epoch 2, iter 119, loss 2.013251543045044, acc 0.25999999046325684\n",
      "Epoch 2, iter 120, loss 2.058198928833008, acc 0.2199999988079071\n",
      "Epoch 2, iter 121, loss 2.078616142272949, acc 0.23000000417232513\n",
      "Epoch 2, iter 122, loss 2.0602877140045166, acc 0.30000001192092896\n",
      "Epoch 2, iter 123, loss 2.0781962871551514, acc 0.14000000059604645\n",
      "Epoch 2, iter 124, loss 2.023991107940674, acc 0.2199999988079071\n",
      "Epoch 2, iter 125, loss 2.0830864906311035, acc 0.18000000715255737\n",
      "Epoch 2, iter 126, loss 2.0538887977600098, acc 0.20000000298023224\n",
      "Epoch 2, iter 127, loss 2.0649871826171875, acc 0.20999999344348907\n",
      "Epoch 2, iter 128, loss 2.090304374694824, acc 0.1899999976158142\n",
      "Epoch 2, iter 129, loss 2.0825583934783936, acc 0.20000000298023224\n",
      "Epoch 2, iter 130, loss 2.067230463027954, acc 0.20999999344348907\n",
      "Epoch 2, iter 131, loss 2.1080942153930664, acc 0.23000000417232513\n",
      "Epoch 2, iter 132, loss 2.0579488277435303, acc 0.25\n",
      "Epoch 2, iter 133, loss 2.0695619583129883, acc 0.2199999988079071\n",
      "Epoch 2, iter 134, loss 2.0624921321868896, acc 0.15000000596046448\n",
      "Epoch 2, iter 135, loss 2.1040191650390625, acc 0.23999999463558197\n",
      "Epoch 2, iter 136, loss 1.9938334226608276, acc 0.30000001192092896\n",
      "Epoch 2, iter 137, loss 2.0133543014526367, acc 0.23999999463558197\n",
      "Epoch 2, iter 138, loss 2.0109622478485107, acc 0.2199999988079071\n",
      "Epoch 2, iter 139, loss 2.0293636322021484, acc 0.20999999344348907\n",
      "Epoch 2, iter 140, loss 2.024685859680176, acc 0.1899999976158142\n",
      "Epoch 2, iter 141, loss 2.0241293907165527, acc 0.20999999344348907\n",
      "Epoch 2, iter 142, loss 2.097675085067749, acc 0.1599999964237213\n",
      "Epoch 2, iter 143, loss 2.0242116451263428, acc 0.20999999344348907\n",
      "Epoch 2, iter 144, loss 2.0454931259155273, acc 0.15000000596046448\n",
      "Epoch 2, iter 145, loss 2.0324127674102783, acc 0.20000000298023224\n",
      "Epoch 2, iter 146, loss 2.0565104484558105, acc 0.20000000298023224\n",
      "Epoch 2, iter 147, loss 2.0135231018066406, acc 0.23999999463558197\n",
      "Epoch 2, iter 148, loss 2.0303075313568115, acc 0.23000000417232513\n",
      "Epoch 2, iter 149, loss 1.9731664657592773, acc 0.2199999988079071\n",
      "Epoch 2, iter 150, loss 2.010751724243164, acc 0.23999999463558197\n",
      "Epoch 2, iter 151, loss 1.9272478818893433, acc 0.25999999046325684\n",
      "Epoch 2, iter 152, loss 2.023218870162964, acc 0.20000000298023224\n",
      "Epoch 2, iter 153, loss 2.0283408164978027, acc 0.23999999463558197\n",
      "Epoch 2, iter 154, loss 2.0161969661712646, acc 0.2199999988079071\n",
      "Epoch 2, iter 155, loss 2.0372369289398193, acc 0.25\n",
      "Epoch 2, iter 156, loss 2.0345168113708496, acc 0.2199999988079071\n",
      "Epoch 2, iter 157, loss 1.990576982498169, acc 0.17000000178813934\n",
      "Epoch 2, iter 158, loss 2.027902841567993, acc 0.20000000298023224\n",
      "Epoch 2, iter 159, loss 2.0592925548553467, acc 0.18000000715255737\n",
      "Epoch 2, iter 160, loss 2.041632890701294, acc 0.17000000178813934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, iter 161, loss 1.9483309984207153, acc 0.20000000298023224\n",
      "Epoch 2, iter 162, loss 1.9978516101837158, acc 0.28999999165534973\n",
      "Epoch 2, iter 163, loss 2.0547258853912354, acc 0.1899999976158142\n",
      "Epoch 2, iter 164, loss 2.0640170574188232, acc 0.1899999976158142\n",
      "Epoch 2, iter 165, loss 2.1016228199005127, acc 0.2199999988079071\n",
      "Epoch 2, iter 166, loss 2.04178786277771, acc 0.23999999463558197\n",
      "Epoch 2, iter 167, loss 2.0187926292419434, acc 0.20999999344348907\n",
      "Epoch 2, iter 168, loss 2.043358087539673, acc 0.2199999988079071\n",
      "Epoch 2, iter 169, loss 1.9980711936950684, acc 0.1899999976158142\n",
      "Epoch 2, iter 170, loss 2.043153762817383, acc 0.12999999523162842\n",
      "Epoch 2, iter 171, loss 2.0385477542877197, acc 0.17000000178813934\n",
      "Epoch 2, iter 172, loss 2.0686376094818115, acc 0.17000000178813934\n",
      "Epoch 2, iter 173, loss 2.038187026977539, acc 0.20000000298023224\n",
      "Epoch 2, iter 174, loss 2.029637336730957, acc 0.17000000178813934\n",
      "Epoch 2, iter 175, loss 1.9844534397125244, acc 0.2199999988079071\n",
      "Epoch 2, iter 176, loss 2.1113381385803223, acc 0.10999999940395355\n",
      "Epoch 2, iter 177, loss 2.0451104640960693, acc 0.25999999046325684\n",
      "Epoch 2, iter 178, loss 2.0601723194122314, acc 0.20999999344348907\n",
      "Epoch 2, iter 179, loss 2.041626214981079, acc 0.18000000715255737\n",
      "Epoch 2, iter 180, loss 2.0363996028900146, acc 0.23999999463558197\n",
      "Epoch 2, iter 181, loss 1.9898914098739624, acc 0.23000000417232513\n",
      "Epoch 2, iter 182, loss 2.0099658966064453, acc 0.25\n",
      "Epoch 2, iter 183, loss 2.0151538848876953, acc 0.20999999344348907\n",
      "Epoch 2, iter 184, loss 2.008841037750244, acc 0.18000000715255737\n",
      "Epoch 2, iter 185, loss 2.005162239074707, acc 0.20000000298023224\n",
      "Epoch 2, iter 186, loss 2.006270170211792, acc 0.2199999988079071\n",
      "Epoch 2, iter 187, loss 2.002581834793091, acc 0.2199999988079071\n",
      "Epoch 2, iter 188, loss 2.0760414600372314, acc 0.2199999988079071\n",
      "Epoch 2, iter 189, loss 2.1194281578063965, acc 0.11999999731779099\n",
      "Epoch 2, iter 190, loss 2.045830726623535, acc 0.20999999344348907\n",
      "Epoch 2, iter 191, loss 2.081422805786133, acc 0.20000000298023224\n",
      "Epoch 2, iter 192, loss 2.017972946166992, acc 0.23000000417232513\n",
      "Epoch 2, iter 193, loss 1.9619081020355225, acc 0.23999999463558197\n",
      "Epoch 2, iter 194, loss 1.9910606145858765, acc 0.1899999976158142\n",
      "Epoch 2, iter 195, loss 1.9969258308410645, acc 0.23000000417232513\n",
      "Epoch 2, iter 196, loss 2.0313427448272705, acc 0.1899999976158142\n",
      "Epoch 2, iter 197, loss 1.9953639507293701, acc 0.25\n",
      "Epoch 2, iter 198, loss 1.9552563428878784, acc 0.3199999928474426\n",
      "Epoch 2, iter 199, loss 2.047238826751709, acc 0.20999999344348907\n",
      "Epoch 2, iter 200, loss 2.0384111404418945, acc 0.27000001072883606\n",
      "Epoch 2, iter 201, loss 1.9714301824569702, acc 0.25\n",
      "Epoch 2, iter 202, loss 2.0282142162323, acc 0.18000000715255737\n",
      "Epoch 2, iter 203, loss 2.009470224380493, acc 0.12999999523162842\n",
      "Epoch 2, iter 204, loss 2.0004405975341797, acc 0.25999999046325684\n",
      "Epoch 2, iter 205, loss 1.9511226415634155, acc 0.23999999463558197\n",
      "Epoch 2, iter 206, loss 2.051304578781128, acc 0.20999999344348907\n",
      "Epoch 2, iter 207, loss 2.0537912845611572, acc 0.15000000596046448\n",
      "Epoch 2, iter 208, loss 2.0620813369750977, acc 0.18000000715255737\n",
      "Epoch 2, iter 209, loss 2.0463979244232178, acc 0.1899999976158142\n",
      "Epoch 2, iter 210, loss 2.0844335556030273, acc 0.1899999976158142\n",
      "Epoch 2, iter 211, loss 2.037163019180298, acc 0.20999999344348907\n",
      "Epoch 2, iter 212, loss 2.0450282096862793, acc 0.15000000596046448\n",
      "Epoch 2, iter 213, loss 2.028184413909912, acc 0.20999999344348907\n",
      "Epoch 2, iter 214, loss 2.08744740486145, acc 0.1899999976158142\n",
      "Epoch 2, iter 215, loss 2.067096710205078, acc 0.14000000059604645\n",
      "Epoch 2, iter 216, loss 2.0772643089294434, acc 0.1599999964237213\n",
      "Epoch 2, iter 217, loss 1.9907281398773193, acc 0.28999999165534973\n",
      "Epoch 2, iter 218, loss 2.117940664291382, acc 0.2199999988079071\n",
      "Epoch 2, iter 219, loss 2.0129382610321045, acc 0.17000000178813934\n",
      "Epoch 2, iter 220, loss 1.9656296968460083, acc 0.23000000417232513\n",
      "Epoch 2, iter 221, loss 2.0210394859313965, acc 0.18000000715255737\n",
      "Epoch 2, iter 222, loss 2.000495433807373, acc 0.2199999988079071\n",
      "Epoch 2, iter 223, loss 1.960730791091919, acc 0.2800000011920929\n",
      "Epoch 2, iter 224, loss 1.9940690994262695, acc 0.23000000417232513\n",
      "Epoch 2, iter 225, loss 2.024624824523926, acc 0.20999999344348907\n",
      "Epoch 2, iter 226, loss 2.0149667263031006, acc 0.23000000417232513\n",
      "Epoch 2, iter 227, loss 2.0216290950775146, acc 0.25\n",
      "Epoch 2, iter 228, loss 2.0723400115966797, acc 0.20000000298023224\n",
      "Epoch 2, iter 229, loss 1.9413338899612427, acc 0.2199999988079071\n",
      "Epoch 2, iter 230, loss 2.016458034515381, acc 0.25\n",
      "Epoch 2, iter 231, loss 1.9973094463348389, acc 0.2199999988079071\n",
      "Epoch 2, iter 232, loss 2.055842161178589, acc 0.15000000596046448\n",
      "Epoch 2, iter 233, loss 2.0344398021698, acc 0.23999999463558197\n",
      "Epoch 2, iter 234, loss 1.9713212251663208, acc 0.28999999165534973\n",
      "Epoch 2, iter 235, loss 1.9878034591674805, acc 0.2199999988079071\n",
      "Epoch 2, iter 236, loss 2.1023871898651123, acc 0.15000000596046448\n",
      "Epoch 2, iter 237, loss 2.1191256046295166, acc 0.1899999976158142\n",
      "Epoch 2, iter 238, loss 2.0325186252593994, acc 0.20999999344348907\n",
      "Epoch 2, iter 239, loss 1.9977115392684937, acc 0.14000000059604645\n",
      "Epoch 2, iter 240, loss 2.0480551719665527, acc 0.17000000178813934\n",
      "Epoch 2, iter 241, loss 2.008118152618408, acc 0.14000000059604645\n",
      "Epoch 2, iter 242, loss 2.073269844055176, acc 0.23000000417232513\n",
      "Epoch 2, iter 243, loss 2.09041690826416, acc 0.17000000178813934\n",
      "Epoch 2, iter 244, loss 2.0429327487945557, acc 0.27000001072883606\n",
      "Epoch 2, iter 245, loss 2.0244710445404053, acc 0.20999999344348907\n",
      "Epoch 2, iter 246, loss 2.076289653778076, acc 0.17000000178813934\n",
      "Epoch 2, iter 247, loss 1.9386094808578491, acc 0.25\n",
      "Epoch 2, iter 248, loss 2.076634645462036, acc 0.18000000715255737\n",
      "Epoch 2, iter 249, loss 2.039417028427124, acc 0.12999999523162842\n",
      "Epoch 2, iter 250, loss 1.977159857749939, acc 0.28999999165534973\n",
      "Epoch 2, iter 251, loss 2.0078656673431396, acc 0.1899999976158142\n",
      "Epoch 2, iter 252, loss 1.9775713682174683, acc 0.25\n",
      "Epoch 2, iter 253, loss 2.127894639968872, acc 0.1599999964237213\n",
      "Epoch 2, iter 254, loss 1.9850138425827026, acc 0.20999999344348907\n",
      "Epoch 2, iter 255, loss 2.0128941535949707, acc 0.18000000715255737\n",
      "Epoch 2, iter 256, loss 2.015071153640747, acc 0.23999999463558197\n",
      "Epoch 2, iter 257, loss 1.9980311393737793, acc 0.17000000178813934\n",
      "Epoch 2, iter 258, loss 2.0470800399780273, acc 0.23999999463558197\n",
      "Epoch 2, iter 259, loss 2.0426559448242188, acc 0.23000000417232513\n",
      "Epoch 2, iter 260, loss 2.0322585105895996, acc 0.20000000298023224\n",
      "Epoch 2, iter 261, loss 1.956206202507019, acc 0.23999999463558197\n",
      "Epoch 2, iter 262, loss 2.072082042694092, acc 0.1599999964237213\n",
      "Epoch 2, iter 263, loss 1.9560694694519043, acc 0.23000000417232513\n",
      "Epoch 2, iter 264, loss 1.9534287452697754, acc 0.27000001072883606\n",
      "Epoch 2, iter 265, loss 2.0448126792907715, acc 0.2199999988079071\n",
      "Epoch 2, iter 266, loss 2.015671968460083, acc 0.17000000178813934\n",
      "Epoch 2, iter 267, loss 1.9781239032745361, acc 0.2800000011920929\n",
      "Epoch 2, iter 268, loss 1.9760366678237915, acc 0.12999999523162842\n",
      "Epoch 2, iter 269, loss 2.0323009490966797, acc 0.20000000298023224\n",
      "Epoch 2, iter 270, loss 2.049532651901245, acc 0.1599999964237213\n",
      "Epoch 2, iter 271, loss 2.0366220474243164, acc 0.20000000298023224\n",
      "Epoch 2, iter 272, loss 2.0309555530548096, acc 0.20000000298023224\n",
      "Epoch 2, iter 273, loss 1.9894359111785889, acc 0.20999999344348907\n",
      "Epoch 2, iter 274, loss 2.03536057472229, acc 0.20999999344348907\n",
      "Epoch 2, iter 275, loss 2.0332088470458984, acc 0.18000000715255737\n",
      "Epoch 2, iter 276, loss 2.0388479232788086, acc 0.20000000298023224\n",
      "Epoch 2, iter 277, loss 2.047304153442383, acc 0.20000000298023224\n",
      "Epoch 2, iter 278, loss 2.0397679805755615, acc 0.17000000178813934\n",
      "Epoch 2, iter 279, loss 2.003566026687622, acc 0.2800000011920929\n",
      "Epoch 2, iter 280, loss 2.0037455558776855, acc 0.1899999976158142\n",
      "Epoch 2, iter 281, loss 1.984605312347412, acc 0.28999999165534973\n",
      "Epoch 2, iter 282, loss 2.0131616592407227, acc 0.1899999976158142\n",
      "Epoch 2, iter 283, loss 2.032259702682495, acc 0.17000000178813934\n",
      "Epoch 2, iter 284, loss 2.0007081031799316, acc 0.2800000011920929\n",
      "Epoch 2, iter 285, loss 2.019412040710449, acc 0.20999999344348907\n",
      "Epoch 2, iter 286, loss 1.9946882724761963, acc 0.23000000417232513\n",
      "Epoch 2, iter 287, loss 2.064786672592163, acc 0.20000000298023224\n",
      "Epoch 2, iter 288, loss 2.046757698059082, acc 0.20999999344348907\n",
      "Epoch 2, iter 289, loss 2.0144195556640625, acc 0.23999999463558197\n",
      "Epoch 2, iter 290, loss 1.980405330657959, acc 0.23000000417232513\n",
      "Epoch 2, iter 291, loss 2.030352830886841, acc 0.20999999344348907\n",
      "Epoch 2, iter 292, loss 2.003892421722412, acc 0.25999999046325684\n",
      "Epoch 2, iter 293, loss 2.047055721282959, acc 0.20000000298023224\n",
      "Epoch 2, iter 294, loss 2.061985492706299, acc 0.1599999964237213\n",
      "Epoch 2, iter 295, loss 2.0006356239318848, acc 0.20999999344348907\n",
      "Epoch 2, iter 296, loss 1.9804692268371582, acc 0.20999999344348907\n",
      "Epoch 2, iter 297, loss 2.0372583866119385, acc 0.23999999463558197\n",
      "Epoch 2, iter 298, loss 1.9654148817062378, acc 0.23999999463558197\n",
      "Epoch 2, iter 299, loss 2.0571889877319336, acc 0.11999999731779099\n",
      "Epoch 2, iter 300, loss 2.0793545246124268, acc 0.17000000178813934\n",
      "Epoch 2, iter 301, loss 2.093036413192749, acc 0.20999999344348907\n",
      "Epoch 2, iter 302, loss 1.9899274110794067, acc 0.2800000011920929\n",
      "Epoch 2, iter 303, loss 2.0263631343841553, acc 0.20000000298023224\n",
      "Epoch 2, iter 304, loss 2.0376789569854736, acc 0.17000000178813934\n",
      "Epoch 2, iter 305, loss 2.153876304626465, acc 0.1599999964237213\n",
      "Epoch 2, iter 306, loss 1.986497402191162, acc 0.20999999344348907\n",
      "Epoch 2, iter 307, loss 1.935774803161621, acc 0.25\n",
      "Epoch 2, iter 308, loss 2.0851895809173584, acc 0.2199999988079071\n",
      "Epoch 2, iter 309, loss 2.0332465171813965, acc 0.18000000715255737\n",
      "Epoch 2, iter 310, loss 2.0384256839752197, acc 0.18000000715255737\n",
      "Epoch 2, iter 311, loss 2.044637680053711, acc 0.23000000417232513\n",
      "Epoch 2, iter 312, loss 2.0388481616973877, acc 0.27000001072883606\n",
      "Epoch 2, iter 313, loss 2.125324249267578, acc 0.11999999731779099\n",
      "Epoch 2, iter 314, loss 2.019141912460327, acc 0.25\n",
      "Epoch 2, iter 315, loss 2.009312391281128, acc 0.25\n",
      "Epoch 2, iter 316, loss 2.014461040496826, acc 0.12999999523162842\n",
      "Epoch 2, iter 317, loss 2.0752716064453125, acc 0.20999999344348907\n",
      "Epoch 2, iter 318, loss 2.0260348320007324, acc 0.2199999988079071\n",
      "Epoch 2, iter 319, loss 2.0722365379333496, acc 0.17000000178813934\n",
      "Epoch 2, iter 320, loss 2.0251550674438477, acc 0.20000000298023224\n",
      "Epoch 2, iter 321, loss 2.055389881134033, acc 0.1899999976158142\n",
      "Epoch 2, iter 322, loss 2.032054901123047, acc 0.2199999988079071\n",
      "Epoch 2, iter 323, loss 2.0316927433013916, acc 0.20000000298023224\n",
      "Epoch 2, iter 324, loss 2.011319160461426, acc 0.23000000417232513\n",
      "Epoch 2, iter 325, loss 2.0115387439727783, acc 0.25\n",
      "Epoch 2, iter 326, loss 1.994685411453247, acc 0.20000000298023224\n",
      "Epoch 2, iter 327, loss 1.9928131103515625, acc 0.17000000178813934\n",
      "Epoch 2, iter 328, loss 1.9883780479431152, acc 0.25\n",
      "Epoch 2, iter 329, loss 2.0170438289642334, acc 0.20999999344348907\n",
      "Epoch 2, iter 330, loss 2.0420749187469482, acc 0.2199999988079071\n",
      "Epoch 2, iter 331, loss 2.0224390029907227, acc 0.18000000715255737\n",
      "Epoch 2, iter 332, loss 1.9801021814346313, acc 0.23999999463558197\n",
      "Epoch 2, iter 333, loss 2.012460708618164, acc 0.23000000417232513\n",
      "Epoch 2, iter 334, loss 1.980363368988037, acc 0.2199999988079071\n",
      "Epoch 2, iter 335, loss 1.946560025215149, acc 0.25\n",
      "Epoch 2, iter 336, loss 1.9912959337234497, acc 0.25\n",
      "Epoch 2, iter 337, loss 2.0702707767486572, acc 0.20000000298023224\n",
      "Epoch 2, iter 338, loss 2.037240505218506, acc 0.2199999988079071\n",
      "Epoch 2, iter 339, loss 2.0100553035736084, acc 0.2199999988079071\n",
      "Epoch 2, iter 340, loss 2.002882957458496, acc 0.23000000417232513\n",
      "Epoch 2, iter 341, loss 1.976676344871521, acc 0.25\n",
      "Epoch 2, iter 342, loss 2.053807020187378, acc 0.2199999988079071\n",
      "Epoch 2, iter 343, loss 1.9791101217269897, acc 0.1899999976158142\n",
      "Epoch 2, iter 344, loss 1.9877221584320068, acc 0.23000000417232513\n",
      "Epoch 2, iter 345, loss 2.074065923690796, acc 0.18000000715255737\n",
      "Epoch 2, iter 346, loss 1.937467336654663, acc 0.27000001072883606\n",
      "Epoch 2, iter 347, loss 2.0840671062469482, acc 0.20000000298023224\n",
      "Epoch 2, iter 348, loss 1.9555096626281738, acc 0.33000001311302185\n",
      "Epoch 2, iter 349, loss 1.9493930339813232, acc 0.27000001072883606\n",
      "Epoch 2, iter 350, loss 2.0242795944213867, acc 0.25\n",
      "Epoch 2, iter 351, loss 1.981137752532959, acc 0.15000000596046448\n",
      "Epoch 2, iter 352, loss 2.009526014328003, acc 0.1899999976158142\n",
      "Epoch 2, iter 353, loss 2.0078024864196777, acc 0.25\n",
      "Epoch 2, iter 354, loss 2.0420432090759277, acc 0.23999999463558197\n",
      "Epoch 2, iter 355, loss 2.0638973712921143, acc 0.1899999976158142\n",
      "Epoch 2, iter 356, loss 2.0455400943756104, acc 0.23999999463558197\n",
      "Epoch 2, iter 357, loss 2.068514823913574, acc 0.20000000298023224\n",
      "Epoch 2, iter 358, loss 2.074492931365967, acc 0.18000000715255737\n",
      "Epoch 2, iter 359, loss 2.0814850330352783, acc 0.12999999523162842\n",
      "Epoch 2, iter 360, loss 2.0681521892547607, acc 0.2199999988079071\n",
      "Epoch 2, iter 361, loss 2.038930654525757, acc 0.1899999976158142\n",
      "Epoch 2, iter 362, loss 2.052851915359497, acc 0.1599999964237213\n",
      "Epoch 2, iter 363, loss 2.0090012550354004, acc 0.28999999165534973\n",
      "Epoch 2, iter 364, loss 2.097954034805298, acc 0.11999999731779099\n",
      "Epoch 2, iter 365, loss 2.0637049674987793, acc 0.20000000298023224\n",
      "Epoch 2, iter 366, loss 2.0942134857177734, acc 0.20999999344348907\n",
      "Epoch 2, iter 367, loss 2.0026438236236572, acc 0.2199999988079071\n",
      "Epoch 2, iter 368, loss 2.054654121398926, acc 0.23999999463558197\n",
      "Epoch 2, iter 369, loss 1.9712449312210083, acc 0.23999999463558197\n",
      "Epoch 2, iter 370, loss 2.0125017166137695, acc 0.20999999344348907\n",
      "Epoch 2, iter 371, loss 2.0311615467071533, acc 0.23999999463558197\n",
      "Epoch 2, iter 372, loss 2.0153141021728516, acc 0.23000000417232513\n",
      "Epoch 2, iter 373, loss 2.0504565238952637, acc 0.17000000178813934\n",
      "Epoch 2, iter 374, loss 2.0669822692871094, acc 0.20000000298023224\n",
      "Epoch 2, iter 375, loss 2.0548369884490967, acc 0.28999999165534973\n",
      "Epoch 2, iter 376, loss 2.022705554962158, acc 0.15000000596046448\n",
      "Epoch 2, iter 377, loss 1.9717283248901367, acc 0.27000001072883606\n",
      "Epoch 2, iter 378, loss 2.000448703765869, acc 0.25999999046325684\n",
      "Epoch 2, iter 379, loss 2.0616674423217773, acc 0.17000000178813934\n",
      "Epoch 2, iter 380, loss 2.1111621856689453, acc 0.15000000596046448\n",
      "Epoch 2, iter 381, loss 2.0253655910491943, acc 0.1599999964237213\n",
      "Epoch 2, iter 382, loss 1.9643405675888062, acc 0.25\n",
      "Epoch 2, iter 383, loss 2.0379068851470947, acc 0.25999999046325684\n",
      "Epoch 2, iter 384, loss 1.9873032569885254, acc 0.18000000715255737\n",
      "Epoch 2, iter 385, loss 1.9836691617965698, acc 0.23000000417232513\n",
      "Epoch 2, iter 386, loss 1.991185188293457, acc 0.20999999344348907\n",
      "Epoch 2, iter 387, loss 2.057227373123169, acc 0.23999999463558197\n",
      "Epoch 2, iter 388, loss 2.008931875228882, acc 0.20999999344348907\n",
      "Epoch 2, iter 389, loss 2.0728511810302734, acc 0.20999999344348907\n",
      "Epoch 2, iter 390, loss 2.1220345497131348, acc 0.10000000149011612\n",
      "Epoch 2, iter 391, loss 1.9848252534866333, acc 0.1899999976158142\n",
      "Epoch 2, iter 392, loss 2.0008811950683594, acc 0.18000000715255737\n",
      "Epoch 2, iter 393, loss 2.0275614261627197, acc 0.15000000596046448\n",
      "Epoch 2, iter 394, loss 2.0068986415863037, acc 0.23999999463558197\n",
      "Epoch 2, iter 395, loss 1.9886627197265625, acc 0.25999999046325684\n",
      "Epoch 2, iter 396, loss 2.0522050857543945, acc 0.15000000596046448\n",
      "Epoch 2, iter 397, loss 2.0338191986083984, acc 0.20000000298023224\n",
      "Epoch 2, iter 398, loss 2.0630273818969727, acc 0.12999999523162842\n",
      "Epoch 2, iter 399, loss 2.0085911750793457, acc 0.23000000417232513\n",
      "Epoch 2, iter 400, loss 1.969918966293335, acc 0.28999999165534973\n",
      "Epoch 2, iter 401, loss 1.9744644165039062, acc 0.20999999344348907\n",
      "Epoch 2, iter 402, loss 2.0588791370391846, acc 0.20999999344348907\n",
      "Epoch 2, iter 403, loss 2.0637669563293457, acc 0.20000000298023224\n",
      "Epoch 2, iter 404, loss 2.0441205501556396, acc 0.1599999964237213\n",
      "Epoch 2, iter 405, loss 2.005995273590088, acc 0.23999999463558197\n",
      "Epoch 2, iter 406, loss 2.0845284461975098, acc 0.11999999731779099\n",
      "Epoch 2, iter 407, loss 2.0441689491271973, acc 0.14000000059604645\n",
      "Epoch 2, iter 408, loss 2.0352165699005127, acc 0.25\n",
      "Epoch 2, iter 409, loss 1.9691777229309082, acc 0.25\n",
      "Epoch 2, iter 410, loss 2.0043535232543945, acc 0.1599999964237213\n",
      "Epoch 2, iter 411, loss 2.005951404571533, acc 0.27000001072883606\n",
      "Epoch 2, iter 412, loss 1.9800310134887695, acc 0.27000001072883606\n",
      "Epoch 2, iter 413, loss 2.0817954540252686, acc 0.14000000059604645\n",
      "Epoch 2, iter 414, loss 2.0010764598846436, acc 0.15000000596046448\n",
      "Epoch 2, iter 415, loss 2.018723964691162, acc 0.20000000298023224\n",
      "Epoch 2, iter 416, loss 1.9887619018554688, acc 0.20999999344348907\n",
      "Epoch 2, iter 417, loss 1.9234787225723267, acc 0.30000001192092896\n",
      "Epoch 2, iter 418, loss 2.048124313354492, acc 0.15000000596046448\n",
      "Epoch 2, iter 419, loss 2.0314717292785645, acc 0.27000001072883606\n",
      "Epoch 2, iter 420, loss 2.0352323055267334, acc 0.23000000417232513\n",
      "Epoch 3, iter 1, loss 2.018868923187256, acc 0.2199999988079071\n",
      "Epoch 3, iter 2, loss 2.0665132999420166, acc 0.17000000178813934\n",
      "Epoch 3, iter 3, loss 1.9563369750976562, acc 0.1899999976158142\n",
      "Epoch 3, iter 4, loss 2.1186280250549316, acc 0.15000000596046448\n",
      "Epoch 3, iter 5, loss 2.0507278442382812, acc 0.1599999964237213\n",
      "Epoch 3, iter 6, loss 2.0210013389587402, acc 0.17000000178813934\n",
      "Epoch 3, iter 7, loss 2.0239992141723633, acc 0.25\n",
      "Epoch 3, iter 8, loss 2.030221462249756, acc 0.18000000715255737\n",
      "Epoch 3, iter 9, loss 1.9941661357879639, acc 0.2199999988079071\n",
      "Epoch 3, iter 10, loss 1.9781157970428467, acc 0.1899999976158142\n",
      "Epoch 3, iter 11, loss 2.0040876865386963, acc 0.2199999988079071\n",
      "Epoch 3, iter 12, loss 1.9997687339782715, acc 0.20000000298023224\n",
      "Epoch 3, iter 13, loss 1.9611735343933105, acc 0.18000000715255737\n",
      "Epoch 3, iter 14, loss 2.0228776931762695, acc 0.2199999988079071\n",
      "Epoch 3, iter 15, loss 1.9694198369979858, acc 0.25999999046325684\n",
      "Epoch 3, iter 16, loss 1.958174705505371, acc 0.20999999344348907\n",
      "Epoch 3, iter 17, loss 1.9579771757125854, acc 0.1599999964237213\n",
      "Epoch 3, iter 18, loss 2.1754534244537354, acc 0.15000000596046448\n",
      "Epoch 3, iter 19, loss 2.298064947128296, acc 0.10000000149011612\n",
      "Epoch 3, iter 20, loss 2.258146286010742, acc 0.15000000596046448\n",
      "Epoch 3, iter 21, loss 2.2472896575927734, acc 0.11999999731779099\n",
      "Epoch 3, iter 22, loss 2.1975481510162354, acc 0.10000000149011612\n",
      "Epoch 3, iter 23, loss 2.1990180015563965, acc 0.1899999976158142\n",
      "Epoch 3, iter 24, loss 2.1537997722625732, acc 0.11999999731779099\n",
      "Epoch 3, iter 25, loss 2.190155267715454, acc 0.15000000596046448\n",
      "Epoch 3, iter 26, loss 2.1140646934509277, acc 0.17000000178813934\n",
      "Epoch 3, iter 27, loss 2.120374917984009, acc 0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 28, loss 2.076504945755005, acc 0.2199999988079071\n",
      "Epoch 3, iter 29, loss 2.0841660499572754, acc 0.20999999344348907\n",
      "Epoch 3, iter 30, loss 2.1172361373901367, acc 0.20000000298023224\n",
      "Epoch 3, iter 31, loss 2.1154446601867676, acc 0.11999999731779099\n",
      "Epoch 3, iter 32, loss 2.1132614612579346, acc 0.1599999964237213\n",
      "Epoch 3, iter 33, loss 2.038438320159912, acc 0.23000000417232513\n",
      "Epoch 3, iter 34, loss 2.0632474422454834, acc 0.18000000715255737\n",
      "Epoch 3, iter 35, loss 2.0115227699279785, acc 0.20999999344348907\n",
      "Epoch 3, iter 36, loss 2.053785800933838, acc 0.17000000178813934\n",
      "Epoch 3, iter 37, loss 2.0542500019073486, acc 0.17000000178813934\n",
      "Epoch 3, iter 38, loss 2.0838325023651123, acc 0.23999999463558197\n",
      "Epoch 3, iter 39, loss 2.105149269104004, acc 0.1899999976158142\n",
      "Epoch 3, iter 40, loss 2.0011823177337646, acc 0.20999999344348907\n",
      "Epoch 3, iter 41, loss 2.0661020278930664, acc 0.15000000596046448\n",
      "Epoch 3, iter 42, loss 2.053424119949341, acc 0.14000000059604645\n",
      "Epoch 3, iter 43, loss 2.036689519882202, acc 0.1899999976158142\n",
      "Epoch 3, iter 44, loss 1.9743468761444092, acc 0.17000000178813934\n",
      "Epoch 3, iter 45, loss 2.0724191665649414, acc 0.1899999976158142\n",
      "Epoch 3, iter 46, loss 2.0182645320892334, acc 0.2800000011920929\n",
      "Epoch 3, iter 47, loss 2.039579153060913, acc 0.1599999964237213\n",
      "Epoch 3, iter 48, loss 1.9816224575042725, acc 0.18000000715255737\n",
      "Epoch 3, iter 49, loss 2.000753879547119, acc 0.20999999344348907\n",
      "Epoch 3, iter 50, loss 2.023496627807617, acc 0.23999999463558197\n",
      "Epoch 3, iter 51, loss 1.998410940170288, acc 0.23999999463558197\n",
      "Epoch 3, iter 52, loss 2.049217462539673, acc 0.1899999976158142\n",
      "Epoch 3, iter 53, loss 1.9291207790374756, acc 0.33000001311302185\n",
      "Epoch 3, iter 54, loss 1.9785194396972656, acc 0.15000000596046448\n",
      "Epoch 3, iter 55, loss 2.061825752258301, acc 0.11999999731779099\n",
      "Epoch 3, iter 56, loss 2.013991355895996, acc 0.18000000715255737\n",
      "Epoch 3, iter 57, loss 2.038198471069336, acc 0.1899999976158142\n",
      "Epoch 3, iter 58, loss 2.0289347171783447, acc 0.18000000715255737\n",
      "Epoch 3, iter 59, loss 2.013885259628296, acc 0.23000000417232513\n",
      "Epoch 3, iter 60, loss 2.0367348194122314, acc 0.2199999988079071\n",
      "Epoch 3, iter 61, loss 1.9774075746536255, acc 0.18000000715255737\n",
      "Epoch 3, iter 62, loss 2.0004067420959473, acc 0.1899999976158142\n",
      "Epoch 3, iter 63, loss 2.040536880493164, acc 0.23000000417232513\n",
      "Epoch 3, iter 64, loss 1.9586896896362305, acc 0.20999999344348907\n",
      "Epoch 3, iter 65, loss 1.9658147096633911, acc 0.27000001072883606\n",
      "Epoch 3, iter 66, loss 1.9771097898483276, acc 0.20999999344348907\n",
      "Epoch 3, iter 67, loss 2.055206298828125, acc 0.18000000715255737\n",
      "Epoch 3, iter 68, loss 1.940171241760254, acc 0.3100000023841858\n",
      "Epoch 3, iter 69, loss 2.0560097694396973, acc 0.1899999976158142\n",
      "Epoch 3, iter 70, loss 1.9502763748168945, acc 0.2800000011920929\n",
      "Epoch 3, iter 71, loss 2.002863883972168, acc 0.18000000715255737\n",
      "Epoch 3, iter 72, loss 2.047787666320801, acc 0.12999999523162842\n",
      "Epoch 3, iter 73, loss 1.9588420391082764, acc 0.25\n",
      "Epoch 3, iter 74, loss 1.9677338600158691, acc 0.2199999988079071\n",
      "Epoch 3, iter 75, loss 2.0003342628479004, acc 0.12999999523162842\n",
      "Epoch 3, iter 76, loss 2.0615172386169434, acc 0.20000000298023224\n",
      "Epoch 3, iter 77, loss 2.1351311206817627, acc 0.1599999964237213\n",
      "Epoch 3, iter 78, loss 2.042757034301758, acc 0.28999999165534973\n",
      "Epoch 3, iter 79, loss 2.036407232284546, acc 0.20999999344348907\n",
      "Epoch 3, iter 80, loss 2.0940799713134766, acc 0.20000000298023224\n",
      "Epoch 3, iter 81, loss 2.0765328407287598, acc 0.1599999964237213\n",
      "Epoch 3, iter 82, loss 2.036001205444336, acc 0.17000000178813934\n",
      "Epoch 3, iter 83, loss 2.01753568649292, acc 0.20999999344348907\n",
      "Epoch 3, iter 84, loss 2.111309289932251, acc 0.15000000596046448\n",
      "Epoch 3, iter 85, loss 2.046884059906006, acc 0.15000000596046448\n",
      "Epoch 3, iter 86, loss 1.9893649816513062, acc 0.20000000298023224\n",
      "Epoch 3, iter 87, loss 2.0653464794158936, acc 0.25\n",
      "Epoch 3, iter 88, loss 1.9795604944229126, acc 0.25999999046325684\n",
      "Epoch 3, iter 89, loss 2.0897414684295654, acc 0.20999999344348907\n",
      "Epoch 3, iter 90, loss 2.008908271789551, acc 0.1899999976158142\n",
      "Epoch 3, iter 91, loss 2.100619077682495, acc 0.1899999976158142\n",
      "Epoch 3, iter 92, loss 2.114068031311035, acc 0.2199999988079071\n",
      "Epoch 3, iter 93, loss 1.956815242767334, acc 0.2199999988079071\n",
      "Epoch 3, iter 94, loss 2.072021245956421, acc 0.1599999964237213\n",
      "Epoch 3, iter 95, loss 2.008780002593994, acc 0.20999999344348907\n",
      "Epoch 3, iter 96, loss 2.012451171875, acc 0.23999999463558197\n",
      "Epoch 3, iter 97, loss 2.0006308555603027, acc 0.10999999940395355\n",
      "Epoch 3, iter 98, loss 2.0606133937835693, acc 0.17000000178813934\n",
      "Epoch 3, iter 99, loss 2.0355324745178223, acc 0.2199999988079071\n",
      "Epoch 3, iter 100, loss 2.0101613998413086, acc 0.25\n",
      "Epoch 3, iter 101, loss 2.064422845840454, acc 0.18000000715255737\n",
      "Epoch 3, iter 102, loss 2.054652452468872, acc 0.23000000417232513\n",
      "Epoch 3, iter 103, loss 2.0526692867279053, acc 0.25\n",
      "Epoch 3, iter 104, loss 2.039503335952759, acc 0.2800000011920929\n",
      "Epoch 3, iter 105, loss 2.0170390605926514, acc 0.1599999964237213\n",
      "Epoch 3, iter 106, loss 2.062075614929199, acc 0.25\n",
      "Epoch 3, iter 107, loss 2.0936503410339355, acc 0.20999999344348907\n",
      "Epoch 3, iter 108, loss 2.0333499908447266, acc 0.12999999523162842\n",
      "Epoch 3, iter 109, loss 2.0898170471191406, acc 0.1899999976158142\n",
      "Epoch 3, iter 110, loss 2.067469596862793, acc 0.11999999731779099\n",
      "Epoch 3, iter 111, loss 2.0407166481018066, acc 0.1599999964237213\n",
      "Epoch 3, iter 112, loss 2.016226291656494, acc 0.25\n",
      "Epoch 3, iter 113, loss 1.953715205192566, acc 0.25999999046325684\n",
      "Epoch 3, iter 114, loss 1.9417529106140137, acc 0.2199999988079071\n",
      "Epoch 3, iter 115, loss 1.9340896606445312, acc 0.25999999046325684\n",
      "Epoch 3, iter 116, loss 1.989959716796875, acc 0.20999999344348907\n",
      "Epoch 3, iter 117, loss 2.0289833545684814, acc 0.2199999988079071\n",
      "Epoch 3, iter 118, loss 1.9938697814941406, acc 0.14000000059604645\n",
      "Epoch 3, iter 119, loss 1.9512542486190796, acc 0.25999999046325684\n",
      "Epoch 3, iter 120, loss 2.0152111053466797, acc 0.23000000417232513\n",
      "Epoch 3, iter 121, loss 2.0305490493774414, acc 0.23000000417232513\n",
      "Epoch 3, iter 122, loss 2.0070409774780273, acc 0.30000001192092896\n",
      "Epoch 3, iter 123, loss 2.0286378860473633, acc 0.14000000059604645\n",
      "Epoch 3, iter 124, loss 1.906816005706787, acc 0.23000000417232513\n",
      "Epoch 3, iter 125, loss 1.9957633018493652, acc 0.1899999976158142\n",
      "Epoch 3, iter 126, loss 1.9753550291061401, acc 0.20000000298023224\n",
      "Epoch 3, iter 127, loss 1.9838186502456665, acc 0.23999999463558197\n",
      "Epoch 3, iter 128, loss 2.032656669616699, acc 0.18000000715255737\n",
      "Epoch 3, iter 129, loss 2.043087959289551, acc 0.20000000298023224\n",
      "Epoch 3, iter 130, loss 2.0594518184661865, acc 0.20999999344348907\n",
      "Epoch 3, iter 131, loss 2.0494260787963867, acc 0.23000000417232513\n",
      "Epoch 3, iter 132, loss 2.017056941986084, acc 0.25\n",
      "Epoch 3, iter 133, loss 1.9978216886520386, acc 0.2199999988079071\n",
      "Epoch 3, iter 134, loss 1.9868797063827515, acc 0.15000000596046448\n",
      "Epoch 3, iter 135, loss 2.035456895828247, acc 0.27000001072883606\n",
      "Epoch 3, iter 136, loss 1.949794888496399, acc 0.2800000011920929\n",
      "Epoch 3, iter 137, loss 1.9873613119125366, acc 0.23999999463558197\n",
      "Epoch 3, iter 138, loss 1.93937349319458, acc 0.23000000417232513\n",
      "Epoch 3, iter 139, loss 1.956741213798523, acc 0.20000000298023224\n",
      "Epoch 3, iter 140, loss 1.9949320554733276, acc 0.1899999976158142\n",
      "Epoch 3, iter 141, loss 1.963293433189392, acc 0.20999999344348907\n",
      "Epoch 3, iter 142, loss 1.979711890220642, acc 0.15000000596046448\n",
      "Epoch 3, iter 143, loss 2.0210039615631104, acc 0.20999999344348907\n",
      "Epoch 3, iter 144, loss 1.9538325071334839, acc 0.15000000596046448\n",
      "Epoch 3, iter 145, loss 1.989243745803833, acc 0.20000000298023224\n",
      "Epoch 3, iter 146, loss 2.058591365814209, acc 0.1899999976158142\n",
      "Epoch 3, iter 147, loss 1.996224045753479, acc 0.23999999463558197\n",
      "Epoch 3, iter 148, loss 1.9684481620788574, acc 0.2199999988079071\n",
      "Epoch 3, iter 149, loss 1.987235426902771, acc 0.20000000298023224\n",
      "Epoch 3, iter 150, loss 2.0233821868896484, acc 0.23000000417232513\n",
      "Epoch 3, iter 151, loss 1.9446475505828857, acc 0.23999999463558197\n",
      "Epoch 3, iter 152, loss 1.9885021448135376, acc 0.20000000298023224\n",
      "Epoch 3, iter 153, loss 2.0648000240325928, acc 0.23000000417232513\n",
      "Epoch 3, iter 154, loss 2.0501303672790527, acc 0.20999999344348907\n",
      "Epoch 3, iter 155, loss 2.019679307937622, acc 0.23999999463558197\n",
      "Epoch 3, iter 156, loss 1.9917421340942383, acc 0.23000000417232513\n",
      "Epoch 3, iter 157, loss 2.0004618167877197, acc 0.1599999964237213\n",
      "Epoch 3, iter 158, loss 1.9933987855911255, acc 0.1899999976158142\n",
      "Epoch 3, iter 159, loss 1.981703758239746, acc 0.17000000178813934\n",
      "Epoch 3, iter 160, loss 1.9955253601074219, acc 0.17000000178813934\n",
      "Epoch 3, iter 161, loss 2.0045087337493896, acc 0.1899999976158142\n",
      "Epoch 3, iter 162, loss 2.0179216861724854, acc 0.27000001072883606\n",
      "Epoch 3, iter 163, loss 2.032625675201416, acc 0.18000000715255737\n",
      "Epoch 3, iter 164, loss 2.01503849029541, acc 0.20000000298023224\n",
      "Epoch 3, iter 165, loss 2.081838846206665, acc 0.23000000417232513\n",
      "Epoch 3, iter 166, loss 2.023061752319336, acc 0.23000000417232513\n",
      "Epoch 3, iter 167, loss 2.005587577819824, acc 0.1899999976158142\n",
      "Epoch 3, iter 168, loss 1.966274380683899, acc 0.2199999988079071\n",
      "Epoch 3, iter 169, loss 1.9675601720809937, acc 0.17000000178813934\n",
      "Epoch 3, iter 170, loss 2.0068209171295166, acc 0.12999999523162842\n",
      "Epoch 3, iter 171, loss 1.9604182243347168, acc 0.1899999976158142\n",
      "Epoch 3, iter 172, loss 2.065833806991577, acc 0.18000000715255737\n",
      "Epoch 3, iter 173, loss 2.016315221786499, acc 0.20000000298023224\n",
      "Epoch 3, iter 174, loss 2.0481913089752197, acc 0.14000000059604645\n",
      "Epoch 3, iter 175, loss 1.9466757774353027, acc 0.20999999344348907\n",
      "Epoch 3, iter 176, loss 2.070366621017456, acc 0.10000000149011612\n",
      "Epoch 3, iter 177, loss 1.9844731092453003, acc 0.25\n",
      "Epoch 3, iter 178, loss 2.010474920272827, acc 0.20999999344348907\n",
      "Epoch 3, iter 179, loss 2.068624973297119, acc 0.17000000178813934\n",
      "Epoch 3, iter 180, loss 2.034813165664673, acc 0.2199999988079071\n",
      "Epoch 3, iter 181, loss 2.007505416870117, acc 0.20000000298023224\n",
      "Epoch 3, iter 182, loss 2.0233609676361084, acc 0.23000000417232513\n",
      "Epoch 3, iter 183, loss 1.9659178256988525, acc 0.20999999344348907\n",
      "Epoch 3, iter 184, loss 2.0282111167907715, acc 0.1599999964237213\n",
      "Epoch 3, iter 185, loss 1.962602972984314, acc 0.20000000298023224\n",
      "Epoch 3, iter 186, loss 1.9878129959106445, acc 0.20999999344348907\n",
      "Epoch 3, iter 187, loss 1.9881007671356201, acc 0.20999999344348907\n",
      "Epoch 3, iter 188, loss 2.0704505443573, acc 0.20000000298023224\n",
      "Epoch 3, iter 189, loss 2.1169087886810303, acc 0.11999999731779099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 190, loss 2.0171070098876953, acc 0.20999999344348907\n",
      "Epoch 3, iter 191, loss 2.0513570308685303, acc 0.20000000298023224\n",
      "Epoch 3, iter 192, loss 1.9934189319610596, acc 0.2199999988079071\n",
      "Epoch 3, iter 193, loss 1.929649829864502, acc 0.23999999463558197\n",
      "Epoch 3, iter 194, loss 1.9207682609558105, acc 0.1899999976158142\n",
      "Epoch 3, iter 195, loss 1.9271736145019531, acc 0.23999999463558197\n",
      "Epoch 3, iter 196, loss 2.037628173828125, acc 0.18000000715255737\n",
      "Epoch 3, iter 197, loss 1.9786763191223145, acc 0.23000000417232513\n",
      "Epoch 3, iter 198, loss 1.8995187282562256, acc 0.3199999928474426\n",
      "Epoch 3, iter 199, loss 2.004110813140869, acc 0.20000000298023224\n",
      "Epoch 3, iter 200, loss 2.027784824371338, acc 0.27000001072883606\n",
      "Epoch 3, iter 201, loss 1.9766571521759033, acc 0.25\n",
      "Epoch 3, iter 202, loss 2.0511422157287598, acc 0.18000000715255737\n",
      "Epoch 3, iter 203, loss 1.9897866249084473, acc 0.12999999523162842\n",
      "Epoch 3, iter 204, loss 1.9701781272888184, acc 0.25999999046325684\n",
      "Epoch 3, iter 205, loss 1.914271354675293, acc 0.23000000417232513\n",
      "Epoch 3, iter 206, loss 1.9775950908660889, acc 0.2199999988079071\n",
      "Epoch 3, iter 207, loss 2.016956090927124, acc 0.15000000596046448\n",
      "Epoch 3, iter 208, loss 2.0201311111450195, acc 0.18000000715255737\n",
      "Epoch 3, iter 209, loss 2.03721284866333, acc 0.18000000715255737\n",
      "Epoch 3, iter 210, loss 2.023742437362671, acc 0.1899999976158142\n",
      "Epoch 3, iter 211, loss 2.0295376777648926, acc 0.20000000298023224\n",
      "Epoch 3, iter 212, loss 1.9763866662979126, acc 0.1599999964237213\n",
      "Epoch 3, iter 213, loss 1.9577734470367432, acc 0.20999999344348907\n",
      "Epoch 3, iter 214, loss 2.0274715423583984, acc 0.1899999976158142\n",
      "Epoch 3, iter 215, loss 1.97832453250885, acc 0.14000000059604645\n",
      "Epoch 3, iter 216, loss 2.038792371749878, acc 0.1599999964237213\n",
      "Epoch 3, iter 217, loss 1.9166651964187622, acc 0.28999999165534973\n",
      "Epoch 3, iter 218, loss 2.097177505493164, acc 0.20999999344348907\n",
      "Epoch 3, iter 219, loss 1.9988020658493042, acc 0.1599999964237213\n",
      "Epoch 3, iter 220, loss 1.8642088174819946, acc 0.23999999463558197\n",
      "Epoch 3, iter 221, loss 1.9524208307266235, acc 0.18000000715255737\n",
      "Epoch 3, iter 222, loss 1.937479853630066, acc 0.2199999988079071\n",
      "Epoch 3, iter 223, loss 1.8890188932418823, acc 0.28999999165534973\n",
      "Epoch 3, iter 224, loss 1.9690214395523071, acc 0.23999999463558197\n",
      "Epoch 3, iter 225, loss 1.9458155632019043, acc 0.23000000417232513\n",
      "Epoch 3, iter 226, loss 1.9213776588439941, acc 0.23999999463558197\n",
      "Epoch 3, iter 227, loss 1.9751441478729248, acc 0.25\n",
      "Epoch 3, iter 228, loss 2.055711269378662, acc 0.20000000298023224\n",
      "Epoch 3, iter 229, loss 1.8894864320755005, acc 0.2199999988079071\n",
      "Epoch 3, iter 230, loss 1.9502302408218384, acc 0.25\n",
      "Epoch 3, iter 231, loss 1.9658275842666626, acc 0.2199999988079071\n",
      "Epoch 3, iter 232, loss 2.0366339683532715, acc 0.15000000596046448\n",
      "Epoch 3, iter 233, loss 2.0214147567749023, acc 0.23999999463558197\n",
      "Epoch 3, iter 234, loss 1.9485290050506592, acc 0.2800000011920929\n",
      "Epoch 3, iter 235, loss 1.9223430156707764, acc 0.23000000417232513\n",
      "Epoch 3, iter 236, loss 2.053391933441162, acc 0.17000000178813934\n",
      "Epoch 3, iter 237, loss 2.078680992126465, acc 0.1899999976158142\n",
      "Epoch 3, iter 238, loss 1.9882397651672363, acc 0.2199999988079071\n",
      "Epoch 3, iter 239, loss 1.9774365425109863, acc 0.14000000059604645\n",
      "Epoch 3, iter 240, loss 2.0156188011169434, acc 0.17000000178813934\n",
      "Epoch 3, iter 241, loss 1.946719765663147, acc 0.14000000059604645\n",
      "Epoch 3, iter 242, loss 2.0110814571380615, acc 0.23000000417232513\n",
      "Epoch 3, iter 243, loss 2.017932653427124, acc 0.17000000178813934\n",
      "Epoch 3, iter 244, loss 1.9478360414505005, acc 0.28999999165534973\n",
      "Epoch 3, iter 245, loss 2.0037267208099365, acc 0.20000000298023224\n",
      "Epoch 3, iter 246, loss 2.06181263923645, acc 0.17000000178813934\n",
      "Epoch 3, iter 247, loss 1.887903094291687, acc 0.23999999463558197\n",
      "Epoch 3, iter 248, loss 2.0295767784118652, acc 0.18000000715255737\n",
      "Epoch 3, iter 249, loss 1.9798800945281982, acc 0.12999999523162842\n",
      "Epoch 3, iter 250, loss 1.9641804695129395, acc 0.28999999165534973\n",
      "Epoch 3, iter 251, loss 1.9800256490707397, acc 0.1899999976158142\n",
      "Epoch 3, iter 252, loss 1.9245659112930298, acc 0.23999999463558197\n",
      "Epoch 3, iter 253, loss 2.084320068359375, acc 0.15000000596046448\n",
      "Epoch 3, iter 254, loss 1.938706874847412, acc 0.20999999344348907\n",
      "Epoch 3, iter 255, loss 1.9883743524551392, acc 0.18000000715255737\n",
      "Epoch 3, iter 256, loss 2.0069878101348877, acc 0.23000000417232513\n",
      "Epoch 3, iter 257, loss 2.006354331970215, acc 0.17000000178813934\n",
      "Epoch 3, iter 258, loss 2.044370651245117, acc 0.23999999463558197\n",
      "Epoch 3, iter 259, loss 2.0326590538024902, acc 0.23000000417232513\n",
      "Epoch 3, iter 260, loss 2.000497817993164, acc 0.20000000298023224\n",
      "Epoch 3, iter 261, loss 1.941532015800476, acc 0.23000000417232513\n",
      "Epoch 3, iter 262, loss 2.0416901111602783, acc 0.15000000596046448\n",
      "Epoch 3, iter 263, loss 1.8995985984802246, acc 0.23000000417232513\n",
      "Epoch 3, iter 264, loss 1.9533342123031616, acc 0.25999999046325684\n",
      "Epoch 3, iter 265, loss 2.0508551597595215, acc 0.2199999988079071\n",
      "Epoch 3, iter 266, loss 1.9437655210494995, acc 0.1599999964237213\n",
      "Epoch 3, iter 267, loss 1.941827654838562, acc 0.27000001072883606\n",
      "Epoch 3, iter 268, loss 1.9589221477508545, acc 0.12999999523162842\n",
      "Epoch 3, iter 269, loss 2.038656711578369, acc 0.18000000715255737\n",
      "Epoch 3, iter 270, loss 1.9671746492385864, acc 0.1599999964237213\n",
      "Epoch 3, iter 271, loss 2.008066415786743, acc 0.20000000298023224\n",
      "Epoch 3, iter 272, loss 1.9877723455429077, acc 0.20000000298023224\n",
      "Epoch 3, iter 273, loss 1.9984763860702515, acc 0.1899999976158142\n",
      "Epoch 3, iter 274, loss 1.9981400966644287, acc 0.20999999344348907\n",
      "Epoch 3, iter 275, loss 1.9881287813186646, acc 0.18000000715255737\n",
      "Epoch 3, iter 276, loss 1.998795986175537, acc 0.20000000298023224\n",
      "Epoch 3, iter 277, loss 1.9910838603973389, acc 0.20000000298023224\n",
      "Epoch 3, iter 278, loss 1.9684510231018066, acc 0.18000000715255737\n",
      "Epoch 3, iter 279, loss 1.926100254058838, acc 0.2800000011920929\n",
      "Epoch 3, iter 280, loss 1.983048677444458, acc 0.1899999976158142\n",
      "Epoch 3, iter 281, loss 1.927282452583313, acc 0.30000001192092896\n",
      "Epoch 3, iter 282, loss 2.0169553756713867, acc 0.1899999976158142\n",
      "Epoch 3, iter 283, loss 2.0052011013031006, acc 0.17000000178813934\n",
      "Epoch 3, iter 284, loss 1.983891248703003, acc 0.27000001072883606\n",
      "Epoch 3, iter 285, loss 2.021766185760498, acc 0.20000000298023224\n",
      "Epoch 3, iter 286, loss 1.9633876085281372, acc 0.23999999463558197\n",
      "Epoch 3, iter 287, loss 1.973568081855774, acc 0.20000000298023224\n",
      "Epoch 3, iter 288, loss 1.9971667528152466, acc 0.20999999344348907\n",
      "Epoch 3, iter 289, loss 1.9576753377914429, acc 0.23999999463558197\n",
      "Epoch 3, iter 290, loss 1.9146132469177246, acc 0.23000000417232513\n",
      "Epoch 3, iter 291, loss 1.9622384309768677, acc 0.20999999344348907\n",
      "Epoch 3, iter 292, loss 1.950996994972229, acc 0.25999999046325684\n",
      "Epoch 3, iter 293, loss 2.0117805004119873, acc 0.1899999976158142\n",
      "Epoch 3, iter 294, loss 2.0348005294799805, acc 0.1599999964237213\n",
      "Epoch 3, iter 295, loss 1.9819178581237793, acc 0.20000000298023224\n",
      "Epoch 3, iter 296, loss 1.931169033050537, acc 0.20999999344348907\n",
      "Epoch 3, iter 297, loss 2.0319254398345947, acc 0.23999999463558197\n",
      "Epoch 3, iter 298, loss 1.9196394681930542, acc 0.23999999463558197\n",
      "Epoch 3, iter 299, loss 2.009653329849243, acc 0.11999999731779099\n",
      "Epoch 3, iter 300, loss 2.0118322372436523, acc 0.18000000715255737\n",
      "Epoch 3, iter 301, loss 2.0339701175689697, acc 0.20000000298023224\n",
      "Epoch 3, iter 302, loss 1.9205416440963745, acc 0.2800000011920929\n",
      "Epoch 3, iter 303, loss 1.9447201490402222, acc 0.1899999976158142\n",
      "Epoch 3, iter 304, loss 2.0220327377319336, acc 0.15000000596046448\n",
      "Epoch 3, iter 305, loss 2.1038167476654053, acc 0.1599999964237213\n",
      "Epoch 3, iter 306, loss 1.8997455835342407, acc 0.20999999344348907\n",
      "Epoch 3, iter 307, loss 1.904109001159668, acc 0.23999999463558197\n",
      "Epoch 3, iter 308, loss 2.099560260772705, acc 0.2199999988079071\n",
      "Epoch 3, iter 309, loss 2.0035173892974854, acc 0.18000000715255737\n",
      "Epoch 3, iter 310, loss 2.0362114906311035, acc 0.18000000715255737\n",
      "Epoch 3, iter 311, loss 1.997247576713562, acc 0.23000000417232513\n",
      "Epoch 3, iter 312, loss 2.030489921569824, acc 0.27000001072883606\n",
      "Epoch 3, iter 313, loss 2.0678606033325195, acc 0.11999999731779099\n",
      "Epoch 3, iter 314, loss 1.9109784364700317, acc 0.25999999046325684\n",
      "Epoch 3, iter 315, loss 1.9776118993759155, acc 0.25\n",
      "Epoch 3, iter 316, loss 2.005856990814209, acc 0.12999999523162842\n",
      "Epoch 3, iter 317, loss 2.062706470489502, acc 0.2199999988079071\n",
      "Epoch 3, iter 318, loss 2.000190496444702, acc 0.20999999344348907\n",
      "Epoch 3, iter 319, loss 1.9376574754714966, acc 0.18000000715255737\n",
      "Epoch 3, iter 320, loss 2.1097517013549805, acc 0.1899999976158142\n",
      "Epoch 3, iter 321, loss 2.0921037197113037, acc 0.18000000715255737\n",
      "Epoch 3, iter 322, loss 2.0070412158966064, acc 0.23999999463558197\n",
      "Epoch 3, iter 323, loss 1.943264126777649, acc 0.20000000298023224\n",
      "Epoch 3, iter 324, loss 1.960490107536316, acc 0.25\n",
      "Epoch 3, iter 325, loss 2.0255305767059326, acc 0.25\n",
      "Epoch 3, iter 326, loss 1.9247252941131592, acc 0.2199999988079071\n",
      "Epoch 3, iter 327, loss 1.9249497652053833, acc 0.17000000178813934\n",
      "Epoch 3, iter 328, loss 1.9803286790847778, acc 0.25\n",
      "Epoch 3, iter 329, loss 1.9528799057006836, acc 0.2199999988079071\n",
      "Epoch 3, iter 330, loss 1.9744318723678589, acc 0.20999999344348907\n",
      "Epoch 3, iter 331, loss 1.9609330892562866, acc 0.1899999976158142\n",
      "Epoch 3, iter 332, loss 1.9966537952423096, acc 0.23000000417232513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 333, loss 2.0254249572753906, acc 0.20000000298023224\n",
      "Epoch 3, iter 334, loss 1.9990061521530151, acc 0.2199999988079071\n",
      "Epoch 3, iter 335, loss 1.907848834991455, acc 0.25\n",
      "Epoch 3, iter 336, loss 1.9866925477981567, acc 0.2199999988079071\n",
      "Epoch 3, iter 337, loss 2.0015881061553955, acc 0.20999999344348907\n",
      "Epoch 3, iter 338, loss 1.9566845893859863, acc 0.2199999988079071\n",
      "Epoch 3, iter 339, loss 1.9309636354446411, acc 0.23000000417232513\n",
      "Epoch 3, iter 340, loss 1.9669550657272339, acc 0.2199999988079071\n",
      "Epoch 3, iter 341, loss 1.9223612546920776, acc 0.25\n",
      "Epoch 3, iter 342, loss 2.0086417198181152, acc 0.2199999988079071\n",
      "Epoch 3, iter 343, loss 1.9559149742126465, acc 0.1899999976158142\n",
      "Epoch 3, iter 344, loss 1.900915503501892, acc 0.23999999463558197\n",
      "Epoch 3, iter 345, loss 2.0714025497436523, acc 0.18000000715255737\n",
      "Epoch 3, iter 346, loss 1.8959970474243164, acc 0.27000001072883606\n",
      "Epoch 3, iter 347, loss 2.0598626136779785, acc 0.20000000298023224\n",
      "Epoch 3, iter 348, loss 1.9370989799499512, acc 0.3199999928474426\n",
      "Epoch 3, iter 349, loss 1.9048004150390625, acc 0.27000001072883606\n",
      "Epoch 3, iter 350, loss 2.001786708831787, acc 0.25\n",
      "Epoch 3, iter 351, loss 1.9632989168167114, acc 0.14000000059604645\n",
      "Epoch 3, iter 352, loss 1.9828345775604248, acc 0.1899999976158142\n",
      "Epoch 3, iter 353, loss 1.9492117166519165, acc 0.25999999046325684\n",
      "Epoch 3, iter 354, loss 1.9547542333602905, acc 0.25\n",
      "Epoch 3, iter 355, loss 1.9368231296539307, acc 0.20999999344348907\n",
      "Epoch 3, iter 356, loss 1.9733963012695312, acc 0.23999999463558197\n",
      "Epoch 3, iter 357, loss 1.9717715978622437, acc 0.20999999344348907\n",
      "Epoch 3, iter 358, loss 2.069946050643921, acc 0.18000000715255737\n",
      "Epoch 3, iter 359, loss 1.9677401781082153, acc 0.12999999523162842\n",
      "Epoch 3, iter 360, loss 1.9951292276382446, acc 0.23000000417232513\n",
      "Epoch 3, iter 361, loss 1.9264249801635742, acc 0.20000000298023224\n",
      "Epoch 3, iter 362, loss 1.998388648033142, acc 0.17000000178813934\n",
      "Epoch 3, iter 363, loss 1.959646463394165, acc 0.28999999165534973\n",
      "Epoch 3, iter 364, loss 1.9791244268417358, acc 0.12999999523162842\n",
      "Epoch 3, iter 365, loss 1.9448416233062744, acc 0.2199999988079071\n",
      "Epoch 3, iter 366, loss 1.9518612623214722, acc 0.25\n",
      "Epoch 3, iter 367, loss 1.9205410480499268, acc 0.2199999988079071\n",
      "Epoch 3, iter 368, loss 2.0011162757873535, acc 0.23000000417232513\n",
      "Epoch 3, iter 369, loss 1.9312832355499268, acc 0.23999999463558197\n",
      "Epoch 3, iter 370, loss 1.9249955415725708, acc 0.20999999344348907\n",
      "Epoch 3, iter 371, loss 1.966255784034729, acc 0.23999999463558197\n",
      "Epoch 3, iter 372, loss 1.952826976776123, acc 0.23000000417232513\n",
      "Epoch 3, iter 373, loss 2.010362386703491, acc 0.17000000178813934\n",
      "Epoch 3, iter 374, loss 2.0308048725128174, acc 0.20999999344348907\n",
      "Epoch 3, iter 375, loss 1.9386613368988037, acc 0.30000001192092896\n",
      "Epoch 3, iter 376, loss 1.9672682285308838, acc 0.15000000596046448\n",
      "Epoch 3, iter 377, loss 1.9438133239746094, acc 0.27000001072883606\n",
      "Epoch 3, iter 378, loss 1.9726495742797852, acc 0.25\n",
      "Epoch 3, iter 379, loss 2.038297176361084, acc 0.18000000715255737\n",
      "Epoch 3, iter 380, loss 2.0382189750671387, acc 0.15000000596046448\n",
      "Epoch 3, iter 381, loss 1.9794235229492188, acc 0.1599999964237213\n",
      "Epoch 3, iter 382, loss 1.9478870630264282, acc 0.25\n",
      "Epoch 3, iter 383, loss 1.9286056756973267, acc 0.2800000011920929\n",
      "Epoch 3, iter 384, loss 1.9360967874526978, acc 0.18000000715255737\n",
      "Epoch 3, iter 385, loss 1.9260183572769165, acc 0.23999999463558197\n",
      "Epoch 3, iter 386, loss 1.9772975444793701, acc 0.20999999344348907\n",
      "Epoch 3, iter 387, loss 1.9770797491073608, acc 0.23999999463558197\n",
      "Epoch 3, iter 388, loss 1.949965238571167, acc 0.20000000298023224\n",
      "Epoch 3, iter 389, loss 1.9828295707702637, acc 0.20999999344348907\n",
      "Epoch 3, iter 390, loss 2.0774316787719727, acc 0.10000000149011612\n",
      "Epoch 3, iter 391, loss 1.9624786376953125, acc 0.1899999976158142\n",
      "Epoch 3, iter 392, loss 2.0011887550354004, acc 0.18000000715255737\n",
      "Epoch 3, iter 393, loss 1.9919099807739258, acc 0.15000000596046448\n",
      "Epoch 3, iter 394, loss 1.9807754755020142, acc 0.23999999463558197\n",
      "Epoch 3, iter 395, loss 1.9283708333969116, acc 0.27000001072883606\n",
      "Epoch 3, iter 396, loss 2.0034782886505127, acc 0.15000000596046448\n",
      "Epoch 3, iter 397, loss 1.9194828271865845, acc 0.20000000298023224\n",
      "Epoch 3, iter 398, loss 2.087925672531128, acc 0.12999999523162842\n",
      "Epoch 3, iter 399, loss 1.9377264976501465, acc 0.23999999463558197\n",
      "Epoch 3, iter 400, loss 1.9309805631637573, acc 0.2800000011920929\n",
      "Epoch 3, iter 401, loss 1.9324451684951782, acc 0.20999999344348907\n",
      "Epoch 3, iter 402, loss 1.9996752738952637, acc 0.20999999344348907\n",
      "Epoch 3, iter 403, loss 2.0737175941467285, acc 0.1899999976158142\n",
      "Epoch 3, iter 404, loss 1.9797805547714233, acc 0.17000000178813934\n",
      "Epoch 3, iter 405, loss 1.9629908800125122, acc 0.23000000417232513\n",
      "Epoch 3, iter 406, loss 2.0265097618103027, acc 0.11999999731779099\n",
      "Epoch 3, iter 407, loss 1.945542335510254, acc 0.14000000059604645\n",
      "Epoch 3, iter 408, loss 2.017468214035034, acc 0.25\n",
      "Epoch 3, iter 409, loss 1.9431072473526, acc 0.23999999463558197\n",
      "Epoch 3, iter 410, loss 1.9759145975112915, acc 0.1599999964237213\n",
      "Epoch 3, iter 411, loss 1.9885597229003906, acc 0.25999999046325684\n",
      "Epoch 3, iter 412, loss 1.9827824831008911, acc 0.25999999046325684\n",
      "Epoch 3, iter 413, loss 2.0562143325805664, acc 0.15000000596046448\n",
      "Epoch 3, iter 414, loss 1.9943513870239258, acc 0.15000000596046448\n",
      "Epoch 3, iter 415, loss 1.951722264289856, acc 0.20000000298023224\n",
      "Epoch 3, iter 416, loss 1.9612802267074585, acc 0.20999999344348907\n",
      "Epoch 3, iter 417, loss 1.8615880012512207, acc 0.30000001192092896\n",
      "Epoch 3, iter 418, loss 1.9622471332550049, acc 0.15000000596046448\n",
      "Epoch 3, iter 419, loss 1.9297946691513062, acc 0.27000001072883606\n",
      "Epoch 3, iter 420, loss 1.9779375791549683, acc 0.23999999463558197\n",
      "Epoch 4, iter 1, loss 1.939150333404541, acc 0.2199999988079071\n",
      "Epoch 4, iter 2, loss 2.022672176361084, acc 0.18000000715255737\n",
      "Epoch 4, iter 3, loss 1.960539698600769, acc 0.1899999976158142\n",
      "Epoch 4, iter 4, loss 2.065870761871338, acc 0.17000000178813934\n",
      "Epoch 4, iter 5, loss 2.0074357986450195, acc 0.18000000715255737\n",
      "Epoch 4, iter 6, loss 2.0576813220977783, acc 0.17000000178813934\n",
      "Epoch 4, iter 7, loss 2.065424680709839, acc 0.23999999463558197\n",
      "Epoch 4, iter 8, loss 2.0479702949523926, acc 0.18000000715255737\n",
      "Epoch 4, iter 9, loss 2.047278642654419, acc 0.2199999988079071\n",
      "Epoch 4, iter 10, loss 2.010272741317749, acc 0.1899999976158142\n",
      "Epoch 4, iter 11, loss 2.0078907012939453, acc 0.20999999344348907\n",
      "Epoch 4, iter 12, loss 2.0196938514709473, acc 0.20000000298023224\n",
      "Epoch 4, iter 13, loss 1.9723702669143677, acc 0.18000000715255737\n",
      "Epoch 4, iter 14, loss 2.051650285720825, acc 0.2199999988079071\n",
      "Epoch 4, iter 15, loss 1.8988860845565796, acc 0.2800000011920929\n",
      "Epoch 4, iter 16, loss 1.9700839519500732, acc 0.20999999344348907\n",
      "Epoch 4, iter 17, loss 1.974623203277588, acc 0.15000000596046448\n",
      "Epoch 4, iter 18, loss 2.012070417404175, acc 0.20000000298023224\n",
      "Epoch 4, iter 19, loss 1.9952874183654785, acc 0.17000000178813934\n",
      "Epoch 4, iter 20, loss 2.0175817012786865, acc 0.23000000417232513\n",
      "Epoch 4, iter 21, loss 1.9369958639144897, acc 0.23000000417232513\n",
      "Epoch 4, iter 22, loss 2.0050742626190186, acc 0.18000000715255737\n",
      "Epoch 4, iter 23, loss 1.9420737028121948, acc 0.27000001072883606\n",
      "Epoch 4, iter 24, loss 1.9154330492019653, acc 0.20000000298023224\n",
      "Epoch 4, iter 25, loss 2.0005812644958496, acc 0.20999999344348907\n",
      "Epoch 4, iter 26, loss 2.0152368545532227, acc 0.20000000298023224\n",
      "Epoch 4, iter 27, loss 1.9524906873703003, acc 0.2800000011920929\n",
      "Epoch 4, iter 28, loss 1.9846577644348145, acc 0.25999999046325684\n",
      "Epoch 4, iter 29, loss 1.955946922302246, acc 0.23999999463558197\n",
      "Epoch 4, iter 30, loss 2.099869728088379, acc 0.18000000715255737\n",
      "Epoch 4, iter 31, loss 2.1022937297821045, acc 0.11999999731779099\n",
      "Epoch 4, iter 32, loss 1.902209758758545, acc 0.17000000178813934\n",
      "Epoch 4, iter 33, loss 2.08858585357666, acc 0.23000000417232513\n",
      "Epoch 4, iter 34, loss 2.0487637519836426, acc 0.1899999976158142\n",
      "Epoch 4, iter 35, loss 1.9830011129379272, acc 0.23999999463558197\n",
      "Epoch 4, iter 36, loss 2.0045762062072754, acc 0.18000000715255737\n",
      "Epoch 4, iter 37, loss 2.0368564128875732, acc 0.18000000715255737\n",
      "Epoch 4, iter 38, loss 1.9654855728149414, acc 0.25\n",
      "Epoch 4, iter 39, loss 1.9500365257263184, acc 0.2199999988079071\n",
      "Epoch 4, iter 40, loss 1.9678045511245728, acc 0.20000000298023224\n",
      "Epoch 4, iter 41, loss 2.0652899742126465, acc 0.14000000059604645\n",
      "Epoch 4, iter 42, loss 1.9844588041305542, acc 0.1599999964237213\n",
      "Epoch 4, iter 43, loss 1.8976757526397705, acc 0.1899999976158142\n",
      "Epoch 4, iter 44, loss 1.879622459411621, acc 0.18000000715255737\n",
      "Epoch 4, iter 45, loss 1.9900649785995483, acc 0.20999999344348907\n",
      "Epoch 4, iter 46, loss 2.0375521183013916, acc 0.27000001072883606\n",
      "Epoch 4, iter 47, loss 2.046891689300537, acc 0.1599999964237213\n",
      "Epoch 4, iter 48, loss 1.8999477624893188, acc 0.1899999976158142\n",
      "Epoch 4, iter 49, loss 2.043423652648926, acc 0.20999999344348907\n",
      "Epoch 4, iter 50, loss 1.991459608078003, acc 0.23000000417232513\n",
      "Epoch 4, iter 51, loss 1.8898658752441406, acc 0.25999999046325684\n",
      "Epoch 4, iter 52, loss 1.9795045852661133, acc 0.20000000298023224\n",
      "Epoch 4, iter 53, loss 1.9686164855957031, acc 0.3199999928474426\n",
      "Epoch 4, iter 54, loss 2.0503733158111572, acc 0.10999999940395355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 55, loss 2.087292432785034, acc 0.10000000149011612\n",
      "Epoch 4, iter 56, loss 2.0044546127319336, acc 0.1599999964237213\n",
      "Epoch 4, iter 57, loss 2.065225124359131, acc 0.1899999976158142\n",
      "Epoch 4, iter 58, loss 1.9643919467926025, acc 0.1899999976158142\n",
      "Epoch 4, iter 59, loss 1.9372481107711792, acc 0.23999999463558197\n",
      "Epoch 4, iter 60, loss 1.9867048263549805, acc 0.2199999988079071\n",
      "Epoch 4, iter 61, loss 1.9749045372009277, acc 0.17000000178813934\n",
      "Epoch 4, iter 62, loss 1.9699184894561768, acc 0.20000000298023224\n",
      "Epoch 4, iter 63, loss 1.9868556261062622, acc 0.23999999463558197\n",
      "Epoch 4, iter 64, loss 1.966992974281311, acc 0.2199999988079071\n",
      "Epoch 4, iter 65, loss 1.9976483583450317, acc 0.25999999046325684\n",
      "Epoch 4, iter 66, loss 1.972436547279358, acc 0.23000000417232513\n",
      "Epoch 4, iter 67, loss 2.0221245288848877, acc 0.17000000178813934\n",
      "Epoch 4, iter 68, loss 1.933129906654358, acc 0.30000001192092896\n",
      "Epoch 4, iter 69, loss 2.015686273574829, acc 0.1899999976158142\n",
      "Epoch 4, iter 70, loss 1.9190601110458374, acc 0.28999999165534973\n",
      "Epoch 4, iter 71, loss 1.9783508777618408, acc 0.18000000715255737\n",
      "Epoch 4, iter 72, loss 2.0068764686584473, acc 0.14000000059604645\n",
      "Epoch 4, iter 73, loss 1.9346909523010254, acc 0.25\n",
      "Epoch 4, iter 74, loss 1.9699691534042358, acc 0.20999999344348907\n",
      "Epoch 4, iter 75, loss 1.976730227470398, acc 0.12999999523162842\n",
      "Epoch 4, iter 76, loss 1.991723895072937, acc 0.20000000298023224\n",
      "Epoch 4, iter 77, loss 2.096173048019409, acc 0.1599999964237213\n",
      "Epoch 4, iter 78, loss 2.0214803218841553, acc 0.2800000011920929\n",
      "Epoch 4, iter 79, loss 1.9436383247375488, acc 0.23000000417232513\n",
      "Epoch 4, iter 80, loss 2.0385348796844482, acc 0.20000000298023224\n",
      "Epoch 4, iter 81, loss 2.0258755683898926, acc 0.1599999964237213\n",
      "Epoch 4, iter 82, loss 2.014791965484619, acc 0.1599999964237213\n",
      "Epoch 4, iter 83, loss 1.932176113128662, acc 0.20999999344348907\n",
      "Epoch 4, iter 84, loss 2.021697759628296, acc 0.14000000059604645\n",
      "Epoch 4, iter 85, loss 1.9895247220993042, acc 0.1599999964237213\n",
      "Epoch 4, iter 86, loss 1.9220999479293823, acc 0.20999999344348907\n",
      "Epoch 4, iter 87, loss 2.074282646179199, acc 0.25\n",
      "Epoch 4, iter 88, loss 1.9682307243347168, acc 0.25\n",
      "Epoch 4, iter 89, loss 1.9653643369674683, acc 0.20999999344348907\n",
      "Epoch 4, iter 90, loss 2.000284194946289, acc 0.1899999976158142\n",
      "Epoch 4, iter 91, loss 2.053842067718506, acc 0.1899999976158142\n",
      "Epoch 4, iter 92, loss 2.0125155448913574, acc 0.20000000298023224\n",
      "Epoch 4, iter 93, loss 1.9852772951126099, acc 0.2199999988079071\n",
      "Epoch 4, iter 94, loss 2.00386905670166, acc 0.1599999964237213\n",
      "Epoch 4, iter 95, loss 1.9540902376174927, acc 0.20000000298023224\n",
      "Epoch 4, iter 96, loss 2.038330554962158, acc 0.23000000417232513\n",
      "Epoch 4, iter 97, loss 2.002753973007202, acc 0.10999999940395355\n",
      "Epoch 4, iter 98, loss 1.988278865814209, acc 0.1599999964237213\n",
      "Epoch 4, iter 99, loss 2.012017011642456, acc 0.20999999344348907\n",
      "Epoch 4, iter 100, loss 1.9487712383270264, acc 0.25\n",
      "Epoch 4, iter 101, loss 1.9626917839050293, acc 0.20999999344348907\n",
      "Epoch 4, iter 102, loss 2.0043587684631348, acc 0.23000000417232513\n",
      "Epoch 4, iter 103, loss 1.9963250160217285, acc 0.25999999046325684\n",
      "Epoch 4, iter 104, loss 1.996454119682312, acc 0.2800000011920929\n",
      "Epoch 4, iter 105, loss 1.8603802919387817, acc 0.1899999976158142\n",
      "Epoch 4, iter 106, loss 1.9638906717300415, acc 0.25999999046325684\n",
      "Epoch 4, iter 107, loss 2.036468267440796, acc 0.20999999344348907\n",
      "Epoch 4, iter 108, loss 1.9600831270217896, acc 0.12999999523162842\n",
      "Epoch 4, iter 109, loss 1.9965885877609253, acc 0.2199999988079071\n",
      "Epoch 4, iter 110, loss 2.0421571731567383, acc 0.14000000059604645\n",
      "Epoch 4, iter 111, loss 1.942103385925293, acc 0.18000000715255737\n",
      "Epoch 4, iter 112, loss 1.9575079679489136, acc 0.25999999046325684\n",
      "Epoch 4, iter 113, loss 1.9347625970840454, acc 0.25\n",
      "Epoch 4, iter 114, loss 1.9382903575897217, acc 0.20000000298023224\n",
      "Epoch 4, iter 115, loss 1.965335488319397, acc 0.25\n",
      "Epoch 4, iter 116, loss 2.0454909801483154, acc 0.20000000298023224\n",
      "Epoch 4, iter 117, loss 2.0369112491607666, acc 0.20999999344348907\n",
      "Epoch 4, iter 118, loss 2.016573429107666, acc 0.14000000059604645\n",
      "Epoch 4, iter 119, loss 1.9721547365188599, acc 0.25999999046325684\n",
      "Epoch 4, iter 120, loss 2.036437511444092, acc 0.2199999988079071\n",
      "Epoch 4, iter 121, loss 2.000892400741577, acc 0.23000000417232513\n",
      "Epoch 4, iter 122, loss 1.9745444059371948, acc 0.30000001192092896\n",
      "Epoch 4, iter 123, loss 2.0834169387817383, acc 0.14000000059604645\n",
      "Epoch 4, iter 124, loss 1.9738389253616333, acc 0.2199999988079071\n",
      "Epoch 4, iter 125, loss 1.9379432201385498, acc 0.1899999976158142\n",
      "Epoch 4, iter 126, loss 1.9942715167999268, acc 0.1899999976158142\n",
      "Epoch 4, iter 127, loss 2.0595874786376953, acc 0.23000000417232513\n",
      "Epoch 4, iter 128, loss 2.033717632293701, acc 0.1899999976158142\n",
      "Epoch 4, iter 129, loss 2.0211989879608154, acc 0.1899999976158142\n",
      "Epoch 4, iter 130, loss 2.053053617477417, acc 0.1899999976158142\n",
      "Epoch 4, iter 131, loss 2.052654981613159, acc 0.2199999988079071\n",
      "Epoch 4, iter 132, loss 1.9758166074752808, acc 0.25\n",
      "Epoch 4, iter 133, loss 1.958013892173767, acc 0.2199999988079071\n",
      "Epoch 4, iter 134, loss 1.9403388500213623, acc 0.15000000596046448\n",
      "Epoch 4, iter 135, loss 1.9817836284637451, acc 0.28999999165534973\n",
      "Epoch 4, iter 136, loss 1.9503183364868164, acc 0.30000001192092896\n",
      "Epoch 4, iter 137, loss 1.9813449382781982, acc 0.25\n",
      "Epoch 4, iter 138, loss 2.0044519901275635, acc 0.20999999344348907\n",
      "Epoch 4, iter 139, loss 1.9718458652496338, acc 0.1899999976158142\n",
      "Epoch 4, iter 140, loss 2.0098655223846436, acc 0.18000000715255737\n",
      "Epoch 4, iter 141, loss 1.9991017580032349, acc 0.1899999976158142\n",
      "Epoch 4, iter 142, loss 2.056669235229492, acc 0.15000000596046448\n",
      "Epoch 4, iter 143, loss 2.0059731006622314, acc 0.20000000298023224\n",
      "Epoch 4, iter 144, loss 1.9631916284561157, acc 0.15000000596046448\n",
      "Epoch 4, iter 145, loss 1.995505690574646, acc 0.20999999344348907\n",
      "Epoch 4, iter 146, loss 2.0380501747131348, acc 0.20000000298023224\n",
      "Epoch 4, iter 147, loss 1.9377126693725586, acc 0.23999999463558197\n",
      "Epoch 4, iter 148, loss 2.025139093399048, acc 0.20999999344348907\n",
      "Epoch 4, iter 149, loss 1.9645075798034668, acc 0.2199999988079071\n",
      "Epoch 4, iter 150, loss 1.9553582668304443, acc 0.23999999463558197\n",
      "Epoch 4, iter 151, loss 1.91300368309021, acc 0.25999999046325684\n",
      "Epoch 4, iter 152, loss 2.0417749881744385, acc 0.20000000298023224\n",
      "Epoch 4, iter 153, loss 1.9856266975402832, acc 0.23999999463558197\n",
      "Epoch 4, iter 154, loss 1.9855303764343262, acc 0.2199999988079071\n",
      "Epoch 4, iter 155, loss 1.9323927164077759, acc 0.25\n",
      "Epoch 4, iter 156, loss 1.9889283180236816, acc 0.2199999988079071\n",
      "Epoch 4, iter 157, loss 1.9411929845809937, acc 0.17000000178813934\n",
      "Epoch 4, iter 158, loss 1.9772851467132568, acc 0.18000000715255737\n",
      "Epoch 4, iter 159, loss 1.9707261323928833, acc 0.18000000715255737\n",
      "Epoch 4, iter 160, loss 1.9820305109024048, acc 0.17000000178813934\n",
      "Epoch 4, iter 161, loss 1.9009655714035034, acc 0.20999999344348907\n",
      "Epoch 4, iter 162, loss 1.9373081922531128, acc 0.28999999165534973\n",
      "Epoch 4, iter 163, loss 1.9865851402282715, acc 0.18000000715255737\n",
      "Epoch 4, iter 164, loss 1.9821527004241943, acc 0.17000000178813934\n",
      "Epoch 4, iter 165, loss 2.0286343097686768, acc 0.23000000417232513\n",
      "Epoch 4, iter 166, loss 2.0228404998779297, acc 0.23000000417232513\n",
      "Epoch 4, iter 167, loss 1.9936481714248657, acc 0.20000000298023224\n",
      "Epoch 4, iter 168, loss 2.0373024940490723, acc 0.2199999988079071\n",
      "Epoch 4, iter 169, loss 1.9405604600906372, acc 0.1899999976158142\n",
      "Epoch 4, iter 170, loss 2.029859781265259, acc 0.12999999523162842\n",
      "Epoch 4, iter 171, loss 1.967372179031372, acc 0.18000000715255737\n",
      "Epoch 4, iter 172, loss 2.000117301940918, acc 0.17000000178813934\n",
      "Epoch 4, iter 173, loss 1.942969560623169, acc 0.20000000298023224\n",
      "Epoch 4, iter 174, loss 1.9746522903442383, acc 0.17000000178813934\n",
      "Epoch 4, iter 175, loss 1.8900251388549805, acc 0.2199999988079071\n",
      "Epoch 4, iter 176, loss 2.0615854263305664, acc 0.10999999940395355\n",
      "Epoch 4, iter 177, loss 1.9634708166122437, acc 0.23999999463558197\n",
      "Epoch 4, iter 178, loss 2.0218377113342285, acc 0.20000000298023224\n",
      "Epoch 4, iter 179, loss 1.95671808719635, acc 0.18000000715255737\n",
      "Epoch 4, iter 180, loss 1.9499480724334717, acc 0.23000000417232513\n",
      "Epoch 4, iter 181, loss 1.9416847229003906, acc 0.2199999988079071\n",
      "Epoch 4, iter 182, loss 1.950430154800415, acc 0.23999999463558197\n",
      "Epoch 4, iter 183, loss 1.919832468032837, acc 0.20999999344348907\n",
      "Epoch 4, iter 184, loss 1.9791568517684937, acc 0.18000000715255737\n",
      "Epoch 4, iter 185, loss 1.9450138807296753, acc 0.20000000298023224\n",
      "Epoch 4, iter 186, loss 1.9339669942855835, acc 0.2199999988079071\n",
      "Epoch 4, iter 187, loss 1.9206660985946655, acc 0.2199999988079071\n",
      "Epoch 4, iter 188, loss 2.070327043533325, acc 0.2199999988079071\n",
      "Epoch 4, iter 189, loss 2.0836775302886963, acc 0.10000000149011612\n",
      "Epoch 4, iter 190, loss 1.9429996013641357, acc 0.23000000417232513\n",
      "Epoch 4, iter 191, loss 1.9991613626480103, acc 0.20999999344348907\n",
      "Epoch 4, iter 192, loss 1.9530839920043945, acc 0.23000000417232513\n",
      "Epoch 4, iter 193, loss 1.9171279668807983, acc 0.23000000417232513\n",
      "Epoch 4, iter 194, loss 1.9355158805847168, acc 0.18000000715255737\n",
      "Epoch 4, iter 195, loss 1.9559799432754517, acc 0.23000000417232513\n",
      "Epoch 4, iter 196, loss 2.0191051959991455, acc 0.18000000715255737\n",
      "Epoch 4, iter 197, loss 1.9661011695861816, acc 0.25\n",
      "Epoch 4, iter 198, loss 1.8577189445495605, acc 0.33000001311302185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 199, loss 1.9710270166397095, acc 0.20000000298023224\n",
      "Epoch 4, iter 200, loss 1.9809170961380005, acc 0.27000001072883606\n",
      "Epoch 4, iter 201, loss 1.9662442207336426, acc 0.25\n",
      "Epoch 4, iter 202, loss 1.9770264625549316, acc 0.17000000178813934\n",
      "Epoch 4, iter 203, loss 2.0066072940826416, acc 0.12999999523162842\n",
      "Epoch 4, iter 204, loss 1.9351868629455566, acc 0.25999999046325684\n",
      "Epoch 4, iter 205, loss 1.9434186220169067, acc 0.23999999463558197\n",
      "Epoch 4, iter 206, loss 1.9712648391723633, acc 0.20999999344348907\n",
      "Epoch 4, iter 207, loss 1.982629418373108, acc 0.1599999964237213\n",
      "Epoch 4, iter 208, loss 1.968971610069275, acc 0.18000000715255737\n",
      "Epoch 4, iter 209, loss 2.024862289428711, acc 0.1899999976158142\n",
      "Epoch 4, iter 210, loss 2.0989584922790527, acc 0.1899999976158142\n",
      "Epoch 4, iter 211, loss 1.9844639301300049, acc 0.20999999344348907\n",
      "Epoch 4, iter 212, loss 1.9474895000457764, acc 0.1599999964237213\n",
      "Epoch 4, iter 213, loss 1.925641655921936, acc 0.20999999344348907\n",
      "Epoch 4, iter 214, loss 2.010857105255127, acc 0.1899999976158142\n",
      "Epoch 4, iter 215, loss 2.0015869140625, acc 0.12999999523162842\n",
      "Epoch 4, iter 216, loss 1.9997680187225342, acc 0.1599999964237213\n",
      "Epoch 4, iter 217, loss 1.9313139915466309, acc 0.28999999165534973\n",
      "Epoch 4, iter 218, loss 2.065692901611328, acc 0.1899999976158142\n",
      "Epoch 4, iter 219, loss 1.9686212539672852, acc 0.17000000178813934\n",
      "Epoch 4, iter 220, loss 1.9346051216125488, acc 0.23000000417232513\n",
      "Epoch 4, iter 221, loss 1.9190688133239746, acc 0.18000000715255737\n",
      "Epoch 4, iter 222, loss 1.9354465007781982, acc 0.2199999988079071\n",
      "Epoch 4, iter 223, loss 1.8848202228546143, acc 0.27000001072883606\n",
      "Epoch 4, iter 224, loss 1.9483283758163452, acc 0.23999999463558197\n",
      "Epoch 4, iter 225, loss 1.9243413209915161, acc 0.23000000417232513\n",
      "Epoch 4, iter 226, loss 1.8918060064315796, acc 0.25\n",
      "Epoch 4, iter 227, loss 2.008387804031372, acc 0.23999999463558197\n",
      "Epoch 4, iter 228, loss 2.01845645904541, acc 0.20000000298023224\n",
      "Epoch 4, iter 229, loss 1.8971757888793945, acc 0.2199999988079071\n",
      "Epoch 4, iter 230, loss 1.9368655681610107, acc 0.25\n",
      "Epoch 4, iter 231, loss 2.010042667388916, acc 0.20999999344348907\n",
      "Epoch 4, iter 232, loss 2.013956069946289, acc 0.15000000596046448\n",
      "Epoch 4, iter 233, loss 1.9490901231765747, acc 0.23999999463558197\n",
      "Epoch 4, iter 234, loss 1.9392186403274536, acc 0.27000001072883606\n",
      "Epoch 4, iter 235, loss 1.9233859777450562, acc 0.23000000417232513\n",
      "Epoch 4, iter 236, loss 1.9753212928771973, acc 0.17000000178813934\n",
      "Epoch 4, iter 237, loss 2.015887975692749, acc 0.1899999976158142\n",
      "Epoch 4, iter 238, loss 2.030625343322754, acc 0.2199999988079071\n",
      "Epoch 4, iter 239, loss 1.9736255407333374, acc 0.15000000596046448\n",
      "Epoch 4, iter 240, loss 1.9689042568206787, acc 0.17000000178813934\n",
      "Epoch 4, iter 241, loss 1.9334794282913208, acc 0.14000000059604645\n",
      "Epoch 4, iter 242, loss 1.9910097122192383, acc 0.23000000417232513\n",
      "Epoch 4, iter 243, loss 1.9598948955535889, acc 0.17000000178813934\n",
      "Epoch 4, iter 244, loss 2.0158071517944336, acc 0.27000001072883606\n",
      "Epoch 4, iter 245, loss 1.9817434549331665, acc 0.20999999344348907\n",
      "Epoch 4, iter 246, loss 2.042194128036499, acc 0.1599999964237213\n",
      "Epoch 4, iter 247, loss 1.8551836013793945, acc 0.25\n",
      "Epoch 4, iter 248, loss 1.9703209400177002, acc 0.18000000715255737\n",
      "Epoch 4, iter 249, loss 1.9885249137878418, acc 0.11999999731779099\n",
      "Epoch 4, iter 250, loss 1.9013558626174927, acc 0.28999999165534973\n",
      "Epoch 4, iter 251, loss 1.9877067804336548, acc 0.1899999976158142\n",
      "Epoch 4, iter 252, loss 1.8854871988296509, acc 0.25\n",
      "Epoch 4, iter 253, loss 2.063281774520874, acc 0.15000000596046448\n",
      "Epoch 4, iter 254, loss 1.9610134363174438, acc 0.20999999344348907\n",
      "Epoch 4, iter 255, loss 1.9409412145614624, acc 0.18000000715255737\n",
      "Epoch 4, iter 256, loss 1.9949194192886353, acc 0.23000000417232513\n",
      "Epoch 4, iter 257, loss 1.9346003532409668, acc 0.17000000178813934\n",
      "Epoch 4, iter 258, loss 1.9938043355941772, acc 0.23999999463558197\n",
      "Epoch 4, iter 259, loss 2.0395119190216064, acc 0.23000000417232513\n",
      "Epoch 4, iter 260, loss 2.028646469116211, acc 0.18000000715255737\n",
      "Epoch 4, iter 261, loss 1.8773404359817505, acc 0.23999999463558197\n",
      "Epoch 4, iter 262, loss 2.0414202213287354, acc 0.1599999964237213\n",
      "Epoch 4, iter 263, loss 1.8719402551651, acc 0.23999999463558197\n",
      "Epoch 4, iter 264, loss 1.8985648155212402, acc 0.27000001072883606\n",
      "Epoch 4, iter 265, loss 2.0510003566741943, acc 0.23000000417232513\n",
      "Epoch 4, iter 266, loss 1.9504300355911255, acc 0.17000000178813934\n",
      "Epoch 4, iter 267, loss 1.9053987264633179, acc 0.2800000011920929\n",
      "Epoch 4, iter 268, loss 1.8881362676620483, acc 0.12999999523162842\n",
      "Epoch 4, iter 269, loss 1.9755173921585083, acc 0.1899999976158142\n",
      "Epoch 4, iter 270, loss 2.0023410320281982, acc 0.1599999964237213\n",
      "Epoch 4, iter 271, loss 1.9743326902389526, acc 0.20000000298023224\n",
      "Epoch 4, iter 272, loss 2.055544137954712, acc 0.1899999976158142\n",
      "Epoch 4, iter 273, loss 2.0315334796905518, acc 0.1899999976158142\n",
      "Epoch 4, iter 274, loss 1.9941260814666748, acc 0.20999999344348907\n",
      "Epoch 4, iter 275, loss 2.0457370281219482, acc 0.18000000715255737\n",
      "Epoch 4, iter 276, loss 2.019822597503662, acc 0.20999999344348907\n",
      "Epoch 4, iter 277, loss 1.9507256746292114, acc 0.20999999344348907\n",
      "Epoch 4, iter 278, loss 1.9380971193313599, acc 0.17000000178813934\n",
      "Epoch 4, iter 279, loss 1.941072940826416, acc 0.2800000011920929\n",
      "Epoch 4, iter 280, loss 2.0894877910614014, acc 0.17000000178813934\n",
      "Epoch 4, iter 281, loss 2.102954387664795, acc 0.25999999046325684\n",
      "Epoch 4, iter 282, loss 2.1606414318084717, acc 0.1599999964237213\n",
      "Epoch 4, iter 283, loss 2.128763198852539, acc 0.15000000596046448\n",
      "Epoch 4, iter 284, loss 2.0878119468688965, acc 0.25999999046325684\n",
      "Epoch 4, iter 285, loss 2.1421685218811035, acc 0.1599999964237213\n",
      "Epoch 4, iter 286, loss 2.043246269226074, acc 0.20999999344348907\n",
      "Epoch 4, iter 287, loss 2.1207125186920166, acc 0.18000000715255737\n",
      "Epoch 4, iter 288, loss 2.11006236076355, acc 0.1899999976158142\n",
      "Epoch 4, iter 289, loss 2.000925302505493, acc 0.23000000417232513\n",
      "Epoch 4, iter 290, loss 2.041806221008301, acc 0.18000000715255737\n",
      "Epoch 4, iter 291, loss 2.0270495414733887, acc 0.1899999976158142\n",
      "Epoch 4, iter 292, loss 1.924214482307434, acc 0.25999999046325684\n",
      "Epoch 4, iter 293, loss 1.9813644886016846, acc 0.20000000298023224\n",
      "Epoch 4, iter 294, loss 2.003735303878784, acc 0.1599999964237213\n",
      "Epoch 4, iter 295, loss 1.9138555526733398, acc 0.20999999344348907\n",
      "Epoch 4, iter 296, loss 1.9704148769378662, acc 0.20999999344348907\n",
      "Epoch 4, iter 297, loss 2.0191969871520996, acc 0.23999999463558197\n",
      "Epoch 4, iter 298, loss 1.8717554807662964, acc 0.25\n",
      "Epoch 4, iter 299, loss 2.061984062194824, acc 0.11999999731779099\n",
      "Epoch 4, iter 300, loss 2.058749198913574, acc 0.17000000178813934\n",
      "Epoch 4, iter 301, loss 2.0422539710998535, acc 0.20000000298023224\n",
      "Epoch 4, iter 302, loss 1.981805443763733, acc 0.27000001072883606\n",
      "Epoch 4, iter 303, loss 1.9361251592636108, acc 0.20000000298023224\n",
      "Epoch 4, iter 304, loss 2.0235297679901123, acc 0.1599999964237213\n",
      "Epoch 4, iter 305, loss 2.0804178714752197, acc 0.1599999964237213\n",
      "Epoch 4, iter 306, loss 1.9499905109405518, acc 0.20000000298023224\n",
      "Epoch 4, iter 307, loss 2.008401870727539, acc 0.23000000417232513\n",
      "Epoch 4, iter 308, loss 2.087238311767578, acc 0.2199999988079071\n",
      "Epoch 4, iter 309, loss 1.9451870918273926, acc 0.20000000298023224\n",
      "Epoch 4, iter 310, loss 2.003537893295288, acc 0.18000000715255737\n",
      "Epoch 4, iter 311, loss 1.9796065092086792, acc 0.2199999988079071\n",
      "Epoch 4, iter 312, loss 1.9768062829971313, acc 0.25999999046325684\n",
      "Epoch 4, iter 313, loss 2.112074851989746, acc 0.11999999731779099\n",
      "Epoch 4, iter 314, loss 1.9865882396697998, acc 0.25999999046325684\n",
      "Epoch 4, iter 315, loss 1.9386836290359497, acc 0.25\n",
      "Epoch 4, iter 316, loss 1.9483968019485474, acc 0.12999999523162842\n",
      "Epoch 4, iter 317, loss 1.9842720031738281, acc 0.20999999344348907\n",
      "Epoch 4, iter 318, loss 1.965156078338623, acc 0.2199999988079071\n",
      "Epoch 4, iter 319, loss 2.0098717212677, acc 0.18000000715255737\n",
      "Epoch 4, iter 320, loss 1.9640017747879028, acc 0.20000000298023224\n",
      "Epoch 4, iter 321, loss 2.0005438327789307, acc 0.1899999976158142\n",
      "Epoch 4, iter 322, loss 1.9383991956710815, acc 0.23000000417232513\n",
      "Epoch 4, iter 323, loss 1.97519850730896, acc 0.20000000298023224\n",
      "Epoch 4, iter 324, loss 1.9225659370422363, acc 0.25\n",
      "Epoch 4, iter 325, loss 2.009162187576294, acc 0.23999999463558197\n",
      "Epoch 4, iter 326, loss 1.8946218490600586, acc 0.2199999988079071\n",
      "Epoch 4, iter 327, loss 1.9019627571105957, acc 0.17000000178813934\n",
      "Epoch 4, iter 328, loss 1.9899623394012451, acc 0.25\n",
      "Epoch 4, iter 329, loss 1.9536012411117554, acc 0.2199999988079071\n",
      "Epoch 4, iter 330, loss 1.9687188863754272, acc 0.20999999344348907\n",
      "Epoch 4, iter 331, loss 1.9934213161468506, acc 0.1899999976158142\n",
      "Epoch 4, iter 332, loss 1.9975515604019165, acc 0.23000000417232513\n",
      "Epoch 4, iter 333, loss 1.9969017505645752, acc 0.20000000298023224\n",
      "Epoch 4, iter 334, loss 1.9941184520721436, acc 0.2199999988079071\n",
      "Epoch 4, iter 335, loss 1.91383957862854, acc 0.25\n",
      "Epoch 4, iter 336, loss 2.0041260719299316, acc 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 337, loss 1.958716869354248, acc 0.20999999344348907\n",
      "Epoch 4, iter 338, loss 1.9504393339157104, acc 0.2199999988079071\n",
      "Epoch 4, iter 339, loss 2.0686745643615723, acc 0.20999999344348907\n",
      "Epoch 4, iter 340, loss 2.0984575748443604, acc 0.1899999976158142\n",
      "Epoch 4, iter 341, loss 2.0705008506774902, acc 0.23999999463558197\n",
      "Epoch 4, iter 342, loss 2.0210189819335938, acc 0.23000000417232513\n",
      "Epoch 4, iter 343, loss 1.9998271465301514, acc 0.1899999976158142\n",
      "Epoch 4, iter 344, loss 1.9393497705459595, acc 0.23999999463558197\n",
      "Epoch 4, iter 345, loss 2.016709089279175, acc 0.18000000715255737\n",
      "Epoch 4, iter 346, loss 1.974117398262024, acc 0.25\n",
      "Epoch 4, iter 347, loss 2.0863399505615234, acc 0.20000000298023224\n",
      "Epoch 4, iter 348, loss 1.9547042846679688, acc 0.33000001311302185\n",
      "Epoch 4, iter 349, loss 1.9276617765426636, acc 0.25999999046325684\n",
      "Epoch 4, iter 350, loss 2.0093207359313965, acc 0.25\n",
      "Epoch 4, iter 351, loss 2.032025098800659, acc 0.14000000059604645\n",
      "Epoch 4, iter 352, loss 1.945857048034668, acc 0.18000000715255737\n",
      "Epoch 4, iter 353, loss 1.9408422708511353, acc 0.25999999046325684\n",
      "Epoch 4, iter 354, loss 1.9315344095230103, acc 0.25\n",
      "Epoch 4, iter 355, loss 1.9160388708114624, acc 0.20999999344348907\n",
      "Epoch 4, iter 356, loss 1.9244318008422852, acc 0.25999999046325684\n",
      "Epoch 4, iter 357, loss 1.9432809352874756, acc 0.2199999988079071\n",
      "Epoch 4, iter 358, loss 2.1344857215881348, acc 0.18000000715255737\n",
      "Epoch 4, iter 359, loss 1.9196759462356567, acc 0.12999999523162842\n",
      "Epoch 4, iter 360, loss 1.9291322231292725, acc 0.23000000417232513\n",
      "Epoch 4, iter 361, loss 1.967575192451477, acc 0.20000000298023224\n",
      "Epoch 4, iter 362, loss 1.9711706638336182, acc 0.17000000178813934\n",
      "Epoch 4, iter 363, loss 1.956925868988037, acc 0.28999999165534973\n",
      "Epoch 4, iter 364, loss 1.9237754344940186, acc 0.12999999523162842\n",
      "Epoch 4, iter 365, loss 1.9725863933563232, acc 0.20999999344348907\n",
      "Epoch 4, iter 366, loss 1.924914836883545, acc 0.25\n",
      "Epoch 4, iter 367, loss 1.8872575759887695, acc 0.23000000417232513\n",
      "Epoch 4, iter 368, loss 1.9963030815124512, acc 0.23000000417232513\n",
      "Epoch 4, iter 369, loss 1.872378945350647, acc 0.23999999463558197\n",
      "Epoch 4, iter 370, loss 1.8514435291290283, acc 0.2199999988079071\n",
      "Epoch 4, iter 371, loss 2.0232536792755127, acc 0.23000000417232513\n",
      "Epoch 4, iter 372, loss 1.9083702564239502, acc 0.23000000417232513\n",
      "Epoch 4, iter 373, loss 1.9434940814971924, acc 0.17000000178813934\n",
      "Epoch 4, iter 374, loss 2.0019612312316895, acc 0.20999999344348907\n",
      "Epoch 4, iter 375, loss 1.9570635557174683, acc 0.30000001192092896\n",
      "Epoch 4, iter 376, loss 1.918614387512207, acc 0.15000000596046448\n",
      "Epoch 4, iter 377, loss 1.9102221727371216, acc 0.27000001072883606\n",
      "Epoch 4, iter 378, loss 1.9478148221969604, acc 0.25\n",
      "Epoch 4, iter 379, loss 2.0079946517944336, acc 0.18000000715255737\n",
      "Epoch 4, iter 380, loss 2.0059075355529785, acc 0.17000000178813934\n",
      "Epoch 4, iter 381, loss 1.9760982990264893, acc 0.1599999964237213\n",
      "Epoch 4, iter 382, loss 1.9301835298538208, acc 0.25\n",
      "Epoch 4, iter 383, loss 1.916418433189392, acc 0.2800000011920929\n",
      "Epoch 4, iter 384, loss 1.9189414978027344, acc 0.18000000715255737\n",
      "Epoch 4, iter 385, loss 1.9047507047653198, acc 0.23999999463558197\n",
      "Epoch 4, iter 386, loss 1.9065277576446533, acc 0.20999999344348907\n",
      "Epoch 4, iter 387, loss 1.9591090679168701, acc 0.23000000417232513\n",
      "Epoch 4, iter 388, loss 1.9420057535171509, acc 0.20000000298023224\n",
      "Epoch 4, iter 389, loss 1.971994161605835, acc 0.20999999344348907\n",
      "Epoch 4, iter 390, loss 2.044004440307617, acc 0.10000000149011612\n",
      "Epoch 4, iter 391, loss 1.9121787548065186, acc 0.1899999976158142\n",
      "Epoch 4, iter 392, loss 1.9469736814498901, acc 0.18000000715255737\n",
      "Epoch 4, iter 393, loss 1.960281491279602, acc 0.15000000596046448\n",
      "Epoch 4, iter 394, loss 1.9355857372283936, acc 0.25\n",
      "Epoch 4, iter 395, loss 1.9146835803985596, acc 0.27000001072883606\n",
      "Epoch 4, iter 396, loss 1.9565229415893555, acc 0.15000000596046448\n",
      "Epoch 4, iter 397, loss 1.9334688186645508, acc 0.20000000298023224\n",
      "Epoch 4, iter 398, loss 2.048712968826294, acc 0.11999999731779099\n",
      "Epoch 4, iter 399, loss 1.9315593242645264, acc 0.23000000417232513\n",
      "Epoch 4, iter 400, loss 1.9461379051208496, acc 0.28999999165534973\n",
      "Epoch 4, iter 401, loss 1.9370663166046143, acc 0.20000000298023224\n",
      "Epoch 4, iter 402, loss 1.952835202217102, acc 0.20000000298023224\n",
      "Epoch 4, iter 403, loss 2.0478599071502686, acc 0.1899999976158142\n",
      "Epoch 4, iter 404, loss 1.9637761116027832, acc 0.1599999964237213\n",
      "Epoch 4, iter 405, loss 1.9357298612594604, acc 0.23999999463558197\n",
      "Epoch 4, iter 406, loss 1.975486397743225, acc 0.11999999731779099\n",
      "Epoch 4, iter 407, loss 1.8932337760925293, acc 0.14000000059604645\n",
      "Epoch 4, iter 408, loss 1.966797947883606, acc 0.25\n",
      "Epoch 4, iter 409, loss 1.8981430530548096, acc 0.23999999463558197\n",
      "Epoch 4, iter 410, loss 1.9340695142745972, acc 0.1599999964237213\n",
      "Epoch 4, iter 411, loss 1.9446008205413818, acc 0.27000001072883606\n",
      "Epoch 4, iter 412, loss 1.9302486181259155, acc 0.25999999046325684\n",
      "Epoch 4, iter 413, loss 2.0471935272216797, acc 0.15000000596046448\n",
      "Epoch 4, iter 414, loss 1.9152237176895142, acc 0.15000000596046448\n",
      "Epoch 4, iter 415, loss 1.9303478002548218, acc 0.20000000298023224\n",
      "Epoch 4, iter 416, loss 1.9070461988449097, acc 0.20999999344348907\n",
      "Epoch 4, iter 417, loss 1.9186761379241943, acc 0.28999999165534973\n",
      "Epoch 4, iter 418, loss 1.9341458082199097, acc 0.15000000596046448\n",
      "Epoch 4, iter 419, loss 1.8400866985321045, acc 0.2800000011920929\n",
      "Epoch 4, iter 420, loss 1.9308085441589355, acc 0.23000000417232513\n",
      "Epoch 5, iter 1, loss 1.889775037765503, acc 0.23000000417232513\n",
      "Epoch 5, iter 2, loss 1.9508671760559082, acc 0.1899999976158142\n",
      "Epoch 5, iter 3, loss 1.8870491981506348, acc 0.18000000715255737\n",
      "Epoch 5, iter 4, loss 1.9803310632705688, acc 0.17000000178813934\n",
      "Epoch 5, iter 5, loss 1.8988661766052246, acc 0.18000000715255737\n",
      "Epoch 5, iter 6, loss 1.9516254663467407, acc 0.17000000178813934\n",
      "Epoch 5, iter 7, loss 1.9587738513946533, acc 0.25\n",
      "Epoch 5, iter 8, loss 2.0100839138031006, acc 0.18000000715255737\n",
      "Epoch 5, iter 9, loss 1.9634056091308594, acc 0.20000000298023224\n",
      "Epoch 5, iter 10, loss 1.8824119567871094, acc 0.1899999976158142\n",
      "Epoch 5, iter 11, loss 1.9606074094772339, acc 0.20999999344348907\n",
      "Epoch 5, iter 12, loss 1.8975250720977783, acc 0.20000000298023224\n",
      "Epoch 5, iter 13, loss 1.9169743061065674, acc 0.18000000715255737\n",
      "Epoch 5, iter 14, loss 1.9382596015930176, acc 0.2199999988079071\n",
      "Epoch 5, iter 15, loss 1.8517775535583496, acc 0.2800000011920929\n",
      "Epoch 5, iter 16, loss 1.8931313753128052, acc 0.20999999344348907\n",
      "Epoch 5, iter 17, loss 1.94036865234375, acc 0.15000000596046448\n",
      "Epoch 5, iter 18, loss 1.9708359241485596, acc 0.20000000298023224\n",
      "Epoch 5, iter 19, loss 1.9618926048278809, acc 0.17000000178813934\n",
      "Epoch 5, iter 20, loss 1.880191683769226, acc 0.25\n",
      "Epoch 5, iter 21, loss 1.9186662435531616, acc 0.23000000417232513\n",
      "Epoch 5, iter 22, loss 1.9477229118347168, acc 0.18000000715255737\n",
      "Epoch 5, iter 23, loss 1.9142590761184692, acc 0.27000001072883606\n",
      "Epoch 5, iter 24, loss 1.9257045984268188, acc 0.1899999976158142\n",
      "Epoch 5, iter 25, loss 1.9428917169570923, acc 0.20999999344348907\n",
      "Epoch 5, iter 26, loss 1.969640851020813, acc 0.20000000298023224\n",
      "Epoch 5, iter 27, loss 1.9042662382125854, acc 0.28999999165534973\n",
      "Epoch 5, iter 28, loss 1.9566526412963867, acc 0.25999999046325684\n",
      "Epoch 5, iter 29, loss 1.9521472454071045, acc 0.23999999463558197\n",
      "Epoch 5, iter 30, loss 2.0249547958374023, acc 0.1899999976158142\n",
      "Epoch 5, iter 31, loss 2.041879177093506, acc 0.11999999731779099\n",
      "Epoch 5, iter 32, loss 1.9015934467315674, acc 0.17000000178813934\n",
      "Epoch 5, iter 33, loss 1.9800564050674438, acc 0.25\n",
      "Epoch 5, iter 34, loss 1.9735794067382812, acc 0.20000000298023224\n",
      "Epoch 5, iter 35, loss 1.9288021326065063, acc 0.23999999463558197\n",
      "Epoch 5, iter 36, loss 1.9594924449920654, acc 0.18000000715255737\n",
      "Epoch 5, iter 37, loss 1.9785114526748657, acc 0.18000000715255737\n",
      "Epoch 5, iter 38, loss 1.9271348714828491, acc 0.25\n",
      "Epoch 5, iter 39, loss 1.9878952503204346, acc 0.23000000417232513\n",
      "Epoch 5, iter 40, loss 1.960297703742981, acc 0.2199999988079071\n",
      "Epoch 5, iter 41, loss 1.9790817499160767, acc 0.14000000059604645\n",
      "Epoch 5, iter 42, loss 1.9460361003875732, acc 0.1599999964237213\n",
      "Epoch 5, iter 43, loss 1.8379408121109009, acc 0.20999999344348907\n",
      "Epoch 5, iter 44, loss 1.893121600151062, acc 0.1899999976158142\n",
      "Epoch 5, iter 45, loss 1.9677292108535767, acc 0.20999999344348907\n",
      "Epoch 5, iter 46, loss 1.961553692817688, acc 0.2800000011920929\n",
      "Epoch 5, iter 47, loss 1.9658098220825195, acc 0.1599999964237213\n",
      "Epoch 5, iter 48, loss 1.8950257301330566, acc 0.1899999976158142\n",
      "Epoch 5, iter 49, loss 1.950820803642273, acc 0.2199999988079071\n",
      "Epoch 5, iter 50, loss 1.9341685771942139, acc 0.23999999463558197\n",
      "Epoch 5, iter 51, loss 1.8372136354446411, acc 0.25999999046325684\n",
      "Epoch 5, iter 52, loss 1.9474178552627563, acc 0.20000000298023224\n",
      "Epoch 5, iter 53, loss 1.9129045009613037, acc 0.33000001311302185\n",
      "Epoch 5, iter 54, loss 1.9662299156188965, acc 0.14000000059604645\n",
      "Epoch 5, iter 55, loss 1.997733473777771, acc 0.10000000149011612\n",
      "Epoch 5, iter 56, loss 2.015176773071289, acc 0.18000000715255737\n",
      "Epoch 5, iter 57, loss 2.032193183898926, acc 0.1899999976158142\n",
      "Epoch 5, iter 58, loss 1.9324151277542114, acc 0.1899999976158142\n",
      "Epoch 5, iter 59, loss 1.9317249059677124, acc 0.25\n",
      "Epoch 5, iter 60, loss 1.963821530342102, acc 0.23000000417232513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 61, loss 1.9082140922546387, acc 0.18000000715255737\n",
      "Epoch 5, iter 62, loss 1.887639045715332, acc 0.20999999344348907\n",
      "Epoch 5, iter 63, loss 1.8826653957366943, acc 0.23999999463558197\n",
      "Epoch 5, iter 64, loss 1.9972021579742432, acc 0.20999999344348907\n",
      "Epoch 5, iter 65, loss 1.9854086637496948, acc 0.25999999046325684\n",
      "Epoch 5, iter 66, loss 2.0062754154205322, acc 0.20999999344348907\n",
      "Epoch 5, iter 67, loss 1.9560096263885498, acc 0.18000000715255737\n",
      "Epoch 5, iter 68, loss 1.9526249170303345, acc 0.3100000023841858\n",
      "Epoch 5, iter 69, loss 1.9734506607055664, acc 0.1899999976158142\n",
      "Epoch 5, iter 70, loss 2.0060501098632812, acc 0.27000001072883606\n",
      "Epoch 5, iter 71, loss 2.031184196472168, acc 0.17000000178813934\n",
      "Epoch 5, iter 72, loss 1.956173062324524, acc 0.14000000059604645\n",
      "Epoch 5, iter 73, loss 2.014749526977539, acc 0.2199999988079071\n",
      "Epoch 5, iter 74, loss 1.9849761724472046, acc 0.2199999988079071\n",
      "Epoch 5, iter 75, loss 1.950708270072937, acc 0.12999999523162842\n",
      "Epoch 5, iter 76, loss 1.972657322883606, acc 0.20000000298023224\n",
      "Epoch 5, iter 77, loss 2.0564675331115723, acc 0.1599999964237213\n",
      "Epoch 5, iter 78, loss 2.0344252586364746, acc 0.2800000011920929\n",
      "Epoch 5, iter 79, loss 2.018939733505249, acc 0.20999999344348907\n",
      "Epoch 5, iter 80, loss 1.9797308444976807, acc 0.20000000298023224\n",
      "Epoch 5, iter 81, loss 1.9802145957946777, acc 0.1599999964237213\n",
      "Epoch 5, iter 82, loss 2.0158684253692627, acc 0.1599999964237213\n",
      "Epoch 5, iter 83, loss 1.995590090751648, acc 0.20000000298023224\n",
      "Epoch 5, iter 84, loss 2.020590305328369, acc 0.14000000059604645\n",
      "Epoch 5, iter 85, loss 2.0033228397369385, acc 0.14000000059604645\n",
      "Epoch 5, iter 86, loss 1.9649193286895752, acc 0.20000000298023224\n",
      "Epoch 5, iter 87, loss 2.064932107925415, acc 0.23999999463558197\n",
      "Epoch 5, iter 88, loss 2.0271334648132324, acc 0.23999999463558197\n",
      "Epoch 5, iter 89, loss 2.039109706878662, acc 0.20000000298023224\n",
      "Epoch 5, iter 90, loss 2.0041208267211914, acc 0.1899999976158142\n",
      "Epoch 5, iter 91, loss 2.036951780319214, acc 0.17000000178813934\n",
      "Epoch 5, iter 92, loss 1.991390347480774, acc 0.2199999988079071\n",
      "Epoch 5, iter 93, loss 1.9106861352920532, acc 0.2199999988079071\n",
      "Epoch 5, iter 94, loss 1.9077694416046143, acc 0.1599999964237213\n",
      "Epoch 5, iter 95, loss 1.9649564027786255, acc 0.20000000298023224\n",
      "Epoch 5, iter 96, loss 1.999954104423523, acc 0.2199999988079071\n",
      "Epoch 5, iter 97, loss 1.9959304332733154, acc 0.10999999940395355\n",
      "Epoch 5, iter 98, loss 1.9614677429199219, acc 0.1599999964237213\n",
      "Epoch 5, iter 99, loss 1.9774410724639893, acc 0.20999999344348907\n",
      "Epoch 5, iter 100, loss 1.9677449464797974, acc 0.23999999463558197\n",
      "Epoch 5, iter 101, loss 1.8977646827697754, acc 0.2199999988079071\n",
      "Epoch 5, iter 102, loss 1.9948105812072754, acc 0.23000000417232513\n",
      "Epoch 5, iter 103, loss 2.0601019859313965, acc 0.23999999463558197\n",
      "Epoch 5, iter 104, loss 1.973275899887085, acc 0.2800000011920929\n",
      "Epoch 5, iter 105, loss 1.8620893955230713, acc 0.1899999976158142\n",
      "Epoch 5, iter 106, loss 1.9258651733398438, acc 0.25999999046325684\n",
      "Epoch 5, iter 107, loss 1.9409065246582031, acc 0.2199999988079071\n",
      "Epoch 5, iter 108, loss 1.9240410327911377, acc 0.12999999523162842\n",
      "Epoch 5, iter 109, loss 1.9530482292175293, acc 0.2199999988079071\n",
      "Epoch 5, iter 110, loss 1.9520564079284668, acc 0.14000000059604645\n",
      "Epoch 5, iter 111, loss 1.9275282621383667, acc 0.18000000715255737\n",
      "Epoch 5, iter 112, loss 1.9489647150039673, acc 0.25999999046325684\n",
      "Epoch 5, iter 113, loss 1.9208544492721558, acc 0.25\n",
      "Epoch 5, iter 114, loss 1.9214012622833252, acc 0.20000000298023224\n",
      "Epoch 5, iter 115, loss 1.906835913658142, acc 0.25999999046325684\n",
      "Epoch 5, iter 116, loss 1.9982671737670898, acc 0.20000000298023224\n",
      "Epoch 5, iter 117, loss 1.9416499137878418, acc 0.2199999988079071\n",
      "Epoch 5, iter 118, loss 1.955405831336975, acc 0.14000000059604645\n",
      "Epoch 5, iter 119, loss 1.9048571586608887, acc 0.25999999046325684\n",
      "Epoch 5, iter 120, loss 1.9557671546936035, acc 0.23000000417232513\n",
      "Epoch 5, iter 121, loss 1.9693843126296997, acc 0.23000000417232513\n",
      "Epoch 5, iter 122, loss 1.9554131031036377, acc 0.3100000023841858\n",
      "Epoch 5, iter 123, loss 2.0138514041900635, acc 0.14000000059604645\n",
      "Epoch 5, iter 124, loss 1.9127024412155151, acc 0.23000000417232513\n",
      "Epoch 5, iter 125, loss 1.9245808124542236, acc 0.18000000715255737\n",
      "Epoch 5, iter 126, loss 1.9317030906677246, acc 0.1899999976158142\n",
      "Epoch 5, iter 127, loss 2.020977258682251, acc 0.23000000417232513\n",
      "Epoch 5, iter 128, loss 1.9457124471664429, acc 0.1899999976158142\n",
      "Epoch 5, iter 129, loss 2.0072648525238037, acc 0.1899999976158142\n",
      "Epoch 5, iter 130, loss 2.0159103870391846, acc 0.20999999344348907\n",
      "Epoch 5, iter 131, loss 2.0197408199310303, acc 0.23000000417232513\n",
      "Epoch 5, iter 132, loss 1.9564294815063477, acc 0.23999999463558197\n",
      "Epoch 5, iter 133, loss 1.9676676988601685, acc 0.20999999344348907\n",
      "Epoch 5, iter 134, loss 1.935492753982544, acc 0.15000000596046448\n",
      "Epoch 5, iter 135, loss 2.0131845474243164, acc 0.27000001072883606\n",
      "Epoch 5, iter 136, loss 1.8790268898010254, acc 0.28999999165534973\n",
      "Epoch 5, iter 137, loss 1.9547970294952393, acc 0.25\n",
      "Epoch 5, iter 138, loss 1.9367995262145996, acc 0.23000000417232513\n",
      "Epoch 5, iter 139, loss 1.9401674270629883, acc 0.1899999976158142\n",
      "Epoch 5, iter 140, loss 1.954656720161438, acc 0.1899999976158142\n",
      "Epoch 5, iter 141, loss 2.0001206398010254, acc 0.1899999976158142\n",
      "Epoch 5, iter 142, loss 1.9625844955444336, acc 0.1599999964237213\n",
      "Epoch 5, iter 143, loss 1.9989633560180664, acc 0.20000000298023224\n",
      "Epoch 5, iter 144, loss 1.96150541305542, acc 0.15000000596046448\n",
      "Epoch 5, iter 145, loss 1.9771112203598022, acc 0.20000000298023224\n",
      "Epoch 5, iter 146, loss 2.0167336463928223, acc 0.1899999976158142\n",
      "Epoch 5, iter 147, loss 1.9870644807815552, acc 0.25\n",
      "Epoch 5, iter 148, loss 1.9677402973175049, acc 0.2199999988079071\n",
      "Epoch 5, iter 149, loss 1.9472101926803589, acc 0.20999999344348907\n",
      "Epoch 5, iter 150, loss 1.9754562377929688, acc 0.23000000417232513\n",
      "Epoch 5, iter 151, loss 1.9045758247375488, acc 0.23999999463558197\n",
      "Epoch 5, iter 152, loss 1.994054913520813, acc 0.20000000298023224\n",
      "Epoch 5, iter 153, loss 1.976706862449646, acc 0.23000000417232513\n",
      "Epoch 5, iter 154, loss 1.9941908121109009, acc 0.2199999988079071\n",
      "Epoch 5, iter 155, loss 1.9098618030548096, acc 0.25\n",
      "Epoch 5, iter 156, loss 1.9326826333999634, acc 0.23000000417232513\n",
      "Epoch 5, iter 157, loss 1.927921175956726, acc 0.17000000178813934\n",
      "Epoch 5, iter 158, loss 1.9294978380203247, acc 0.1899999976158142\n",
      "Epoch 5, iter 159, loss 1.9362423419952393, acc 0.18000000715255737\n",
      "Epoch 5, iter 160, loss 1.925118088722229, acc 0.18000000715255737\n",
      "Epoch 5, iter 161, loss 1.9408854246139526, acc 0.1899999976158142\n",
      "Epoch 5, iter 162, loss 1.9744453430175781, acc 0.28999999165534973\n",
      "Epoch 5, iter 163, loss 1.9908541440963745, acc 0.18000000715255737\n",
      "Epoch 5, iter 164, loss 1.9450674057006836, acc 0.18000000715255737\n",
      "Epoch 5, iter 165, loss 2.0604047775268555, acc 0.23000000417232513\n",
      "Epoch 5, iter 166, loss 1.9607425928115845, acc 0.23999999463558197\n",
      "Epoch 5, iter 167, loss 1.981495976448059, acc 0.20000000298023224\n",
      "Epoch 5, iter 168, loss 1.9674301147460938, acc 0.20999999344348907\n",
      "Epoch 5, iter 169, loss 1.9959595203399658, acc 0.1599999964237213\n",
      "Epoch 5, iter 170, loss 1.9888628721237183, acc 0.11999999731779099\n",
      "Epoch 5, iter 171, loss 1.9881236553192139, acc 0.17000000178813934\n",
      "Epoch 5, iter 172, loss 1.9794937372207642, acc 0.18000000715255737\n",
      "Epoch 5, iter 173, loss 2.0003621578216553, acc 0.20000000298023224\n",
      "Epoch 5, iter 174, loss 2.0162270069122314, acc 0.14000000059604645\n",
      "Epoch 5, iter 175, loss 1.93896484375, acc 0.20999999344348907\n",
      "Epoch 5, iter 176, loss 2.1197946071624756, acc 0.09000000357627869\n",
      "Epoch 5, iter 177, loss 2.055360794067383, acc 0.23000000417232513\n",
      "Epoch 5, iter 178, loss 2.0844717025756836, acc 0.1899999976158142\n",
      "Epoch 5, iter 179, loss 2.0206379890441895, acc 0.18000000715255737\n",
      "Epoch 5, iter 180, loss 2.0700619220733643, acc 0.20999999344348907\n",
      "Epoch 5, iter 181, loss 2.01922869682312, acc 0.1899999976158142\n",
      "Epoch 5, iter 182, loss 2.00250244140625, acc 0.23000000417232513\n",
      "Epoch 5, iter 183, loss 1.9561409950256348, acc 0.20000000298023224\n",
      "Epoch 5, iter 184, loss 2.0545737743377686, acc 0.15000000596046448\n",
      "Epoch 5, iter 185, loss 1.940271019935608, acc 0.1899999976158142\n",
      "Epoch 5, iter 186, loss 1.9538750648498535, acc 0.20999999344348907\n",
      "Epoch 5, iter 187, loss 1.9348431825637817, acc 0.20999999344348907\n",
      "Epoch 5, iter 188, loss 2.0852773189544678, acc 0.20999999344348907\n",
      "Epoch 5, iter 189, loss 2.041132688522339, acc 0.10999999940395355\n",
      "Epoch 5, iter 190, loss 2.001702308654785, acc 0.2199999988079071\n",
      "Epoch 5, iter 191, loss 1.9833993911743164, acc 0.20000000298023224\n",
      "Epoch 5, iter 192, loss 1.9689726829528809, acc 0.23000000417232513\n",
      "Epoch 5, iter 193, loss 1.9226982593536377, acc 0.23000000417232513\n",
      "Epoch 5, iter 194, loss 1.937635898590088, acc 0.1899999976158142\n",
      "Epoch 5, iter 195, loss 1.9408832788467407, acc 0.23000000417232513\n",
      "Epoch 5, iter 196, loss 2.0418686866760254, acc 0.17000000178813934\n",
      "Epoch 5, iter 197, loss 1.9511909484863281, acc 0.23999999463558197\n",
      "Epoch 5, iter 198, loss 1.8655657768249512, acc 0.3100000023841858\n",
      "Epoch 5, iter 199, loss 1.9480979442596436, acc 0.20000000298023224\n",
      "Epoch 5, iter 200, loss 2.0134036540985107, acc 0.27000001072883606\n",
      "Epoch 5, iter 201, loss 1.9561576843261719, acc 0.23999999463558197\n",
      "Epoch 5, iter 202, loss 1.958654522895813, acc 0.18000000715255737\n",
      "Epoch 5, iter 203, loss 1.8888468742370605, acc 0.12999999523162842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 204, loss 1.9139857292175293, acc 0.25999999046325684\n",
      "Epoch 5, iter 205, loss 1.9030075073242188, acc 0.23000000417232513\n",
      "Epoch 5, iter 206, loss 1.9800339937210083, acc 0.20999999344348907\n",
      "Epoch 5, iter 207, loss 2.0392189025878906, acc 0.12999999523162842\n",
      "Epoch 5, iter 208, loss 1.9763706922531128, acc 0.18000000715255737\n",
      "Epoch 5, iter 209, loss 2.072882890701294, acc 0.18000000715255737\n",
      "Epoch 5, iter 210, loss 1.9926865100860596, acc 0.1899999976158142\n",
      "Epoch 5, iter 211, loss 2.0286262035369873, acc 0.1899999976158142\n",
      "Epoch 5, iter 212, loss 1.9218899011611938, acc 0.17000000178813934\n",
      "Epoch 5, iter 213, loss 1.9141441583633423, acc 0.20999999344348907\n",
      "Epoch 5, iter 214, loss 2.0020697116851807, acc 0.1899999976158142\n",
      "Epoch 5, iter 215, loss 1.9341617822647095, acc 0.15000000596046448\n",
      "Epoch 5, iter 216, loss 1.9830734729766846, acc 0.1599999964237213\n",
      "Epoch 5, iter 217, loss 1.8997677564620972, acc 0.28999999165534973\n",
      "Epoch 5, iter 218, loss 2.091118097305298, acc 0.20999999344348907\n",
      "Epoch 5, iter 219, loss 1.9859846830368042, acc 0.17000000178813934\n",
      "Epoch 5, iter 220, loss 1.893627643585205, acc 0.23999999463558197\n",
      "Epoch 5, iter 221, loss 1.9704395532608032, acc 0.18000000715255737\n",
      "Epoch 5, iter 222, loss 1.9313627481460571, acc 0.20999999344348907\n",
      "Epoch 5, iter 223, loss 1.8701938390731812, acc 0.2800000011920929\n",
      "Epoch 5, iter 224, loss 1.9473655223846436, acc 0.23999999463558197\n",
      "Epoch 5, iter 225, loss 1.8587291240692139, acc 0.23000000417232513\n",
      "Epoch 5, iter 226, loss 1.8946847915649414, acc 0.25\n",
      "Epoch 5, iter 227, loss 1.953031301498413, acc 0.25\n",
      "Epoch 5, iter 228, loss 1.956486701965332, acc 0.20999999344348907\n",
      "Epoch 5, iter 229, loss 1.8491883277893066, acc 0.2199999988079071\n",
      "Epoch 5, iter 230, loss 1.9106930494308472, acc 0.25\n",
      "Epoch 5, iter 231, loss 1.9543557167053223, acc 0.20999999344348907\n",
      "Epoch 5, iter 232, loss 2.0333163738250732, acc 0.15000000596046448\n",
      "Epoch 5, iter 233, loss 1.9581058025360107, acc 0.25\n",
      "Epoch 5, iter 234, loss 1.8819677829742432, acc 0.2800000011920929\n",
      "Epoch 5, iter 235, loss 1.8827725648880005, acc 0.2199999988079071\n",
      "Epoch 5, iter 236, loss 1.93385910987854, acc 0.17000000178813934\n",
      "Epoch 5, iter 237, loss 2.031782865524292, acc 0.1899999976158142\n",
      "Epoch 5, iter 238, loss 1.993882179260254, acc 0.20999999344348907\n",
      "Epoch 5, iter 239, loss 1.9203057289123535, acc 0.15000000596046448\n",
      "Epoch 5, iter 240, loss 1.9530061483383179, acc 0.17000000178813934\n",
      "Epoch 5, iter 241, loss 1.9142045974731445, acc 0.14000000059604645\n",
      "Epoch 5, iter 242, loss 1.9950354099273682, acc 0.23000000417232513\n",
      "Epoch 5, iter 243, loss 2.0142900943756104, acc 0.17000000178813934\n",
      "Epoch 5, iter 244, loss 1.9826031923294067, acc 0.27000001072883606\n",
      "Epoch 5, iter 245, loss 1.9125549793243408, acc 0.20999999344348907\n",
      "Epoch 5, iter 246, loss 1.9905530214309692, acc 0.17000000178813934\n",
      "Epoch 5, iter 247, loss 1.9308722019195557, acc 0.23000000417232513\n",
      "Epoch 5, iter 248, loss 1.9931641817092896, acc 0.18000000715255737\n",
      "Epoch 5, iter 249, loss 1.9552435874938965, acc 0.12999999523162842\n",
      "Epoch 5, iter 250, loss 1.9341697692871094, acc 0.28999999165534973\n",
      "Epoch 5, iter 251, loss 1.9878078699111938, acc 0.1899999976158142\n",
      "Epoch 5, iter 252, loss 1.9175615310668945, acc 0.25\n",
      "Epoch 5, iter 253, loss 2.0525331497192383, acc 0.1599999964237213\n",
      "Epoch 5, iter 254, loss 1.8856594562530518, acc 0.20999999344348907\n",
      "Epoch 5, iter 255, loss 1.9311039447784424, acc 0.18000000715255737\n",
      "Epoch 5, iter 256, loss 2.0096399784088135, acc 0.2199999988079071\n",
      "Epoch 5, iter 257, loss 1.903059720993042, acc 0.17000000178813934\n",
      "Epoch 5, iter 258, loss 2.014303684234619, acc 0.23000000417232513\n",
      "Epoch 5, iter 259, loss 2.000753402709961, acc 0.23000000417232513\n",
      "Epoch 5, iter 260, loss 2.004373550415039, acc 0.1899999976158142\n",
      "Epoch 5, iter 261, loss 1.8758622407913208, acc 0.23999999463558197\n",
      "Epoch 5, iter 262, loss 1.9731281995773315, acc 0.1599999964237213\n",
      "Epoch 5, iter 263, loss 1.837519884109497, acc 0.23999999463558197\n",
      "Epoch 5, iter 264, loss 1.883017897605896, acc 0.27000001072883606\n",
      "Epoch 5, iter 265, loss 2.027888298034668, acc 0.23000000417232513\n",
      "Epoch 5, iter 266, loss 1.9049911499023438, acc 0.17000000178813934\n",
      "Epoch 5, iter 267, loss 1.9044466018676758, acc 0.2800000011920929\n",
      "Epoch 5, iter 268, loss 1.8999435901641846, acc 0.12999999523162842\n",
      "Epoch 5, iter 269, loss 1.9653691053390503, acc 0.1899999976158142\n",
      "Epoch 5, iter 270, loss 1.9575090408325195, acc 0.1599999964237213\n",
      "Epoch 5, iter 271, loss 1.9299921989440918, acc 0.20000000298023224\n",
      "Epoch 5, iter 272, loss 1.932958960533142, acc 0.20999999344348907\n",
      "Epoch 5, iter 273, loss 1.9484409093856812, acc 0.20000000298023224\n",
      "Epoch 5, iter 274, loss 1.9575331211090088, acc 0.20999999344348907\n",
      "Epoch 5, iter 275, loss 1.9951776266098022, acc 0.18000000715255737\n",
      "Epoch 5, iter 276, loss 1.9644733667373657, acc 0.20999999344348907\n",
      "Epoch 5, iter 277, loss 1.9443050622940063, acc 0.20999999344348907\n",
      "Epoch 5, iter 278, loss 1.9131428003311157, acc 0.17000000178813934\n",
      "Epoch 5, iter 279, loss 1.9090121984481812, acc 0.2800000011920929\n",
      "Epoch 5, iter 280, loss 1.935736060142517, acc 0.1899999976158142\n",
      "Epoch 5, iter 281, loss 1.9418545961380005, acc 0.2800000011920929\n",
      "Epoch 5, iter 282, loss 1.993262529373169, acc 0.1899999976158142\n",
      "Epoch 5, iter 283, loss 1.9264075756072998, acc 0.17000000178813934\n",
      "Epoch 5, iter 284, loss 1.961513638496399, acc 0.27000001072883606\n",
      "Epoch 5, iter 285, loss 1.9672386646270752, acc 0.20000000298023224\n",
      "Epoch 5, iter 286, loss 1.8789665699005127, acc 0.23999999463558197\n",
      "Epoch 5, iter 287, loss 1.9254014492034912, acc 0.20000000298023224\n",
      "Epoch 5, iter 288, loss 1.9880191087722778, acc 0.2199999988079071\n",
      "Epoch 5, iter 289, loss 1.9031705856323242, acc 0.23999999463558197\n",
      "Epoch 5, iter 290, loss 1.8607615232467651, acc 0.23000000417232513\n",
      "Epoch 5, iter 291, loss 1.9443004131317139, acc 0.20999999344348907\n",
      "Epoch 5, iter 292, loss 1.8803439140319824, acc 0.25999999046325684\n",
      "Epoch 5, iter 293, loss 1.9889445304870605, acc 0.1899999976158142\n",
      "Epoch 5, iter 294, loss 2.005620002746582, acc 0.1599999964237213\n",
      "Epoch 5, iter 295, loss 1.938002586364746, acc 0.20000000298023224\n",
      "Epoch 5, iter 296, loss 1.9028282165527344, acc 0.20999999344348907\n",
      "Epoch 5, iter 297, loss 1.9934507608413696, acc 0.23999999463558197\n",
      "Epoch 5, iter 298, loss 1.8335338830947876, acc 0.25\n",
      "Epoch 5, iter 299, loss 1.9589145183563232, acc 0.12999999523162842\n",
      "Epoch 5, iter 300, loss 1.9912179708480835, acc 0.18000000715255737\n",
      "Epoch 5, iter 301, loss 2.0390818119049072, acc 0.20999999344348907\n",
      "Epoch 5, iter 302, loss 1.9604688882827759, acc 0.25999999046325684\n",
      "Epoch 5, iter 303, loss 1.9420231580734253, acc 0.20000000298023224\n",
      "Epoch 5, iter 304, loss 1.983425259590149, acc 0.17000000178813934\n",
      "Epoch 5, iter 305, loss 2.005669355392456, acc 0.1599999964237213\n",
      "Epoch 5, iter 306, loss 1.8624082803726196, acc 0.20999999344348907\n",
      "Epoch 5, iter 307, loss 1.8917285203933716, acc 0.25\n",
      "Epoch 5, iter 308, loss 2.0323691368103027, acc 0.2199999988079071\n",
      "Epoch 5, iter 309, loss 1.928774118423462, acc 0.1899999976158142\n",
      "Epoch 5, iter 310, loss 2.0394175052642822, acc 0.18000000715255737\n",
      "Epoch 5, iter 311, loss 1.9515669345855713, acc 0.2199999988079071\n",
      "Epoch 5, iter 312, loss 2.0411386489868164, acc 0.25\n",
      "Epoch 5, iter 313, loss 2.075319290161133, acc 0.11999999731779099\n",
      "Epoch 5, iter 314, loss 1.891749382019043, acc 0.25999999046325684\n",
      "Epoch 5, iter 315, loss 1.8946099281311035, acc 0.25\n",
      "Epoch 5, iter 316, loss 1.9700405597686768, acc 0.12999999523162842\n",
      "Epoch 5, iter 317, loss 2.001227617263794, acc 0.2199999988079071\n",
      "Epoch 5, iter 318, loss 1.9254217147827148, acc 0.2199999988079071\n",
      "Epoch 5, iter 319, loss 1.9627209901809692, acc 0.17000000178813934\n",
      "Epoch 5, iter 320, loss 1.9772169589996338, acc 0.1899999976158142\n",
      "Epoch 5, iter 321, loss 2.041912317276001, acc 0.1899999976158142\n",
      "Epoch 5, iter 322, loss 1.9559766054153442, acc 0.23999999463558197\n",
      "Epoch 5, iter 323, loss 1.9278972148895264, acc 0.20000000298023224\n",
      "Epoch 5, iter 324, loss 1.9099082946777344, acc 0.25\n",
      "Epoch 5, iter 325, loss 1.996107578277588, acc 0.23999999463558197\n",
      "Epoch 5, iter 326, loss 1.85993230342865, acc 0.23000000417232513\n",
      "Epoch 5, iter 327, loss 1.909055233001709, acc 0.17000000178813934\n",
      "Epoch 5, iter 328, loss 1.9094773530960083, acc 0.25999999046325684\n",
      "Epoch 5, iter 329, loss 1.9287272691726685, acc 0.2199999988079071\n",
      "Epoch 5, iter 330, loss 1.9412851333618164, acc 0.20999999344348907\n",
      "Epoch 5, iter 331, loss 1.9342797994613647, acc 0.1899999976158142\n",
      "Epoch 5, iter 332, loss 2.0092902183532715, acc 0.23000000417232513\n",
      "Epoch 5, iter 333, loss 1.9317353963851929, acc 0.2199999988079071\n",
      "Epoch 5, iter 334, loss 1.9819369316101074, acc 0.2199999988079071\n",
      "Epoch 5, iter 335, loss 1.8876118659973145, acc 0.25\n",
      "Epoch 5, iter 336, loss 1.9773271083831787, acc 0.2199999988079071\n",
      "Epoch 5, iter 337, loss 1.942784309387207, acc 0.20999999344348907\n",
      "Epoch 5, iter 338, loss 1.9037960767745972, acc 0.2199999988079071\n",
      "Epoch 5, iter 339, loss 1.8949366807937622, acc 0.23000000417232513\n",
      "Epoch 5, iter 340, loss 1.87449312210083, acc 0.23000000417232513\n",
      "Epoch 5, iter 341, loss 1.8987617492675781, acc 0.25\n",
      "Epoch 5, iter 342, loss 1.998470425605774, acc 0.2199999988079071\n",
      "Epoch 5, iter 343, loss 1.9703896045684814, acc 0.1899999976158142\n",
      "Epoch 5, iter 344, loss 1.8946048021316528, acc 0.23999999463558197\n",
      "Epoch 5, iter 345, loss 2.043271064758301, acc 0.18000000715255737\n",
      "Epoch 5, iter 346, loss 1.8891793489456177, acc 0.25\n",
      "Epoch 5, iter 347, loss 1.9831337928771973, acc 0.20000000298023224\n",
      "Epoch 5, iter 348, loss 1.8980095386505127, acc 0.33000001311302185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 349, loss 1.899083137512207, acc 0.27000001072883606\n",
      "Epoch 5, iter 350, loss 1.9936363697052002, acc 0.25\n",
      "Epoch 5, iter 351, loss 1.9034205675125122, acc 0.15000000596046448\n",
      "Epoch 5, iter 352, loss 1.9297465085983276, acc 0.1899999976158142\n",
      "Epoch 5, iter 353, loss 1.902488112449646, acc 0.25999999046325684\n",
      "Epoch 5, iter 354, loss 1.8815263509750366, acc 0.25\n",
      "Epoch 5, iter 355, loss 1.9256277084350586, acc 0.20000000298023224\n",
      "Epoch 5, iter 356, loss 1.930181860923767, acc 0.25\n",
      "Epoch 5, iter 357, loss 1.8997035026550293, acc 0.2199999988079071\n",
      "Epoch 5, iter 358, loss 2.056602716445923, acc 0.1899999976158142\n",
      "Epoch 5, iter 359, loss 1.9320881366729736, acc 0.12999999523162842\n",
      "Epoch 5, iter 360, loss 1.9974621534347534, acc 0.23000000417232513\n",
      "Epoch 5, iter 361, loss 1.9166582822799683, acc 0.20000000298023224\n",
      "Epoch 5, iter 362, loss 1.9645183086395264, acc 0.17000000178813934\n",
      "Epoch 5, iter 363, loss 1.9555816650390625, acc 0.28999999165534973\n",
      "Epoch 5, iter 364, loss 1.9649959802627563, acc 0.11999999731779099\n",
      "Epoch 5, iter 365, loss 1.9626182317733765, acc 0.20999999344348907\n",
      "Epoch 5, iter 366, loss 1.939692735671997, acc 0.23999999463558197\n",
      "Epoch 5, iter 367, loss 1.8583544492721558, acc 0.23000000417232513\n",
      "Epoch 5, iter 368, loss 1.968436598777771, acc 0.23000000417232513\n",
      "Epoch 5, iter 369, loss 1.9203568696975708, acc 0.23999999463558197\n",
      "Epoch 5, iter 370, loss 1.916079044342041, acc 0.1899999976158142\n",
      "Epoch 5, iter 371, loss 1.9898779392242432, acc 0.2199999988079071\n",
      "Epoch 5, iter 372, loss 1.9149166345596313, acc 0.23000000417232513\n",
      "Epoch 5, iter 373, loss 1.9362874031066895, acc 0.17000000178813934\n",
      "Epoch 5, iter 374, loss 2.0274665355682373, acc 0.20999999344348907\n",
      "Epoch 5, iter 375, loss 1.9462618827819824, acc 0.30000001192092896\n",
      "Epoch 5, iter 376, loss 1.9322677850723267, acc 0.15000000596046448\n",
      "Epoch 5, iter 377, loss 1.9097747802734375, acc 0.27000001072883606\n",
      "Epoch 5, iter 378, loss 1.952048897743225, acc 0.25\n",
      "Epoch 5, iter 379, loss 2.0051722526550293, acc 0.18000000715255737\n",
      "Epoch 5, iter 380, loss 1.9923988580703735, acc 0.17000000178813934\n",
      "Epoch 5, iter 381, loss 1.9583874940872192, acc 0.1599999964237213\n",
      "Epoch 5, iter 382, loss 1.924625277519226, acc 0.25\n",
      "Epoch 5, iter 383, loss 1.9602227210998535, acc 0.27000001072883606\n",
      "Epoch 5, iter 384, loss 1.9265309572219849, acc 0.18000000715255737\n",
      "Epoch 5, iter 385, loss 1.8674169778823853, acc 0.23999999463558197\n",
      "Epoch 5, iter 386, loss 1.9394443035125732, acc 0.20999999344348907\n",
      "Epoch 5, iter 387, loss 1.9351377487182617, acc 0.23000000417232513\n",
      "Epoch 5, iter 388, loss 1.9512866735458374, acc 0.20000000298023224\n",
      "Epoch 5, iter 389, loss 1.9567373991012573, acc 0.20999999344348907\n",
      "Epoch 5, iter 390, loss 2.0037529468536377, acc 0.10000000149011612\n",
      "Epoch 5, iter 391, loss 1.8965672254562378, acc 0.1899999976158142\n",
      "Epoch 5, iter 392, loss 1.9513466358184814, acc 0.18000000715255737\n",
      "Epoch 5, iter 393, loss 1.962069034576416, acc 0.15000000596046448\n",
      "Epoch 5, iter 394, loss 1.9086260795593262, acc 0.25\n",
      "Epoch 5, iter 395, loss 1.9453731775283813, acc 0.25999999046325684\n",
      "Epoch 5, iter 396, loss 1.9248782396316528, acc 0.1599999964237213\n",
      "Epoch 5, iter 397, loss 1.9055383205413818, acc 0.20000000298023224\n",
      "Epoch 5, iter 398, loss 2.0875818729400635, acc 0.11999999731779099\n",
      "Epoch 5, iter 399, loss 1.887455940246582, acc 0.23999999463558197\n",
      "Epoch 5, iter 400, loss 1.901516079902649, acc 0.2800000011920929\n",
      "Epoch 5, iter 401, loss 1.9129610061645508, acc 0.20999999344348907\n",
      "Epoch 5, iter 402, loss 1.9015278816223145, acc 0.20000000298023224\n",
      "Epoch 5, iter 403, loss 2.0010030269622803, acc 0.1899999976158142\n",
      "Epoch 5, iter 404, loss 1.968422532081604, acc 0.1599999964237213\n",
      "Epoch 5, iter 405, loss 1.953832745552063, acc 0.23000000417232513\n",
      "Epoch 5, iter 406, loss 1.9465816020965576, acc 0.11999999731779099\n",
      "Epoch 5, iter 407, loss 1.9233818054199219, acc 0.14000000059604645\n",
      "Epoch 5, iter 408, loss 1.992519736289978, acc 0.25\n",
      "Epoch 5, iter 409, loss 1.9042975902557373, acc 0.23999999463558197\n",
      "Epoch 5, iter 410, loss 1.9247617721557617, acc 0.1599999964237213\n",
      "Epoch 5, iter 411, loss 1.9084172248840332, acc 0.2800000011920929\n",
      "Epoch 5, iter 412, loss 1.894172191619873, acc 0.27000001072883606\n",
      "Epoch 5, iter 413, loss 2.019217014312744, acc 0.15000000596046448\n",
      "Epoch 5, iter 414, loss 1.9029221534729004, acc 0.15000000596046448\n",
      "Epoch 5, iter 415, loss 1.9218840599060059, acc 0.20000000298023224\n",
      "Epoch 5, iter 416, loss 1.939059853553772, acc 0.20000000298023224\n",
      "Epoch 5, iter 417, loss 1.9341925382614136, acc 0.28999999165534973\n",
      "Epoch 5, iter 418, loss 1.8883538246154785, acc 0.15000000596046448\n",
      "Epoch 5, iter 419, loss 1.881384253501892, acc 0.25999999046325684\n",
      "Epoch 5, iter 420, loss 1.9373373985290527, acc 0.23000000417232513\n",
      "Epoch 6, iter 1, loss 1.9024380445480347, acc 0.23000000417232513\n",
      "Epoch 6, iter 2, loss 1.980147123336792, acc 0.18000000715255737\n",
      "Epoch 6, iter 3, loss 1.973852276802063, acc 0.18000000715255737\n",
      "Epoch 6, iter 4, loss 2.0117909908294678, acc 0.1599999964237213\n",
      "Epoch 6, iter 5, loss 1.9872901439666748, acc 0.1599999964237213\n",
      "Epoch 6, iter 6, loss 2.0060741901397705, acc 0.17000000178813934\n",
      "Epoch 6, iter 7, loss 1.9946768283843994, acc 0.23999999463558197\n",
      "Epoch 6, iter 8, loss 2.0095858573913574, acc 0.18000000715255737\n",
      "Epoch 6, iter 9, loss 2.0033750534057617, acc 0.20999999344348907\n",
      "Epoch 6, iter 10, loss 1.9046273231506348, acc 0.18000000715255737\n",
      "Epoch 6, iter 11, loss 2.0270349979400635, acc 0.1899999976158142\n",
      "Epoch 6, iter 12, loss 1.907016634941101, acc 0.20000000298023224\n",
      "Epoch 6, iter 13, loss 1.9375076293945312, acc 0.18000000715255737\n",
      "Epoch 6, iter 14, loss 1.936423897743225, acc 0.20999999344348907\n",
      "Epoch 6, iter 15, loss 1.8461745977401733, acc 0.2800000011920929\n",
      "Epoch 6, iter 16, loss 1.879199504852295, acc 0.20000000298023224\n",
      "Epoch 6, iter 17, loss 1.953317403793335, acc 0.1599999964237213\n",
      "Epoch 6, iter 18, loss 1.955803394317627, acc 0.20000000298023224\n",
      "Epoch 6, iter 19, loss 1.9850528240203857, acc 0.18000000715255737\n",
      "Epoch 6, iter 20, loss 1.8965308666229248, acc 0.25\n",
      "Epoch 6, iter 21, loss 2.0643186569213867, acc 0.20999999344348907\n",
      "Epoch 6, iter 22, loss 2.094043254852295, acc 0.18000000715255737\n",
      "Epoch 6, iter 23, loss 2.040585994720459, acc 0.27000001072883606\n",
      "Epoch 6, iter 24, loss 2.0414164066314697, acc 0.1899999976158142\n",
      "Epoch 6, iter 25, loss 2.0660295486450195, acc 0.20999999344348907\n",
      "Epoch 6, iter 26, loss 2.1025753021240234, acc 0.20000000298023224\n",
      "Epoch 6, iter 27, loss 2.12153697013855, acc 0.25999999046325684\n",
      "Epoch 6, iter 28, loss 1.961620807647705, acc 0.25999999046325684\n",
      "Epoch 6, iter 29, loss 2.009436845779419, acc 0.23999999463558197\n",
      "Epoch 6, iter 30, loss 2.035797357559204, acc 0.1899999976158142\n",
      "Epoch 6, iter 31, loss 1.996372938156128, acc 0.11999999731779099\n",
      "Epoch 6, iter 32, loss 1.9186036586761475, acc 0.17000000178813934\n",
      "Epoch 6, iter 33, loss 2.048252820968628, acc 0.23000000417232513\n",
      "Epoch 6, iter 34, loss 1.9901328086853027, acc 0.1899999976158142\n",
      "Epoch 6, iter 35, loss 1.950039029121399, acc 0.23999999463558197\n",
      "Epoch 6, iter 36, loss 2.003507375717163, acc 0.18000000715255737\n",
      "Epoch 6, iter 37, loss 1.9954719543457031, acc 0.18000000715255737\n",
      "Epoch 6, iter 38, loss 1.8811602592468262, acc 0.25999999046325684\n",
      "Epoch 6, iter 39, loss 1.9092326164245605, acc 0.23000000417232513\n",
      "Epoch 6, iter 40, loss 1.9357590675354004, acc 0.20000000298023224\n",
      "Epoch 6, iter 41, loss 2.0540759563446045, acc 0.14000000059604645\n",
      "Epoch 6, iter 42, loss 2.0076589584350586, acc 0.1599999964237213\n",
      "Epoch 6, iter 43, loss 1.8870596885681152, acc 0.1899999976158142\n",
      "Epoch 6, iter 44, loss 1.892265796661377, acc 0.18000000715255737\n",
      "Epoch 6, iter 45, loss 1.9676485061645508, acc 0.20999999344348907\n",
      "Epoch 6, iter 46, loss 1.9903457164764404, acc 0.2800000011920929\n",
      "Epoch 6, iter 47, loss 1.9634284973144531, acc 0.1599999964237213\n",
      "Epoch 6, iter 48, loss 1.911272406578064, acc 0.1899999976158142\n",
      "Epoch 6, iter 49, loss 2.0211539268493652, acc 0.20999999344348907\n",
      "Epoch 6, iter 50, loss 1.9503867626190186, acc 0.23999999463558197\n",
      "Epoch 6, iter 51, loss 1.8361637592315674, acc 0.25999999046325684\n",
      "Epoch 6, iter 52, loss 1.9365265369415283, acc 0.20000000298023224\n",
      "Epoch 6, iter 53, loss 1.9746419191360474, acc 0.3199999928474426\n",
      "Epoch 6, iter 54, loss 1.9993348121643066, acc 0.11999999731779099\n",
      "Epoch 6, iter 55, loss 2.0723326206207275, acc 0.09000000357627869\n",
      "Epoch 6, iter 56, loss 2.038374662399292, acc 0.15000000596046448\n",
      "Epoch 6, iter 57, loss 2.0091593265533447, acc 0.1899999976158142\n",
      "Epoch 6, iter 58, loss 1.9246090650558472, acc 0.1899999976158142\n",
      "Epoch 6, iter 59, loss 1.9882762432098389, acc 0.23000000417232513\n",
      "Epoch 6, iter 60, loss 1.9569827318191528, acc 0.2199999988079071\n",
      "Epoch 6, iter 61, loss 1.9681715965270996, acc 0.1599999964237213\n",
      "Epoch 6, iter 62, loss 1.9513413906097412, acc 0.20000000298023224\n",
      "Epoch 6, iter 63, loss 1.9334747791290283, acc 0.23999999463558197\n",
      "Epoch 6, iter 64, loss 1.9663991928100586, acc 0.20999999344348907\n",
      "Epoch 6, iter 65, loss 1.9734811782836914, acc 0.25999999046325684\n",
      "Epoch 6, iter 66, loss 1.9525777101516724, acc 0.23000000417232513\n",
      "Epoch 6, iter 67, loss 1.9329251050949097, acc 0.17000000178813934\n",
      "Epoch 6, iter 68, loss 1.9332772493362427, acc 0.3199999928474426\n",
      "Epoch 6, iter 69, loss 1.9400725364685059, acc 0.1899999976158142\n",
      "Epoch 6, iter 70, loss 1.9903247356414795, acc 0.27000001072883606\n",
      "Epoch 6, iter 71, loss 2.001749038696289, acc 0.17000000178813934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 72, loss 1.906226396560669, acc 0.15000000596046448\n",
      "Epoch 6, iter 73, loss 1.9872304201126099, acc 0.20999999344348907\n",
      "Epoch 6, iter 74, loss 1.9882779121398926, acc 0.2199999988079071\n",
      "Epoch 6, iter 75, loss 1.9280128479003906, acc 0.12999999523162842\n",
      "Epoch 6, iter 76, loss 2.012934684753418, acc 0.1899999976158142\n",
      "Epoch 6, iter 77, loss 2.036888360977173, acc 0.1599999964237213\n",
      "Epoch 6, iter 78, loss 1.9832484722137451, acc 0.2800000011920929\n",
      "Epoch 6, iter 79, loss 1.9514085054397583, acc 0.20999999344348907\n",
      "Epoch 6, iter 80, loss 1.9735205173492432, acc 0.20000000298023224\n",
      "Epoch 6, iter 81, loss 2.0002057552337646, acc 0.1599999964237213\n",
      "Epoch 6, iter 82, loss 1.9984657764434814, acc 0.1599999964237213\n",
      "Epoch 6, iter 83, loss 1.9741092920303345, acc 0.20000000298023224\n",
      "Epoch 6, iter 84, loss 1.968228816986084, acc 0.14000000059604645\n",
      "Epoch 6, iter 85, loss 1.9806026220321655, acc 0.14000000059604645\n",
      "Epoch 6, iter 86, loss 1.960784912109375, acc 0.20000000298023224\n",
      "Epoch 6, iter 87, loss 2.004102945327759, acc 0.23999999463558197\n",
      "Epoch 6, iter 88, loss 2.0010170936584473, acc 0.23999999463558197\n",
      "Epoch 6, iter 89, loss 1.9994109869003296, acc 0.1899999976158142\n",
      "Epoch 6, iter 90, loss 1.9777106046676636, acc 0.1899999976158142\n",
      "Epoch 6, iter 91, loss 1.9941459894180298, acc 0.18000000715255737\n",
      "Epoch 6, iter 92, loss 1.9786241054534912, acc 0.2199999988079071\n",
      "Epoch 6, iter 93, loss 1.9909727573394775, acc 0.2199999988079071\n",
      "Epoch 6, iter 94, loss 1.9266868829727173, acc 0.1599999964237213\n",
      "Epoch 6, iter 95, loss 1.8835095167160034, acc 0.20000000298023224\n",
      "Epoch 6, iter 96, loss 2.0212595462799072, acc 0.2199999988079071\n",
      "Epoch 6, iter 97, loss 1.9496504068374634, acc 0.10999999940395355\n",
      "Epoch 6, iter 98, loss 1.960874319076538, acc 0.1599999964237213\n",
      "Epoch 6, iter 99, loss 1.983033299446106, acc 0.20999999344348907\n",
      "Epoch 6, iter 100, loss 1.9606122970581055, acc 0.23999999463558197\n",
      "Epoch 6, iter 101, loss 1.8807677030563354, acc 0.2199999988079071\n",
      "Epoch 6, iter 102, loss 1.985944390296936, acc 0.23000000417232513\n",
      "Epoch 6, iter 103, loss 2.005965232849121, acc 0.23999999463558197\n",
      "Epoch 6, iter 104, loss 1.9644545316696167, acc 0.2800000011920929\n",
      "Epoch 6, iter 105, loss 1.8350167274475098, acc 0.1899999976158142\n",
      "Epoch 6, iter 106, loss 1.8677148818969727, acc 0.25999999046325684\n",
      "Epoch 6, iter 107, loss 1.9057605266571045, acc 0.2199999988079071\n",
      "Epoch 6, iter 108, loss 1.997443675994873, acc 0.12999999523162842\n",
      "Epoch 6, iter 109, loss 1.9860459566116333, acc 0.2199999988079071\n",
      "Epoch 6, iter 110, loss 1.979253888130188, acc 0.14000000059604645\n",
      "Epoch 6, iter 111, loss 1.9504526853561401, acc 0.17000000178813934\n",
      "Epoch 6, iter 112, loss 1.983831524848938, acc 0.25999999046325684\n",
      "Epoch 6, iter 113, loss 1.9419997930526733, acc 0.23000000417232513\n",
      "Epoch 6, iter 114, loss 1.8992503881454468, acc 0.20999999344348907\n",
      "Epoch 6, iter 115, loss 1.9183579683303833, acc 0.25\n",
      "Epoch 6, iter 116, loss 1.9786213636398315, acc 0.20000000298023224\n",
      "Epoch 6, iter 117, loss 1.9430325031280518, acc 0.2199999988079071\n",
      "Epoch 6, iter 118, loss 1.955593228340149, acc 0.14000000059604645\n",
      "Epoch 6, iter 119, loss 1.8901219367980957, acc 0.25999999046325684\n",
      "Epoch 6, iter 120, loss 1.9404090642929077, acc 0.23000000417232513\n",
      "Epoch 6, iter 121, loss 1.9297959804534912, acc 0.23000000417232513\n",
      "Epoch 6, iter 122, loss 1.9466156959533691, acc 0.30000001192092896\n",
      "Epoch 6, iter 123, loss 1.9826360940933228, acc 0.14000000059604645\n",
      "Epoch 6, iter 124, loss 1.9301432371139526, acc 0.2199999988079071\n",
      "Epoch 6, iter 125, loss 1.9201226234436035, acc 0.18000000715255737\n",
      "Epoch 6, iter 126, loss 1.9522476196289062, acc 0.1899999976158142\n",
      "Epoch 6, iter 127, loss 1.9472683668136597, acc 0.23999999463558197\n",
      "Epoch 6, iter 128, loss 1.957419753074646, acc 0.20000000298023224\n",
      "Epoch 6, iter 129, loss 2.0032176971435547, acc 0.20000000298023224\n",
      "Epoch 6, iter 130, loss 2.0426409244537354, acc 0.20999999344348907\n",
      "Epoch 6, iter 131, loss 2.0470244884490967, acc 0.23000000417232513\n",
      "Epoch 6, iter 132, loss 1.9699593782424927, acc 0.25\n",
      "Epoch 6, iter 133, loss 2.1393117904663086, acc 0.23000000417232513\n",
      "Epoch 6, iter 134, loss 2.0881998538970947, acc 0.15000000596046448\n",
      "Epoch 6, iter 135, loss 1.983933687210083, acc 0.2800000011920929\n",
      "Epoch 6, iter 136, loss 1.9029864072799683, acc 0.30000001192092896\n",
      "Epoch 6, iter 137, loss 1.992519497871399, acc 0.25\n",
      "Epoch 6, iter 138, loss 1.9471286535263062, acc 0.23000000417232513\n",
      "Epoch 6, iter 139, loss 1.9646410942077637, acc 0.20999999344348907\n",
      "Epoch 6, iter 140, loss 1.9910178184509277, acc 0.1899999976158142\n",
      "Epoch 6, iter 141, loss 2.1052582263946533, acc 0.20000000298023224\n",
      "Epoch 6, iter 142, loss 2.056868314743042, acc 0.17000000178813934\n",
      "Epoch 6, iter 143, loss 2.027893543243408, acc 0.20000000298023224\n",
      "Epoch 6, iter 144, loss 2.0333924293518066, acc 0.15000000596046448\n",
      "Epoch 6, iter 145, loss 1.991642951965332, acc 0.20000000298023224\n",
      "Epoch 6, iter 146, loss 2.036114454269409, acc 0.20000000298023224\n",
      "Epoch 6, iter 147, loss 2.0688953399658203, acc 0.23999999463558197\n",
      "Epoch 6, iter 148, loss 2.0297365188598633, acc 0.23000000417232513\n",
      "Epoch 6, iter 149, loss 1.9461811780929565, acc 0.2199999988079071\n",
      "Epoch 6, iter 150, loss 1.9870786666870117, acc 0.25\n",
      "Epoch 6, iter 151, loss 1.8274314403533936, acc 0.25999999046325684\n",
      "Epoch 6, iter 152, loss 2.085179328918457, acc 0.20000000298023224\n",
      "Epoch 6, iter 153, loss 2.0084760189056396, acc 0.23999999463558197\n",
      "Epoch 6, iter 154, loss 2.000296115875244, acc 0.2199999988079071\n",
      "Epoch 6, iter 155, loss 1.9157662391662598, acc 0.25\n",
      "Epoch 6, iter 156, loss 1.9293572902679443, acc 0.23000000417232513\n",
      "Epoch 6, iter 157, loss 1.9703772068023682, acc 0.17000000178813934\n",
      "Epoch 6, iter 158, loss 1.9194130897521973, acc 0.20000000298023224\n",
      "Epoch 6, iter 159, loss 2.01788067817688, acc 0.1899999976158142\n",
      "Epoch 6, iter 160, loss 2.0196127891540527, acc 0.18000000715255737\n",
      "Epoch 6, iter 161, loss 1.9594699144363403, acc 0.20999999344348907\n",
      "Epoch 6, iter 162, loss 2.112246513366699, acc 0.28999999165534973\n",
      "Epoch 6, iter 163, loss 2.051819086074829, acc 0.18000000715255737\n",
      "Epoch 6, iter 164, loss 2.0063393115997314, acc 0.18000000715255737\n",
      "Epoch 6, iter 165, loss 2.1053900718688965, acc 0.23000000417232513\n",
      "Epoch 6, iter 166, loss 2.0037717819213867, acc 0.25\n",
      "Epoch 6, iter 167, loss 2.0253653526306152, acc 0.20000000298023224\n",
      "Epoch 6, iter 168, loss 2.027515411376953, acc 0.2199999988079071\n",
      "Epoch 6, iter 169, loss 2.0051422119140625, acc 0.1899999976158142\n",
      "Epoch 6, iter 170, loss 1.9603389501571655, acc 0.12999999523162842\n",
      "Epoch 6, iter 171, loss 1.990297555923462, acc 0.17000000178813934\n",
      "Epoch 6, iter 172, loss 2.0813374519348145, acc 0.17000000178813934\n",
      "Epoch 6, iter 173, loss 2.0566325187683105, acc 0.20000000298023224\n",
      "Epoch 6, iter 174, loss 1.9338046312332153, acc 0.17000000178813934\n",
      "Epoch 6, iter 175, loss 1.9203606843948364, acc 0.2199999988079071\n",
      "Epoch 6, iter 176, loss 2.095618724822998, acc 0.10999999940395355\n",
      "Epoch 6, iter 177, loss 1.9788885116577148, acc 0.1599999964237213\n",
      "Epoch 6, iter 178, loss 2.0924668312072754, acc 0.20000000298023224\n",
      "Epoch 6, iter 179, loss 2.009611129760742, acc 0.18000000715255737\n",
      "Epoch 6, iter 180, loss 1.9982417821884155, acc 0.23999999463558197\n",
      "Epoch 6, iter 181, loss 1.9418928623199463, acc 0.23000000417232513\n",
      "Epoch 6, iter 182, loss 1.942857265472412, acc 0.25\n",
      "Epoch 6, iter 183, loss 1.9980173110961914, acc 0.20999999344348907\n",
      "Epoch 6, iter 184, loss 1.9981377124786377, acc 0.18000000715255737\n",
      "Epoch 6, iter 185, loss 1.893200397491455, acc 0.20000000298023224\n",
      "Epoch 6, iter 186, loss 2.009995937347412, acc 0.20999999344348907\n",
      "Epoch 6, iter 187, loss 1.9285650253295898, acc 0.20000000298023224\n",
      "Epoch 6, iter 188, loss 2.078730583190918, acc 0.23000000417232513\n",
      "Epoch 6, iter 189, loss 2.0621306896209717, acc 0.10999999940395355\n",
      "Epoch 6, iter 190, loss 1.9232536554336548, acc 0.23000000417232513\n",
      "Epoch 6, iter 191, loss 1.977715253829956, acc 0.20000000298023224\n",
      "Epoch 6, iter 192, loss 2.007394313812256, acc 0.23000000417232513\n",
      "Epoch 6, iter 193, loss 1.901625394821167, acc 0.23000000417232513\n",
      "Epoch 6, iter 194, loss 1.908892035484314, acc 0.18000000715255737\n",
      "Epoch 6, iter 195, loss 1.9341235160827637, acc 0.23000000417232513\n",
      "Epoch 6, iter 196, loss 2.0322906970977783, acc 0.18000000715255737\n",
      "Epoch 6, iter 197, loss 1.9561172723770142, acc 0.23000000417232513\n",
      "Epoch 6, iter 198, loss 1.8656468391418457, acc 0.3100000023841858\n",
      "Epoch 6, iter 199, loss 2.0037503242492676, acc 0.20000000298023224\n",
      "Epoch 6, iter 200, loss 2.048452377319336, acc 0.25999999046325684\n",
      "Epoch 6, iter 201, loss 1.9754139184951782, acc 0.23999999463558197\n",
      "Epoch 6, iter 202, loss 2.026693105697632, acc 0.1599999964237213\n",
      "Epoch 6, iter 203, loss 1.9348794221878052, acc 0.11999999731779099\n",
      "Epoch 6, iter 204, loss 1.9596867561340332, acc 0.25999999046325684\n",
      "Epoch 6, iter 205, loss 1.8816343545913696, acc 0.23999999463558197\n",
      "Epoch 6, iter 206, loss 1.962386965751648, acc 0.20999999344348907\n",
      "Epoch 6, iter 207, loss 1.9441674947738647, acc 0.1599999964237213\n",
      "Epoch 6, iter 208, loss 1.9441522359848022, acc 0.18000000715255737\n",
      "Epoch 6, iter 209, loss 2.022552013397217, acc 0.18000000715255737\n",
      "Epoch 6, iter 210, loss 2.0428740978240967, acc 0.1899999976158142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 211, loss 1.985557198524475, acc 0.20999999344348907\n",
      "Epoch 6, iter 212, loss 1.9412286281585693, acc 0.1599999964237213\n",
      "Epoch 6, iter 213, loss 1.9307801723480225, acc 0.1899999976158142\n",
      "Epoch 6, iter 214, loss 2.0039331912994385, acc 0.1899999976158142\n",
      "Epoch 6, iter 215, loss 1.9758321046829224, acc 0.12999999523162842\n",
      "Epoch 6, iter 216, loss 2.049558639526367, acc 0.1599999964237213\n",
      "Epoch 6, iter 217, loss 1.9256956577301025, acc 0.2800000011920929\n",
      "Epoch 6, iter 218, loss 2.142388343811035, acc 0.17000000178813934\n",
      "Epoch 6, iter 219, loss 2.0514464378356934, acc 0.17000000178813934\n",
      "Epoch 6, iter 220, loss 1.9091984033584595, acc 0.23000000417232513\n",
      "Epoch 6, iter 221, loss 1.908799409866333, acc 0.18000000715255737\n",
      "Epoch 6, iter 222, loss 1.9496194124221802, acc 0.20999999344348907\n",
      "Epoch 6, iter 223, loss 1.932543158531189, acc 0.25999999046325684\n",
      "Epoch 6, iter 224, loss 1.950854778289795, acc 0.23000000417232513\n",
      "Epoch 6, iter 225, loss 1.9433958530426025, acc 0.20999999344348907\n",
      "Epoch 6, iter 226, loss 1.9937827587127686, acc 0.23000000417232513\n",
      "Epoch 6, iter 227, loss 2.024174690246582, acc 0.23999999463558197\n",
      "Epoch 6, iter 228, loss 1.9941303730010986, acc 0.20000000298023224\n",
      "Epoch 6, iter 229, loss 1.8796626329421997, acc 0.2199999988079071\n",
      "Epoch 6, iter 230, loss 1.9905405044555664, acc 0.25\n",
      "Epoch 6, iter 231, loss 1.9938819408416748, acc 0.2199999988079071\n",
      "Epoch 6, iter 232, loss 1.995681643486023, acc 0.15000000596046448\n",
      "Epoch 6, iter 233, loss 2.041386365890503, acc 0.23999999463558197\n",
      "Epoch 6, iter 234, loss 1.9468226432800293, acc 0.27000001072883606\n",
      "Epoch 6, iter 235, loss 1.9203872680664062, acc 0.2199999988079071\n",
      "Epoch 6, iter 236, loss 1.9751181602478027, acc 0.1599999964237213\n",
      "Epoch 6, iter 237, loss 1.9223837852478027, acc 0.1899999976158142\n",
      "Epoch 6, iter 238, loss 2.055509567260742, acc 0.20999999344348907\n",
      "Epoch 6, iter 239, loss 1.962844967842102, acc 0.15000000596046448\n",
      "Epoch 6, iter 240, loss 1.9231950044631958, acc 0.17000000178813934\n",
      "Epoch 6, iter 241, loss 1.9719809293746948, acc 0.14000000059604645\n",
      "Epoch 6, iter 242, loss 2.006147861480713, acc 0.23000000417232513\n",
      "Epoch 6, iter 243, loss 1.9477484226226807, acc 0.17000000178813934\n",
      "Epoch 6, iter 244, loss 1.9732577800750732, acc 0.27000001072883606\n",
      "Epoch 6, iter 245, loss 1.949666142463684, acc 0.20000000298023224\n",
      "Epoch 6, iter 246, loss 2.0547935962677, acc 0.1599999964237213\n",
      "Epoch 6, iter 247, loss 1.8753271102905273, acc 0.25\n",
      "Epoch 6, iter 248, loss 2.042660713195801, acc 0.17000000178813934\n",
      "Epoch 6, iter 249, loss 1.937954068183899, acc 0.11999999731779099\n",
      "Epoch 6, iter 250, loss 1.9523403644561768, acc 0.28999999165534973\n",
      "Epoch 6, iter 251, loss 1.996170997619629, acc 0.18000000715255737\n",
      "Epoch 6, iter 252, loss 1.901892066001892, acc 0.23000000417232513\n",
      "Epoch 6, iter 253, loss 2.011697769165039, acc 0.15000000596046448\n",
      "Epoch 6, iter 254, loss 1.925889253616333, acc 0.20000000298023224\n",
      "Epoch 6, iter 255, loss 1.9251517057418823, acc 0.18000000715255737\n",
      "Epoch 6, iter 256, loss 1.9278175830841064, acc 0.23000000417232513\n",
      "Epoch 6, iter 257, loss 1.945635199546814, acc 0.17000000178813934\n",
      "Epoch 6, iter 258, loss 2.013524293899536, acc 0.23000000417232513\n",
      "Epoch 6, iter 259, loss 1.9701964855194092, acc 0.23999999463558197\n",
      "Epoch 6, iter 260, loss 1.968440055847168, acc 0.18000000715255737\n",
      "Epoch 6, iter 261, loss 1.8783705234527588, acc 0.23000000417232513\n",
      "Epoch 6, iter 262, loss 2.0683679580688477, acc 0.1599999964237213\n",
      "Epoch 6, iter 263, loss 1.9420111179351807, acc 0.23999999463558197\n",
      "Epoch 6, iter 264, loss 2.0234715938568115, acc 0.27000001072883606\n",
      "Epoch 6, iter 265, loss 2.093080997467041, acc 0.23999999463558197\n",
      "Epoch 6, iter 266, loss 1.989843487739563, acc 0.17000000178813934\n",
      "Epoch 6, iter 267, loss 1.9688029289245605, acc 0.2800000011920929\n",
      "Epoch 6, iter 268, loss 1.9961994886398315, acc 0.12999999523162842\n",
      "Epoch 6, iter 269, loss 2.146482467651367, acc 0.1899999976158142\n",
      "Epoch 6, iter 270, loss 2.0990474224090576, acc 0.1599999964237213\n",
      "Epoch 6, iter 271, loss 2.115752935409546, acc 0.20000000298023224\n",
      "Epoch 6, iter 272, loss 1.9914495944976807, acc 0.20999999344348907\n",
      "Epoch 6, iter 273, loss 2.044774055480957, acc 0.20000000298023224\n",
      "Epoch 6, iter 274, loss 2.0554487705230713, acc 0.20999999344348907\n",
      "Epoch 6, iter 275, loss 2.024557113647461, acc 0.18000000715255737\n",
      "Epoch 6, iter 276, loss 1.9313387870788574, acc 0.2199999988079071\n",
      "Epoch 6, iter 277, loss 2.01023268699646, acc 0.2199999988079071\n",
      "Epoch 6, iter 278, loss 1.996849536895752, acc 0.18000000715255737\n",
      "Epoch 6, iter 279, loss 1.9901437759399414, acc 0.2800000011920929\n",
      "Epoch 6, iter 280, loss 2.108579397201538, acc 0.1899999976158142\n",
      "Epoch 6, iter 281, loss 1.9836407899856567, acc 0.30000001192092896\n",
      "Epoch 6, iter 282, loss 2.0647857189178467, acc 0.1899999976158142\n",
      "Epoch 6, iter 283, loss 2.0283546447753906, acc 0.17000000178813934\n",
      "Epoch 6, iter 284, loss 2.044825315475464, acc 0.27000001072883606\n",
      "Epoch 6, iter 285, loss 1.9838628768920898, acc 0.20000000298023224\n",
      "Epoch 6, iter 286, loss 1.9464894533157349, acc 0.23000000417232513\n",
      "Epoch 6, iter 287, loss 2.0089762210845947, acc 0.20000000298023224\n",
      "Epoch 6, iter 288, loss 1.9168353080749512, acc 0.2199999988079071\n",
      "Epoch 6, iter 289, loss 1.924696683883667, acc 0.23999999463558197\n",
      "Epoch 6, iter 290, loss 1.9441015720367432, acc 0.23000000417232513\n",
      "Epoch 6, iter 291, loss 1.9888396263122559, acc 0.20999999344348907\n",
      "Epoch 6, iter 292, loss 1.9760130643844604, acc 0.25999999046325684\n",
      "Epoch 6, iter 293, loss 1.979555606842041, acc 0.20000000298023224\n",
      "Epoch 6, iter 294, loss 2.02836275100708, acc 0.1599999964237213\n",
      "Epoch 6, iter 295, loss 1.9277772903442383, acc 0.20999999344348907\n",
      "Epoch 6, iter 296, loss 1.9912326335906982, acc 0.20999999344348907\n",
      "Epoch 6, iter 297, loss 1.9499061107635498, acc 0.23999999463558197\n",
      "Epoch 6, iter 298, loss 1.8986725807189941, acc 0.25\n",
      "Epoch 6, iter 299, loss 2.0266811847686768, acc 0.11999999731779099\n",
      "Epoch 6, iter 300, loss 1.9623621702194214, acc 0.18000000715255737\n",
      "Epoch 6, iter 301, loss 1.986414909362793, acc 0.20999999344348907\n",
      "Epoch 6, iter 302, loss 1.9457629919052124, acc 0.2800000011920929\n",
      "Epoch 6, iter 303, loss 1.9583073854446411, acc 0.20000000298023224\n",
      "Epoch 6, iter 304, loss 2.011852502822876, acc 0.17000000178813934\n",
      "Epoch 6, iter 305, loss 2.084836959838867, acc 0.1599999964237213\n",
      "Epoch 6, iter 306, loss 2.0164992809295654, acc 0.20999999344348907\n",
      "Epoch 6, iter 307, loss 1.9820536375045776, acc 0.25\n",
      "Epoch 6, iter 308, loss 2.078049659729004, acc 0.23000000417232513\n",
      "Epoch 6, iter 309, loss 1.9247465133666992, acc 0.20000000298023224\n",
      "Epoch 6, iter 310, loss 2.066053867340088, acc 0.18000000715255737\n",
      "Epoch 6, iter 311, loss 1.9778506755828857, acc 0.23000000417232513\n",
      "Epoch 6, iter 312, loss 1.9851819276809692, acc 0.27000001072883606\n",
      "Epoch 6, iter 313, loss 2.1329424381256104, acc 0.11999999731779099\n",
      "Epoch 6, iter 314, loss 2.0638513565063477, acc 0.25999999046325684\n",
      "Epoch 6, iter 315, loss 1.921647071838379, acc 0.25\n",
      "Epoch 6, iter 316, loss 2.035686492919922, acc 0.12999999523162842\n",
      "Epoch 6, iter 317, loss 2.077681541442871, acc 0.20999999344348907\n",
      "Epoch 6, iter 318, loss 1.9563038349151611, acc 0.2199999988079071\n",
      "Epoch 6, iter 319, loss 2.083444595336914, acc 0.18000000715255737\n",
      "Epoch 6, iter 320, loss 1.9801994562149048, acc 0.20000000298023224\n",
      "Epoch 6, iter 321, loss 2.031128406524658, acc 0.1899999976158142\n",
      "Epoch 6, iter 322, loss 1.9295071363449097, acc 0.23999999463558197\n",
      "Epoch 6, iter 323, loss 2.0145511627197266, acc 0.20000000298023224\n",
      "Epoch 6, iter 324, loss 1.9338865280151367, acc 0.25\n",
      "Epoch 6, iter 325, loss 1.9374624490737915, acc 0.25\n",
      "Epoch 6, iter 326, loss 1.9692693948745728, acc 0.20999999344348907\n",
      "Epoch 6, iter 327, loss 1.9793918132781982, acc 0.17000000178813934\n",
      "Epoch 6, iter 328, loss 1.9223045110702515, acc 0.27000001072883606\n",
      "Epoch 6, iter 329, loss 1.9565839767456055, acc 0.2199999988079071\n",
      "Epoch 6, iter 330, loss 2.043083429336548, acc 0.20999999344348907\n",
      "Epoch 6, iter 331, loss 1.9287567138671875, acc 0.1899999976158142\n",
      "Epoch 6, iter 332, loss 2.0108535289764404, acc 0.23000000417232513\n",
      "Epoch 6, iter 333, loss 1.9717984199523926, acc 0.23000000417232513\n",
      "Epoch 6, iter 334, loss 1.9601428508758545, acc 0.2199999988079071\n",
      "Epoch 6, iter 335, loss 1.8808999061584473, acc 0.25\n",
      "Epoch 6, iter 336, loss 1.9910720586776733, acc 0.23999999463558197\n",
      "Epoch 6, iter 337, loss 1.968258023262024, acc 0.20999999344348907\n",
      "Epoch 6, iter 338, loss 2.069667339324951, acc 0.2199999988079071\n",
      "Epoch 6, iter 339, loss 1.9567161798477173, acc 0.23000000417232513\n",
      "Epoch 6, iter 340, loss 1.9818758964538574, acc 0.23000000417232513\n",
      "Epoch 6, iter 341, loss 1.9511196613311768, acc 0.25\n",
      "Epoch 6, iter 342, loss 2.022934675216675, acc 0.23000000417232513\n",
      "Epoch 6, iter 343, loss 1.9649381637573242, acc 0.1899999976158142\n",
      "Epoch 6, iter 344, loss 1.867823839187622, acc 0.23999999463558197\n",
      "Epoch 6, iter 345, loss 2.0104634761810303, acc 0.18000000715255737\n",
      "Epoch 6, iter 346, loss 1.9266961812973022, acc 0.25\n",
      "Epoch 6, iter 347, loss 2.0063135623931885, acc 0.20000000298023224\n",
      "Epoch 6, iter 348, loss 1.8887158632278442, acc 0.33000001311302185\n",
      "Epoch 6, iter 349, loss 1.898972511291504, acc 0.25999999046325684\n",
      "Epoch 6, iter 350, loss 1.9787341356277466, acc 0.25\n",
      "Epoch 6, iter 351, loss 1.9246554374694824, acc 0.15000000596046448\n",
      "Epoch 6, iter 352, loss 1.9453045129776, acc 0.18000000715255737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 353, loss 1.8760560750961304, acc 0.25999999046325684\n",
      "Epoch 6, iter 354, loss 1.9021300077438354, acc 0.25\n",
      "Epoch 6, iter 355, loss 1.9128085374832153, acc 0.20999999344348907\n",
      "Epoch 6, iter 356, loss 1.942359447479248, acc 0.25\n",
      "Epoch 6, iter 357, loss 1.8890907764434814, acc 0.2199999988079071\n",
      "Epoch 6, iter 358, loss 2.058234453201294, acc 0.1899999976158142\n",
      "Epoch 6, iter 359, loss 1.9238284826278687, acc 0.12999999523162842\n",
      "Epoch 6, iter 360, loss 1.938169002532959, acc 0.23000000417232513\n",
      "Epoch 6, iter 361, loss 1.9487212896347046, acc 0.20000000298023224\n",
      "Epoch 6, iter 362, loss 1.9766920804977417, acc 0.17000000178813934\n",
      "Epoch 6, iter 363, loss 1.9296166896820068, acc 0.28999999165534973\n",
      "Epoch 6, iter 364, loss 1.9492706060409546, acc 0.12999999523162842\n",
      "Epoch 6, iter 365, loss 1.9185972213745117, acc 0.20999999344348907\n",
      "Epoch 6, iter 366, loss 1.8975307941436768, acc 0.25\n",
      "Epoch 6, iter 367, loss 1.8677892684936523, acc 0.23000000417232513\n",
      "Epoch 6, iter 368, loss 1.9658359289169312, acc 0.23000000417232513\n",
      "Epoch 6, iter 369, loss 1.838884711265564, acc 0.23999999463558197\n",
      "Epoch 6, iter 370, loss 1.8224908113479614, acc 0.2199999988079071\n",
      "Epoch 6, iter 371, loss 1.9951342344284058, acc 0.23999999463558197\n",
      "Epoch 6, iter 372, loss 1.9037672281265259, acc 0.23000000417232513\n",
      "Epoch 6, iter 373, loss 1.9648436307907104, acc 0.17000000178813934\n",
      "Epoch 6, iter 374, loss 1.969871163368225, acc 0.23999999463558197\n",
      "Epoch 6, iter 375, loss 1.9343987703323364, acc 0.3100000023841858\n",
      "Epoch 6, iter 376, loss 1.9757291078567505, acc 0.15000000596046448\n",
      "Epoch 6, iter 377, loss 1.9976012706756592, acc 0.27000001072883606\n",
      "Epoch 6, iter 378, loss 1.957023024559021, acc 0.25999999046325684\n",
      "Epoch 6, iter 379, loss 2.0148098468780518, acc 0.18000000715255737\n",
      "Epoch 6, iter 380, loss 1.9688611030578613, acc 0.17000000178813934\n",
      "Epoch 6, iter 381, loss 2.019956111907959, acc 0.1599999964237213\n",
      "Epoch 6, iter 382, loss 1.9313910007476807, acc 0.25\n",
      "Epoch 6, iter 383, loss 1.946643352508545, acc 0.2800000011920929\n",
      "Epoch 6, iter 384, loss 1.9486851692199707, acc 0.18000000715255737\n",
      "Epoch 6, iter 385, loss 1.8632258176803589, acc 0.23999999463558197\n",
      "Epoch 6, iter 386, loss 1.9533555507659912, acc 0.20999999344348907\n",
      "Epoch 6, iter 387, loss 1.952437162399292, acc 0.23000000417232513\n",
      "Epoch 6, iter 388, loss 1.9167991876602173, acc 0.20000000298023224\n",
      "Epoch 6, iter 389, loss 1.9576764106750488, acc 0.20999999344348907\n",
      "Epoch 6, iter 390, loss 2.071314811706543, acc 0.10000000149011612\n",
      "Epoch 6, iter 391, loss 1.9072877168655396, acc 0.1899999976158142\n",
      "Epoch 6, iter 392, loss 1.9538426399230957, acc 0.18000000715255737\n",
      "Epoch 6, iter 393, loss 2.0444998741149902, acc 0.15000000596046448\n",
      "Epoch 6, iter 394, loss 1.9526114463806152, acc 0.23999999463558197\n",
      "Epoch 6, iter 395, loss 1.9419254064559937, acc 0.25999999046325684\n",
      "Epoch 6, iter 396, loss 1.9882190227508545, acc 0.1599999964237213\n",
      "Epoch 6, iter 397, loss 1.9666054248809814, acc 0.1899999976158142\n",
      "Epoch 6, iter 398, loss 2.048553228378296, acc 0.12999999523162842\n",
      "Epoch 6, iter 399, loss 1.994209885597229, acc 0.23999999463558197\n",
      "Epoch 6, iter 400, loss 1.8908740282058716, acc 0.28999999165534973\n",
      "Epoch 6, iter 401, loss 1.9631965160369873, acc 0.20000000298023224\n",
      "Epoch 6, iter 402, loss 1.990492343902588, acc 0.20999999344348907\n",
      "Epoch 6, iter 403, loss 2.042695999145508, acc 0.1899999976158142\n",
      "Epoch 6, iter 404, loss 2.009631872177124, acc 0.17000000178813934\n",
      "Epoch 6, iter 405, loss 1.983840823173523, acc 0.23000000417232513\n",
      "Epoch 6, iter 406, loss 2.018627643585205, acc 0.11999999731779099\n",
      "Epoch 6, iter 407, loss 1.9703025817871094, acc 0.14000000059604645\n",
      "Epoch 6, iter 408, loss 2.0114777088165283, acc 0.23999999463558197\n",
      "Epoch 6, iter 409, loss 1.9852616786956787, acc 0.23000000417232513\n",
      "Epoch 6, iter 410, loss 1.9560081958770752, acc 0.17000000178813934\n",
      "Epoch 6, iter 411, loss 1.9171669483184814, acc 0.28999999165534973\n",
      "Epoch 6, iter 412, loss 1.960060715675354, acc 0.25999999046325684\n",
      "Epoch 6, iter 413, loss 2.087740182876587, acc 0.14000000059604645\n",
      "Epoch 6, iter 414, loss 1.9783194065093994, acc 0.15000000596046448\n",
      "Epoch 6, iter 415, loss 1.9588210582733154, acc 0.20000000298023224\n",
      "Epoch 6, iter 416, loss 1.9607235193252563, acc 0.20999999344348907\n",
      "Epoch 6, iter 417, loss 1.8337668180465698, acc 0.30000001192092896\n",
      "Epoch 6, iter 418, loss 1.9742792844772339, acc 0.15000000596046448\n",
      "Epoch 6, iter 419, loss 1.9291844367980957, acc 0.2800000011920929\n",
      "Epoch 6, iter 420, loss 1.943607211112976, acc 0.23000000417232513\n",
      "Epoch 7, iter 1, loss 1.8998483419418335, acc 0.23000000417232513\n",
      "Epoch 7, iter 2, loss 1.9859696626663208, acc 0.1899999976158142\n",
      "Epoch 7, iter 3, loss 1.9060163497924805, acc 0.1899999976158142\n",
      "Epoch 7, iter 4, loss 1.983270287513733, acc 0.17000000178813934\n",
      "Epoch 7, iter 5, loss 1.9691489934921265, acc 0.18000000715255737\n",
      "Epoch 7, iter 6, loss 2.0027670860290527, acc 0.17000000178813934\n",
      "Epoch 7, iter 7, loss 1.9719816446304321, acc 0.25\n",
      "Epoch 7, iter 8, loss 1.974988579750061, acc 0.18000000715255737\n",
      "Epoch 7, iter 9, loss 1.9817490577697754, acc 0.20999999344348907\n",
      "Epoch 7, iter 10, loss 1.9589325189590454, acc 0.1899999976158142\n",
      "Epoch 7, iter 11, loss 1.9646557569503784, acc 0.2199999988079071\n",
      "Epoch 7, iter 12, loss 1.9169219732284546, acc 0.20000000298023224\n",
      "Epoch 7, iter 13, loss 1.909268856048584, acc 0.18000000715255737\n",
      "Epoch 7, iter 14, loss 1.9931226968765259, acc 0.2199999988079071\n",
      "Epoch 7, iter 15, loss 1.8182835578918457, acc 0.2800000011920929\n",
      "Epoch 7, iter 16, loss 1.914207100868225, acc 0.20999999344348907\n",
      "Epoch 7, iter 17, loss 1.9184666872024536, acc 0.15000000596046448\n",
      "Epoch 7, iter 18, loss 1.9638009071350098, acc 0.20000000298023224\n",
      "Epoch 7, iter 19, loss 2.025622606277466, acc 0.17000000178813934\n",
      "Epoch 7, iter 20, loss 1.9739172458648682, acc 0.23999999463558197\n",
      "Epoch 7, iter 21, loss 1.9443180561065674, acc 0.23000000417232513\n",
      "Epoch 7, iter 22, loss 1.9376192092895508, acc 0.18000000715255737\n",
      "Epoch 7, iter 23, loss 1.96916925907135, acc 0.27000001072883606\n",
      "Epoch 7, iter 24, loss 1.9400891065597534, acc 0.18000000715255737\n",
      "Epoch 7, iter 25, loss 1.985603928565979, acc 0.20999999344348907\n",
      "Epoch 7, iter 26, loss 2.0058252811431885, acc 0.20000000298023224\n",
      "Epoch 7, iter 27, loss 1.9676032066345215, acc 0.28999999165534973\n",
      "Epoch 7, iter 28, loss 1.9421380758285522, acc 0.27000001072883606\n",
      "Epoch 7, iter 29, loss 1.9468971490859985, acc 0.23999999463558197\n",
      "Epoch 7, iter 30, loss 2.118847131729126, acc 0.20000000298023224\n",
      "Epoch 7, iter 31, loss 2.063089370727539, acc 0.11999999731779099\n",
      "Epoch 7, iter 32, loss 1.9973945617675781, acc 0.18000000715255737\n",
      "Epoch 7, iter 33, loss 1.9700689315795898, acc 0.25\n",
      "Epoch 7, iter 34, loss 1.9715931415557861, acc 0.20000000298023224\n",
      "Epoch 7, iter 35, loss 1.9186686277389526, acc 0.23000000417232513\n",
      "Epoch 7, iter 36, loss 1.8890657424926758, acc 0.1899999976158142\n",
      "Epoch 7, iter 37, loss 1.9302334785461426, acc 0.1899999976158142\n",
      "Epoch 7, iter 38, loss 2.0279736518859863, acc 0.25\n",
      "Epoch 7, iter 39, loss 1.969411015510559, acc 0.23000000417232513\n",
      "Epoch 7, iter 40, loss 1.9586673974990845, acc 0.2199999988079071\n",
      "Epoch 7, iter 41, loss 2.0161643028259277, acc 0.15000000596046448\n",
      "Epoch 7, iter 42, loss 1.954207181930542, acc 0.1599999964237213\n",
      "Epoch 7, iter 43, loss 1.9174282550811768, acc 0.20999999344348907\n",
      "Epoch 7, iter 44, loss 1.863413691520691, acc 0.20000000298023224\n",
      "Epoch 7, iter 45, loss 1.9905264377593994, acc 0.20999999344348907\n",
      "Epoch 7, iter 46, loss 1.9536268711090088, acc 0.28999999165534973\n",
      "Epoch 7, iter 47, loss 2.0009474754333496, acc 0.1599999964237213\n",
      "Epoch 7, iter 48, loss 1.8717094659805298, acc 0.1899999976158142\n",
      "Epoch 7, iter 49, loss 1.9199671745300293, acc 0.2199999988079071\n",
      "Epoch 7, iter 50, loss 1.9827018976211548, acc 0.23999999463558197\n",
      "Epoch 7, iter 51, loss 1.9466078281402588, acc 0.25\n",
      "Epoch 7, iter 52, loss 2.061729669570923, acc 0.20000000298023224\n",
      "Epoch 7, iter 53, loss 1.8702985048294067, acc 0.3400000035762787\n",
      "Epoch 7, iter 54, loss 2.01686954498291, acc 0.14000000059604645\n",
      "Epoch 7, iter 55, loss 2.0431621074676514, acc 0.10999999940395355\n",
      "Epoch 7, iter 56, loss 1.9454927444458008, acc 0.18000000715255737\n",
      "Epoch 7, iter 57, loss 2.0010862350463867, acc 0.1899999976158142\n",
      "Epoch 7, iter 58, loss 1.9893195629119873, acc 0.1899999976158142\n",
      "Epoch 7, iter 59, loss 1.971914529800415, acc 0.23999999463558197\n",
      "Epoch 7, iter 60, loss 1.9367560148239136, acc 0.25\n",
      "Epoch 7, iter 61, loss 2.0035853385925293, acc 0.18000000715255737\n",
      "Epoch 7, iter 62, loss 1.9140342473983765, acc 0.20999999344348907\n",
      "Epoch 7, iter 63, loss 2.018303155899048, acc 0.23999999463558197\n",
      "Epoch 7, iter 64, loss 1.9067312479019165, acc 0.2199999988079071\n",
      "Epoch 7, iter 65, loss 1.9171251058578491, acc 0.2800000011920929\n",
      "Epoch 7, iter 66, loss 1.9098396301269531, acc 0.20999999344348907\n",
      "Epoch 7, iter 67, loss 2.0750021934509277, acc 0.18000000715255737\n",
      "Epoch 7, iter 68, loss 1.8728222846984863, acc 0.3199999928474426\n",
      "Epoch 7, iter 69, loss 2.0589373111724854, acc 0.18000000715255737\n",
      "Epoch 7, iter 70, loss 1.887107491493225, acc 0.2800000011920929\n",
      "Epoch 7, iter 71, loss 1.9035422801971436, acc 0.1899999976158142\n",
      "Epoch 7, iter 72, loss 1.9382247924804688, acc 0.14000000059604645\n",
      "Epoch 7, iter 73, loss 1.919959306716919, acc 0.25\n",
      "Epoch 7, iter 74, loss 1.9923317432403564, acc 0.20999999344348907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 75, loss 2.004544496536255, acc 0.12999999523162842\n",
      "Epoch 7, iter 76, loss 2.091007709503174, acc 0.20000000298023224\n",
      "Epoch 7, iter 77, loss 2.119166612625122, acc 0.1599999964237213\n",
      "Epoch 7, iter 78, loss 1.9667493104934692, acc 0.28999999165534973\n",
      "Epoch 7, iter 79, loss 1.9044102430343628, acc 0.23000000417232513\n",
      "Epoch 7, iter 80, loss 1.9700578451156616, acc 0.20000000298023224\n",
      "Epoch 7, iter 81, loss 1.9464529752731323, acc 0.17000000178813934\n",
      "Epoch 7, iter 82, loss 2.0027594566345215, acc 0.1599999964237213\n",
      "Epoch 7, iter 83, loss 1.8945611715316772, acc 0.2199999988079071\n",
      "Epoch 7, iter 84, loss 1.9365365505218506, acc 0.15000000596046448\n",
      "Epoch 7, iter 85, loss 1.9474443197250366, acc 0.1599999964237213\n",
      "Epoch 7, iter 86, loss 1.8505847454071045, acc 0.20999999344348907\n",
      "Epoch 7, iter 87, loss 2.0344715118408203, acc 0.25\n",
      "Epoch 7, iter 88, loss 1.9216712713241577, acc 0.25999999046325684\n",
      "Epoch 7, iter 89, loss 1.956802248954773, acc 0.20000000298023224\n",
      "Epoch 7, iter 90, loss 1.9395524263381958, acc 0.1899999976158142\n",
      "Epoch 7, iter 91, loss 1.9580566883087158, acc 0.1899999976158142\n",
      "Epoch 7, iter 92, loss 1.9857171773910522, acc 0.20999999344348907\n",
      "Epoch 7, iter 93, loss 1.9636483192443848, acc 0.2199999988079071\n",
      "Epoch 7, iter 94, loss 1.9790794849395752, acc 0.1599999964237213\n",
      "Epoch 7, iter 95, loss 1.952988862991333, acc 0.20999999344348907\n",
      "Epoch 7, iter 96, loss 2.004598379135132, acc 0.23999999463558197\n",
      "Epoch 7, iter 97, loss 1.969632863998413, acc 0.11999999731779099\n",
      "Epoch 7, iter 98, loss 1.9605927467346191, acc 0.17000000178813934\n",
      "Epoch 7, iter 99, loss 1.9917328357696533, acc 0.2199999988079071\n",
      "Epoch 7, iter 100, loss 1.9912338256835938, acc 0.25\n",
      "Epoch 7, iter 101, loss 1.9224575757980347, acc 0.2199999988079071\n",
      "Epoch 7, iter 102, loss 1.965497612953186, acc 0.23999999463558197\n",
      "Epoch 7, iter 103, loss 1.938480019569397, acc 0.27000001072883606\n",
      "Epoch 7, iter 104, loss 1.8672603368759155, acc 0.28999999165534973\n",
      "Epoch 7, iter 105, loss 1.8466885089874268, acc 0.1899999976158142\n",
      "Epoch 7, iter 106, loss 1.9681882858276367, acc 0.25999999046325684\n",
      "Epoch 7, iter 107, loss 1.9788165092468262, acc 0.23000000417232513\n",
      "Epoch 7, iter 108, loss 1.9744740724563599, acc 0.12999999523162842\n",
      "Epoch 7, iter 109, loss 1.96883225440979, acc 0.2199999988079071\n",
      "Epoch 7, iter 110, loss 1.9854741096496582, acc 0.14000000059604645\n",
      "Epoch 7, iter 111, loss 1.902969241142273, acc 0.18000000715255737\n",
      "Epoch 7, iter 112, loss 1.9486808776855469, acc 0.25999999046325684\n",
      "Epoch 7, iter 113, loss 1.9319919347763062, acc 0.25\n",
      "Epoch 7, iter 114, loss 1.9892524480819702, acc 0.20999999344348907\n",
      "Epoch 7, iter 115, loss 1.8817416429519653, acc 0.25999999046325684\n",
      "Epoch 7, iter 116, loss 1.9616286754608154, acc 0.20999999344348907\n",
      "Epoch 7, iter 117, loss 2.0053153038024902, acc 0.2199999988079071\n",
      "Epoch 7, iter 118, loss 1.9931222200393677, acc 0.14000000059604645\n",
      "Epoch 7, iter 119, loss 1.9559662342071533, acc 0.25999999046325684\n",
      "Epoch 7, iter 120, loss 2.0056302547454834, acc 0.23000000417232513\n",
      "Epoch 7, iter 121, loss 1.9834834337234497, acc 0.23999999463558197\n",
      "Epoch 7, iter 122, loss 1.9416966438293457, acc 0.33000001311302185\n",
      "Epoch 7, iter 123, loss 1.9406296014785767, acc 0.14000000059604645\n",
      "Epoch 7, iter 124, loss 1.980604887008667, acc 0.23000000417232513\n",
      "Epoch 7, iter 125, loss 1.9925352334976196, acc 0.1899999976158142\n",
      "Epoch 7, iter 126, loss 1.8983967304229736, acc 0.20000000298023224\n",
      "Epoch 7, iter 127, loss 1.9321633577346802, acc 0.23999999463558197\n",
      "Epoch 7, iter 128, loss 1.9798084497451782, acc 0.20000000298023224\n",
      "Epoch 7, iter 129, loss 2.036503553390503, acc 0.20000000298023224\n",
      "Epoch 7, iter 130, loss 2.0510871410369873, acc 0.20999999344348907\n",
      "Epoch 7, iter 131, loss 2.0526115894317627, acc 0.23000000417232513\n",
      "Epoch 7, iter 132, loss 1.9493463039398193, acc 0.25\n",
      "Epoch 7, iter 133, loss 1.957614779472351, acc 0.2199999988079071\n",
      "Epoch 7, iter 134, loss 1.9500482082366943, acc 0.1599999964237213\n",
      "Epoch 7, iter 135, loss 2.0304672718048096, acc 0.27000001072883606\n",
      "Epoch 7, iter 136, loss 1.8264377117156982, acc 0.30000001192092896\n",
      "Epoch 7, iter 137, loss 1.9095953702926636, acc 0.25\n",
      "Epoch 7, iter 138, loss 1.8993582725524902, acc 0.23000000417232513\n",
      "Epoch 7, iter 139, loss 1.9071552753448486, acc 0.20000000298023224\n",
      "Epoch 7, iter 140, loss 1.9538705348968506, acc 0.18000000715255737\n",
      "Epoch 7, iter 141, loss 2.0195934772491455, acc 0.1899999976158142\n",
      "Epoch 7, iter 142, loss 2.0763535499572754, acc 0.14000000059604645\n",
      "Epoch 7, iter 143, loss 2.074955940246582, acc 0.20000000298023224\n",
      "Epoch 7, iter 144, loss 2.0933539867401123, acc 0.15000000596046448\n",
      "Epoch 7, iter 145, loss 2.078871488571167, acc 0.20999999344348907\n",
      "Epoch 7, iter 146, loss 2.169090747833252, acc 0.20000000298023224\n",
      "Epoch 7, iter 147, loss 1.9920356273651123, acc 0.23999999463558197\n",
      "Epoch 7, iter 148, loss 1.983433485031128, acc 0.2199999988079071\n",
      "Epoch 7, iter 149, loss 2.0146634578704834, acc 0.2199999988079071\n",
      "Epoch 7, iter 150, loss 1.9644761085510254, acc 0.23999999463558197\n",
      "Epoch 7, iter 151, loss 1.8866219520568848, acc 0.25999999046325684\n",
      "Epoch 7, iter 152, loss 2.019848585128784, acc 0.1899999976158142\n",
      "Epoch 7, iter 153, loss 2.0884413719177246, acc 0.23999999463558197\n",
      "Epoch 7, iter 154, loss 2.0111865997314453, acc 0.2199999988079071\n",
      "Epoch 7, iter 155, loss 2.037048101425171, acc 0.23000000417232513\n",
      "Epoch 7, iter 156, loss 1.977997899055481, acc 0.23000000417232513\n",
      "Epoch 7, iter 157, loss 1.9924964904785156, acc 0.17000000178813934\n",
      "Epoch 7, iter 158, loss 2.0435492992401123, acc 0.17000000178813934\n",
      "Epoch 7, iter 159, loss 1.9910120964050293, acc 0.1899999976158142\n",
      "Epoch 7, iter 160, loss 2.0367980003356934, acc 0.17000000178813934\n",
      "Epoch 7, iter 161, loss 1.9780277013778687, acc 0.20000000298023224\n",
      "Epoch 7, iter 162, loss 2.0224480628967285, acc 0.27000001072883606\n",
      "Epoch 7, iter 163, loss 2.098738670349121, acc 0.18000000715255737\n",
      "Epoch 7, iter 164, loss 2.056821346282959, acc 0.18000000715255737\n",
      "Epoch 7, iter 165, loss 2.085675001144409, acc 0.23000000417232513\n",
      "Epoch 7, iter 166, loss 1.9984238147735596, acc 0.23999999463558197\n",
      "Epoch 7, iter 167, loss 2.0484530925750732, acc 0.20000000298023224\n",
      "Epoch 7, iter 168, loss 2.1015748977661133, acc 0.20000000298023224\n",
      "Epoch 7, iter 169, loss 1.985215663909912, acc 0.1899999976158142\n",
      "Epoch 7, iter 170, loss 1.95639967918396, acc 0.12999999523162842\n",
      "Epoch 7, iter 171, loss 2.099541425704956, acc 0.1599999964237213\n",
      "Epoch 7, iter 172, loss 2.0074257850646973, acc 0.17000000178813934\n",
      "Epoch 7, iter 173, loss 1.9499621391296387, acc 0.18000000715255737\n",
      "Epoch 7, iter 174, loss 2.0054008960723877, acc 0.17000000178813934\n",
      "Epoch 7, iter 175, loss 1.9331071376800537, acc 0.2199999988079071\n",
      "Epoch 7, iter 176, loss 2.0893964767456055, acc 0.09000000357627869\n",
      "Epoch 7, iter 177, loss 2.1007981300354004, acc 0.23000000417232513\n",
      "Epoch 7, iter 178, loss 2.0893678665161133, acc 0.1899999976158142\n",
      "Epoch 7, iter 179, loss 1.9368537664413452, acc 0.18000000715255737\n",
      "Epoch 7, iter 180, loss 1.9009252786636353, acc 0.23000000417232513\n",
      "Epoch 7, iter 181, loss 1.8532702922821045, acc 0.23000000417232513\n",
      "Epoch 7, iter 182, loss 1.9704031944274902, acc 0.23999999463558197\n",
      "Epoch 7, iter 183, loss 2.0237646102905273, acc 0.18000000715255737\n",
      "Epoch 7, iter 184, loss 2.032289505004883, acc 0.17000000178813934\n",
      "Epoch 7, iter 185, loss 1.922613263130188, acc 0.20000000298023224\n",
      "Epoch 7, iter 186, loss 2.011763572692871, acc 0.20999999344348907\n",
      "Epoch 7, iter 187, loss 1.9122830629348755, acc 0.20999999344348907\n",
      "Epoch 7, iter 188, loss 2.022778034210205, acc 0.23000000417232513\n",
      "Epoch 7, iter 189, loss 2.0588152408599854, acc 0.10999999940395355\n",
      "Epoch 7, iter 190, loss 1.9041954278945923, acc 0.23000000417232513\n",
      "Epoch 7, iter 191, loss 2.009800672531128, acc 0.20000000298023224\n",
      "Epoch 7, iter 192, loss 2.0071630477905273, acc 0.23000000417232513\n",
      "Epoch 7, iter 193, loss 1.9101191759109497, acc 0.23000000417232513\n",
      "Epoch 7, iter 194, loss 1.8762480020523071, acc 0.18000000715255737\n",
      "Epoch 7, iter 195, loss 1.9608150720596313, acc 0.23000000417232513\n",
      "Epoch 7, iter 196, loss 2.0559756755828857, acc 0.18000000715255737\n",
      "Epoch 7, iter 197, loss 1.946004033088684, acc 0.23000000417232513\n",
      "Epoch 7, iter 198, loss 1.8692113161087036, acc 0.3100000023841858\n",
      "Epoch 7, iter 199, loss 1.9978641271591187, acc 0.20000000298023224\n",
      "Epoch 7, iter 200, loss 2.0370023250579834, acc 0.25999999046325684\n",
      "Epoch 7, iter 201, loss 1.9470429420471191, acc 0.23999999463558197\n",
      "Epoch 7, iter 202, loss 2.0077061653137207, acc 0.17000000178813934\n",
      "Epoch 7, iter 203, loss 1.9698994159698486, acc 0.11999999731779099\n",
      "Epoch 7, iter 204, loss 1.9874615669250488, acc 0.25\n",
      "Epoch 7, iter 205, loss 1.88739812374115, acc 0.23999999463558197\n",
      "Epoch 7, iter 206, loss 1.9766120910644531, acc 0.20999999344348907\n",
      "Epoch 7, iter 207, loss 1.9303375482559204, acc 0.1599999964237213\n",
      "Epoch 7, iter 208, loss 1.9432867765426636, acc 0.18000000715255737\n",
      "Epoch 7, iter 209, loss 1.9648247957229614, acc 0.18000000715255737\n",
      "Epoch 7, iter 210, loss 2.0954205989837646, acc 0.1899999976158142\n",
      "Epoch 7, iter 211, loss 2.026306629180908, acc 0.20999999344348907\n",
      "Epoch 7, iter 212, loss 1.924699068069458, acc 0.1599999964237213\n",
      "Epoch 7, iter 213, loss 1.999910831451416, acc 0.1899999976158142\n",
      "Epoch 7, iter 214, loss 2.033311128616333, acc 0.1899999976158142\n",
      "Epoch 7, iter 215, loss 1.964619755744934, acc 0.14000000059604645\n",
      "Epoch 7, iter 216, loss 2.08408522605896, acc 0.1599999964237213\n",
      "Epoch 7, iter 217, loss 1.9243323802947998, acc 0.2800000011920929\n",
      "Epoch 7, iter 218, loss 2.1082253456115723, acc 0.18000000715255737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 219, loss 2.0525970458984375, acc 0.17000000178813934\n",
      "Epoch 7, iter 220, loss 1.9048657417297363, acc 0.23000000417232513\n",
      "Epoch 7, iter 221, loss 1.9352521896362305, acc 0.18000000715255737\n",
      "Epoch 7, iter 222, loss 1.9192184209823608, acc 0.20999999344348907\n",
      "Epoch 7, iter 223, loss 1.92283296585083, acc 0.27000001072883606\n",
      "Epoch 7, iter 224, loss 1.9196877479553223, acc 0.23000000417232513\n",
      "Epoch 7, iter 225, loss 1.9242770671844482, acc 0.2199999988079071\n",
      "Epoch 7, iter 226, loss 2.001278877258301, acc 0.23000000417232513\n",
      "Epoch 7, iter 227, loss 1.9874800443649292, acc 0.23999999463558197\n",
      "Epoch 7, iter 228, loss 2.0059762001037598, acc 0.20000000298023224\n",
      "Epoch 7, iter 229, loss 1.8629286289215088, acc 0.2199999988079071\n",
      "Epoch 7, iter 230, loss 2.0005993843078613, acc 0.25\n",
      "Epoch 7, iter 231, loss 2.0286142826080322, acc 0.2199999988079071\n",
      "Epoch 7, iter 232, loss 1.9965484142303467, acc 0.15000000596046448\n",
      "Epoch 7, iter 233, loss 1.9975405931472778, acc 0.23999999463558197\n",
      "Epoch 7, iter 234, loss 1.9170399904251099, acc 0.2800000011920929\n",
      "Epoch 7, iter 235, loss 1.8983588218688965, acc 0.2199999988079071\n",
      "Epoch 7, iter 236, loss 2.0043981075286865, acc 0.17000000178813934\n",
      "Epoch 7, iter 237, loss 1.9969367980957031, acc 0.1899999976158142\n",
      "Epoch 7, iter 238, loss 1.992326021194458, acc 0.20999999344348907\n",
      "Epoch 7, iter 239, loss 1.9625763893127441, acc 0.15000000596046448\n",
      "Epoch 7, iter 240, loss 1.9660346508026123, acc 0.17000000178813934\n",
      "Epoch 7, iter 241, loss 1.9586445093154907, acc 0.14000000059604645\n",
      "Epoch 7, iter 242, loss 2.005031108856201, acc 0.23000000417232513\n",
      "Epoch 7, iter 243, loss 1.9982573986053467, acc 0.17000000178813934\n",
      "Epoch 7, iter 244, loss 1.9311370849609375, acc 0.28999999165534973\n",
      "Epoch 7, iter 245, loss 1.949519395828247, acc 0.20999999344348907\n",
      "Epoch 7, iter 246, loss 2.0881214141845703, acc 0.1599999964237213\n",
      "Epoch 7, iter 247, loss 1.8714485168457031, acc 0.25\n",
      "Epoch 7, iter 248, loss 1.9769123792648315, acc 0.18000000715255737\n",
      "Epoch 7, iter 249, loss 1.9206037521362305, acc 0.12999999523162842\n",
      "Epoch 7, iter 250, loss 1.8759454488754272, acc 0.28999999165534973\n",
      "Epoch 7, iter 251, loss 1.949873447418213, acc 0.1899999976158142\n",
      "Epoch 7, iter 252, loss 1.8872262239456177, acc 0.23999999463558197\n",
      "Epoch 7, iter 253, loss 2.0412514209747314, acc 0.15000000596046448\n",
      "Epoch 7, iter 254, loss 1.9081579446792603, acc 0.20999999344348907\n",
      "Epoch 7, iter 255, loss 1.9218957424163818, acc 0.18000000715255737\n",
      "Epoch 7, iter 256, loss 1.926702618598938, acc 0.23000000417232513\n",
      "Epoch 7, iter 257, loss 1.9295849800109863, acc 0.17000000178813934\n",
      "Epoch 7, iter 258, loss 2.024758815765381, acc 0.23000000417232513\n",
      "Epoch 7, iter 259, loss 1.9492201805114746, acc 0.23999999463558197\n",
      "Epoch 7, iter 260, loss 1.9512443542480469, acc 0.18000000715255737\n",
      "Epoch 7, iter 261, loss 1.869170069694519, acc 0.23999999463558197\n",
      "Epoch 7, iter 262, loss 1.9755696058273315, acc 0.1599999964237213\n",
      "Epoch 7, iter 263, loss 1.8419904708862305, acc 0.23999999463558197\n",
      "Epoch 7, iter 264, loss 1.9343764781951904, acc 0.27000001072883606\n",
      "Epoch 7, iter 265, loss 2.0162265300750732, acc 0.23000000417232513\n",
      "Epoch 7, iter 266, loss 1.9432203769683838, acc 0.17000000178813934\n",
      "Epoch 7, iter 267, loss 1.8797122240066528, acc 0.2800000011920929\n",
      "Epoch 7, iter 268, loss 1.9306690692901611, acc 0.12999999523162842\n",
      "Epoch 7, iter 269, loss 1.929782509803772, acc 0.20000000298023224\n",
      "Epoch 7, iter 270, loss 1.9373191595077515, acc 0.1599999964237213\n",
      "Epoch 7, iter 271, loss 2.005066156387329, acc 0.20000000298023224\n",
      "Epoch 7, iter 272, loss 1.978827953338623, acc 0.20000000298023224\n",
      "Epoch 7, iter 273, loss 1.8754665851593018, acc 0.20999999344348907\n",
      "Epoch 7, iter 274, loss 1.947141170501709, acc 0.20999999344348907\n",
      "Epoch 7, iter 275, loss 1.8948768377304077, acc 0.18000000715255737\n",
      "Epoch 7, iter 276, loss 2.0021564960479736, acc 0.20000000298023224\n",
      "Epoch 7, iter 277, loss 1.9617215394973755, acc 0.20999999344348907\n",
      "Epoch 7, iter 278, loss 1.9058667421340942, acc 0.17000000178813934\n",
      "Epoch 7, iter 279, loss 1.9884434938430786, acc 0.2800000011920929\n",
      "Epoch 7, iter 280, loss 1.9448494911193848, acc 0.1899999976158142\n",
      "Epoch 7, iter 281, loss 1.8893423080444336, acc 0.30000001192092896\n",
      "Epoch 7, iter 282, loss 1.941880464553833, acc 0.1899999976158142\n",
      "Epoch 7, iter 283, loss 1.9827170372009277, acc 0.17000000178813934\n",
      "Epoch 7, iter 284, loss 1.933103322982788, acc 0.27000001072883606\n",
      "Epoch 7, iter 285, loss 1.9900707006454468, acc 0.20000000298023224\n",
      "Epoch 7, iter 286, loss 1.8723578453063965, acc 0.23999999463558197\n",
      "Epoch 7, iter 287, loss 1.9106212854385376, acc 0.20000000298023224\n",
      "Epoch 7, iter 288, loss 2.003289222717285, acc 0.2199999988079071\n",
      "Epoch 7, iter 289, loss 1.902988076210022, acc 0.23999999463558197\n",
      "Epoch 7, iter 290, loss 1.8597511053085327, acc 0.23000000417232513\n",
      "Epoch 7, iter 291, loss 1.9189883470535278, acc 0.20999999344348907\n",
      "Epoch 7, iter 292, loss 1.9277490377426147, acc 0.25999999046325684\n",
      "Epoch 7, iter 293, loss 2.0024030208587646, acc 0.1899999976158142\n",
      "Epoch 7, iter 294, loss 2.002376079559326, acc 0.1599999964237213\n",
      "Epoch 7, iter 295, loss 1.986997365951538, acc 0.1899999976158142\n",
      "Epoch 7, iter 296, loss 1.9632158279418945, acc 0.20999999344348907\n",
      "Epoch 7, iter 297, loss 2.0186922550201416, acc 0.23000000417232513\n",
      "Epoch 7, iter 298, loss 1.824313759803772, acc 0.25\n",
      "Epoch 7, iter 299, loss 1.953769326210022, acc 0.11999999731779099\n",
      "Epoch 7, iter 300, loss 1.995732307434082, acc 0.18000000715255737\n",
      "Epoch 7, iter 301, loss 1.968885064125061, acc 0.20999999344348907\n",
      "Epoch 7, iter 302, loss 1.9440377950668335, acc 0.27000001072883606\n",
      "Epoch 7, iter 303, loss 1.922315239906311, acc 0.20000000298023224\n",
      "Epoch 7, iter 304, loss 1.9397273063659668, acc 0.17000000178813934\n",
      "Epoch 7, iter 305, loss 2.0330004692077637, acc 0.1599999964237213\n",
      "Epoch 7, iter 306, loss 1.873283863067627, acc 0.20999999344348907\n",
      "Epoch 7, iter 307, loss 1.8994827270507812, acc 0.25\n",
      "Epoch 7, iter 308, loss 2.0497608184814453, acc 0.2199999988079071\n",
      "Epoch 7, iter 309, loss 1.9406898021697998, acc 0.1899999976158142\n",
      "Epoch 7, iter 310, loss 2.0267069339752197, acc 0.18000000715255737\n",
      "Epoch 7, iter 311, loss 1.9323025941848755, acc 0.23000000417232513\n",
      "Epoch 7, iter 312, loss 1.9712141752243042, acc 0.25999999046325684\n",
      "Epoch 7, iter 313, loss 2.03045392036438, acc 0.11999999731779099\n",
      "Epoch 7, iter 314, loss 1.9381152391433716, acc 0.25999999046325684\n",
      "Epoch 7, iter 315, loss 1.8624714612960815, acc 0.25\n",
      "Epoch 7, iter 316, loss 1.9751211404800415, acc 0.12999999523162842\n",
      "Epoch 7, iter 317, loss 2.0314559936523438, acc 0.2199999988079071\n",
      "Epoch 7, iter 318, loss 1.8715423345565796, acc 0.2199999988079071\n",
      "Epoch 7, iter 319, loss 1.9582175016403198, acc 0.18000000715255737\n",
      "Epoch 7, iter 320, loss 1.9988462924957275, acc 0.20000000298023224\n",
      "Epoch 7, iter 321, loss 2.042569637298584, acc 0.1899999976158142\n",
      "Epoch 7, iter 322, loss 1.9545379877090454, acc 0.23999999463558197\n",
      "Epoch 7, iter 323, loss 1.912339687347412, acc 0.20000000298023224\n",
      "Epoch 7, iter 324, loss 1.952428936958313, acc 0.25\n",
      "Epoch 7, iter 325, loss 2.154238700866699, acc 0.23000000417232513\n",
      "Epoch 7, iter 326, loss 2.0413522720336914, acc 0.20000000298023224\n",
      "Epoch 7, iter 327, loss 2.058068037033081, acc 0.1599999964237213\n",
      "Epoch 7, iter 328, loss 2.1437718868255615, acc 0.23000000417232513\n",
      "Epoch 7, iter 329, loss 2.019451379776001, acc 0.2199999988079071\n",
      "Epoch 7, iter 330, loss 2.0782718658447266, acc 0.20999999344348907\n",
      "Epoch 7, iter 331, loss 2.0351128578186035, acc 0.18000000715255737\n",
      "Epoch 7, iter 332, loss 2.157015085220337, acc 0.20000000298023224\n",
      "Epoch 7, iter 333, loss 2.0363237857818604, acc 0.1899999976158142\n",
      "Epoch 7, iter 334, loss 1.9973647594451904, acc 0.20000000298023224\n",
      "Epoch 7, iter 335, loss 1.9424058198928833, acc 0.23999999463558197\n",
      "Epoch 7, iter 336, loss 2.0042617321014404, acc 0.2199999988079071\n",
      "Epoch 7, iter 337, loss 1.9316340684890747, acc 0.20000000298023224\n",
      "Epoch 7, iter 338, loss 1.9097312688827515, acc 0.2199999988079071\n",
      "Epoch 7, iter 339, loss 1.9391677379608154, acc 0.2199999988079071\n",
      "Epoch 7, iter 340, loss 2.0043249130249023, acc 0.1899999976158142\n",
      "Epoch 7, iter 341, loss 1.8630214929580688, acc 0.25\n",
      "Epoch 7, iter 342, loss 2.0236032009124756, acc 0.23000000417232513\n",
      "Epoch 7, iter 343, loss 1.9589805603027344, acc 0.18000000715255737\n",
      "Epoch 7, iter 344, loss 1.8968687057495117, acc 0.23999999463558197\n",
      "Epoch 7, iter 345, loss 2.016897201538086, acc 0.17000000178813934\n",
      "Epoch 7, iter 346, loss 1.9743989706039429, acc 0.23999999463558197\n",
      "Epoch 7, iter 347, loss 1.954494595527649, acc 0.20000000298023224\n",
      "Epoch 7, iter 348, loss 2.0426230430603027, acc 0.3100000023841858\n",
      "Epoch 7, iter 349, loss 1.9536232948303223, acc 0.23999999463558197\n",
      "Epoch 7, iter 350, loss 1.927900791168213, acc 0.25\n",
      "Epoch 7, iter 351, loss 2.03121280670166, acc 0.12999999523162842\n",
      "Epoch 7, iter 352, loss 1.9010717868804932, acc 0.18000000715255737\n",
      "Epoch 7, iter 353, loss 1.9449387788772583, acc 0.25999999046325684\n",
      "Epoch 7, iter 354, loss 1.9514820575714111, acc 0.25\n",
      "Epoch 7, iter 355, loss 1.9548012018203735, acc 0.1899999976158142\n",
      "Epoch 7, iter 356, loss 1.9402128458023071, acc 0.23000000417232513\n",
      "Epoch 7, iter 357, loss 1.9497652053833008, acc 0.20999999344348907\n",
      "Epoch 7, iter 358, loss 2.057634115219116, acc 0.17000000178813934\n",
      "Epoch 7, iter 359, loss 1.9453532695770264, acc 0.12999999523162842\n",
      "Epoch 7, iter 360, loss 1.9510023593902588, acc 0.23000000417232513\n",
      "Epoch 7, iter 361, loss 1.9628938436508179, acc 0.1899999976158142\n",
      "Epoch 7, iter 362, loss 1.9761648178100586, acc 0.1599999964237213\n",
      "Epoch 7, iter 363, loss 1.9209086894989014, acc 0.27000001072883606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 364, loss 1.9753433465957642, acc 0.11999999731779099\n",
      "Epoch 7, iter 365, loss 1.982981562614441, acc 0.18000000715255737\n",
      "Epoch 7, iter 366, loss 1.924826979637146, acc 0.23999999463558197\n",
      "Epoch 7, iter 367, loss 1.899001955986023, acc 0.2199999988079071\n",
      "Epoch 7, iter 368, loss 1.9544700384140015, acc 0.23000000417232513\n",
      "Epoch 7, iter 369, loss 1.871389627456665, acc 0.23999999463558197\n",
      "Epoch 7, iter 370, loss 1.9105724096298218, acc 0.20999999344348907\n",
      "Epoch 7, iter 371, loss 2.0038137435913086, acc 0.23999999463558197\n",
      "Epoch 7, iter 372, loss 1.8804807662963867, acc 0.23000000417232513\n",
      "Epoch 7, iter 373, loss 1.9298145771026611, acc 0.17000000178813934\n",
      "Epoch 7, iter 374, loss 2.0428686141967773, acc 0.1899999976158142\n",
      "Epoch 7, iter 375, loss 1.9500950574874878, acc 0.2800000011920929\n",
      "Epoch 7, iter 376, loss 1.9237258434295654, acc 0.15000000596046448\n",
      "Epoch 7, iter 377, loss 1.9389662742614746, acc 0.25999999046325684\n",
      "Epoch 7, iter 378, loss 1.8981294631958008, acc 0.23999999463558197\n",
      "Epoch 7, iter 379, loss 1.9872627258300781, acc 0.18000000715255737\n",
      "Epoch 7, iter 380, loss 2.015512466430664, acc 0.1599999964237213\n",
      "Epoch 7, iter 381, loss 1.956972599029541, acc 0.1599999964237213\n",
      "Epoch 7, iter 382, loss 1.869964599609375, acc 0.25\n",
      "Epoch 7, iter 383, loss 1.9201146364212036, acc 0.25999999046325684\n",
      "Epoch 7, iter 384, loss 1.9154185056686401, acc 0.18000000715255737\n",
      "Epoch 7, iter 385, loss 1.863248348236084, acc 0.23000000417232513\n",
      "Epoch 7, iter 386, loss 1.8745349645614624, acc 0.20999999344348907\n",
      "Epoch 7, iter 387, loss 1.9358488321304321, acc 0.23999999463558197\n",
      "Epoch 7, iter 388, loss 1.887636661529541, acc 0.20999999344348907\n",
      "Epoch 7, iter 389, loss 2.0011909008026123, acc 0.20999999344348907\n",
      "Epoch 7, iter 390, loss 2.0639891624450684, acc 0.10000000149011612\n",
      "Epoch 7, iter 391, loss 1.9303336143493652, acc 0.1899999976158142\n",
      "Epoch 7, iter 392, loss 1.9521113634109497, acc 0.1599999964237213\n",
      "Epoch 7, iter 393, loss 1.9641221761703491, acc 0.15000000596046448\n",
      "Epoch 7, iter 394, loss 1.869797706604004, acc 0.25\n",
      "Epoch 7, iter 395, loss 1.9805121421813965, acc 0.25\n",
      "Epoch 7, iter 396, loss 1.9742146730422974, acc 0.12999999523162842\n",
      "Epoch 7, iter 397, loss 1.9101502895355225, acc 0.20000000298023224\n",
      "Epoch 7, iter 398, loss 1.9613131284713745, acc 0.12999999523162842\n",
      "Epoch 7, iter 399, loss 1.8966548442840576, acc 0.23000000417232513\n",
      "Epoch 7, iter 400, loss 1.9188770055770874, acc 0.2800000011920929\n",
      "Epoch 7, iter 401, loss 1.8965853452682495, acc 0.20000000298023224\n",
      "Epoch 7, iter 402, loss 1.9642891883850098, acc 0.20999999344348907\n",
      "Epoch 7, iter 403, loss 2.063889265060425, acc 0.1899999976158142\n",
      "Epoch 7, iter 404, loss 1.9827179908752441, acc 0.1599999964237213\n",
      "Epoch 7, iter 405, loss 1.9427763223648071, acc 0.23000000417232513\n",
      "Epoch 7, iter 406, loss 1.9819623231887817, acc 0.12999999523162842\n",
      "Epoch 7, iter 407, loss 1.9713650941848755, acc 0.14000000059604645\n",
      "Epoch 7, iter 408, loss 1.9476103782653809, acc 0.25\n",
      "Epoch 7, iter 409, loss 1.9673871994018555, acc 0.23000000417232513\n",
      "Epoch 7, iter 410, loss 1.9608169794082642, acc 0.15000000596046448\n",
      "Epoch 7, iter 411, loss 1.893788456916809, acc 0.25999999046325684\n",
      "Epoch 7, iter 412, loss 1.9393506050109863, acc 0.25\n",
      "Epoch 7, iter 413, loss 2.0014657974243164, acc 0.15000000596046448\n",
      "Epoch 7, iter 414, loss 1.8939377069473267, acc 0.1599999964237213\n",
      "Epoch 7, iter 415, loss 1.938480019569397, acc 0.20000000298023224\n",
      "Epoch 7, iter 416, loss 1.9351919889450073, acc 0.20999999344348907\n",
      "Epoch 7, iter 417, loss 1.993370532989502, acc 0.27000001072883606\n",
      "Epoch 7, iter 418, loss 1.9470105171203613, acc 0.15000000596046448\n",
      "Epoch 7, iter 419, loss 1.871159315109253, acc 0.25999999046325684\n",
      "Epoch 7, iter 420, loss 1.9866100549697876, acc 0.23999999463558197\n",
      "Epoch 8, iter 1, loss 1.8680354356765747, acc 0.23000000417232513\n",
      "Epoch 8, iter 2, loss 1.9977242946624756, acc 0.15000000596046448\n",
      "Epoch 8, iter 3, loss 1.8932703733444214, acc 0.18000000715255737\n",
      "Epoch 8, iter 4, loss 1.960741400718689, acc 0.15000000596046448\n",
      "Epoch 8, iter 5, loss 1.937954068183899, acc 0.1599999964237213\n",
      "Epoch 8, iter 6, loss 2.004209518432617, acc 0.17000000178813934\n",
      "Epoch 8, iter 7, loss 2.021223545074463, acc 0.20999999344348907\n",
      "Epoch 8, iter 8, loss 1.991423487663269, acc 0.17000000178813934\n",
      "Epoch 8, iter 9, loss 1.9163012504577637, acc 0.20999999344348907\n",
      "Epoch 8, iter 10, loss 1.9146536588668823, acc 0.18000000715255737\n",
      "Epoch 8, iter 11, loss 2.034680128097534, acc 0.1899999976158142\n",
      "Epoch 8, iter 12, loss 1.9869989156723022, acc 0.18000000715255737\n",
      "Epoch 8, iter 13, loss 1.9348336458206177, acc 0.17000000178813934\n",
      "Epoch 8, iter 14, loss 1.8941712379455566, acc 0.20999999344348907\n",
      "Epoch 8, iter 15, loss 1.8367338180541992, acc 0.2800000011920929\n",
      "Epoch 8, iter 16, loss 1.8700652122497559, acc 0.20000000298023224\n",
      "Epoch 8, iter 17, loss 1.8994709253311157, acc 0.1599999964237213\n",
      "Epoch 8, iter 18, loss 1.9272160530090332, acc 0.20000000298023224\n",
      "Epoch 8, iter 19, loss 1.933478593826294, acc 0.2199999988079071\n",
      "Epoch 8, iter 20, loss 1.9221175909042358, acc 0.20000000298023224\n",
      "Epoch 8, iter 21, loss 1.9764126539230347, acc 0.23999999463558197\n",
      "Epoch 8, iter 22, loss 1.9681522846221924, acc 0.2199999988079071\n",
      "Epoch 8, iter 23, loss 1.9705102443695068, acc 0.23000000417232513\n",
      "Epoch 8, iter 24, loss 1.8644437789916992, acc 0.27000001072883606\n",
      "Epoch 8, iter 25, loss 2.0474939346313477, acc 0.18000000715255737\n",
      "Epoch 8, iter 26, loss 1.9641237258911133, acc 0.1899999976158142\n",
      "Epoch 8, iter 27, loss 1.9566149711608887, acc 0.20999999344348907\n",
      "Epoch 8, iter 28, loss 1.8900065422058105, acc 0.23000000417232513\n",
      "Epoch 8, iter 29, loss 1.9170414209365845, acc 0.23999999463558197\n",
      "Epoch 8, iter 30, loss 2.069073438644409, acc 0.18000000715255737\n",
      "Epoch 8, iter 31, loss 2.012810707092285, acc 0.11999999731779099\n",
      "Epoch 8, iter 32, loss 1.923810601234436, acc 0.17000000178813934\n",
      "Epoch 8, iter 33, loss 2.051844358444214, acc 0.23000000417232513\n",
      "Epoch 8, iter 34, loss 1.9888612031936646, acc 0.18000000715255737\n",
      "Epoch 8, iter 35, loss 1.9668644666671753, acc 0.23000000417232513\n",
      "Epoch 8, iter 36, loss 1.9874038696289062, acc 0.18000000715255737\n",
      "Epoch 8, iter 37, loss 1.9604597091674805, acc 0.18000000715255737\n",
      "Epoch 8, iter 38, loss 1.8599470853805542, acc 0.25999999046325684\n",
      "Epoch 8, iter 39, loss 1.9750431776046753, acc 0.2199999988079071\n",
      "Epoch 8, iter 40, loss 1.9521843194961548, acc 0.2199999988079071\n",
      "Epoch 8, iter 41, loss 2.011317253112793, acc 0.14000000059604645\n",
      "Epoch 8, iter 42, loss 2.073570489883423, acc 0.1599999964237213\n",
      "Epoch 8, iter 43, loss 2.017361640930176, acc 0.20999999344348907\n",
      "Epoch 8, iter 44, loss 1.9912854433059692, acc 0.20000000298023224\n",
      "Epoch 8, iter 45, loss 1.9218227863311768, acc 0.20000000298023224\n",
      "Epoch 8, iter 46, loss 1.9727073907852173, acc 0.27000001072883606\n",
      "Epoch 8, iter 47, loss 1.9425338506698608, acc 0.1599999964237213\n",
      "Epoch 8, iter 48, loss 1.962396264076233, acc 0.18000000715255737\n",
      "Epoch 8, iter 49, loss 2.0008764266967773, acc 0.20999999344348907\n",
      "Epoch 8, iter 50, loss 1.9416085481643677, acc 0.23000000417232513\n",
      "Epoch 8, iter 51, loss 1.8415833711624146, acc 0.25999999046325684\n",
      "Epoch 8, iter 52, loss 1.9327807426452637, acc 0.20000000298023224\n",
      "Epoch 8, iter 53, loss 1.9339371919631958, acc 0.3199999928474426\n",
      "Epoch 8, iter 54, loss 1.9736937284469604, acc 0.11999999731779099\n",
      "Epoch 8, iter 55, loss 2.0388376712799072, acc 0.09000000357627869\n",
      "Epoch 8, iter 56, loss 1.9720181226730347, acc 0.1599999964237213\n",
      "Epoch 8, iter 57, loss 1.9945247173309326, acc 0.1899999976158142\n",
      "Epoch 8, iter 58, loss 1.8955646753311157, acc 0.1899999976158142\n",
      "Epoch 8, iter 59, loss 1.9653351306915283, acc 0.23999999463558197\n",
      "Epoch 8, iter 60, loss 1.917486310005188, acc 0.2199999988079071\n",
      "Epoch 8, iter 61, loss 1.9525904655456543, acc 0.17000000178813934\n",
      "Epoch 8, iter 62, loss 1.9431456327438354, acc 0.20000000298023224\n",
      "Epoch 8, iter 63, loss 1.9132664203643799, acc 0.23999999463558197\n",
      "Epoch 8, iter 64, loss 1.8885444402694702, acc 0.20999999344348907\n",
      "Epoch 8, iter 65, loss 1.9374651908874512, acc 0.25999999046325684\n",
      "Epoch 8, iter 66, loss 1.8979960680007935, acc 0.23000000417232513\n",
      "Epoch 8, iter 67, loss 1.945509910583496, acc 0.17000000178813934\n",
      "Epoch 8, iter 68, loss 1.940126657485962, acc 0.3199999928474426\n",
      "Epoch 8, iter 69, loss 1.917184591293335, acc 0.1899999976158142\n",
      "Epoch 8, iter 70, loss 1.9116703271865845, acc 0.27000001072883606\n",
      "Epoch 8, iter 71, loss 1.9277549982070923, acc 0.17000000178813934\n",
      "Epoch 8, iter 72, loss 1.9091814756393433, acc 0.15000000596046448\n",
      "Epoch 8, iter 73, loss 1.9318116903305054, acc 0.2199999988079071\n",
      "Epoch 8, iter 74, loss 1.9244410991668701, acc 0.2199999988079071\n",
      "Epoch 8, iter 75, loss 1.909117579460144, acc 0.12999999523162842\n",
      "Epoch 8, iter 76, loss 2.025273323059082, acc 0.1899999976158142\n",
      "Epoch 8, iter 77, loss 2.0481796264648438, acc 0.1599999964237213\n",
      "Epoch 8, iter 78, loss 1.942186713218689, acc 0.2800000011920929\n",
      "Epoch 8, iter 79, loss 1.9537783861160278, acc 0.20999999344348907\n",
      "Epoch 8, iter 80, loss 1.9340314865112305, acc 0.20000000298023224\n",
      "Epoch 8, iter 81, loss 1.8938724994659424, acc 0.1599999964237213\n",
      "Epoch 8, iter 82, loss 1.9770143032073975, acc 0.17000000178813934\n",
      "Epoch 8, iter 83, loss 1.9922142028808594, acc 0.20999999344348907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 84, loss 1.9670356512069702, acc 0.12999999523162842\n",
      "Epoch 8, iter 85, loss 1.9587492942810059, acc 0.14000000059604645\n",
      "Epoch 8, iter 86, loss 1.924115777015686, acc 0.20000000298023224\n",
      "Epoch 8, iter 87, loss 1.9714601039886475, acc 0.17000000178813934\n",
      "Epoch 8, iter 88, loss 1.9820666313171387, acc 0.23999999463558197\n",
      "Epoch 8, iter 89, loss 1.9107131958007812, acc 0.1899999976158142\n",
      "Epoch 8, iter 90, loss 1.9105383157730103, acc 0.1899999976158142\n",
      "Epoch 8, iter 91, loss 1.9848296642303467, acc 0.18000000715255737\n",
      "Epoch 8, iter 92, loss 1.9476245641708374, acc 0.15000000596046448\n",
      "Epoch 8, iter 93, loss 1.9458884000778198, acc 0.2199999988079071\n",
      "Epoch 8, iter 94, loss 1.9499191045761108, acc 0.1599999964237213\n",
      "Epoch 8, iter 95, loss 1.942905068397522, acc 0.1899999976158142\n",
      "Epoch 8, iter 96, loss 1.953398585319519, acc 0.2199999988079071\n",
      "Epoch 8, iter 97, loss 1.9333289861679077, acc 0.10999999940395355\n",
      "Epoch 8, iter 98, loss 1.9068129062652588, acc 0.1899999976158142\n",
      "Epoch 8, iter 99, loss 2.0021896362304688, acc 0.1599999964237213\n",
      "Epoch 8, iter 100, loss 1.9693958759307861, acc 0.2199999988079071\n",
      "Epoch 8, iter 101, loss 1.8732677698135376, acc 0.2199999988079071\n",
      "Epoch 8, iter 102, loss 1.9697703123092651, acc 0.23000000417232513\n",
      "Epoch 8, iter 103, loss 2.0050206184387207, acc 0.23999999463558197\n",
      "Epoch 8, iter 104, loss 1.9333053827285767, acc 0.2800000011920929\n",
      "Epoch 8, iter 105, loss 1.8596991300582886, acc 0.1899999976158142\n",
      "Epoch 8, iter 106, loss 1.8748772144317627, acc 0.25\n",
      "Epoch 8, iter 107, loss 1.9297960996627808, acc 0.23000000417232513\n",
      "Epoch 8, iter 108, loss 2.0745294094085693, acc 0.12999999523162842\n",
      "Epoch 8, iter 109, loss 1.9779776334762573, acc 0.20999999344348907\n",
      "Epoch 8, iter 110, loss 2.0714619159698486, acc 0.14000000059604645\n",
      "Epoch 8, iter 111, loss 1.991296410560608, acc 0.1599999964237213\n",
      "Epoch 8, iter 112, loss 1.9361579418182373, acc 0.25999999046325684\n",
      "Epoch 8, iter 113, loss 1.9457429647445679, acc 0.2199999988079071\n",
      "Epoch 8, iter 114, loss 1.9056261777877808, acc 0.20999999344348907\n",
      "Epoch 8, iter 115, loss 1.9457428455352783, acc 0.2199999988079071\n",
      "Epoch 8, iter 116, loss 1.9851412773132324, acc 0.20000000298023224\n",
      "Epoch 8, iter 117, loss 1.9536442756652832, acc 0.20999999344348907\n",
      "Epoch 8, iter 118, loss 1.9930756092071533, acc 0.12999999523162842\n",
      "Epoch 8, iter 119, loss 1.9616546630859375, acc 0.23000000417232513\n",
      "Epoch 8, iter 120, loss 1.9805999994277954, acc 0.2199999988079071\n",
      "Epoch 8, iter 121, loss 1.9532597064971924, acc 0.23000000417232513\n",
      "Epoch 8, iter 122, loss 1.949225902557373, acc 0.28999999165534973\n",
      "Epoch 8, iter 123, loss 2.0127477645874023, acc 0.14000000059604645\n",
      "Epoch 8, iter 124, loss 1.9437551498413086, acc 0.2199999988079071\n",
      "Epoch 8, iter 125, loss 1.9579746723175049, acc 0.18000000715255737\n",
      "Epoch 8, iter 126, loss 1.9218802452087402, acc 0.1899999976158142\n",
      "Epoch 8, iter 127, loss 2.058199882507324, acc 0.20999999344348907\n",
      "Epoch 8, iter 128, loss 1.9835865497589111, acc 0.1899999976158142\n",
      "Epoch 8, iter 129, loss 2.0778582096099854, acc 0.1899999976158142\n",
      "Epoch 8, iter 130, loss 1.989696979522705, acc 0.1899999976158142\n",
      "Epoch 8, iter 131, loss 2.0305800437927246, acc 0.20000000298023224\n",
      "Epoch 8, iter 132, loss 1.9623271226882935, acc 0.25\n",
      "Epoch 8, iter 133, loss 1.9916715621948242, acc 0.20999999344348907\n",
      "Epoch 8, iter 134, loss 1.9331152439117432, acc 0.15000000596046448\n",
      "Epoch 8, iter 135, loss 1.962233543395996, acc 0.28999999165534973\n",
      "Epoch 8, iter 136, loss 1.9510204792022705, acc 0.27000001072883606\n",
      "Epoch 8, iter 137, loss 1.9855830669403076, acc 0.23000000417232513\n",
      "Epoch 8, iter 138, loss 1.9338557720184326, acc 0.20999999344348907\n",
      "Epoch 8, iter 139, loss 1.9298580884933472, acc 0.20000000298023224\n",
      "Epoch 8, iter 140, loss 1.9113247394561768, acc 0.1899999976158142\n",
      "Epoch 8, iter 141, loss 1.9666900634765625, acc 0.1899999976158142\n",
      "Epoch 8, iter 142, loss 1.9822078943252563, acc 0.14000000059604645\n",
      "Epoch 8, iter 143, loss 1.9972507953643799, acc 0.20000000298023224\n",
      "Epoch 8, iter 144, loss 1.974104881286621, acc 0.15000000596046448\n",
      "Epoch 8, iter 145, loss 1.9798818826675415, acc 0.20999999344348907\n",
      "Epoch 8, iter 146, loss 2.1085569858551025, acc 0.23000000417232513\n",
      "Epoch 8, iter 147, loss 1.8773009777069092, acc 0.20000000298023224\n",
      "Epoch 8, iter 148, loss 1.9690475463867188, acc 0.25\n",
      "Epoch 8, iter 149, loss 1.9388797283172607, acc 0.25999999046325684\n",
      "Epoch 8, iter 150, loss 1.9465793371200562, acc 0.23999999463558197\n",
      "Epoch 8, iter 151, loss 1.8515342473983765, acc 0.2800000011920929\n",
      "Epoch 8, iter 152, loss 2.021686553955078, acc 0.1599999964237213\n",
      "Epoch 8, iter 153, loss 1.9405556917190552, acc 0.18000000715255737\n",
      "Epoch 8, iter 154, loss 1.979374647140503, acc 0.23000000417232513\n",
      "Epoch 8, iter 155, loss 1.892646074295044, acc 0.27000001072883606\n",
      "Epoch 8, iter 156, loss 1.8884769678115845, acc 0.17000000178813934\n",
      "Epoch 8, iter 157, loss 1.8922561407089233, acc 0.17000000178813934\n",
      "Epoch 8, iter 158, loss 1.9269403219223022, acc 0.20000000298023224\n",
      "Epoch 8, iter 159, loss 1.9201912879943848, acc 0.2199999988079071\n",
      "Epoch 8, iter 160, loss 1.91749906539917, acc 0.1899999976158142\n",
      "Epoch 8, iter 161, loss 1.8637806177139282, acc 0.23999999463558197\n",
      "Epoch 8, iter 162, loss 2.004579544067383, acc 0.20000000298023224\n",
      "Epoch 8, iter 163, loss 1.9641575813293457, acc 0.1599999964237213\n",
      "Epoch 8, iter 164, loss 1.944211721420288, acc 0.23000000417232513\n",
      "Epoch 8, iter 165, loss 1.976115107536316, acc 0.10999999940395355\n",
      "Epoch 8, iter 166, loss 1.9032485485076904, acc 0.25\n",
      "Epoch 8, iter 167, loss 1.9210689067840576, acc 0.20999999344348907\n",
      "Epoch 8, iter 168, loss 2.008890390396118, acc 0.20999999344348907\n",
      "Epoch 8, iter 169, loss 1.8542827367782593, acc 0.1899999976158142\n",
      "Epoch 8, iter 170, loss 1.8947147130966187, acc 0.2199999988079071\n",
      "Epoch 8, iter 171, loss 1.9901115894317627, acc 0.17000000178813934\n",
      "Epoch 8, iter 172, loss 1.9178043603897095, acc 0.20000000298023224\n",
      "Epoch 8, iter 173, loss 1.9582444429397583, acc 0.15000000596046448\n",
      "Epoch 8, iter 174, loss 1.8996473550796509, acc 0.20999999344348907\n",
      "Epoch 8, iter 175, loss 1.8753300905227661, acc 0.18000000715255737\n",
      "Epoch 8, iter 176, loss 2.0160019397735596, acc 0.1899999976158142\n",
      "Epoch 8, iter 177, loss 1.9469404220581055, acc 0.1599999964237213\n",
      "Epoch 8, iter 178, loss 1.9457275867462158, acc 0.20999999344348907\n",
      "Epoch 8, iter 179, loss 1.9178786277770996, acc 0.14000000059604645\n",
      "Epoch 8, iter 180, loss 1.9351511001586914, acc 0.2199999988079071\n",
      "Epoch 8, iter 181, loss 1.8365877866744995, acc 0.20000000298023224\n",
      "Epoch 8, iter 182, loss 1.8901019096374512, acc 0.18000000715255737\n",
      "Epoch 8, iter 183, loss 1.8812679052352905, acc 0.18000000715255737\n",
      "Epoch 8, iter 184, loss 1.9744333028793335, acc 0.18000000715255737\n",
      "Epoch 8, iter 185, loss 1.8708912134170532, acc 0.2199999988079071\n",
      "Epoch 8, iter 186, loss 1.9480220079421997, acc 0.2199999988079071\n",
      "Epoch 8, iter 187, loss 1.8902900218963623, acc 0.23999999463558197\n",
      "Epoch 8, iter 188, loss 2.0785112380981445, acc 0.20999999344348907\n",
      "Epoch 8, iter 189, loss 2.019094944000244, acc 0.18000000715255737\n",
      "Epoch 8, iter 190, loss 1.8472304344177246, acc 0.1899999976158142\n",
      "Epoch 8, iter 191, loss 1.963017225265503, acc 0.20999999344348907\n",
      "Epoch 8, iter 192, loss 1.9190751314163208, acc 0.3100000023841858\n",
      "Epoch 8, iter 193, loss 1.8824527263641357, acc 0.1899999976158142\n",
      "Epoch 8, iter 194, loss 1.8897477388381958, acc 0.25999999046325684\n",
      "Epoch 8, iter 195, loss 1.8961575031280518, acc 0.23999999463558197\n",
      "Epoch 8, iter 196, loss 2.0000710487365723, acc 0.18000000715255737\n",
      "Epoch 8, iter 197, loss 1.9483624696731567, acc 0.14000000059604645\n",
      "Epoch 8, iter 198, loss 1.9189660549163818, acc 0.3199999928474426\n",
      "Epoch 8, iter 199, loss 1.9318979978561401, acc 0.20000000298023224\n",
      "Epoch 8, iter 200, loss 2.0253331661224365, acc 0.20000000298023224\n",
      "Epoch 8, iter 201, loss 1.944669485092163, acc 0.23999999463558197\n",
      "Epoch 8, iter 202, loss 2.0063233375549316, acc 0.17000000178813934\n",
      "Epoch 8, iter 203, loss 1.9874004125595093, acc 0.1599999964237213\n",
      "Epoch 8, iter 204, loss 1.9561362266540527, acc 0.2199999988079071\n",
      "Epoch 8, iter 205, loss 1.9709177017211914, acc 0.23000000417232513\n",
      "Epoch 8, iter 206, loss 1.9759881496429443, acc 0.25999999046325684\n",
      "Epoch 8, iter 207, loss 1.9418333768844604, acc 0.1599999964237213\n",
      "Epoch 8, iter 208, loss 2.0444021224975586, acc 0.17000000178813934\n",
      "Epoch 8, iter 209, loss 2.0394582748413086, acc 0.1899999976158142\n",
      "Epoch 8, iter 210, loss 1.9561996459960938, acc 0.20000000298023224\n",
      "Epoch 8, iter 211, loss 1.9479506015777588, acc 0.23999999463558197\n",
      "Epoch 8, iter 212, loss 1.9065803289413452, acc 0.20000000298023224\n",
      "Epoch 8, iter 213, loss 1.9783110618591309, acc 0.12999999523162842\n",
      "Epoch 8, iter 214, loss 2.0613012313842773, acc 0.18000000715255737\n",
      "Epoch 8, iter 215, loss 1.9553773403167725, acc 0.1899999976158142\n",
      "Epoch 8, iter 216, loss 1.986372947692871, acc 0.2199999988079071\n",
      "Epoch 8, iter 217, loss 1.9894813299179077, acc 0.2199999988079071\n",
      "Epoch 8, iter 218, loss 2.1160895824432373, acc 0.1599999964237213\n",
      "Epoch 8, iter 219, loss 1.9803749322891235, acc 0.17000000178813934\n",
      "Epoch 8, iter 220, loss 1.992485523223877, acc 0.1599999964237213\n",
      "Epoch 8, iter 221, loss 1.9746593236923218, acc 0.18000000715255737\n",
      "Epoch 8, iter 222, loss 1.9826449155807495, acc 0.2199999988079071\n",
      "Epoch 8, iter 223, loss 1.967958688735962, acc 0.2800000011920929\n",
      "Epoch 8, iter 224, loss 1.9888423681259155, acc 0.23999999463558197\n",
      "Epoch 8, iter 225, loss 1.9303990602493286, acc 0.23000000417232513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 226, loss 1.9888325929641724, acc 0.23999999463558197\n",
      "Epoch 8, iter 227, loss 1.9743008613586426, acc 0.23999999463558197\n",
      "Epoch 8, iter 228, loss 1.9746642112731934, acc 0.20000000298023224\n",
      "Epoch 8, iter 229, loss 2.010215997695923, acc 0.2199999988079071\n",
      "Epoch 8, iter 230, loss 2.0257339477539062, acc 0.25999999046325684\n",
      "Epoch 8, iter 231, loss 2.0180771350860596, acc 0.2199999988079071\n",
      "Epoch 8, iter 232, loss 2.083641529083252, acc 0.15000000596046448\n",
      "Epoch 8, iter 233, loss 1.913886308670044, acc 0.25\n",
      "Epoch 8, iter 234, loss 1.9202630519866943, acc 0.27000001072883606\n",
      "Epoch 8, iter 235, loss 1.9103422164916992, acc 0.23000000417232513\n",
      "Epoch 8, iter 236, loss 1.9800513982772827, acc 0.17000000178813934\n",
      "Epoch 8, iter 237, loss 1.9951767921447754, acc 0.1899999976158142\n",
      "Epoch 8, iter 238, loss 1.9674949645996094, acc 0.2199999988079071\n",
      "Epoch 8, iter 239, loss 1.928490400314331, acc 0.15000000596046448\n",
      "Epoch 8, iter 240, loss 1.921526312828064, acc 0.17000000178813934\n",
      "Epoch 8, iter 241, loss 1.897579550743103, acc 0.14000000059604645\n",
      "Epoch 8, iter 242, loss 2.010474443435669, acc 0.23000000417232513\n",
      "Epoch 8, iter 243, loss 1.9861133098602295, acc 0.17000000178813934\n",
      "Epoch 8, iter 244, loss 1.9737375974655151, acc 0.28999999165534973\n",
      "Epoch 8, iter 245, loss 1.9551464319229126, acc 0.20999999344348907\n",
      "Epoch 8, iter 246, loss 2.0305745601654053, acc 0.1599999964237213\n",
      "Epoch 8, iter 247, loss 1.8886823654174805, acc 0.25\n",
      "Epoch 8, iter 248, loss 1.9791656732559204, acc 0.18000000715255737\n",
      "Epoch 8, iter 249, loss 1.9640083312988281, acc 0.11999999731779099\n",
      "Epoch 8, iter 250, loss 1.926918625831604, acc 0.28999999165534973\n",
      "Epoch 8, iter 251, loss 1.9930243492126465, acc 0.1899999976158142\n",
      "Epoch 8, iter 252, loss 1.9482128620147705, acc 0.23999999463558197\n",
      "Epoch 8, iter 253, loss 2.0674102306365967, acc 0.15000000596046448\n",
      "Epoch 8, iter 254, loss 1.913157343864441, acc 0.20999999344348907\n",
      "Epoch 8, iter 255, loss 1.9467941522598267, acc 0.18000000715255737\n",
      "Epoch 8, iter 256, loss 1.9188700914382935, acc 0.23999999463558197\n",
      "Epoch 8, iter 257, loss 1.9321507215499878, acc 0.17000000178813934\n",
      "Epoch 8, iter 258, loss 1.991465449333191, acc 0.23000000417232513\n",
      "Epoch 8, iter 259, loss 2.015418291091919, acc 0.23000000417232513\n",
      "Epoch 8, iter 260, loss 1.970247745513916, acc 0.1899999976158142\n",
      "Epoch 8, iter 261, loss 1.982459306716919, acc 0.23999999463558197\n",
      "Epoch 8, iter 262, loss 1.993849515914917, acc 0.1599999964237213\n",
      "Epoch 8, iter 263, loss 1.8358019590377808, acc 0.23999999463558197\n",
      "Epoch 8, iter 264, loss 2.008119821548462, acc 0.27000001072883606\n",
      "Epoch 8, iter 265, loss 1.9895652532577515, acc 0.2199999988079071\n",
      "Epoch 8, iter 266, loss 1.9423984289169312, acc 0.17000000178813934\n",
      "Epoch 8, iter 267, loss 1.8857704401016235, acc 0.2800000011920929\n",
      "Epoch 8, iter 268, loss 1.903296709060669, acc 0.12999999523162842\n",
      "Epoch 8, iter 269, loss 1.9367862939834595, acc 0.1899999976158142\n",
      "Epoch 8, iter 270, loss 1.9144237041473389, acc 0.1599999964237213\n",
      "Epoch 8, iter 271, loss 1.9720591306686401, acc 0.1899999976158142\n",
      "Epoch 8, iter 272, loss 1.9558812379837036, acc 0.20999999344348907\n",
      "Epoch 8, iter 273, loss 1.896604299545288, acc 0.20999999344348907\n",
      "Epoch 8, iter 274, loss 1.943062424659729, acc 0.20999999344348907\n",
      "Epoch 8, iter 275, loss 1.9164372682571411, acc 0.18000000715255737\n",
      "Epoch 8, iter 276, loss 2.038435459136963, acc 0.20000000298023224\n",
      "Epoch 8, iter 277, loss 1.9483916759490967, acc 0.20999999344348907\n",
      "Epoch 8, iter 278, loss 1.9127899408340454, acc 0.1599999964237213\n",
      "Epoch 8, iter 279, loss 1.9872803688049316, acc 0.2800000011920929\n",
      "Epoch 8, iter 280, loss 1.9035953283309937, acc 0.20000000298023224\n",
      "Epoch 8, iter 281, loss 1.9036566019058228, acc 0.28999999165534973\n",
      "Epoch 8, iter 282, loss 1.9193682670593262, acc 0.18000000715255737\n",
      "Epoch 8, iter 283, loss 1.9510126113891602, acc 0.17000000178813934\n",
      "Epoch 8, iter 284, loss 1.9490433931350708, acc 0.25999999046325684\n",
      "Epoch 8, iter 285, loss 1.979284644126892, acc 0.1899999976158142\n",
      "Epoch 8, iter 286, loss 1.8548800945281982, acc 0.23000000417232513\n",
      "Epoch 8, iter 287, loss 1.959449291229248, acc 0.1899999976158142\n",
      "Epoch 8, iter 288, loss 2.0194921493530273, acc 0.20999999344348907\n",
      "Epoch 8, iter 289, loss 1.9703185558319092, acc 0.23999999463558197\n",
      "Epoch 8, iter 290, loss 1.9480814933776855, acc 0.2199999988079071\n",
      "Epoch 8, iter 291, loss 1.9497630596160889, acc 0.20000000298023224\n",
      "Epoch 8, iter 292, loss 1.9733957052230835, acc 0.23999999463558197\n",
      "Epoch 8, iter 293, loss 2.001086950302124, acc 0.20000000298023224\n",
      "Epoch 8, iter 294, loss 2.016815423965454, acc 0.14000000059604645\n",
      "Epoch 8, iter 295, loss 2.0205259323120117, acc 0.18000000715255737\n",
      "Epoch 8, iter 296, loss 1.9458600282669067, acc 0.20999999344348907\n",
      "Epoch 8, iter 297, loss 2.0666048526763916, acc 0.2199999988079071\n",
      "Epoch 8, iter 298, loss 1.867497444152832, acc 0.25\n",
      "Epoch 8, iter 299, loss 2.0299391746520996, acc 0.10000000149011612\n",
      "Epoch 8, iter 300, loss 1.9993716478347778, acc 0.17000000178813934\n",
      "Epoch 8, iter 301, loss 2.0240938663482666, acc 0.20999999344348907\n",
      "Epoch 8, iter 302, loss 1.9532651901245117, acc 0.25999999046325684\n",
      "Epoch 8, iter 303, loss 1.93381929397583, acc 0.20000000298023224\n",
      "Epoch 8, iter 304, loss 1.9403303861618042, acc 0.17000000178813934\n",
      "Epoch 8, iter 305, loss 2.021920680999756, acc 0.1599999964237213\n",
      "Epoch 8, iter 306, loss 1.8701543807983398, acc 0.20000000298023224\n",
      "Epoch 8, iter 307, loss 1.8841725587844849, acc 0.23000000417232513\n",
      "Epoch 8, iter 308, loss 2.0532784461975098, acc 0.20999999344348907\n",
      "Epoch 8, iter 309, loss 1.9041825532913208, acc 0.1899999976158142\n",
      "Epoch 8, iter 310, loss 1.9800959825515747, acc 0.1899999976158142\n",
      "Epoch 8, iter 311, loss 1.9539145231246948, acc 0.20000000298023224\n",
      "Epoch 8, iter 312, loss 1.9496924877166748, acc 0.27000001072883606\n",
      "Epoch 8, iter 313, loss 2.057065010070801, acc 0.2199999988079071\n",
      "Epoch 8, iter 314, loss 1.9393352270126343, acc 0.27000001072883606\n",
      "Epoch 8, iter 315, loss 1.8430923223495483, acc 0.2199999988079071\n",
      "Epoch 8, iter 316, loss 2.005267858505249, acc 0.10999999940395355\n",
      "Epoch 8, iter 317, loss 2.0306882858276367, acc 0.17000000178813934\n",
      "Epoch 8, iter 318, loss 1.9016515016555786, acc 0.20000000298023224\n",
      "Epoch 8, iter 319, loss 1.9558755159378052, acc 0.20999999344348907\n",
      "Epoch 8, iter 320, loss 2.0697145462036133, acc 0.1599999964237213\n",
      "Epoch 8, iter 321, loss 2.1091694831848145, acc 0.1599999964237213\n",
      "Epoch 8, iter 322, loss 1.9654027223587036, acc 0.20000000298023224\n",
      "Epoch 8, iter 323, loss 1.9663978815078735, acc 0.20999999344348907\n",
      "Epoch 8, iter 324, loss 1.9072855710983276, acc 0.2800000011920929\n",
      "Epoch 8, iter 325, loss 1.9594601392745972, acc 0.18000000715255737\n",
      "Epoch 8, iter 326, loss 1.9297895431518555, acc 0.2199999988079071\n",
      "Epoch 8, iter 327, loss 1.8724851608276367, acc 0.18000000715255737\n",
      "Epoch 8, iter 328, loss 1.9032474756240845, acc 0.25\n",
      "Epoch 8, iter 329, loss 1.9419561624526978, acc 0.23999999463558197\n",
      "Epoch 8, iter 330, loss 1.866499423980713, acc 0.1599999964237213\n",
      "Epoch 8, iter 331, loss 1.9339715242385864, acc 0.18000000715255737\n",
      "Epoch 8, iter 332, loss 1.9694867134094238, acc 0.18000000715255737\n",
      "Epoch 8, iter 333, loss 1.95967698097229, acc 0.20000000298023224\n",
      "Epoch 8, iter 334, loss 1.9322662353515625, acc 0.20999999344348907\n",
      "Epoch 8, iter 335, loss 1.923211693763733, acc 0.23999999463558197\n",
      "Epoch 8, iter 336, loss 1.992867112159729, acc 0.2199999988079071\n",
      "Epoch 8, iter 337, loss 1.949461817741394, acc 0.20000000298023224\n",
      "Epoch 8, iter 338, loss 1.8870762586593628, acc 0.20999999344348907\n",
      "Epoch 8, iter 339, loss 1.8805038928985596, acc 0.23000000417232513\n",
      "Epoch 8, iter 340, loss 1.9632399082183838, acc 0.20000000298023224\n",
      "Epoch 8, iter 341, loss 1.8435275554656982, acc 0.25\n",
      "Epoch 8, iter 342, loss 2.021836519241333, acc 0.23000000417232513\n",
      "Epoch 8, iter 343, loss 1.9046276807785034, acc 0.20999999344348907\n",
      "Epoch 8, iter 344, loss 1.8548922538757324, acc 0.27000001072883606\n",
      "Epoch 8, iter 345, loss 1.9852490425109863, acc 0.1899999976158142\n",
      "Epoch 8, iter 346, loss 1.9389839172363281, acc 0.27000001072883606\n",
      "Epoch 8, iter 347, loss 1.938744068145752, acc 0.17000000178813934\n",
      "Epoch 8, iter 348, loss 1.9490501880645752, acc 0.25999999046325684\n",
      "Epoch 8, iter 349, loss 1.995061993598938, acc 0.25\n",
      "Epoch 8, iter 350, loss 1.8766785860061646, acc 0.1899999976158142\n",
      "Epoch 8, iter 351, loss 1.997838020324707, acc 0.12999999523162842\n",
      "Epoch 8, iter 352, loss 1.869368076324463, acc 0.18000000715255737\n",
      "Epoch 8, iter 353, loss 1.881227970123291, acc 0.25999999046325684\n",
      "Epoch 8, iter 354, loss 1.9647727012634277, acc 0.25\n",
      "Epoch 8, iter 355, loss 1.9480971097946167, acc 0.1899999976158142\n",
      "Epoch 8, iter 356, loss 1.9256622791290283, acc 0.23000000417232513\n",
      "Epoch 8, iter 357, loss 1.9296875, acc 0.2199999988079071\n",
      "Epoch 8, iter 358, loss 2.065875768661499, acc 0.1599999964237213\n",
      "Epoch 8, iter 359, loss 1.9092563390731812, acc 0.12999999523162842\n",
      "Epoch 8, iter 360, loss 1.9512901306152344, acc 0.23999999463558197\n",
      "Epoch 8, iter 361, loss 1.990858554840088, acc 0.20000000298023224\n",
      "Epoch 8, iter 362, loss 2.0034666061401367, acc 0.1599999964237213\n",
      "Epoch 8, iter 363, loss 1.938507080078125, acc 0.27000001072883606\n",
      "Epoch 8, iter 364, loss 1.9376307725906372, acc 0.11999999731779099\n",
      "Epoch 8, iter 365, loss 1.995001196861267, acc 0.1899999976158142\n",
      "Epoch 8, iter 366, loss 1.8806395530700684, acc 0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 367, loss 1.9286396503448486, acc 0.2199999988079071\n",
      "Epoch 8, iter 368, loss 1.951483130455017, acc 0.23000000417232513\n",
      "Epoch 8, iter 369, loss 1.9111313819885254, acc 0.23999999463558197\n",
      "Epoch 8, iter 370, loss 1.9190043210983276, acc 0.20000000298023224\n",
      "Epoch 8, iter 371, loss 1.9763953685760498, acc 0.23999999463558197\n",
      "Epoch 8, iter 372, loss 1.8596465587615967, acc 0.23000000417232513\n",
      "Epoch 8, iter 373, loss 1.9179664850234985, acc 0.17000000178813934\n",
      "Epoch 8, iter 374, loss 2.0502126216888428, acc 0.20000000298023224\n",
      "Epoch 8, iter 375, loss 1.930704951286316, acc 0.28999999165534973\n",
      "Epoch 8, iter 376, loss 1.9142773151397705, acc 0.15000000596046448\n",
      "Epoch 8, iter 377, loss 1.900701880455017, acc 0.25999999046325684\n",
      "Epoch 8, iter 378, loss 1.9273695945739746, acc 0.25\n",
      "Epoch 8, iter 379, loss 1.9387151002883911, acc 0.18000000715255737\n",
      "Epoch 8, iter 380, loss 1.988766074180603, acc 0.15000000596046448\n",
      "Epoch 8, iter 381, loss 1.9529178142547607, acc 0.1599999964237213\n",
      "Epoch 8, iter 382, loss 1.8541473150253296, acc 0.25\n",
      "Epoch 8, iter 383, loss 1.9536323547363281, acc 0.23999999463558197\n",
      "Epoch 8, iter 384, loss 1.9067057371139526, acc 0.18000000715255737\n",
      "Epoch 8, iter 385, loss 1.825078010559082, acc 0.23999999463558197\n",
      "Epoch 8, iter 386, loss 1.882200002670288, acc 0.20999999344348907\n",
      "Epoch 8, iter 387, loss 1.9043408632278442, acc 0.23000000417232513\n",
      "Epoch 8, iter 388, loss 1.898882269859314, acc 0.20999999344348907\n",
      "Epoch 8, iter 389, loss 1.913007378578186, acc 0.20999999344348907\n",
      "Epoch 8, iter 390, loss 2.073533535003662, acc 0.09000000357627869\n",
      "Epoch 8, iter 391, loss 1.9103574752807617, acc 0.1899999976158142\n",
      "Epoch 8, iter 392, loss 1.9240117073059082, acc 0.17000000178813934\n",
      "Epoch 8, iter 393, loss 1.9266830682754517, acc 0.15000000596046448\n",
      "Epoch 8, iter 394, loss 1.8570187091827393, acc 0.25\n",
      "Epoch 8, iter 395, loss 2.0000998973846436, acc 0.25\n",
      "Epoch 8, iter 396, loss 1.9437695741653442, acc 0.14000000059604645\n",
      "Epoch 8, iter 397, loss 1.8480421304702759, acc 0.20000000298023224\n",
      "Epoch 8, iter 398, loss 1.989965558052063, acc 0.11999999731779099\n",
      "Epoch 8, iter 399, loss 1.8901317119598389, acc 0.23000000417232513\n",
      "Epoch 8, iter 400, loss 1.9157229661941528, acc 0.28999999165534973\n",
      "Epoch 8, iter 401, loss 1.920000433921814, acc 0.1899999976158142\n",
      "Epoch 8, iter 402, loss 1.9339871406555176, acc 0.20999999344348907\n",
      "Epoch 8, iter 403, loss 2.0085182189941406, acc 0.1899999976158142\n",
      "Epoch 8, iter 404, loss 1.9903217554092407, acc 0.1599999964237213\n",
      "Epoch 8, iter 405, loss 1.9448332786560059, acc 0.23000000417232513\n",
      "Epoch 8, iter 406, loss 1.9532501697540283, acc 0.11999999731779099\n",
      "Epoch 8, iter 407, loss 2.0016019344329834, acc 0.14000000059604645\n",
      "Epoch 8, iter 408, loss 1.9018425941467285, acc 0.1899999976158142\n",
      "Epoch 8, iter 409, loss 1.9415500164031982, acc 0.23000000417232513\n",
      "Epoch 8, iter 410, loss 1.934271216392517, acc 0.1599999964237213\n",
      "Epoch 8, iter 411, loss 1.8534536361694336, acc 0.27000001072883606\n",
      "Epoch 8, iter 412, loss 1.9180225133895874, acc 0.27000001072883606\n",
      "Epoch 8, iter 413, loss 2.0131759643554688, acc 0.15000000596046448\n",
      "Epoch 8, iter 414, loss 1.9061098098754883, acc 0.1599999964237213\n",
      "Epoch 8, iter 415, loss 1.9434247016906738, acc 0.20000000298023224\n",
      "Epoch 8, iter 416, loss 1.9043351411819458, acc 0.20999999344348907\n",
      "Epoch 8, iter 417, loss 1.9264352321624756, acc 0.2800000011920929\n",
      "Epoch 8, iter 418, loss 1.9560728073120117, acc 0.15000000596046448\n",
      "Epoch 8, iter 419, loss 1.8962684869766235, acc 0.23999999463558197\n",
      "Epoch 8, iter 420, loss 2.0079238414764404, acc 0.23999999463558197\n",
      "Epoch 9, iter 1, loss 1.9333348274230957, acc 0.28999999165534973\n",
      "Epoch 9, iter 2, loss 1.9510616064071655, acc 0.1599999964237213\n",
      "Epoch 9, iter 3, loss 1.8861738443374634, acc 0.18000000715255737\n",
      "Epoch 9, iter 4, loss 1.9156988859176636, acc 0.17000000178813934\n",
      "Epoch 9, iter 5, loss 1.9511910676956177, acc 0.20999999344348907\n",
      "Epoch 9, iter 6, loss 1.9887001514434814, acc 0.1899999976158142\n",
      "Epoch 9, iter 7, loss 1.94951593875885, acc 0.20999999344348907\n",
      "Epoch 9, iter 8, loss 1.896639108657837, acc 0.1899999976158142\n",
      "Epoch 9, iter 9, loss 1.9145349264144897, acc 0.15000000596046448\n",
      "Epoch 9, iter 10, loss 1.8738232851028442, acc 0.15000000596046448\n",
      "Epoch 9, iter 11, loss 2.037107467651367, acc 0.20000000298023224\n",
      "Epoch 9, iter 12, loss 1.906204342842102, acc 0.20000000298023224\n",
      "Epoch 9, iter 13, loss 1.920029878616333, acc 0.18000000715255737\n",
      "Epoch 9, iter 14, loss 1.9543161392211914, acc 0.20999999344348907\n",
      "Epoch 9, iter 15, loss 1.8398579359054565, acc 0.2800000011920929\n",
      "Epoch 9, iter 16, loss 1.8898077011108398, acc 0.25\n",
      "Epoch 9, iter 17, loss 1.8899281024932861, acc 0.2199999988079071\n",
      "Epoch 9, iter 18, loss 1.9690492153167725, acc 0.20000000298023224\n",
      "Epoch 9, iter 19, loss 1.9453887939453125, acc 0.2199999988079071\n",
      "Epoch 9, iter 20, loss 1.9411752223968506, acc 0.20000000298023224\n",
      "Epoch 9, iter 21, loss 1.888566493988037, acc 0.25\n",
      "Epoch 9, iter 22, loss 1.9914991855621338, acc 0.2199999988079071\n",
      "Epoch 9, iter 23, loss 1.9544788599014282, acc 0.23000000417232513\n",
      "Epoch 9, iter 24, loss 1.9119563102722168, acc 0.25999999046325684\n",
      "Epoch 9, iter 25, loss 1.9959760904312134, acc 0.1899999976158142\n",
      "Epoch 9, iter 26, loss 1.9506072998046875, acc 0.1899999976158142\n",
      "Epoch 9, iter 27, loss 1.9117878675460815, acc 0.20999999344348907\n",
      "Epoch 9, iter 28, loss 1.936613917350769, acc 0.23000000417232513\n",
      "Epoch 9, iter 29, loss 1.8739315271377563, acc 0.20999999344348907\n",
      "Epoch 9, iter 30, loss 2.075284004211426, acc 0.15000000596046448\n",
      "Epoch 9, iter 31, loss 1.9837651252746582, acc 0.14000000059604645\n",
      "Epoch 9, iter 32, loss 1.9816502332687378, acc 0.20999999344348907\n",
      "Epoch 9, iter 33, loss 2.0161609649658203, acc 0.1599999964237213\n",
      "Epoch 9, iter 34, loss 1.9296696186065674, acc 0.18000000715255737\n",
      "Epoch 9, iter 35, loss 1.9587589502334595, acc 0.23000000417232513\n",
      "Epoch 9, iter 36, loss 1.9674639701843262, acc 0.18000000715255737\n",
      "Epoch 9, iter 37, loss 1.9266600608825684, acc 0.18000000715255737\n",
      "Epoch 9, iter 38, loss 1.9008172750473022, acc 0.25999999046325684\n",
      "Epoch 9, iter 39, loss 1.9504603147506714, acc 0.23000000417232513\n",
      "Epoch 9, iter 40, loss 1.94795560836792, acc 0.20000000298023224\n",
      "Epoch 9, iter 41, loss 2.052661180496216, acc 0.14000000059604645\n",
      "Epoch 9, iter 42, loss 1.9712300300598145, acc 0.1599999964237213\n",
      "Epoch 9, iter 43, loss 1.863267183303833, acc 0.1899999976158142\n",
      "Epoch 9, iter 44, loss 1.878689169883728, acc 0.18000000715255737\n",
      "Epoch 9, iter 45, loss 1.8980876207351685, acc 0.1899999976158142\n",
      "Epoch 9, iter 46, loss 1.9433717727661133, acc 0.20999999344348907\n",
      "Epoch 9, iter 47, loss 1.9344395399093628, acc 0.1599999964237213\n",
      "Epoch 9, iter 48, loss 1.9743915796279907, acc 0.23000000417232513\n",
      "Epoch 9, iter 49, loss 1.9911062717437744, acc 0.20999999344348907\n",
      "Epoch 9, iter 50, loss 1.9325908422470093, acc 0.1599999964237213\n",
      "Epoch 9, iter 51, loss 1.8807945251464844, acc 0.25999999046325684\n",
      "Epoch 9, iter 52, loss 1.9803043603897095, acc 0.20000000298023224\n",
      "Epoch 9, iter 53, loss 1.9142059087753296, acc 0.33000001311302185\n",
      "Epoch 9, iter 54, loss 1.8907966613769531, acc 0.11999999731779099\n",
      "Epoch 9, iter 55, loss 2.002545118331909, acc 0.10000000149011612\n",
      "Epoch 9, iter 56, loss 1.9943461418151855, acc 0.15000000596046448\n",
      "Epoch 9, iter 57, loss 1.9461913108825684, acc 0.1599999964237213\n",
      "Epoch 9, iter 58, loss 1.8914028406143188, acc 0.1899999976158142\n",
      "Epoch 9, iter 59, loss 1.9419538974761963, acc 0.23999999463558197\n",
      "Epoch 9, iter 60, loss 1.914355754852295, acc 0.2199999988079071\n",
      "Epoch 9, iter 61, loss 1.8873116970062256, acc 0.18000000715255737\n",
      "Epoch 9, iter 62, loss 1.9207696914672852, acc 0.20000000298023224\n",
      "Epoch 9, iter 63, loss 1.9664552211761475, acc 0.23999999463558197\n",
      "Epoch 9, iter 64, loss 1.8844294548034668, acc 0.20999999344348907\n",
      "Epoch 9, iter 65, loss 1.9245502948760986, acc 0.2199999988079071\n",
      "Epoch 9, iter 66, loss 1.8843744993209839, acc 0.23000000417232513\n",
      "Epoch 9, iter 67, loss 1.9107398986816406, acc 0.20999999344348907\n",
      "Epoch 9, iter 68, loss 1.8907859325408936, acc 0.23999999463558197\n",
      "Epoch 9, iter 69, loss 1.9176336526870728, acc 0.20999999344348907\n",
      "Epoch 9, iter 70, loss 1.9096015691757202, acc 0.2199999988079071\n",
      "Epoch 9, iter 71, loss 1.9573222398757935, acc 0.17000000178813934\n",
      "Epoch 9, iter 72, loss 1.9016261100769043, acc 0.15000000596046448\n",
      "Epoch 9, iter 73, loss 1.9362156391143799, acc 0.23000000417232513\n",
      "Epoch 9, iter 74, loss 1.8605809211730957, acc 0.2199999988079071\n",
      "Epoch 9, iter 75, loss 1.9396235942840576, acc 0.1899999976158142\n",
      "Epoch 9, iter 76, loss 1.9853941202163696, acc 0.17000000178813934\n",
      "Epoch 9, iter 77, loss 2.0314347743988037, acc 0.20000000298023224\n",
      "Epoch 9, iter 78, loss 1.8980975151062012, acc 0.20999999344348907\n",
      "Epoch 9, iter 79, loss 1.9347156286239624, acc 0.20999999344348907\n",
      "Epoch 9, iter 80, loss 2.006950855255127, acc 0.20000000298023224\n",
      "Epoch 9, iter 81, loss 1.8840605020523071, acc 0.1599999964237213\n",
      "Epoch 9, iter 82, loss 1.9240269660949707, acc 0.20999999344348907\n",
      "Epoch 9, iter 83, loss 1.9203202724456787, acc 0.23999999463558197\n",
      "Epoch 9, iter 84, loss 1.943408489227295, acc 0.15000000596046448\n",
      "Epoch 9, iter 85, loss 1.9703959226608276, acc 0.17000000178813934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 86, loss 1.9285366535186768, acc 0.20999999344348907\n",
      "Epoch 9, iter 87, loss 1.9494867324829102, acc 0.17000000178813934\n",
      "Epoch 9, iter 88, loss 1.9922795295715332, acc 0.25999999046325684\n",
      "Epoch 9, iter 89, loss 1.9915353059768677, acc 0.20999999344348907\n",
      "Epoch 9, iter 90, loss 1.9323935508728027, acc 0.2199999988079071\n",
      "Epoch 9, iter 91, loss 1.983890414237976, acc 0.20999999344348907\n",
      "Epoch 9, iter 92, loss 1.890851616859436, acc 0.15000000596046448\n",
      "Epoch 9, iter 93, loss 1.896173357963562, acc 0.17000000178813934\n",
      "Epoch 9, iter 94, loss 1.91591477394104, acc 0.1599999964237213\n",
      "Epoch 9, iter 95, loss 1.9473124742507935, acc 0.23999999463558197\n",
      "Epoch 9, iter 96, loss 1.9628597497940063, acc 0.1899999976158142\n",
      "Epoch 9, iter 97, loss 1.9386345148086548, acc 0.20999999344348907\n",
      "Epoch 9, iter 98, loss 1.9437974691390991, acc 0.1899999976158142\n",
      "Epoch 9, iter 99, loss 1.9840489625930786, acc 0.1599999964237213\n",
      "Epoch 9, iter 100, loss 1.9779481887817383, acc 0.2199999988079071\n",
      "Epoch 9, iter 101, loss 1.852795124053955, acc 0.2199999988079071\n",
      "Epoch 9, iter 102, loss 1.9409910440444946, acc 0.23000000417232513\n",
      "Epoch 9, iter 103, loss 2.000412940979004, acc 0.1899999976158142\n",
      "Epoch 9, iter 104, loss 1.9426900148391724, acc 0.2800000011920929\n",
      "Epoch 9, iter 105, loss 1.8350214958190918, acc 0.1899999976158142\n",
      "Epoch 9, iter 106, loss 1.8634731769561768, acc 0.25999999046325684\n",
      "Epoch 9, iter 107, loss 1.950894832611084, acc 0.2199999988079071\n",
      "Epoch 9, iter 108, loss 1.9440258741378784, acc 0.12999999523162842\n",
      "Epoch 9, iter 109, loss 1.9875950813293457, acc 0.2199999988079071\n",
      "Epoch 9, iter 110, loss 1.891502857208252, acc 0.15000000596046448\n",
      "Epoch 9, iter 111, loss 1.9855284690856934, acc 0.17000000178813934\n",
      "Epoch 9, iter 112, loss 1.975651502609253, acc 0.25999999046325684\n",
      "Epoch 9, iter 113, loss 1.937699794769287, acc 0.23000000417232513\n",
      "Epoch 9, iter 114, loss 1.9140924215316772, acc 0.23999999463558197\n",
      "Epoch 9, iter 115, loss 1.8777987957000732, acc 0.2199999988079071\n",
      "Epoch 9, iter 116, loss 1.9522373676300049, acc 0.20999999344348907\n",
      "Epoch 9, iter 117, loss 1.921332836151123, acc 0.1599999964237213\n",
      "Epoch 9, iter 118, loss 1.8982315063476562, acc 0.14000000059604645\n",
      "Epoch 9, iter 119, loss 2.138153314590454, acc 0.18000000715255737\n",
      "Epoch 9, iter 120, loss 2.0647051334381104, acc 0.2199999988079071\n",
      "Epoch 9, iter 121, loss 2.095510959625244, acc 0.23000000417232513\n",
      "Epoch 9, iter 122, loss 2.110966682434082, acc 0.25999999046325684\n",
      "Epoch 9, iter 123, loss 2.2306106090545654, acc 0.14000000059604645\n",
      "Epoch 9, iter 124, loss 2.0904111862182617, acc 0.20999999344348907\n",
      "Epoch 9, iter 125, loss 2.0651445388793945, acc 0.18000000715255737\n",
      "Epoch 9, iter 126, loss 2.013479232788086, acc 0.18000000715255737\n",
      "Epoch 9, iter 127, loss 2.1729345321655273, acc 0.20000000298023224\n",
      "Epoch 9, iter 128, loss 2.1009204387664795, acc 0.1899999976158142\n",
      "Epoch 9, iter 129, loss 2.276588201522827, acc 0.10999999940395355\n",
      "Epoch 9, iter 130, loss 2.106253147125244, acc 0.18000000715255737\n",
      "Epoch 9, iter 131, loss 2.207632303237915, acc 0.1899999976158142\n",
      "Epoch 9, iter 132, loss 2.079244613647461, acc 0.25\n",
      "Epoch 9, iter 133, loss 2.0603086948394775, acc 0.20999999344348907\n",
      "Epoch 9, iter 134, loss 2.021864414215088, acc 0.15000000596046448\n",
      "Epoch 9, iter 135, loss 2.031529664993286, acc 0.2800000011920929\n",
      "Epoch 9, iter 136, loss 2.1902174949645996, acc 0.25999999046325684\n",
      "Epoch 9, iter 137, loss 1.987991213798523, acc 0.23999999463558197\n",
      "Epoch 9, iter 138, loss 2.0720341205596924, acc 0.20000000298023224\n",
      "Epoch 9, iter 139, loss 1.9589645862579346, acc 0.20000000298023224\n",
      "Epoch 9, iter 140, loss 2.060398817062378, acc 0.1899999976158142\n",
      "Epoch 9, iter 141, loss 2.036015510559082, acc 0.1899999976158142\n",
      "Epoch 9, iter 142, loss 2.0969035625457764, acc 0.14000000059604645\n",
      "Epoch 9, iter 143, loss 2.0394742488861084, acc 0.20000000298023224\n",
      "Epoch 9, iter 144, loss 2.1521575450897217, acc 0.14000000059604645\n",
      "Epoch 9, iter 145, loss 1.9758144617080688, acc 0.25\n",
      "Epoch 9, iter 146, loss 2.1260390281677246, acc 0.2199999988079071\n",
      "Epoch 9, iter 147, loss 1.9793989658355713, acc 0.1899999976158142\n",
      "Epoch 9, iter 148, loss 2.0866000652313232, acc 0.23999999463558197\n",
      "Epoch 9, iter 149, loss 1.9603602886199951, acc 0.23999999463558197\n",
      "Epoch 9, iter 150, loss 2.1105878353118896, acc 0.2199999988079071\n",
      "Epoch 9, iter 151, loss 1.9478243589401245, acc 0.2800000011920929\n",
      "Epoch 9, iter 152, loss 2.090230703353882, acc 0.12999999523162842\n",
      "Epoch 9, iter 153, loss 2.0590505599975586, acc 0.1599999964237213\n",
      "Epoch 9, iter 154, loss 2.0240492820739746, acc 0.20000000298023224\n",
      "Epoch 9, iter 155, loss 2.0546767711639404, acc 0.2199999988079071\n",
      "Epoch 9, iter 156, loss 1.9669828414916992, acc 0.1599999964237213\n",
      "Epoch 9, iter 157, loss 1.9565352201461792, acc 0.2199999988079071\n",
      "Epoch 9, iter 158, loss 2.0016298294067383, acc 0.1899999976158142\n",
      "Epoch 9, iter 159, loss 2.032151222229004, acc 0.20999999344348907\n",
      "Epoch 9, iter 160, loss 2.120215654373169, acc 0.1599999964237213\n",
      "Epoch 9, iter 161, loss 1.9328200817108154, acc 0.2199999988079071\n",
      "Epoch 9, iter 162, loss 2.049251079559326, acc 0.20000000298023224\n",
      "Epoch 9, iter 163, loss 2.070955276489258, acc 0.15000000596046448\n",
      "Epoch 9, iter 164, loss 2.054035186767578, acc 0.20999999344348907\n",
      "Epoch 9, iter 165, loss 2.035280466079712, acc 0.10999999940395355\n",
      "Epoch 9, iter 166, loss 1.9382922649383545, acc 0.25\n",
      "Epoch 9, iter 167, loss 2.057614326477051, acc 0.23000000417232513\n",
      "Epoch 9, iter 168, loss 2.096182346343994, acc 0.20999999344348907\n",
      "Epoch 9, iter 169, loss 1.971063494682312, acc 0.25\n",
      "Epoch 9, iter 170, loss 1.99015212059021, acc 0.20000000298023224\n",
      "Epoch 9, iter 171, loss 2.0985448360443115, acc 0.1599999964237213\n",
      "Epoch 9, iter 172, loss 2.0293586254119873, acc 0.1899999976158142\n",
      "Epoch 9, iter 173, loss 2.0707590579986572, acc 0.12999999523162842\n",
      "Epoch 9, iter 174, loss 2.118215799331665, acc 0.18000000715255737\n",
      "Epoch 9, iter 175, loss 2.0338380336761475, acc 0.1599999964237213\n",
      "Epoch 9, iter 176, loss 2.0398004055023193, acc 0.18000000715255737\n",
      "Epoch 9, iter 177, loss 2.0810515880584717, acc 0.15000000596046448\n",
      "Epoch 9, iter 178, loss 1.9682376384735107, acc 0.20999999344348907\n",
      "Epoch 9, iter 179, loss 1.8885183334350586, acc 0.14000000059604645\n",
      "Epoch 9, iter 180, loss 2.017639398574829, acc 0.20999999344348907\n",
      "Epoch 9, iter 181, loss 2.040773391723633, acc 0.18000000715255737\n",
      "Epoch 9, iter 182, loss 2.132708787918091, acc 0.14000000059604645\n",
      "Epoch 9, iter 183, loss 2.079951524734497, acc 0.17000000178813934\n",
      "Epoch 9, iter 184, loss 2.1322033405303955, acc 0.20000000298023224\n",
      "Epoch 9, iter 185, loss 2.032893180847168, acc 0.2199999988079071\n",
      "Epoch 9, iter 186, loss 2.0377798080444336, acc 0.20999999344348907\n",
      "Epoch 9, iter 187, loss 2.0199832916259766, acc 0.20999999344348907\n",
      "Epoch 9, iter 188, loss 2.044381856918335, acc 0.2199999988079071\n",
      "Epoch 9, iter 189, loss 2.2092413902282715, acc 0.11999999731779099\n",
      "Epoch 9, iter 190, loss 1.8619487285614014, acc 0.1899999976158142\n",
      "Epoch 9, iter 191, loss 1.967503309249878, acc 0.20999999344348907\n",
      "Epoch 9, iter 192, loss 1.8984348773956299, acc 0.30000001192092896\n",
      "Epoch 9, iter 193, loss 1.900436282157898, acc 0.1899999976158142\n",
      "Epoch 9, iter 194, loss 1.8946484327316284, acc 0.25999999046325684\n",
      "Epoch 9, iter 195, loss 1.912900686264038, acc 0.23999999463558197\n",
      "Epoch 9, iter 196, loss 2.043524980545044, acc 0.17000000178813934\n",
      "Epoch 9, iter 197, loss 1.9226806163787842, acc 0.14000000059604645\n",
      "Epoch 9, iter 198, loss 1.8810197114944458, acc 0.3199999928474426\n",
      "Epoch 9, iter 199, loss 1.9320825338363647, acc 0.18000000715255737\n",
      "Epoch 9, iter 200, loss 2.018523931503296, acc 0.20000000298023224\n",
      "Epoch 9, iter 201, loss 1.9203509092330933, acc 0.23000000417232513\n",
      "Epoch 9, iter 202, loss 1.9712998867034912, acc 0.1899999976158142\n",
      "Epoch 9, iter 203, loss 1.902297854423523, acc 0.1599999964237213\n",
      "Epoch 9, iter 204, loss 1.9275250434875488, acc 0.2199999988079071\n",
      "Epoch 9, iter 205, loss 1.8929606676101685, acc 0.23000000417232513\n",
      "Epoch 9, iter 206, loss 2.0024306774139404, acc 0.25\n",
      "Epoch 9, iter 207, loss 1.9384056329727173, acc 0.1599999964237213\n",
      "Epoch 9, iter 208, loss 1.933414340019226, acc 0.17000000178813934\n",
      "Epoch 9, iter 209, loss 1.9792081117630005, acc 0.1899999976158142\n",
      "Epoch 9, iter 210, loss 1.9840806722640991, acc 0.20999999344348907\n",
      "Epoch 9, iter 211, loss 1.9565598964691162, acc 0.23999999463558197\n",
      "Epoch 9, iter 212, loss 1.9011112451553345, acc 0.20000000298023224\n",
      "Epoch 9, iter 213, loss 1.9271005392074585, acc 0.12999999523162842\n",
      "Epoch 9, iter 214, loss 2.045905590057373, acc 0.18000000715255737\n",
      "Epoch 9, iter 215, loss 1.963512897491455, acc 0.1899999976158142\n",
      "Epoch 9, iter 216, loss 1.9567625522613525, acc 0.2199999988079071\n",
      "Epoch 9, iter 217, loss 1.9274595975875854, acc 0.2199999988079071\n",
      "Epoch 9, iter 218, loss 2.0704855918884277, acc 0.1599999964237213\n",
      "Epoch 9, iter 219, loss 1.9921411275863647, acc 0.18000000715255737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 220, loss 1.9602911472320557, acc 0.1599999964237213\n",
      "Epoch 9, iter 221, loss 1.914015769958496, acc 0.1899999976158142\n",
      "Epoch 9, iter 222, loss 1.9978508949279785, acc 0.20999999344348907\n",
      "Epoch 9, iter 223, loss 1.864687204360962, acc 0.17000000178813934\n",
      "Epoch 9, iter 224, loss 1.9421050548553467, acc 0.23999999463558197\n",
      "Epoch 9, iter 225, loss 1.8579825162887573, acc 0.23000000417232513\n",
      "Epoch 9, iter 226, loss 1.9145070314407349, acc 0.25\n",
      "Epoch 9, iter 227, loss 1.987958550453186, acc 0.23999999463558197\n",
      "Epoch 9, iter 228, loss 1.9408305883407593, acc 0.20000000298023224\n",
      "Epoch 9, iter 229, loss 1.9346673488616943, acc 0.2199999988079071\n",
      "Epoch 9, iter 230, loss 2.0217461585998535, acc 0.25\n",
      "Epoch 9, iter 231, loss 2.0540642738342285, acc 0.2199999988079071\n",
      "Epoch 9, iter 232, loss 2.057734489440918, acc 0.15000000596046448\n",
      "Epoch 9, iter 233, loss 1.9163321256637573, acc 0.25\n",
      "Epoch 9, iter 234, loss 1.8564845323562622, acc 0.2800000011920929\n",
      "Epoch 9, iter 235, loss 1.8632467985153198, acc 0.23000000417232513\n",
      "Epoch 9, iter 236, loss 1.9979327917099, acc 0.17000000178813934\n",
      "Epoch 9, iter 237, loss 1.968825340270996, acc 0.1899999976158142\n",
      "Epoch 9, iter 238, loss 2.037917137145996, acc 0.20999999344348907\n",
      "Epoch 9, iter 239, loss 1.9281467199325562, acc 0.15000000596046448\n",
      "Epoch 9, iter 240, loss 1.9724735021591187, acc 0.17000000178813934\n",
      "Epoch 9, iter 241, loss 1.8875924348831177, acc 0.14000000059604645\n",
      "Epoch 9, iter 242, loss 1.9784257411956787, acc 0.17000000178813934\n",
      "Epoch 9, iter 243, loss 2.018024206161499, acc 0.17000000178813934\n",
      "Epoch 9, iter 244, loss 1.9723865985870361, acc 0.28999999165534973\n",
      "Epoch 9, iter 245, loss 1.9290521144866943, acc 0.20999999344348907\n",
      "Epoch 9, iter 246, loss 1.9826754331588745, acc 0.1599999964237213\n",
      "Epoch 9, iter 247, loss 1.9090678691864014, acc 0.23999999463558197\n",
      "Epoch 9, iter 248, loss 1.9546916484832764, acc 0.18000000715255737\n",
      "Epoch 9, iter 249, loss 1.9668679237365723, acc 0.12999999523162842\n",
      "Epoch 9, iter 250, loss 1.9013633728027344, acc 0.20999999344348907\n",
      "Epoch 9, iter 251, loss 1.932334542274475, acc 0.1899999976158142\n",
      "Epoch 9, iter 252, loss 1.881283164024353, acc 0.20000000298023224\n",
      "Epoch 9, iter 253, loss 2.02842378616333, acc 0.15000000596046448\n",
      "Epoch 9, iter 254, loss 1.911366581916809, acc 0.20999999344348907\n",
      "Epoch 9, iter 255, loss 1.897465467453003, acc 0.18000000715255737\n",
      "Epoch 9, iter 256, loss 1.9230014085769653, acc 0.23999999463558197\n",
      "Epoch 9, iter 257, loss 1.9587055444717407, acc 0.17000000178813934\n",
      "Epoch 9, iter 258, loss 1.966048002243042, acc 0.23000000417232513\n",
      "Epoch 9, iter 259, loss 1.9820882081985474, acc 0.23999999463558197\n",
      "Epoch 9, iter 260, loss 1.9440562725067139, acc 0.1899999976158142\n",
      "Epoch 9, iter 261, loss 1.815488576889038, acc 0.23999999463558197\n",
      "Epoch 9, iter 262, loss 1.928078293800354, acc 0.1599999964237213\n",
      "Epoch 9, iter 263, loss 1.8545470237731934, acc 0.2199999988079071\n",
      "Epoch 9, iter 264, loss 1.9201430082321167, acc 0.27000001072883606\n",
      "Epoch 9, iter 265, loss 1.952951192855835, acc 0.23000000417232513\n",
      "Epoch 9, iter 266, loss 1.92751145362854, acc 0.17000000178813934\n",
      "Epoch 9, iter 267, loss 1.868492603302002, acc 0.2800000011920929\n",
      "Epoch 9, iter 268, loss 1.8734619617462158, acc 0.12999999523162842\n",
      "Epoch 9, iter 269, loss 1.9123550653457642, acc 0.1899999976158142\n",
      "Epoch 9, iter 270, loss 1.9636399745941162, acc 0.1599999964237213\n",
      "Epoch 9, iter 271, loss 1.8968526124954224, acc 0.1899999976158142\n",
      "Epoch 9, iter 272, loss 1.9071160554885864, acc 0.2199999988079071\n",
      "Epoch 9, iter 273, loss 1.9597692489624023, acc 0.20000000298023224\n",
      "Epoch 9, iter 274, loss 2.0585200786590576, acc 0.20999999344348907\n",
      "Epoch 9, iter 275, loss 1.9579265117645264, acc 0.18000000715255737\n",
      "Epoch 9, iter 276, loss 1.9982061386108398, acc 0.20999999344348907\n",
      "Epoch 9, iter 277, loss 2.005732774734497, acc 0.2199999988079071\n",
      "Epoch 9, iter 278, loss 1.9681280851364136, acc 0.17000000178813934\n",
      "Epoch 9, iter 279, loss 1.992928147315979, acc 0.2800000011920929\n",
      "Epoch 9, iter 280, loss 2.001326084136963, acc 0.1899999976158142\n",
      "Epoch 9, iter 281, loss 1.875062108039856, acc 0.28999999165534973\n",
      "Epoch 9, iter 282, loss 1.956793189048767, acc 0.1899999976158142\n",
      "Epoch 9, iter 283, loss 1.9351695775985718, acc 0.17000000178813934\n",
      "Epoch 9, iter 284, loss 1.91644287109375, acc 0.27000001072883606\n",
      "Epoch 9, iter 285, loss 1.977339744567871, acc 0.20000000298023224\n",
      "Epoch 9, iter 286, loss 1.9018490314483643, acc 0.23999999463558197\n",
      "Epoch 9, iter 287, loss 1.9596741199493408, acc 0.20000000298023224\n",
      "Epoch 9, iter 288, loss 1.9938724040985107, acc 0.2199999988079071\n",
      "Epoch 9, iter 289, loss 1.9305014610290527, acc 0.23999999463558197\n",
      "Epoch 9, iter 290, loss 1.8907594680786133, acc 0.23000000417232513\n",
      "Epoch 9, iter 291, loss 2.025554895401001, acc 0.20999999344348907\n",
      "Epoch 9, iter 292, loss 1.8972222805023193, acc 0.25999999046325684\n",
      "Epoch 9, iter 293, loss 2.0010006427764893, acc 0.20000000298023224\n",
      "Epoch 9, iter 294, loss 1.9982339143753052, acc 0.1599999964237213\n",
      "Epoch 9, iter 295, loss 1.9778465032577515, acc 0.18000000715255737\n",
      "Epoch 9, iter 296, loss 1.9665871858596802, acc 0.20999999344348907\n",
      "Epoch 9, iter 297, loss 1.8998342752456665, acc 0.23999999463558197\n",
      "Epoch 9, iter 298, loss 1.9242427349090576, acc 0.25\n",
      "Epoch 9, iter 299, loss 2.0414671897888184, acc 0.11999999731779099\n",
      "Epoch 9, iter 300, loss 2.000284433364868, acc 0.18000000715255737\n",
      "Epoch 9, iter 301, loss 1.9258395433425903, acc 0.20999999344348907\n",
      "Epoch 9, iter 302, loss 1.9962246417999268, acc 0.27000001072883606\n",
      "Epoch 9, iter 303, loss 1.891481637954712, acc 0.20000000298023224\n",
      "Epoch 9, iter 304, loss 1.9446098804473877, acc 0.17000000178813934\n",
      "Epoch 9, iter 305, loss 2.0295276641845703, acc 0.1599999964237213\n",
      "Epoch 9, iter 306, loss 1.8830372095108032, acc 0.25\n",
      "Epoch 9, iter 307, loss 1.966109037399292, acc 0.23000000417232513\n",
      "Epoch 9, iter 308, loss 2.002498149871826, acc 0.20999999344348907\n",
      "Epoch 9, iter 309, loss 1.9106048345565796, acc 0.2199999988079071\n",
      "Epoch 9, iter 310, loss 2.0050694942474365, acc 0.20999999344348907\n",
      "Epoch 9, iter 311, loss 1.9516719579696655, acc 0.20000000298023224\n",
      "Epoch 9, iter 312, loss 1.9013514518737793, acc 0.27000001072883606\n",
      "Epoch 9, iter 313, loss 2.065941095352173, acc 0.2199999988079071\n",
      "Epoch 9, iter 314, loss 1.994612216949463, acc 0.27000001072883606\n",
      "Epoch 9, iter 315, loss 1.8553190231323242, acc 0.2199999988079071\n",
      "Epoch 9, iter 316, loss 1.9438694715499878, acc 0.11999999731779099\n",
      "Epoch 9, iter 317, loss 1.9587979316711426, acc 0.17000000178813934\n",
      "Epoch 9, iter 318, loss 1.8755154609680176, acc 0.20000000298023224\n",
      "Epoch 9, iter 319, loss 1.9833821058273315, acc 0.2199999988079071\n",
      "Epoch 9, iter 320, loss 1.9250102043151855, acc 0.18000000715255737\n",
      "Epoch 9, iter 321, loss 2.0514299869537354, acc 0.17000000178813934\n",
      "Epoch 9, iter 322, loss 1.9268693923950195, acc 0.20999999344348907\n",
      "Epoch 9, iter 323, loss 1.949160099029541, acc 0.20999999344348907\n",
      "Epoch 9, iter 324, loss 1.8623751401901245, acc 0.30000001192092896\n",
      "Epoch 9, iter 325, loss 1.913352608680725, acc 0.20000000298023224\n",
      "Epoch 9, iter 326, loss 1.947258472442627, acc 0.2199999988079071\n",
      "Epoch 9, iter 327, loss 1.904707908630371, acc 0.18000000715255737\n",
      "Epoch 9, iter 328, loss 1.9239099025726318, acc 0.25\n",
      "Epoch 9, iter 329, loss 1.957473874092102, acc 0.23999999463558197\n",
      "Epoch 9, iter 330, loss 1.9142903089523315, acc 0.1599999964237213\n",
      "Epoch 9, iter 331, loss 1.8716102838516235, acc 0.18000000715255737\n",
      "Epoch 9, iter 332, loss 1.9269952774047852, acc 0.1899999976158142\n",
      "Epoch 9, iter 333, loss 1.9656296968460083, acc 0.20999999344348907\n",
      "Epoch 9, iter 334, loss 1.908827304840088, acc 0.2199999988079071\n",
      "Epoch 9, iter 335, loss 1.9050871133804321, acc 0.23999999463558197\n",
      "Epoch 9, iter 336, loss 1.9640164375305176, acc 0.2199999988079071\n",
      "Epoch 9, iter 337, loss 1.9043281078338623, acc 0.20000000298023224\n",
      "Epoch 9, iter 338, loss 1.9596463441848755, acc 0.20999999344348907\n",
      "Epoch 9, iter 339, loss 1.895302414894104, acc 0.23000000417232513\n",
      "Epoch 9, iter 340, loss 2.015988349914551, acc 0.1899999976158142\n",
      "Epoch 9, iter 341, loss 1.8587698936462402, acc 0.25\n",
      "Epoch 9, iter 342, loss 2.027987480163574, acc 0.23000000417232513\n",
      "Epoch 9, iter 343, loss 1.8888026475906372, acc 0.20999999344348907\n",
      "Epoch 9, iter 344, loss 1.8481708765029907, acc 0.27000001072883606\n",
      "Epoch 9, iter 345, loss 1.9591586589813232, acc 0.1899999976158142\n",
      "Epoch 9, iter 346, loss 1.9103626012802124, acc 0.2800000011920929\n",
      "Epoch 9, iter 347, loss 1.9405864477157593, acc 0.17000000178813934\n",
      "Epoch 9, iter 348, loss 1.9253917932510376, acc 0.25999999046325684\n",
      "Epoch 9, iter 349, loss 1.9453134536743164, acc 0.25999999046325684\n",
      "Epoch 9, iter 350, loss 1.888413906097412, acc 0.1899999976158142\n",
      "Epoch 9, iter 351, loss 1.9775053262710571, acc 0.14000000059604645\n",
      "Epoch 9, iter 352, loss 1.8684136867523193, acc 0.18000000715255737\n",
      "Epoch 9, iter 353, loss 1.8756049871444702, acc 0.25999999046325684\n",
      "Epoch 9, iter 354, loss 2.0109100341796875, acc 0.25\n",
      "Epoch 9, iter 355, loss 1.9322903156280518, acc 0.20000000298023224\n",
      "Epoch 9, iter 356, loss 1.862807273864746, acc 0.25\n",
      "Epoch 9, iter 357, loss 1.9049714803695679, acc 0.2199999988079071\n",
      "Epoch 9, iter 358, loss 1.9957799911499023, acc 0.17000000178813934\n",
      "Epoch 9, iter 359, loss 1.8925518989562988, acc 0.12999999523162842\n",
      "Epoch 9, iter 360, loss 1.919985055923462, acc 0.23000000417232513\n",
      "Epoch 9, iter 361, loss 1.9239200353622437, acc 0.20000000298023224\n",
      "Epoch 9, iter 362, loss 1.9524954557418823, acc 0.1599999964237213\n",
      "Epoch 9, iter 363, loss 1.9300737380981445, acc 0.27000001072883606\n",
      "Epoch 9, iter 364, loss 1.9589838981628418, acc 0.11999999731779099\n",
      "Epoch 9, iter 365, loss 1.9733669757843018, acc 0.20999999344348907\n",
      "Epoch 9, iter 366, loss 1.9175388813018799, acc 0.25\n",
      "Epoch 9, iter 367, loss 1.9485032558441162, acc 0.2199999988079071\n",
      "Epoch 9, iter 368, loss 1.956174373626709, acc 0.23000000417232513\n",
      "Epoch 9, iter 369, loss 1.911841869354248, acc 0.23999999463558197\n",
      "Epoch 9, iter 370, loss 1.8882936239242554, acc 0.20000000298023224\n",
      "Epoch 9, iter 371, loss 1.992556095123291, acc 0.23999999463558197\n",
      "Epoch 9, iter 372, loss 1.8862131834030151, acc 0.23000000417232513\n",
      "Epoch 9, iter 373, loss 1.907609462738037, acc 0.17000000178813934\n",
      "Epoch 9, iter 374, loss 2.066115617752075, acc 0.20000000298023224\n",
      "Epoch 9, iter 375, loss 1.9272613525390625, acc 0.28999999165534973\n",
      "Epoch 9, iter 376, loss 1.8546754121780396, acc 0.15000000596046448\n",
      "Epoch 9, iter 377, loss 1.8955475091934204, acc 0.25999999046325684\n",
      "Epoch 9, iter 378, loss 1.955065131187439, acc 0.25\n",
      "Epoch 9, iter 379, loss 1.9401909112930298, acc 0.18000000715255737\n",
      "Epoch 9, iter 380, loss 1.989210605621338, acc 0.15000000596046448\n",
      "Epoch 9, iter 381, loss 1.9534109830856323, acc 0.1599999964237213\n",
      "Epoch 9, iter 382, loss 1.8344322443008423, acc 0.25\n",
      "Epoch 9, iter 383, loss 1.9544312953948975, acc 0.25\n",
      "Epoch 9, iter 384, loss 1.8791390657424927, acc 0.18000000715255737\n",
      "Epoch 9, iter 385, loss 1.8215113878250122, acc 0.23999999463558197\n",
      "Epoch 9, iter 386, loss 1.8781394958496094, acc 0.20999999344348907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 387, loss 1.9548661708831787, acc 0.2199999988079071\n",
      "Epoch 9, iter 388, loss 1.9230811595916748, acc 0.20000000298023224\n",
      "Epoch 9, iter 389, loss 1.8973993062973022, acc 0.20999999344348907\n",
      "Epoch 9, iter 390, loss 2.032564163208008, acc 0.10000000149011612\n",
      "Epoch 9, iter 391, loss 1.9345974922180176, acc 0.1899999976158142\n",
      "Epoch 9, iter 392, loss 1.9071760177612305, acc 0.18000000715255737\n",
      "Epoch 9, iter 393, loss 2.0152502059936523, acc 0.15000000596046448\n",
      "Epoch 9, iter 394, loss 1.8105322122573853, acc 0.25999999046325684\n",
      "Epoch 9, iter 395, loss 1.9602192640304565, acc 0.27000001072883606\n",
      "Epoch 9, iter 396, loss 1.9392194747924805, acc 0.15000000596046448\n",
      "Epoch 9, iter 397, loss 1.8745391368865967, acc 0.20000000298023224\n",
      "Epoch 9, iter 398, loss 2.005418539047241, acc 0.12999999523162842\n",
      "Epoch 9, iter 399, loss 1.8891340494155884, acc 0.23999999463558197\n",
      "Epoch 9, iter 400, loss 1.8432787656784058, acc 0.28999999165534973\n",
      "Epoch 9, iter 401, loss 1.8694037199020386, acc 0.20999999344348907\n",
      "Epoch 9, iter 402, loss 1.9800257682800293, acc 0.20999999344348907\n",
      "Epoch 9, iter 403, loss 1.9650261402130127, acc 0.20000000298023224\n",
      "Epoch 9, iter 404, loss 1.9065148830413818, acc 0.17000000178813934\n",
      "Epoch 9, iter 405, loss 1.9052280187606812, acc 0.23000000417232513\n",
      "Epoch 9, iter 406, loss 2.0446884632110596, acc 0.11999999731779099\n",
      "Epoch 9, iter 407, loss 1.9432443380355835, acc 0.14000000059604645\n",
      "Epoch 9, iter 408, loss 1.919663906097412, acc 0.25\n",
      "Epoch 9, iter 409, loss 1.9427720308303833, acc 0.23000000417232513\n",
      "Epoch 9, iter 410, loss 1.9414575099945068, acc 0.1599999964237213\n",
      "Epoch 9, iter 411, loss 1.9453837871551514, acc 0.2800000011920929\n",
      "Epoch 9, iter 412, loss 1.9077057838439941, acc 0.27000001072883606\n",
      "Epoch 9, iter 413, loss 2.039008378982544, acc 0.15000000596046448\n",
      "Epoch 9, iter 414, loss 1.8977305889129639, acc 0.1599999964237213\n",
      "Epoch 9, iter 415, loss 1.9494025707244873, acc 0.20000000298023224\n",
      "Epoch 9, iter 416, loss 1.9262357950210571, acc 0.2199999988079071\n",
      "Epoch 9, iter 417, loss 1.9008067846298218, acc 0.2800000011920929\n",
      "Epoch 9, iter 418, loss 1.9040008783340454, acc 0.15000000596046448\n",
      "Epoch 9, iter 419, loss 1.9237054586410522, acc 0.27000001072883606\n",
      "Epoch 9, iter 420, loss 2.0278148651123047, acc 0.23000000417232513\n",
      "Epoch 10, iter 1, loss 1.89705228805542, acc 0.23000000417232513\n",
      "Epoch 10, iter 2, loss 1.9221514463424683, acc 0.1599999964237213\n",
      "Epoch 10, iter 3, loss 1.9063953161239624, acc 0.1899999976158142\n",
      "Epoch 10, iter 4, loss 1.9579838514328003, acc 0.17000000178813934\n",
      "Epoch 10, iter 5, loss 1.9542765617370605, acc 0.17000000178813934\n",
      "Epoch 10, iter 6, loss 2.002981185913086, acc 0.1899999976158142\n",
      "Epoch 10, iter 7, loss 2.018209457397461, acc 0.20999999344348907\n",
      "Epoch 10, iter 8, loss 1.95731520652771, acc 0.20000000298023224\n",
      "Epoch 10, iter 9, loss 1.93625807762146, acc 0.15000000596046448\n",
      "Epoch 10, iter 10, loss 1.8921681642532349, acc 0.1899999976158142\n",
      "Epoch 10, iter 11, loss 2.0104641914367676, acc 0.20999999344348907\n",
      "Epoch 10, iter 12, loss 1.9468039274215698, acc 0.20000000298023224\n",
      "Epoch 10, iter 13, loss 1.9589717388153076, acc 0.18000000715255737\n",
      "Epoch 10, iter 14, loss 2.082929849624634, acc 0.20999999344348907\n",
      "Epoch 10, iter 15, loss 1.8666948080062866, acc 0.2800000011920929\n",
      "Epoch 10, iter 16, loss 1.838178277015686, acc 0.20999999344348907\n",
      "Epoch 10, iter 17, loss 1.8980941772460938, acc 0.1599999964237213\n",
      "Epoch 10, iter 18, loss 1.9842075109481812, acc 0.20000000298023224\n",
      "Epoch 10, iter 19, loss 1.931138515472412, acc 0.20999999344348907\n",
      "Epoch 10, iter 20, loss 1.909787893295288, acc 0.20000000298023224\n",
      "Epoch 10, iter 21, loss 1.8958706855773926, acc 0.25\n",
      "Epoch 10, iter 22, loss 1.9835646152496338, acc 0.2199999988079071\n",
      "Epoch 10, iter 23, loss 1.9924789667129517, acc 0.23000000417232513\n",
      "Epoch 10, iter 24, loss 1.9096096754074097, acc 0.25999999046325684\n",
      "Epoch 10, iter 25, loss 2.0026793479919434, acc 0.1899999976158142\n",
      "Epoch 10, iter 26, loss 1.9520241022109985, acc 0.1899999976158142\n",
      "Epoch 10, iter 27, loss 1.8858723640441895, acc 0.20999999344348907\n",
      "Epoch 10, iter 28, loss 1.9192696809768677, acc 0.23000000417232513\n",
      "Epoch 10, iter 29, loss 1.8948159217834473, acc 0.20999999344348907\n",
      "Epoch 10, iter 30, loss 2.1240639686584473, acc 0.1899999976158142\n",
      "Epoch 10, iter 31, loss 1.9984883069992065, acc 0.11999999731779099\n",
      "Epoch 10, iter 32, loss 1.980623722076416, acc 0.17000000178813934\n",
      "Epoch 10, iter 33, loss 1.9861332178115845, acc 0.23999999463558197\n",
      "Epoch 10, iter 34, loss 1.921457052230835, acc 0.1899999976158142\n",
      "Epoch 10, iter 35, loss 2.0934789180755615, acc 0.2199999988079071\n",
      "Epoch 10, iter 36, loss 1.9610741138458252, acc 0.18000000715255737\n",
      "Epoch 10, iter 37, loss 1.9275217056274414, acc 0.18000000715255737\n",
      "Epoch 10, iter 38, loss 1.8646312952041626, acc 0.25999999046325684\n",
      "Epoch 10, iter 39, loss 1.9496999979019165, acc 0.23000000417232513\n",
      "Epoch 10, iter 40, loss 1.9116852283477783, acc 0.20999999344348907\n",
      "Epoch 10, iter 41, loss 2.1068975925445557, acc 0.14000000059604645\n",
      "Epoch 10, iter 42, loss 2.0375077724456787, acc 0.1599999964237213\n",
      "Epoch 10, iter 43, loss 1.9076141119003296, acc 0.20000000298023224\n",
      "Epoch 10, iter 44, loss 1.9987518787384033, acc 0.18000000715255737\n",
      "Epoch 10, iter 45, loss 1.9332112073898315, acc 0.20999999344348907\n",
      "Epoch 10, iter 46, loss 1.94368314743042, acc 0.27000001072883606\n",
      "Epoch 10, iter 47, loss 1.9985761642456055, acc 0.1599999964237213\n",
      "Epoch 10, iter 48, loss 2.060424566268921, acc 0.1899999976158142\n",
      "Epoch 10, iter 49, loss 2.000509262084961, acc 0.20999999344348907\n",
      "Epoch 10, iter 50, loss 2.0283708572387695, acc 0.23000000417232513\n",
      "Epoch 10, iter 51, loss 1.8453776836395264, acc 0.25\n",
      "Epoch 10, iter 52, loss 1.9409023523330688, acc 0.20000000298023224\n",
      "Epoch 10, iter 53, loss 1.9781460762023926, acc 0.3199999928474426\n",
      "Epoch 10, iter 54, loss 1.8901787996292114, acc 0.11999999731779099\n",
      "Epoch 10, iter 55, loss 2.1047143936157227, acc 0.10000000149011612\n",
      "Epoch 10, iter 56, loss 1.98520827293396, acc 0.1599999964237213\n",
      "Epoch 10, iter 57, loss 1.925825834274292, acc 0.1899999976158142\n",
      "Epoch 10, iter 58, loss 1.9466191530227661, acc 0.1899999976158142\n",
      "Epoch 10, iter 59, loss 2.0089986324310303, acc 0.23999999463558197\n",
      "Epoch 10, iter 60, loss 1.9106800556182861, acc 0.2199999988079071\n",
      "Epoch 10, iter 61, loss 1.9629812240600586, acc 0.1599999964237213\n",
      "Epoch 10, iter 62, loss 1.9859397411346436, acc 0.20000000298023224\n",
      "Epoch 10, iter 63, loss 1.963965892791748, acc 0.23999999463558197\n",
      "Epoch 10, iter 64, loss 1.889432430267334, acc 0.20999999344348907\n",
      "Epoch 10, iter 65, loss 1.9225175380706787, acc 0.27000001072883606\n",
      "Epoch 10, iter 66, loss 1.970494031906128, acc 0.2199999988079071\n",
      "Epoch 10, iter 67, loss 1.9597529172897339, acc 0.1599999964237213\n",
      "Epoch 10, iter 68, loss 1.951311469078064, acc 0.23999999463558197\n",
      "Epoch 10, iter 69, loss 1.9822086095809937, acc 0.1899999976158142\n",
      "Epoch 10, iter 70, loss 1.9850653409957886, acc 0.27000001072883606\n",
      "Epoch 10, iter 71, loss 2.0578622817993164, acc 0.1599999964237213\n",
      "Epoch 10, iter 72, loss 1.951904296875, acc 0.15000000596046448\n",
      "Epoch 10, iter 73, loss 1.987682819366455, acc 0.20999999344348907\n",
      "Epoch 10, iter 74, loss 1.8894582986831665, acc 0.2199999988079071\n",
      "Epoch 10, iter 75, loss 1.9183021783828735, acc 0.12999999523162842\n",
      "Epoch 10, iter 76, loss 1.9219578504562378, acc 0.1899999976158142\n",
      "Epoch 10, iter 77, loss 2.044093132019043, acc 0.1599999964237213\n",
      "Epoch 10, iter 78, loss 1.9677255153656006, acc 0.2800000011920929\n",
      "Epoch 10, iter 79, loss 2.0085794925689697, acc 0.20999999344348907\n",
      "Epoch 10, iter 80, loss 2.0208330154418945, acc 0.1899999976158142\n",
      "Epoch 10, iter 81, loss 1.9357227087020874, acc 0.1599999964237213\n",
      "Epoch 10, iter 82, loss 1.993855595588684, acc 0.15000000596046448\n",
      "Epoch 10, iter 83, loss 2.0181446075439453, acc 0.20000000298023224\n",
      "Epoch 10, iter 84, loss 2.029858350753784, acc 0.14000000059604645\n",
      "Epoch 10, iter 85, loss 1.9516303539276123, acc 0.15000000596046448\n",
      "Epoch 10, iter 86, loss 1.9182168245315552, acc 0.20999999344348907\n",
      "Epoch 10, iter 87, loss 2.0354881286621094, acc 0.15000000596046448\n",
      "Epoch 10, iter 88, loss 1.9866572618484497, acc 0.23999999463558197\n",
      "Epoch 10, iter 89, loss 1.9802135229110718, acc 0.1899999976158142\n",
      "Epoch 10, iter 90, loss 1.8984897136688232, acc 0.1899999976158142\n",
      "Epoch 10, iter 91, loss 1.9681494235992432, acc 0.17000000178813934\n",
      "Epoch 10, iter 92, loss 1.9162330627441406, acc 0.15000000596046448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 93, loss 1.929071068763733, acc 0.2199999988079071\n",
      "Epoch 10, iter 94, loss 1.8725265264511108, acc 0.1599999964237213\n",
      "Epoch 10, iter 95, loss 1.9454584121704102, acc 0.1899999976158142\n",
      "Epoch 10, iter 96, loss 1.9179925918579102, acc 0.2199999988079071\n",
      "Epoch 10, iter 97, loss 1.9506335258483887, acc 0.10999999940395355\n",
      "Epoch 10, iter 98, loss 1.899953007698059, acc 0.18000000715255737\n",
      "Epoch 10, iter 99, loss 1.996575951576233, acc 0.1599999964237213\n",
      "Epoch 10, iter 100, loss 1.9578449726104736, acc 0.23999999463558197\n",
      "Epoch 10, iter 101, loss 1.9020999670028687, acc 0.2199999988079071\n",
      "Epoch 10, iter 102, loss 2.038090705871582, acc 0.23000000417232513\n",
      "Epoch 10, iter 103, loss 1.9843761920928955, acc 0.23999999463558197\n",
      "Epoch 10, iter 104, loss 2.009354829788208, acc 0.2800000011920929\n",
      "Epoch 10, iter 105, loss 1.8341935873031616, acc 0.1899999976158142\n",
      "Epoch 10, iter 106, loss 1.8391281366348267, acc 0.25999999046325684\n",
      "Epoch 10, iter 107, loss 1.9701662063598633, acc 0.2199999988079071\n",
      "Epoch 10, iter 108, loss 1.958418846130371, acc 0.12999999523162842\n",
      "Epoch 10, iter 109, loss 2.01931095123291, acc 0.2199999988079071\n",
      "Epoch 10, iter 110, loss 1.9420959949493408, acc 0.14000000059604645\n",
      "Epoch 10, iter 111, loss 1.9632043838500977, acc 0.17000000178813934\n",
      "Epoch 10, iter 112, loss 1.9534269571304321, acc 0.25999999046325684\n",
      "Epoch 10, iter 113, loss 1.9175223112106323, acc 0.23999999463558197\n",
      "Epoch 10, iter 114, loss 1.9290969371795654, acc 0.20999999344348907\n",
      "Epoch 10, iter 115, loss 1.868690848350525, acc 0.23999999463558197\n",
      "Epoch 10, iter 116, loss 1.943085789680481, acc 0.20999999344348907\n",
      "Epoch 10, iter 117, loss 1.9187573194503784, acc 0.20999999344348907\n",
      "Epoch 10, iter 118, loss 1.8736709356307983, acc 0.14000000059604645\n",
      "Epoch 10, iter 119, loss 2.006472110748291, acc 0.25\n",
      "Epoch 10, iter 120, loss 2.014885663986206, acc 0.23000000417232513\n",
      "Epoch 10, iter 121, loss 1.9254465103149414, acc 0.23000000417232513\n",
      "Epoch 10, iter 122, loss 1.9322034120559692, acc 0.30000001192092896\n",
      "Epoch 10, iter 123, loss 2.0227811336517334, acc 0.14000000059604645\n",
      "Epoch 10, iter 124, loss 1.8651766777038574, acc 0.2199999988079071\n",
      "Epoch 10, iter 125, loss 1.8969515562057495, acc 0.18000000715255737\n",
      "Epoch 10, iter 126, loss 1.892543911933899, acc 0.1899999976158142\n",
      "Epoch 10, iter 127, loss 1.9241658449172974, acc 0.2199999988079071\n",
      "Epoch 10, iter 128, loss 1.9070643186569214, acc 0.1899999976158142\n",
      "Epoch 10, iter 129, loss 2.0845251083374023, acc 0.1899999976158142\n",
      "Epoch 10, iter 130, loss 1.94843327999115, acc 0.20000000298023224\n",
      "Epoch 10, iter 131, loss 2.0114939212799072, acc 0.20999999344348907\n",
      "Epoch 10, iter 132, loss 1.985520601272583, acc 0.23999999463558197\n",
      "Epoch 10, iter 133, loss 1.9100500345230103, acc 0.23000000417232513\n",
      "Epoch 10, iter 134, loss 1.873396873474121, acc 0.15000000596046448\n",
      "Epoch 10, iter 135, loss 1.929805874824524, acc 0.28999999165534973\n",
      "Epoch 10, iter 136, loss 1.888037085533142, acc 0.2800000011920929\n",
      "Epoch 10, iter 137, loss 1.9514535665512085, acc 0.23999999463558197\n",
      "Epoch 10, iter 138, loss 1.9069637060165405, acc 0.2199999988079071\n",
      "Epoch 10, iter 139, loss 1.902680516242981, acc 0.20999999344348907\n",
      "Epoch 10, iter 140, loss 1.8731117248535156, acc 0.1899999976158142\n",
      "Epoch 10, iter 141, loss 1.9772709608078003, acc 0.20000000298023224\n",
      "Epoch 10, iter 142, loss 1.9174630641937256, acc 0.1599999964237213\n",
      "Epoch 10, iter 143, loss 1.9702637195587158, acc 0.20000000298023224\n",
      "Epoch 10, iter 144, loss 1.9472441673278809, acc 0.15000000596046448\n",
      "Epoch 10, iter 145, loss 1.922552466392517, acc 0.20000000298023224\n",
      "Epoch 10, iter 146, loss 1.9787230491638184, acc 0.23000000417232513\n",
      "Epoch 10, iter 147, loss 1.886309027671814, acc 0.20000000298023224\n",
      "Epoch 10, iter 148, loss 1.901522159576416, acc 0.25\n",
      "Epoch 10, iter 149, loss 1.9322288036346436, acc 0.25999999046325684\n",
      "Epoch 10, iter 150, loss 1.9681494235992432, acc 0.23000000417232513\n",
      "Epoch 10, iter 151, loss 1.8688491582870483, acc 0.2800000011920929\n",
      "Epoch 10, iter 152, loss 1.9154362678527832, acc 0.1599999964237213\n",
      "Epoch 10, iter 153, loss 1.9248045682907104, acc 0.18000000715255737\n",
      "Epoch 10, iter 154, loss 1.9840703010559082, acc 0.2199999988079071\n",
      "Epoch 10, iter 155, loss 1.8963435888290405, acc 0.23000000417232513\n",
      "Epoch 10, iter 156, loss 1.8945801258087158, acc 0.17000000178813934\n",
      "Epoch 10, iter 157, loss 1.8629252910614014, acc 0.17000000178813934\n",
      "Epoch 10, iter 158, loss 1.922346591949463, acc 0.20000000298023224\n",
      "Epoch 10, iter 159, loss 1.919541358947754, acc 0.20999999344348907\n",
      "Epoch 10, iter 160, loss 1.9298914670944214, acc 0.1899999976158142\n",
      "Epoch 10, iter 161, loss 1.8642268180847168, acc 0.23000000417232513\n",
      "Epoch 10, iter 162, loss 1.9606032371520996, acc 0.20999999344348907\n",
      "Epoch 10, iter 163, loss 1.9217689037322998, acc 0.17000000178813934\n",
      "Epoch 10, iter 164, loss 2.017108201980591, acc 0.23000000417232513\n",
      "Epoch 10, iter 165, loss 1.9951307773590088, acc 0.10999999940395355\n",
      "Epoch 10, iter 166, loss 1.8810511827468872, acc 0.25\n",
      "Epoch 10, iter 167, loss 1.9222373962402344, acc 0.20999999344348907\n",
      "Epoch 10, iter 168, loss 2.048825263977051, acc 0.20000000298023224\n",
      "Epoch 10, iter 169, loss 1.8849176168441772, acc 0.1899999976158142\n",
      "Epoch 10, iter 170, loss 1.8984434604644775, acc 0.2199999988079071\n",
      "Epoch 10, iter 171, loss 1.9547418355941772, acc 0.17000000178813934\n",
      "Epoch 10, iter 172, loss 1.9203698635101318, acc 0.20000000298023224\n",
      "Epoch 10, iter 173, loss 1.928233027458191, acc 0.15000000596046448\n",
      "Epoch 10, iter 174, loss 1.861821174621582, acc 0.20999999344348907\n",
      "Epoch 10, iter 175, loss 1.8971683979034424, acc 0.18000000715255737\n",
      "Epoch 10, iter 176, loss 1.9724844694137573, acc 0.18000000715255737\n",
      "Epoch 10, iter 177, loss 1.9443140029907227, acc 0.1599999964237213\n",
      "Epoch 10, iter 178, loss 1.9333579540252686, acc 0.20999999344348907\n",
      "Epoch 10, iter 179, loss 1.883766770362854, acc 0.14000000059604645\n",
      "Epoch 10, iter 180, loss 1.8963978290557861, acc 0.2199999988079071\n",
      "Epoch 10, iter 181, loss 1.8625231981277466, acc 0.20000000298023224\n",
      "Epoch 10, iter 182, loss 1.8161611557006836, acc 0.18000000715255737\n",
      "Epoch 10, iter 183, loss 1.8751903772354126, acc 0.20000000298023224\n",
      "Epoch 10, iter 184, loss 1.8716717958450317, acc 0.18000000715255737\n",
      "Epoch 10, iter 185, loss 1.8851234912872314, acc 0.2199999988079071\n",
      "Epoch 10, iter 186, loss 1.909658670425415, acc 0.2199999988079071\n",
      "Epoch 10, iter 187, loss 1.9094356298446655, acc 0.23000000417232513\n",
      "Epoch 10, iter 188, loss 2.0373127460479736, acc 0.20999999344348907\n",
      "Epoch 10, iter 189, loss 1.9720027446746826, acc 0.18000000715255737\n",
      "Epoch 10, iter 190, loss 1.8774501085281372, acc 0.18000000715255737\n",
      "Epoch 10, iter 191, loss 1.9244091510772705, acc 0.20999999344348907\n",
      "Epoch 10, iter 192, loss 1.858811616897583, acc 0.3100000023841858\n",
      "Epoch 10, iter 193, loss 1.8850871324539185, acc 0.1899999976158142\n",
      "Epoch 10, iter 194, loss 1.9135910272598267, acc 0.25999999046325684\n",
      "Epoch 10, iter 195, loss 1.9038949012756348, acc 0.23999999463558197\n",
      "Epoch 10, iter 196, loss 2.0995473861694336, acc 0.17000000178813934\n",
      "Epoch 10, iter 197, loss 1.9533944129943848, acc 0.12999999523162842\n",
      "Epoch 10, iter 198, loss 1.8858712911605835, acc 0.3199999928474426\n",
      "Epoch 10, iter 199, loss 1.9659782648086548, acc 0.18000000715255737\n",
      "Epoch 10, iter 200, loss 1.9859800338745117, acc 0.20000000298023224\n",
      "Epoch 10, iter 201, loss 1.929685354232788, acc 0.23000000417232513\n",
      "Epoch 10, iter 202, loss 2.020205497741699, acc 0.1599999964237213\n",
      "Epoch 10, iter 203, loss 1.904239296913147, acc 0.11999999731779099\n",
      "Epoch 10, iter 204, loss 1.9250849485397339, acc 0.20999999344348907\n",
      "Epoch 10, iter 205, loss 1.901496171951294, acc 0.23999999463558197\n",
      "Epoch 10, iter 206, loss 1.9669145345687866, acc 0.20000000298023224\n",
      "Epoch 10, iter 207, loss 1.8891769647598267, acc 0.1599999964237213\n",
      "Epoch 10, iter 208, loss 1.9206913709640503, acc 0.17000000178813934\n",
      "Epoch 10, iter 209, loss 1.8982146978378296, acc 0.18000000715255737\n",
      "Epoch 10, iter 210, loss 2.008469820022583, acc 0.1899999976158142\n",
      "Epoch 10, iter 211, loss 1.8879183530807495, acc 0.23999999463558197\n",
      "Epoch 10, iter 212, loss 1.9340916872024536, acc 0.18000000715255737\n",
      "Epoch 10, iter 213, loss 2.010852575302124, acc 0.10000000149011612\n",
      "Epoch 10, iter 214, loss 1.957565426826477, acc 0.18000000715255737\n",
      "Epoch 10, iter 215, loss 2.006570339202881, acc 0.17000000178813934\n",
      "Epoch 10, iter 216, loss 2.0004472732543945, acc 0.2199999988079071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 217, loss 1.8355532884597778, acc 0.20999999344348907\n",
      "Epoch 10, iter 218, loss 2.0524165630340576, acc 0.15000000596046448\n",
      "Epoch 10, iter 219, loss 2.012756824493408, acc 0.1599999964237213\n",
      "Epoch 10, iter 220, loss 1.9423762559890747, acc 0.1599999964237213\n",
      "Epoch 10, iter 221, loss 1.8519364595413208, acc 0.18000000715255737\n",
      "Epoch 10, iter 222, loss 1.928844928741455, acc 0.20999999344348907\n",
      "Epoch 10, iter 223, loss 1.9163936376571655, acc 0.27000001072883606\n",
      "Epoch 10, iter 224, loss 1.8755031824111938, acc 0.23999999463558197\n",
      "Epoch 10, iter 225, loss 1.8735268115997314, acc 0.2199999988079071\n",
      "Epoch 10, iter 226, loss 1.9069552421569824, acc 0.23999999463558197\n",
      "Epoch 10, iter 227, loss 1.9613969326019287, acc 0.23999999463558197\n",
      "Epoch 10, iter 228, loss 1.9450031518936157, acc 0.1899999976158142\n",
      "Epoch 10, iter 229, loss 1.8856897354125977, acc 0.20999999344348907\n",
      "Epoch 10, iter 230, loss 2.001882553100586, acc 0.23999999463558197\n",
      "Epoch 10, iter 231, loss 2.069774866104126, acc 0.2199999988079071\n",
      "Epoch 10, iter 232, loss 1.9721664190292358, acc 0.15000000596046448\n",
      "Epoch 10, iter 233, loss 1.9655849933624268, acc 0.23999999463558197\n",
      "Epoch 10, iter 234, loss 1.9398388862609863, acc 0.25999999046325684\n",
      "Epoch 10, iter 235, loss 1.8422448635101318, acc 0.23000000417232513\n",
      "Epoch 10, iter 236, loss 1.9693876504898071, acc 0.17000000178813934\n",
      "Epoch 10, iter 237, loss 1.9684754610061646, acc 0.18000000715255737\n",
      "Epoch 10, iter 238, loss 1.9876434803009033, acc 0.20000000298023224\n",
      "Epoch 10, iter 239, loss 1.9389077425003052, acc 0.15000000596046448\n",
      "Epoch 10, iter 240, loss 1.9040714502334595, acc 0.17000000178813934\n",
      "Epoch 10, iter 241, loss 1.9772329330444336, acc 0.14000000059604645\n",
      "Epoch 10, iter 242, loss 1.9937102794647217, acc 0.23000000417232513\n",
      "Epoch 10, iter 243, loss 1.9684147834777832, acc 0.17000000178813934\n",
      "Epoch 10, iter 244, loss 1.9102375507354736, acc 0.27000001072883606\n",
      "Epoch 10, iter 245, loss 1.9509409666061401, acc 0.20000000298023224\n",
      "Epoch 10, iter 246, loss 1.897597074508667, acc 0.1599999964237213\n",
      "Epoch 10, iter 247, loss 1.8658376932144165, acc 0.25\n",
      "Epoch 10, iter 248, loss 2.042623996734619, acc 0.17000000178813934\n",
      "Epoch 10, iter 249, loss 1.903005838394165, acc 0.11999999731779099\n",
      "Epoch 10, iter 250, loss 1.831791639328003, acc 0.28999999165534973\n",
      "Epoch 10, iter 251, loss 1.9155884981155396, acc 0.1899999976158142\n",
      "Epoch 10, iter 252, loss 1.9478251934051514, acc 0.23000000417232513\n",
      "Epoch 10, iter 253, loss 2.0373446941375732, acc 0.14000000059604645\n",
      "Epoch 10, iter 254, loss 1.8970707654953003, acc 0.20000000298023224\n",
      "Epoch 10, iter 255, loss 1.9421310424804688, acc 0.17000000178813934\n",
      "Epoch 10, iter 256, loss 1.895262598991394, acc 0.23000000417232513\n",
      "Epoch 10, iter 257, loss 1.9197293519973755, acc 0.17000000178813934\n",
      "Epoch 10, iter 258, loss 1.948830008506775, acc 0.23000000417232513\n",
      "Epoch 10, iter 259, loss 1.8899754285812378, acc 0.23999999463558197\n",
      "Epoch 10, iter 260, loss 1.9359207153320312, acc 0.17000000178813934\n",
      "Epoch 10, iter 261, loss 1.813280463218689, acc 0.23000000417232513\n",
      "Epoch 10, iter 262, loss 1.915376901626587, acc 0.1599999964237213\n",
      "Epoch 10, iter 263, loss 1.8286867141723633, acc 0.2199999988079071\n",
      "Epoch 10, iter 264, loss 1.9261060953140259, acc 0.27000001072883606\n",
      "Epoch 10, iter 265, loss 1.903475046157837, acc 0.23000000417232513\n",
      "Epoch 10, iter 266, loss 1.8971104621887207, acc 0.17000000178813934\n",
      "Epoch 10, iter 267, loss 1.888620138168335, acc 0.2800000011920929\n",
      "Epoch 10, iter 268, loss 1.8723042011260986, acc 0.12999999523162842\n",
      "Epoch 10, iter 269, loss 1.9492568969726562, acc 0.1899999976158142\n",
      "Epoch 10, iter 270, loss 1.9190031290054321, acc 0.1599999964237213\n",
      "Epoch 10, iter 271, loss 1.9302018880844116, acc 0.1899999976158142\n",
      "Epoch 10, iter 272, loss 1.9291737079620361, acc 0.2199999988079071\n",
      "Epoch 10, iter 273, loss 1.9064068794250488, acc 0.20000000298023224\n",
      "Epoch 10, iter 274, loss 2.0267953872680664, acc 0.20999999344348907\n",
      "Epoch 10, iter 275, loss 1.8676502704620361, acc 0.18000000715255737\n",
      "Epoch 10, iter 276, loss 2.034390449523926, acc 0.20000000298023224\n",
      "Epoch 10, iter 277, loss 1.9198217391967773, acc 0.20999999344348907\n",
      "Epoch 10, iter 278, loss 1.9005730152130127, acc 0.17000000178813934\n",
      "Epoch 10, iter 279, loss 1.9511520862579346, acc 0.2800000011920929\n",
      "Epoch 10, iter 280, loss 1.9610302448272705, acc 0.1899999976158142\n",
      "Epoch 10, iter 281, loss 1.901224970817566, acc 0.28999999165534973\n",
      "Epoch 10, iter 282, loss 1.8768872022628784, acc 0.18000000715255737\n",
      "Epoch 10, iter 283, loss 1.9601963758468628, acc 0.17000000178813934\n",
      "Epoch 10, iter 284, loss 1.9707627296447754, acc 0.25999999046325684\n",
      "Epoch 10, iter 285, loss 1.9781391620635986, acc 0.1899999976158142\n",
      "Epoch 10, iter 286, loss 1.873663067817688, acc 0.23000000417232513\n",
      "Epoch 10, iter 287, loss 1.907339334487915, acc 0.20000000298023224\n",
      "Epoch 10, iter 288, loss 2.0289008617401123, acc 0.20999999344348907\n",
      "Epoch 10, iter 289, loss 1.9620224237442017, acc 0.23000000417232513\n",
      "Epoch 10, iter 290, loss 1.9329349994659424, acc 0.2199999988079071\n",
      "Epoch 10, iter 291, loss 1.9781779050827026, acc 0.20000000298023224\n",
      "Epoch 10, iter 292, loss 1.9891334772109985, acc 0.23999999463558197\n",
      "Epoch 10, iter 293, loss 2.004452705383301, acc 0.1899999976158142\n",
      "Epoch 10, iter 294, loss 2.0319664478302, acc 0.15000000596046448\n",
      "Epoch 10, iter 295, loss 2.041654586791992, acc 0.18000000715255737\n",
      "Epoch 10, iter 296, loss 1.8676505088806152, acc 0.20999999344348907\n",
      "Epoch 10, iter 297, loss 2.120535373687744, acc 0.2199999988079071\n",
      "Epoch 10, iter 298, loss 1.9275342226028442, acc 0.23999999463558197\n",
      "Epoch 10, iter 299, loss 2.0405211448669434, acc 0.09000000357627869\n",
      "Epoch 10, iter 300, loss 2.0413177013397217, acc 0.17000000178813934\n",
      "Epoch 10, iter 301, loss 2.0269627571105957, acc 0.20999999344348907\n",
      "Epoch 10, iter 302, loss 1.9319043159484863, acc 0.25999999046325684\n",
      "Epoch 10, iter 303, loss 1.9437298774719238, acc 0.20000000298023224\n",
      "Epoch 10, iter 304, loss 2.0239429473876953, acc 0.1599999964237213\n",
      "Epoch 10, iter 305, loss 1.961118221282959, acc 0.1599999964237213\n",
      "Epoch 10, iter 306, loss 1.9530771970748901, acc 0.20000000298023224\n",
      "Epoch 10, iter 307, loss 1.893345594406128, acc 0.23000000417232513\n",
      "Epoch 10, iter 308, loss 2.0618059635162354, acc 0.20000000298023224\n",
      "Epoch 10, iter 309, loss 1.9767292737960815, acc 0.1899999976158142\n",
      "Epoch 10, iter 310, loss 2.024104595184326, acc 0.1899999976158142\n",
      "Epoch 10, iter 311, loss 2.0353925228118896, acc 0.18000000715255737\n",
      "Epoch 10, iter 312, loss 1.9536556005477905, acc 0.27000001072883606\n",
      "Epoch 10, iter 313, loss 1.9495017528533936, acc 0.20999999344348907\n",
      "Epoch 10, iter 314, loss 1.9823969602584839, acc 0.25999999046325684\n",
      "Epoch 10, iter 315, loss 1.9629156589508057, acc 0.20000000298023224\n",
      "Epoch 10, iter 316, loss 2.0450210571289062, acc 0.10999999940395355\n",
      "Epoch 10, iter 317, loss 2.1265206336975098, acc 0.15000000596046448\n",
      "Epoch 10, iter 318, loss 1.9870097637176514, acc 0.20000000298023224\n",
      "Epoch 10, iter 319, loss 1.9736824035644531, acc 0.1899999976158142\n",
      "Epoch 10, iter 320, loss 2.2614355087280273, acc 0.12999999523162842\n",
      "Epoch 10, iter 321, loss 2.0832037925720215, acc 0.14000000059604645\n",
      "Epoch 10, iter 322, loss 2.0174927711486816, acc 0.1899999976158142\n",
      "Epoch 10, iter 323, loss 1.963842511177063, acc 0.20000000298023224\n",
      "Epoch 10, iter 324, loss 1.925744891166687, acc 0.27000001072883606\n",
      "Epoch 10, iter 325, loss 2.0217697620391846, acc 0.18000000715255737\n",
      "Epoch 10, iter 326, loss 1.944976806640625, acc 0.2199999988079071\n",
      "Epoch 10, iter 327, loss 1.9590387344360352, acc 0.1599999964237213\n",
      "Epoch 10, iter 328, loss 1.9866982698440552, acc 0.23000000417232513\n",
      "Epoch 10, iter 329, loss 2.061178207397461, acc 0.2199999988079071\n",
      "Epoch 10, iter 330, loss 1.9603970050811768, acc 0.12999999523162842\n",
      "Epoch 10, iter 331, loss 1.9623855352401733, acc 0.18000000715255737\n",
      "Epoch 10, iter 332, loss 1.9959094524383545, acc 0.18000000715255737\n",
      "Epoch 10, iter 333, loss 1.9254558086395264, acc 0.15000000596046448\n",
      "Epoch 10, iter 334, loss 1.9624484777450562, acc 0.20999999344348907\n",
      "Epoch 10, iter 335, loss 2.0166704654693604, acc 0.23999999463558197\n",
      "Epoch 10, iter 336, loss 1.9567593336105347, acc 0.2199999988079071\n",
      "Epoch 10, iter 337, loss 1.956933617591858, acc 0.2199999988079071\n",
      "Epoch 10, iter 338, loss 1.9719328880310059, acc 0.2199999988079071\n",
      "Epoch 10, iter 339, loss 1.9340074062347412, acc 0.23000000417232513\n",
      "Epoch 10, iter 340, loss 2.0122580528259277, acc 0.18000000715255737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 341, loss 1.8972057104110718, acc 0.25\n",
      "Epoch 10, iter 342, loss 2.002013921737671, acc 0.23000000417232513\n",
      "Epoch 10, iter 343, loss 1.9470114707946777, acc 0.1899999976158142\n",
      "Epoch 10, iter 344, loss 1.9121705293655396, acc 0.27000001072883606\n",
      "Epoch 10, iter 345, loss 1.937361717224121, acc 0.1899999976158142\n",
      "Epoch 10, iter 346, loss 1.973631739616394, acc 0.25999999046325684\n",
      "Epoch 10, iter 347, loss 1.9576022624969482, acc 0.17000000178813934\n",
      "Epoch 10, iter 348, loss 1.9956932067871094, acc 0.25\n",
      "Epoch 10, iter 349, loss 2.0254149436950684, acc 0.23000000417232513\n",
      "Epoch 10, iter 350, loss 1.9843045473098755, acc 0.18000000715255737\n",
      "Epoch 10, iter 351, loss 2.1157195568084717, acc 0.11999999731779099\n",
      "Epoch 10, iter 352, loss 1.9463441371917725, acc 0.1899999976158142\n",
      "Epoch 10, iter 353, loss 1.9671391248703003, acc 0.14000000059604645\n",
      "Epoch 10, iter 354, loss 2.022249460220337, acc 0.25\n",
      "Epoch 10, iter 355, loss 1.9991642236709595, acc 0.1899999976158142\n",
      "Epoch 10, iter 356, loss 1.9756481647491455, acc 0.23000000417232513\n",
      "Epoch 10, iter 357, loss 1.9353998899459839, acc 0.2199999988079071\n",
      "Epoch 10, iter 358, loss 2.102492332458496, acc 0.14000000059604645\n",
      "Epoch 10, iter 359, loss 1.9133589267730713, acc 0.12999999523162842\n",
      "Epoch 10, iter 360, loss 1.926714301109314, acc 0.23000000417232513\n",
      "Epoch 10, iter 361, loss 1.994805097579956, acc 0.20000000298023224\n",
      "Epoch 10, iter 362, loss 1.9945480823516846, acc 0.15000000596046448\n",
      "Epoch 10, iter 363, loss 1.9761533737182617, acc 0.25\n",
      "Epoch 10, iter 364, loss 1.9900888204574585, acc 0.11999999731779099\n",
      "Epoch 10, iter 365, loss 2.0413198471069336, acc 0.17000000178813934\n",
      "Epoch 10, iter 366, loss 1.9579429626464844, acc 0.25\n",
      "Epoch 10, iter 367, loss 1.904310703277588, acc 0.2199999988079071\n",
      "Epoch 10, iter 368, loss 1.9791797399520874, acc 0.23000000417232513\n",
      "Epoch 10, iter 369, loss 1.9301025867462158, acc 0.23999999463558197\n",
      "Epoch 10, iter 370, loss 1.9708831310272217, acc 0.20000000298023224\n",
      "Epoch 10, iter 371, loss 1.9896197319030762, acc 0.23999999463558197\n",
      "Epoch 10, iter 372, loss 1.8928428888320923, acc 0.23000000417232513\n",
      "Epoch 10, iter 373, loss 1.8989425897598267, acc 0.17000000178813934\n",
      "Epoch 10, iter 374, loss 2.0095183849334717, acc 0.1899999976158142\n",
      "Epoch 10, iter 375, loss 2.0000617504119873, acc 0.2800000011920929\n",
      "Epoch 10, iter 376, loss 1.880293607711792, acc 0.15000000596046448\n",
      "Epoch 10, iter 377, loss 2.012366533279419, acc 0.25\n",
      "Epoch 10, iter 378, loss 1.94648015499115, acc 0.23999999463558197\n",
      "Epoch 10, iter 379, loss 1.9777981042861938, acc 0.17000000178813934\n",
      "Epoch 10, iter 380, loss 1.9938383102416992, acc 0.15000000596046448\n",
      "Epoch 10, iter 381, loss 1.9520673751831055, acc 0.15000000596046448\n",
      "Epoch 10, iter 382, loss 1.861961007118225, acc 0.25\n",
      "Epoch 10, iter 383, loss 2.0574278831481934, acc 0.23000000417232513\n",
      "Epoch 10, iter 384, loss 1.9189332723617554, acc 0.18000000715255737\n",
      "Epoch 10, iter 385, loss 1.854772686958313, acc 0.23000000417232513\n",
      "Epoch 10, iter 386, loss 1.9516428709030151, acc 0.20000000298023224\n",
      "Epoch 10, iter 387, loss 1.980736255645752, acc 0.2199999988079071\n",
      "Epoch 10, iter 388, loss 1.922460675239563, acc 0.20000000298023224\n",
      "Epoch 10, iter 389, loss 1.905450701713562, acc 0.20999999344348907\n",
      "Epoch 10, iter 390, loss 2.0055723190307617, acc 0.09000000357627869\n",
      "Epoch 10, iter 391, loss 1.8909999132156372, acc 0.1899999976158142\n",
      "Epoch 10, iter 392, loss 1.9590628147125244, acc 0.1599999964237213\n",
      "Epoch 10, iter 393, loss 1.957969307899475, acc 0.14000000059604645\n",
      "Epoch 10, iter 394, loss 1.8691716194152832, acc 0.20000000298023224\n",
      "Epoch 10, iter 395, loss 1.9552202224731445, acc 0.25\n",
      "Epoch 10, iter 396, loss 1.9341851472854614, acc 0.14000000059604645\n",
      "Epoch 10, iter 397, loss 1.8825852870941162, acc 0.1599999964237213\n",
      "Epoch 10, iter 398, loss 1.9579695463180542, acc 0.15000000596046448\n",
      "Epoch 10, iter 399, loss 1.9098854064941406, acc 0.1899999976158142\n",
      "Epoch 10, iter 400, loss 1.9313620328903198, acc 0.2800000011920929\n",
      "Epoch 10, iter 401, loss 1.8804805278778076, acc 0.20999999344348907\n",
      "Epoch 10, iter 402, loss 1.9667364358901978, acc 0.20000000298023224\n",
      "Epoch 10, iter 403, loss 1.9853211641311646, acc 0.1899999976158142\n",
      "Epoch 10, iter 404, loss 2.0127553939819336, acc 0.1599999964237213\n",
      "Epoch 10, iter 405, loss 1.9780994653701782, acc 0.23000000417232513\n",
      "Epoch 10, iter 406, loss 1.9735922813415527, acc 0.11999999731779099\n",
      "Epoch 10, iter 407, loss 1.9760550260543823, acc 0.14000000059604645\n",
      "Epoch 10, iter 408, loss 1.893233060836792, acc 0.1899999976158142\n",
      "Epoch 10, iter 409, loss 1.9235291481018066, acc 0.2199999988079071\n",
      "Epoch 10, iter 410, loss 1.8800380229949951, acc 0.1899999976158142\n",
      "Epoch 10, iter 411, loss 1.8731733560562134, acc 0.28999999165534973\n",
      "Epoch 10, iter 412, loss 1.9414241313934326, acc 0.1899999976158142\n",
      "Epoch 10, iter 413, loss 1.9951897859573364, acc 0.15000000596046448\n",
      "Epoch 10, iter 414, loss 1.8554902076721191, acc 0.1599999964237213\n",
      "Epoch 10, iter 415, loss 1.903910517692566, acc 0.18000000715255737\n",
      "Epoch 10, iter 416, loss 1.9387173652648926, acc 0.25999999046325684\n",
      "Epoch 10, iter 417, loss 2.0006120204925537, acc 0.2800000011920929\n",
      "Epoch 10, iter 418, loss 1.8746598958969116, acc 0.1899999976158142\n",
      "Epoch 10, iter 419, loss 1.8706483840942383, acc 0.23999999463558197\n",
      "Epoch 10, iter 420, loss 2.0033254623413086, acc 0.23000000417232513\n"
     ]
    }
   ],
   "source": [
    "Loss=[]\n",
    "num_epoch=10\n",
    "for i in range(num_epoch):\n",
    "    for j,batch in enumerate(mnist_batched):\n",
    "        x=batch['X']\n",
    "        Y=batch['y']\n",
    "        p=mod(x.float())\n",
    "        loss=CE(p,Y)\n",
    "        loss.backward()\n",
    "        Loss.append(loss.item())\n",
    "        acc=(p.argmax(axis=1)==Y).float().mean().item()\n",
    "        print(f\"Epoch {i+1}, iter {j+1}, loss {loss.item()}, acc {acc}\")\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x137bcb5d0>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(Loss)),Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can make one last change, instead of defining a loss function ourselves we will use a predifined one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gunnvantsaini/miniconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 1, loss 2.298886299133301, acc 0.05000000074505806\n",
      "Epoch 1, iter 2, loss 2.299427032470703, acc 0.07000000029802322\n",
      "Epoch 1, iter 3, loss 2.2928478717803955, acc 0.03999999910593033\n",
      "Epoch 1, iter 4, loss 2.3054468631744385, acc 0.05999999865889549\n",
      "Epoch 1, iter 5, loss 2.3021371364593506, acc 0.07000000029802322\n",
      "Epoch 1, iter 6, loss 2.307072639465332, acc 0.07000000029802322\n",
      "Epoch 1, iter 7, loss 2.3009884357452393, acc 0.019999999552965164\n",
      "Epoch 1, iter 8, loss 2.297549247741699, acc 0.05999999865889549\n",
      "Epoch 1, iter 9, loss 2.2971537113189697, acc 0.07999999821186066\n",
      "Epoch 1, iter 10, loss 2.3003745079040527, acc 0.05000000074505806\n",
      "Epoch 1, iter 11, loss 2.3002185821533203, acc 0.09000000357627869\n",
      "Epoch 1, iter 12, loss 2.3004846572875977, acc 0.07999999821186066\n",
      "Epoch 1, iter 13, loss 2.299527645111084, acc 0.07000000029802322\n",
      "Epoch 1, iter 14, loss 2.2902917861938477, acc 0.09000000357627869\n",
      "Epoch 1, iter 15, loss 2.282951831817627, acc 0.07000000029802322\n",
      "Epoch 1, iter 16, loss 2.288849115371704, acc 0.10000000149011612\n",
      "Epoch 1, iter 17, loss 2.2976300716400146, acc 0.05999999865889549\n",
      "Epoch 1, iter 18, loss 2.29718017578125, acc 0.05999999865889549\n",
      "Epoch 1, iter 19, loss 2.296088933944702, acc 0.03999999910593033\n",
      "Epoch 1, iter 20, loss 2.2938392162323, acc 0.05000000074505806\n",
      "Epoch 1, iter 21, loss 2.2869465351104736, acc 0.05000000074505806\n",
      "Epoch 1, iter 22, loss 2.293290376663208, acc 0.05000000074505806\n",
      "Epoch 1, iter 23, loss 2.28753924369812, acc 0.11999999731779099\n",
      "Epoch 1, iter 24, loss 2.296445369720459, acc 0.019999999552965164\n",
      "Epoch 1, iter 25, loss 2.296401023864746, acc 0.07999999821186066\n",
      "Epoch 1, iter 26, loss 2.2944304943084717, acc 0.05999999865889549\n",
      "Epoch 1, iter 27, loss 2.281611919403076, acc 0.17000000178813934\n",
      "Epoch 1, iter 28, loss 2.2910499572753906, acc 0.07999999821186066\n",
      "Epoch 1, iter 29, loss 2.2923383712768555, acc 0.10000000149011612\n",
      "Epoch 1, iter 30, loss 2.297685146331787, acc 0.10000000149011612\n",
      "Epoch 1, iter 31, loss 2.2997756004333496, acc 0.10000000149011612\n",
      "Epoch 1, iter 32, loss 2.290113925933838, acc 0.05999999865889549\n",
      "Epoch 1, iter 33, loss 2.290876626968384, acc 0.15000000596046448\n",
      "Epoch 1, iter 34, loss 2.2929608821868896, acc 0.09000000357627869\n",
      "Epoch 1, iter 35, loss 2.2906041145324707, acc 0.10000000149011612\n",
      "Epoch 1, iter 36, loss 2.2978124618530273, acc 0.09000000357627869\n",
      "Epoch 1, iter 37, loss 2.293996810913086, acc 0.10999999940395355\n",
      "Epoch 1, iter 38, loss 2.2903192043304443, acc 0.17000000178813934\n",
      "Epoch 1, iter 39, loss 2.2880125045776367, acc 0.10999999940395355\n",
      "Epoch 1, iter 40, loss 2.281367063522339, acc 0.05000000074505806\n",
      "Epoch 1, iter 41, loss 2.2991831302642822, acc 0.07000000029802322\n",
      "Epoch 1, iter 42, loss 2.2880702018737793, acc 0.09000000357627869\n",
      "Epoch 1, iter 43, loss 2.282827377319336, acc 0.09000000357627869\n",
      "Epoch 1, iter 44, loss 2.2855958938598633, acc 0.05999999865889549\n",
      "Epoch 1, iter 45, loss 2.2909293174743652, acc 0.10999999940395355\n",
      "Epoch 1, iter 46, loss 2.28629732131958, acc 0.17000000178813934\n",
      "Epoch 1, iter 47, loss 2.298499822616577, acc 0.05999999865889549\n",
      "Epoch 1, iter 48, loss 2.285886287689209, acc 0.07000000029802322\n",
      "Epoch 1, iter 49, loss 2.2930970191955566, acc 0.10000000149011612\n",
      "Epoch 1, iter 50, loss 2.2912042140960693, acc 0.10999999940395355\n",
      "Epoch 1, iter 51, loss 2.2828774452209473, acc 0.10999999940395355\n",
      "Epoch 1, iter 52, loss 2.2910516262054443, acc 0.10999999940395355\n",
      "Epoch 1, iter 53, loss 2.283045768737793, acc 0.18000000715255737\n",
      "Epoch 1, iter 54, loss 2.2901763916015625, acc 0.05999999865889549\n",
      "Epoch 1, iter 55, loss 2.304318904876709, acc 0.09000000357627869\n",
      "Epoch 1, iter 56, loss 2.289983034133911, acc 0.10000000149011612\n",
      "Epoch 1, iter 57, loss 2.2941229343414307, acc 0.11999999731779099\n",
      "Epoch 1, iter 58, loss 2.289384126663208, acc 0.11999999731779099\n",
      "Epoch 1, iter 59, loss 2.280949115753174, acc 0.11999999731779099\n",
      "Epoch 1, iter 60, loss 2.288236141204834, acc 0.14000000059604645\n",
      "Epoch 1, iter 61, loss 2.2862207889556885, acc 0.07999999821186066\n",
      "Epoch 1, iter 62, loss 2.286728858947754, acc 0.10000000149011612\n",
      "Epoch 1, iter 63, loss 2.2851369380950928, acc 0.12999999523162842\n",
      "Epoch 1, iter 64, loss 2.277604579925537, acc 0.05999999865889549\n",
      "Epoch 1, iter 65, loss 2.281911849975586, acc 0.15000000596046448\n",
      "Epoch 1, iter 66, loss 2.2821035385131836, acc 0.20999999344348907\n",
      "Epoch 1, iter 67, loss 2.293877601623535, acc 0.18000000715255737\n",
      "Epoch 1, iter 68, loss 2.271867275238037, acc 0.33000001311302185\n",
      "Epoch 1, iter 69, loss 2.289438247680664, acc 0.18000000715255737\n",
      "Epoch 1, iter 70, loss 2.2828073501586914, acc 0.27000001072883606\n",
      "Epoch 1, iter 71, loss 2.2901394367218018, acc 0.17000000178813934\n",
      "Epoch 1, iter 72, loss 2.2850887775421143, acc 0.14000000059604645\n",
      "Epoch 1, iter 73, loss 2.2824177742004395, acc 0.23000000417232513\n",
      "Epoch 1, iter 74, loss 2.282972574234009, acc 0.20000000298023224\n",
      "Epoch 1, iter 75, loss 2.2890074253082275, acc 0.12999999523162842\n",
      "Epoch 1, iter 76, loss 2.284970760345459, acc 0.20000000298023224\n",
      "Epoch 1, iter 77, loss 2.2924394607543945, acc 0.18000000715255737\n",
      "Epoch 1, iter 78, loss 2.280305862426758, acc 0.27000001072883606\n",
      "Epoch 1, iter 79, loss 2.283123254776001, acc 0.25999999046325684\n",
      "Epoch 1, iter 80, loss 2.284217119216919, acc 0.18000000715255737\n",
      "Epoch 1, iter 81, loss 2.289461612701416, acc 0.1599999964237213\n",
      "Epoch 1, iter 82, loss 2.2903265953063965, acc 0.1599999964237213\n",
      "Epoch 1, iter 83, loss 2.275233507156372, acc 0.2199999988079071\n",
      "Epoch 1, iter 84, loss 2.2908005714416504, acc 0.10999999940395355\n",
      "Epoch 1, iter 85, loss 2.2903428077697754, acc 0.15000000596046448\n",
      "Epoch 1, iter 86, loss 2.2781896591186523, acc 0.20000000298023224\n",
      "Epoch 1, iter 87, loss 2.2811591625213623, acc 0.25\n",
      "Epoch 1, iter 88, loss 2.271594762802124, acc 0.25999999046325684\n",
      "Epoch 1, iter 89, loss 2.2802393436431885, acc 0.1899999976158142\n",
      "Epoch 1, iter 90, loss 2.278435468673706, acc 0.1899999976158142\n",
      "Epoch 1, iter 91, loss 2.27978253364563, acc 0.20999999344348907\n",
      "Epoch 1, iter 92, loss 2.286241292953491, acc 0.20000000298023224\n",
      "Epoch 1, iter 93, loss 2.276796817779541, acc 0.2199999988079071\n",
      "Epoch 1, iter 94, loss 2.287060022354126, acc 0.1599999964237213\n",
      "Epoch 1, iter 95, loss 2.276937961578369, acc 0.20999999344348907\n",
      "Epoch 1, iter 96, loss 2.284107208251953, acc 0.23000000417232513\n",
      "Epoch 1, iter 97, loss 2.2863411903381348, acc 0.11999999731779099\n",
      "Epoch 1, iter 98, loss 2.2842767238616943, acc 0.1899999976158142\n",
      "Epoch 1, iter 99, loss 2.280959367752075, acc 0.23999999463558197\n",
      "Epoch 1, iter 100, loss 2.2787206172943115, acc 0.25999999046325684\n",
      "Epoch 1, iter 101, loss 2.2736246585845947, acc 0.2199999988079071\n",
      "Epoch 1, iter 102, loss 2.279078483581543, acc 0.25\n",
      "Epoch 1, iter 103, loss 2.2711141109466553, acc 0.28999999165534973\n",
      "Epoch 1, iter 104, loss 2.2819550037384033, acc 0.2800000011920929\n",
      "Epoch 1, iter 105, loss 2.2739315032958984, acc 0.18000000715255737\n",
      "Epoch 1, iter 106, loss 2.280435085296631, acc 0.25\n",
      "Epoch 1, iter 107, loss 2.2798047065734863, acc 0.1899999976158142\n",
      "Epoch 1, iter 108, loss 2.284303903579712, acc 0.14000000059604645\n",
      "Epoch 1, iter 109, loss 2.2785348892211914, acc 0.2199999988079071\n",
      "Epoch 1, iter 110, loss 2.282661199569702, acc 0.14000000059604645\n",
      "Epoch 1, iter 111, loss 2.280416488647461, acc 0.1599999964237213\n",
      "Epoch 1, iter 112, loss 2.277390241622925, acc 0.25\n",
      "Epoch 1, iter 113, loss 2.2657086849212646, acc 0.25999999046325684\n",
      "Epoch 1, iter 114, loss 2.2788944244384766, acc 0.17000000178813934\n",
      "Epoch 1, iter 115, loss 2.2692694664001465, acc 0.25999999046325684\n",
      "Epoch 1, iter 116, loss 2.2692818641662598, acc 0.20999999344348907\n",
      "Epoch 1, iter 117, loss 2.281033754348755, acc 0.2199999988079071\n",
      "Epoch 1, iter 118, loss 2.2831883430480957, acc 0.11999999731779099\n",
      "Epoch 1, iter 119, loss 2.27380108833313, acc 0.25\n",
      "Epoch 1, iter 120, loss 2.281519889831543, acc 0.23000000417232513\n",
      "Epoch 1, iter 121, loss 2.2767984867095947, acc 0.23000000417232513\n",
      "Epoch 1, iter 122, loss 2.272397041320801, acc 0.3100000023841858\n",
      "Epoch 1, iter 123, loss 2.2865095138549805, acc 0.11999999731779099\n",
      "Epoch 1, iter 124, loss 2.2687063217163086, acc 0.23000000417232513\n",
      "Epoch 1, iter 125, loss 2.2742247581481934, acc 0.1899999976158142\n",
      "Epoch 1, iter 126, loss 2.273203134536743, acc 0.23000000417232513\n",
      "Epoch 1, iter 127, loss 2.273022174835205, acc 0.23999999463558197\n",
      "Epoch 1, iter 128, loss 2.279367446899414, acc 0.2199999988079071\n",
      "Epoch 1, iter 129, loss 2.281136989593506, acc 0.20999999344348907\n",
      "Epoch 1, iter 130, loss 2.280498743057251, acc 0.20999999344348907\n",
      "Epoch 1, iter 131, loss 2.281081438064575, acc 0.23000000417232513\n",
      "Epoch 1, iter 132, loss 2.2719459533691406, acc 0.25999999046325684\n",
      "Epoch 1, iter 133, loss 2.2731902599334717, acc 0.20999999344348907\n",
      "Epoch 1, iter 134, loss 2.284815549850464, acc 0.15000000596046448\n",
      "Epoch 1, iter 135, loss 2.2724287509918213, acc 0.2800000011920929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 136, loss 2.2618229389190674, acc 0.2800000011920929\n",
      "Epoch 1, iter 137, loss 2.270925760269165, acc 0.23999999463558197\n",
      "Epoch 1, iter 138, loss 2.2713394165039062, acc 0.20000000298023224\n",
      "Epoch 1, iter 139, loss 2.2759249210357666, acc 0.20999999344348907\n",
      "Epoch 1, iter 140, loss 2.2728729248046875, acc 0.1899999976158142\n",
      "Epoch 1, iter 141, loss 2.2730295658111572, acc 0.2199999988079071\n",
      "Epoch 1, iter 142, loss 2.2782890796661377, acc 0.17000000178813934\n",
      "Epoch 1, iter 143, loss 2.2749152183532715, acc 0.1899999976158142\n",
      "Epoch 1, iter 144, loss 2.2770655155181885, acc 0.1599999964237213\n",
      "Epoch 1, iter 145, loss 2.271343231201172, acc 0.1899999976158142\n",
      "Epoch 1, iter 146, loss 2.270331621170044, acc 0.1899999976158142\n",
      "Epoch 1, iter 147, loss 2.2738327980041504, acc 0.20999999344348907\n",
      "Epoch 1, iter 148, loss 2.262932777404785, acc 0.25\n",
      "Epoch 1, iter 149, loss 2.263397216796875, acc 0.23000000417232513\n",
      "Epoch 1, iter 150, loss 2.2716214656829834, acc 0.23999999463558197\n",
      "Epoch 1, iter 151, loss 2.2577712535858154, acc 0.23999999463558197\n",
      "Epoch 1, iter 152, loss 2.271082878112793, acc 0.23000000417232513\n",
      "Epoch 1, iter 153, loss 2.2718334197998047, acc 0.23999999463558197\n",
      "Epoch 1, iter 154, loss 2.2739124298095703, acc 0.20000000298023224\n",
      "Epoch 1, iter 155, loss 2.2717506885528564, acc 0.25999999046325684\n",
      "Epoch 1, iter 156, loss 2.2725138664245605, acc 0.23000000417232513\n",
      "Epoch 1, iter 157, loss 2.2807304859161377, acc 0.18000000715255737\n",
      "Epoch 1, iter 158, loss 2.2721972465515137, acc 0.25\n",
      "Epoch 1, iter 159, loss 2.2744088172912598, acc 0.2199999988079071\n",
      "Epoch 1, iter 160, loss 2.2766942977905273, acc 0.20000000298023224\n",
      "Epoch 1, iter 161, loss 2.267932176589966, acc 0.2199999988079071\n",
      "Epoch 1, iter 162, loss 2.256124973297119, acc 0.2800000011920929\n",
      "Epoch 1, iter 163, loss 2.278275728225708, acc 0.20000000298023224\n",
      "Epoch 1, iter 164, loss 2.270439624786377, acc 0.20000000298023224\n",
      "Epoch 1, iter 165, loss 2.2826178073883057, acc 0.20000000298023224\n",
      "Epoch 1, iter 166, loss 2.2637217044830322, acc 0.25999999046325684\n",
      "Epoch 1, iter 167, loss 2.2724485397338867, acc 0.20000000298023224\n",
      "Epoch 1, iter 168, loss 2.2683334350585938, acc 0.2199999988079071\n",
      "Epoch 1, iter 169, loss 2.26007080078125, acc 0.20999999344348907\n",
      "Epoch 1, iter 170, loss 2.272024393081665, acc 0.15000000596046448\n",
      "Epoch 1, iter 171, loss 2.2707748413085938, acc 0.20000000298023224\n",
      "Epoch 1, iter 172, loss 2.2763264179229736, acc 0.1899999976158142\n",
      "Epoch 1, iter 173, loss 2.2802133560180664, acc 0.20999999344348907\n",
      "Epoch 1, iter 174, loss 2.266998529434204, acc 0.20000000298023224\n",
      "Epoch 1, iter 175, loss 2.263815402984619, acc 0.23000000417232513\n",
      "Epoch 1, iter 176, loss 2.2822792530059814, acc 0.1599999964237213\n",
      "Epoch 1, iter 177, loss 2.272118091583252, acc 0.25999999046325684\n",
      "Epoch 1, iter 178, loss 2.2694427967071533, acc 0.2199999988079071\n",
      "Epoch 1, iter 179, loss 2.2771880626678467, acc 0.17000000178813934\n",
      "Epoch 1, iter 180, loss 2.274988889694214, acc 0.23999999463558197\n",
      "Epoch 1, iter 181, loss 2.252939224243164, acc 0.23999999463558197\n",
      "Epoch 1, iter 182, loss 2.2631635665893555, acc 0.25999999046325684\n",
      "Epoch 1, iter 183, loss 2.2688181400299072, acc 0.23000000417232513\n",
      "Epoch 1, iter 184, loss 2.263735294342041, acc 0.2199999988079071\n",
      "Epoch 1, iter 185, loss 2.2637128829956055, acc 0.23000000417232513\n",
      "Epoch 1, iter 186, loss 2.268371820449829, acc 0.23000000417232513\n",
      "Epoch 1, iter 187, loss 2.2590889930725098, acc 0.25\n",
      "Epoch 1, iter 188, loss 2.2685365676879883, acc 0.20000000298023224\n",
      "Epoch 1, iter 189, loss 2.2830803394317627, acc 0.10999999940395355\n",
      "Epoch 1, iter 190, loss 2.2712185382843018, acc 0.23999999463558197\n",
      "Epoch 1, iter 191, loss 2.278263568878174, acc 0.18000000715255737\n",
      "Epoch 1, iter 192, loss 2.2633421421051025, acc 0.27000001072883606\n",
      "Epoch 1, iter 193, loss 2.2653417587280273, acc 0.1899999976158142\n",
      "Epoch 1, iter 194, loss 2.2677860260009766, acc 0.25999999046325684\n",
      "Epoch 1, iter 195, loss 2.2600302696228027, acc 0.23999999463558197\n",
      "Epoch 1, iter 196, loss 2.27717661857605, acc 0.20000000298023224\n",
      "Epoch 1, iter 197, loss 2.2734127044677734, acc 0.15000000596046448\n",
      "Epoch 1, iter 198, loss 2.241542100906372, acc 0.36000001430511475\n",
      "Epoch 1, iter 199, loss 2.2700443267822266, acc 0.1899999976158142\n",
      "Epoch 1, iter 200, loss 2.26790714263916, acc 0.18000000715255737\n",
      "Epoch 1, iter 201, loss 2.2498600482940674, acc 0.23999999463558197\n",
      "Epoch 1, iter 202, loss 2.2573342323303223, acc 0.1899999976158142\n",
      "Epoch 1, iter 203, loss 2.2768094539642334, acc 0.1599999964237213\n",
      "Epoch 1, iter 204, loss 2.259467601776123, acc 0.23000000417232513\n",
      "Epoch 1, iter 205, loss 2.251560926437378, acc 0.2199999988079071\n",
      "Epoch 1, iter 206, loss 2.268958330154419, acc 0.25\n",
      "Epoch 1, iter 207, loss 2.2810046672821045, acc 0.11999999731779099\n",
      "Epoch 1, iter 208, loss 2.2806825637817383, acc 0.15000000596046448\n",
      "Epoch 1, iter 209, loss 2.2798879146575928, acc 0.14000000059604645\n",
      "Epoch 1, iter 210, loss 2.2783641815185547, acc 0.1599999964237213\n",
      "Epoch 1, iter 211, loss 2.261281967163086, acc 0.20000000298023224\n",
      "Epoch 1, iter 212, loss 2.2780303955078125, acc 0.1899999976158142\n",
      "Epoch 1, iter 213, loss 2.276137351989746, acc 0.17000000178813934\n",
      "Epoch 1, iter 214, loss 2.2700679302215576, acc 0.1599999964237213\n",
      "Epoch 1, iter 215, loss 2.2715702056884766, acc 0.18000000715255737\n",
      "Epoch 1, iter 216, loss 2.2747974395751953, acc 0.2199999988079071\n",
      "Epoch 1, iter 217, loss 2.253220319747925, acc 0.20999999344348907\n",
      "Epoch 1, iter 218, loss 2.2822606563568115, acc 0.15000000596046448\n",
      "Epoch 1, iter 219, loss 2.2738516330718994, acc 0.1899999976158142\n",
      "Epoch 1, iter 220, loss 2.261624336242676, acc 0.1599999964237213\n",
      "Epoch 1, iter 221, loss 2.2639522552490234, acc 0.18000000715255737\n",
      "Epoch 1, iter 222, loss 2.2706196308135986, acc 0.2199999988079071\n",
      "Epoch 1, iter 223, loss 2.2564361095428467, acc 0.1899999976158142\n",
      "Epoch 1, iter 224, loss 2.2689805030822754, acc 0.1599999964237213\n",
      "Epoch 1, iter 225, loss 2.2509634494781494, acc 0.25999999046325684\n",
      "Epoch 1, iter 226, loss 2.2486445903778076, acc 0.25\n",
      "Epoch 1, iter 227, loss 2.264712333679199, acc 0.17000000178813934\n",
      "Epoch 1, iter 228, loss 2.2646291255950928, acc 0.1599999964237213\n",
      "Epoch 1, iter 229, loss 2.2631888389587402, acc 0.1899999976158142\n",
      "Epoch 1, iter 230, loss 2.2594029903411865, acc 0.1899999976158142\n",
      "Epoch 1, iter 231, loss 2.2502639293670654, acc 0.25\n",
      "Epoch 1, iter 232, loss 2.2760262489318848, acc 0.14000000059604645\n",
      "Epoch 1, iter 233, loss 2.2436604499816895, acc 0.20999999344348907\n",
      "Epoch 1, iter 234, loss 2.2440571784973145, acc 0.20999999344348907\n",
      "Epoch 1, iter 235, loss 2.2561426162719727, acc 0.2199999988079071\n",
      "Epoch 1, iter 236, loss 2.2675209045410156, acc 0.17000000178813934\n",
      "Epoch 1, iter 237, loss 2.2684528827667236, acc 0.1599999964237213\n",
      "Epoch 1, iter 238, loss 2.264099597930908, acc 0.11999999731779099\n",
      "Epoch 1, iter 239, loss 2.2651712894439697, acc 0.17000000178813934\n",
      "Epoch 1, iter 240, loss 2.2718732357025146, acc 0.15000000596046448\n",
      "Epoch 1, iter 241, loss 2.263822078704834, acc 0.17000000178813934\n",
      "Epoch 1, iter 242, loss 2.2661287784576416, acc 0.1599999964237213\n",
      "Epoch 1, iter 243, loss 2.2795767784118652, acc 0.07000000029802322\n",
      "Epoch 1, iter 244, loss 2.248922824859619, acc 0.23999999463558197\n",
      "Epoch 1, iter 245, loss 2.251467227935791, acc 0.17000000178813934\n",
      "Epoch 1, iter 246, loss 2.2736763954162598, acc 0.1899999976158142\n",
      "Epoch 1, iter 247, loss 2.2589268684387207, acc 0.17000000178813934\n",
      "Epoch 1, iter 248, loss 2.269244909286499, acc 0.1599999964237213\n",
      "Epoch 1, iter 249, loss 2.273714542388916, acc 0.11999999731779099\n",
      "Epoch 1, iter 250, loss 2.259286880493164, acc 0.1599999964237213\n",
      "Epoch 1, iter 251, loss 2.261503219604492, acc 0.17000000178813934\n",
      "Epoch 1, iter 252, loss 2.256483316421509, acc 0.12999999523162842\n",
      "Epoch 1, iter 253, loss 2.284183979034424, acc 0.07999999821186066\n",
      "Epoch 1, iter 254, loss 2.2696542739868164, acc 0.10999999940395355\n",
      "Epoch 1, iter 255, loss 2.270259141921997, acc 0.10000000149011612\n",
      "Epoch 1, iter 256, loss 2.259476661682129, acc 0.10000000149011612\n",
      "Epoch 1, iter 257, loss 2.265624761581421, acc 0.12999999523162842\n",
      "Epoch 1, iter 258, loss 2.255830764770508, acc 0.15000000596046448\n",
      "Epoch 1, iter 259, loss 2.267087459564209, acc 0.15000000596046448\n",
      "Epoch 1, iter 260, loss 2.2602083683013916, acc 0.18000000715255737\n",
      "Epoch 1, iter 261, loss 2.249523639678955, acc 0.1599999964237213\n",
      "Epoch 1, iter 262, loss 2.2696781158447266, acc 0.15000000596046448\n",
      "Epoch 1, iter 263, loss 2.243856906890869, acc 0.1599999964237213\n",
      "Epoch 1, iter 264, loss 2.2512097358703613, acc 0.17000000178813934\n",
      "Epoch 1, iter 265, loss 2.267038345336914, acc 0.14000000059604645\n",
      "Epoch 1, iter 266, loss 2.2565789222717285, acc 0.17000000178813934\n",
      "Epoch 1, iter 267, loss 2.2324390411376953, acc 0.23999999463558197\n",
      "Epoch 1, iter 268, loss 2.2611331939697266, acc 0.18000000715255737\n",
      "Epoch 1, iter 269, loss 2.253377914428711, acc 0.1899999976158142\n",
      "Epoch 1, iter 270, loss 2.261723279953003, acc 0.18000000715255737\n",
      "Epoch 1, iter 271, loss 2.2755753993988037, acc 0.07999999821186066\n",
      "Epoch 1, iter 272, loss 2.258819818496704, acc 0.14000000059604645\n",
      "Epoch 1, iter 273, loss 2.261634111404419, acc 0.12999999523162842\n",
      "Epoch 1, iter 274, loss 2.2540321350097656, acc 0.14000000059604645\n",
      "Epoch 1, iter 275, loss 2.2672791481018066, acc 0.14000000059604645\n",
      "Epoch 1, iter 276, loss 2.2596397399902344, acc 0.1899999976158142\n",
      "Epoch 1, iter 277, loss 2.2577128410339355, acc 0.15000000596046448\n",
      "Epoch 1, iter 278, loss 2.255594491958618, acc 0.15000000596046448\n",
      "Epoch 1, iter 279, loss 2.242246627807617, acc 0.1899999976158142\n",
      "Epoch 1, iter 280, loss 2.2540905475616455, acc 0.20999999344348907\n",
      "Epoch 1, iter 281, loss 2.255307197570801, acc 0.20999999344348907\n",
      "Epoch 1, iter 282, loss 2.2684149742126465, acc 0.1599999964237213\n",
      "Epoch 1, iter 283, loss 2.253497362136841, acc 0.17000000178813934\n",
      "Epoch 1, iter 284, loss 2.237807035446167, acc 0.20999999344348907\n",
      "Epoch 1, iter 285, loss 2.244493007659912, acc 0.2199999988079071\n",
      "Epoch 1, iter 286, loss 2.2441976070404053, acc 0.2199999988079071\n",
      "Epoch 1, iter 287, loss 2.2554497718811035, acc 0.17000000178813934\n",
      "Epoch 1, iter 288, loss 2.2411279678344727, acc 0.20000000298023224\n",
      "Epoch 1, iter 289, loss 2.257462978363037, acc 0.20000000298023224\n",
      "Epoch 1, iter 290, loss 2.229379177093506, acc 0.28999999165534973\n",
      "Epoch 1, iter 291, loss 2.2510342597961426, acc 0.18000000715255737\n",
      "Epoch 1, iter 292, loss 2.236959934234619, acc 0.23000000417232513\n",
      "Epoch 1, iter 293, loss 2.248589277267456, acc 0.20999999344348907\n",
      "Epoch 1, iter 294, loss 2.2606754302978516, acc 0.18000000715255737\n",
      "Epoch 1, iter 295, loss 2.2589173316955566, acc 0.12999999523162842\n",
      "Epoch 1, iter 296, loss 2.2455124855041504, acc 0.18000000715255737\n",
      "Epoch 1, iter 297, loss 2.2517313957214355, acc 0.1599999964237213\n",
      "Epoch 1, iter 298, loss 2.240887403488159, acc 0.20000000298023224\n",
      "Epoch 1, iter 299, loss 2.2865841388702393, acc 0.07999999821186066\n",
      "Epoch 1, iter 300, loss 2.2573771476745605, acc 0.1899999976158142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 301, loss 2.2532949447631836, acc 0.1899999976158142\n",
      "Epoch 1, iter 302, loss 2.239081382751465, acc 0.23000000417232513\n",
      "Epoch 1, iter 303, loss 2.250300645828247, acc 0.25999999046325684\n",
      "Epoch 1, iter 304, loss 2.266481876373291, acc 0.1599999964237213\n",
      "Epoch 1, iter 305, loss 2.2697014808654785, acc 0.2199999988079071\n",
      "Epoch 1, iter 306, loss 2.240532636642456, acc 0.25\n",
      "Epoch 1, iter 307, loss 2.2471399307250977, acc 0.20999999344348907\n",
      "Epoch 1, iter 308, loss 2.2627313137054443, acc 0.23000000417232513\n",
      "Epoch 1, iter 309, loss 2.2552289962768555, acc 0.15000000596046448\n",
      "Epoch 1, iter 310, loss 2.2569339275360107, acc 0.18000000715255737\n",
      "Epoch 1, iter 311, loss 2.244062900543213, acc 0.20000000298023224\n",
      "Epoch 1, iter 312, loss 2.236319065093994, acc 0.27000001072883606\n",
      "Epoch 1, iter 313, loss 2.276365041732788, acc 0.11999999731779099\n",
      "Epoch 1, iter 314, loss 2.222223997116089, acc 0.27000001072883606\n",
      "Epoch 1, iter 315, loss 2.2438788414001465, acc 0.23000000417232513\n",
      "Epoch 1, iter 316, loss 2.2704224586486816, acc 0.10999999940395355\n",
      "Epoch 1, iter 317, loss 2.2577807903289795, acc 0.15000000596046448\n",
      "Epoch 1, iter 318, loss 2.2409849166870117, acc 0.18000000715255737\n",
      "Epoch 1, iter 319, loss 2.253363609313965, acc 0.1899999976158142\n",
      "Epoch 1, iter 320, loss 2.2681820392608643, acc 0.20999999344348907\n",
      "Epoch 1, iter 321, loss 2.2624552249908447, acc 0.15000000596046448\n",
      "Epoch 1, iter 322, loss 2.2402961254119873, acc 0.20999999344348907\n",
      "Epoch 1, iter 323, loss 2.2465763092041016, acc 0.20000000298023224\n",
      "Epoch 1, iter 324, loss 2.2219138145446777, acc 0.3100000023841858\n",
      "Epoch 1, iter 325, loss 2.253491163253784, acc 0.20000000298023224\n",
      "Epoch 1, iter 326, loss 2.2390944957733154, acc 0.25999999046325684\n",
      "Epoch 1, iter 327, loss 2.2599194049835205, acc 0.17000000178813934\n",
      "Epoch 1, iter 328, loss 2.227036476135254, acc 0.23000000417232513\n",
      "Epoch 1, iter 329, loss 2.231189250946045, acc 0.25999999046325684\n",
      "Epoch 1, iter 330, loss 2.251612663269043, acc 0.1599999964237213\n",
      "Epoch 1, iter 331, loss 2.2486307621002197, acc 0.18000000715255737\n",
      "Epoch 1, iter 332, loss 2.249819755554199, acc 0.1599999964237213\n",
      "Epoch 1, iter 333, loss 2.249263286590576, acc 0.1599999964237213\n",
      "Epoch 1, iter 334, loss 2.259263038635254, acc 0.18000000715255737\n",
      "Epoch 1, iter 335, loss 2.2204158306121826, acc 0.23000000417232513\n",
      "Epoch 1, iter 336, loss 2.230813980102539, acc 0.2800000011920929\n",
      "Epoch 1, iter 337, loss 2.2496204376220703, acc 0.20000000298023224\n",
      "Epoch 1, iter 338, loss 2.2509610652923584, acc 0.20999999344348907\n",
      "Epoch 1, iter 339, loss 2.2459557056427, acc 0.25\n",
      "Epoch 1, iter 340, loss 2.2522194385528564, acc 0.20000000298023224\n",
      "Epoch 1, iter 341, loss 2.227799654006958, acc 0.23999999463558197\n",
      "Epoch 1, iter 342, loss 2.237527847290039, acc 0.27000001072883606\n",
      "Epoch 1, iter 343, loss 2.2649624347686768, acc 0.2199999988079071\n",
      "Epoch 1, iter 344, loss 2.2275266647338867, acc 0.23000000417232513\n",
      "Epoch 1, iter 345, loss 2.2589194774627686, acc 0.20999999344348907\n",
      "Epoch 1, iter 346, loss 2.2146036624908447, acc 0.2800000011920929\n",
      "Epoch 1, iter 347, loss 2.257836103439331, acc 0.18000000715255737\n",
      "Epoch 1, iter 348, loss 2.2191476821899414, acc 0.27000001072883606\n",
      "Epoch 1, iter 349, loss 2.21720027923584, acc 0.23000000417232513\n",
      "Epoch 1, iter 350, loss 2.237346887588501, acc 0.20000000298023224\n",
      "Epoch 1, iter 351, loss 2.2571473121643066, acc 0.17000000178813934\n",
      "Epoch 1, iter 352, loss 2.2471959590911865, acc 0.20999999344348907\n",
      "Epoch 1, iter 353, loss 2.250518560409546, acc 0.18000000715255737\n",
      "Epoch 1, iter 354, loss 2.2338271141052246, acc 0.25\n",
      "Epoch 1, iter 355, loss 2.2502243518829346, acc 0.23000000417232513\n",
      "Epoch 1, iter 356, loss 2.254969835281372, acc 0.17000000178813934\n",
      "Epoch 1, iter 357, loss 2.2595274448394775, acc 0.17000000178813934\n",
      "Epoch 1, iter 358, loss 2.268573522567749, acc 0.1599999964237213\n",
      "Epoch 1, iter 359, loss 2.258009672164917, acc 0.20000000298023224\n",
      "Epoch 1, iter 360, loss 2.233562707901001, acc 0.23999999463558197\n",
      "Epoch 1, iter 361, loss 2.2437288761138916, acc 0.1599999964237213\n",
      "Epoch 1, iter 362, loss 2.2628958225250244, acc 0.1899999976158142\n",
      "Epoch 1, iter 363, loss 2.227114200592041, acc 0.23999999463558197\n",
      "Epoch 1, iter 364, loss 2.2595129013061523, acc 0.10000000149011612\n",
      "Epoch 1, iter 365, loss 2.238974094390869, acc 0.1899999976158142\n",
      "Epoch 1, iter 366, loss 2.2120697498321533, acc 0.23000000417232513\n",
      "Epoch 1, iter 367, loss 2.2265889644622803, acc 0.20999999344348907\n",
      "Epoch 1, iter 368, loss 2.2400450706481934, acc 0.1899999976158142\n",
      "Epoch 1, iter 369, loss 2.235107660293579, acc 0.1899999976158142\n",
      "Epoch 1, iter 370, loss 2.2215845584869385, acc 0.25999999046325684\n",
      "Epoch 1, iter 371, loss 2.2210426330566406, acc 0.27000001072883606\n",
      "Epoch 1, iter 372, loss 2.225648880004883, acc 0.1899999976158142\n",
      "Epoch 1, iter 373, loss 2.2473552227020264, acc 0.18000000715255737\n",
      "Epoch 1, iter 374, loss 2.241901159286499, acc 0.12999999523162842\n",
      "Epoch 1, iter 375, loss 2.2125680446624756, acc 0.23999999463558197\n",
      "Epoch 1, iter 376, loss 2.2454960346221924, acc 0.1899999976158142\n",
      "Epoch 1, iter 377, loss 2.2121171951293945, acc 0.25\n",
      "Epoch 1, iter 378, loss 2.238302707672119, acc 0.11999999731779099\n",
      "Epoch 1, iter 379, loss 2.25882625579834, acc 0.17000000178813934\n",
      "Epoch 1, iter 380, loss 2.2550766468048096, acc 0.1599999964237213\n",
      "Epoch 1, iter 381, loss 2.2624547481536865, acc 0.17000000178813934\n",
      "Epoch 1, iter 382, loss 2.220914602279663, acc 0.2199999988079071\n",
      "Epoch 1, iter 383, loss 2.2266383171081543, acc 0.18000000715255737\n",
      "Epoch 1, iter 384, loss 2.2523529529571533, acc 0.17000000178813934\n",
      "Epoch 1, iter 385, loss 2.2203080654144287, acc 0.2199999988079071\n",
      "Epoch 1, iter 386, loss 2.2230095863342285, acc 0.2199999988079071\n",
      "Epoch 1, iter 387, loss 2.227705240249634, acc 0.23000000417232513\n",
      "Epoch 1, iter 388, loss 2.2561378479003906, acc 0.11999999731779099\n",
      "Epoch 1, iter 389, loss 2.2340548038482666, acc 0.17000000178813934\n",
      "Epoch 1, iter 390, loss 2.276505947113037, acc 0.10000000149011612\n",
      "Epoch 1, iter 391, loss 2.246575117111206, acc 0.1599999964237213\n",
      "Epoch 1, iter 392, loss 2.2497243881225586, acc 0.15000000596046448\n",
      "Epoch 1, iter 393, loss 2.251344680786133, acc 0.17000000178813934\n",
      "Epoch 1, iter 394, loss 2.233424425125122, acc 0.1899999976158142\n",
      "Epoch 1, iter 395, loss 2.207948684692383, acc 0.23999999463558197\n",
      "Epoch 1, iter 396, loss 2.2471768856048584, acc 0.18000000715255737\n",
      "Epoch 1, iter 397, loss 2.2403337955474854, acc 0.15000000596046448\n",
      "Epoch 1, iter 398, loss 2.262298345565796, acc 0.14000000059604645\n",
      "Epoch 1, iter 399, loss 2.233182430267334, acc 0.18000000715255737\n",
      "Epoch 1, iter 400, loss 2.2108004093170166, acc 0.23999999463558197\n",
      "Epoch 1, iter 401, loss 2.238929033279419, acc 0.18000000715255737\n",
      "Epoch 1, iter 402, loss 2.2308619022369385, acc 0.1599999964237213\n",
      "Epoch 1, iter 403, loss 2.247243881225586, acc 0.1599999964237213\n",
      "Epoch 1, iter 404, loss 2.2474167346954346, acc 0.1899999976158142\n",
      "Epoch 1, iter 405, loss 2.2528743743896484, acc 0.14000000059604645\n",
      "Epoch 1, iter 406, loss 2.259955644607544, acc 0.15000000596046448\n",
      "Epoch 1, iter 407, loss 2.2569265365600586, acc 0.18000000715255737\n",
      "Epoch 1, iter 408, loss 2.240081310272217, acc 0.1899999976158142\n",
      "Epoch 1, iter 409, loss 2.22796368598938, acc 0.18000000715255737\n",
      "Epoch 1, iter 410, loss 2.2296578884124756, acc 0.15000000596046448\n",
      "Epoch 1, iter 411, loss 2.209167957305908, acc 0.27000001072883606\n",
      "Epoch 1, iter 412, loss 2.2285468578338623, acc 0.1599999964237213\n",
      "Epoch 1, iter 413, loss 2.2462549209594727, acc 0.14000000059604645\n",
      "Epoch 1, iter 414, loss 2.2486133575439453, acc 0.20000000298023224\n",
      "Epoch 1, iter 415, loss 2.244677782058716, acc 0.1599999964237213\n",
      "Epoch 1, iter 416, loss 2.2147672176361084, acc 0.23000000417232513\n",
      "Epoch 1, iter 417, loss 2.2126142978668213, acc 0.25\n",
      "Epoch 1, iter 418, loss 2.2363386154174805, acc 0.14000000059604645\n",
      "Epoch 1, iter 419, loss 2.2046360969543457, acc 0.30000001192092896\n",
      "Epoch 1, iter 420, loss 2.224994421005249, acc 0.23999999463558197\n",
      "Epoch 2, iter 1, loss 2.2108378410339355, acc 0.30000001192092896\n",
      "Epoch 2, iter 2, loss 2.2512755393981934, acc 0.14000000059604645\n",
      "Epoch 2, iter 3, loss 2.238199472427368, acc 0.17000000178813934\n",
      "Epoch 2, iter 4, loss 2.262000560760498, acc 0.1599999964237213\n",
      "Epoch 2, iter 5, loss 2.2320871353149414, acc 0.20999999344348907\n",
      "Epoch 2, iter 6, loss 2.241100311279297, acc 0.18000000715255737\n",
      "Epoch 2, iter 7, loss 2.2393195629119873, acc 0.1899999976158142\n",
      "Epoch 2, iter 8, loss 2.237092971801758, acc 0.18000000715255737\n",
      "Epoch 2, iter 9, loss 2.256110668182373, acc 0.12999999523162842\n",
      "Epoch 2, iter 10, loss 2.2632431983947754, acc 0.20999999344348907\n",
      "Epoch 2, iter 11, loss 2.243619203567505, acc 0.23000000417232513\n",
      "Epoch 2, iter 12, loss 2.2410826683044434, acc 0.25999999046325684\n",
      "Epoch 2, iter 13, loss 2.234724521636963, acc 0.3100000023841858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, iter 14, loss 2.2213051319122314, acc 0.36000001430511475\n",
      "Epoch 2, iter 15, loss 2.1852567195892334, acc 0.3100000023841858\n",
      "Epoch 2, iter 16, loss 2.2244651317596436, acc 0.3400000035762787\n",
      "Epoch 2, iter 17, loss 2.2407281398773193, acc 0.23999999463558197\n",
      "Epoch 2, iter 18, loss 2.242586612701416, acc 0.28999999165534973\n",
      "Epoch 2, iter 19, loss 2.2213294506073, acc 0.33000001311302185\n",
      "Epoch 2, iter 20, loss 2.2161638736724854, acc 0.3100000023841858\n",
      "Epoch 2, iter 21, loss 2.2018611431121826, acc 0.3199999928474426\n",
      "Epoch 2, iter 22, loss 2.2338058948516846, acc 0.28999999165534973\n",
      "Epoch 2, iter 23, loss 2.1980414390563965, acc 0.30000001192092896\n",
      "Epoch 2, iter 24, loss 2.2130985260009766, acc 0.3199999928474426\n",
      "Epoch 2, iter 25, loss 2.2403526306152344, acc 0.25\n",
      "Epoch 2, iter 26, loss 2.231159210205078, acc 0.25999999046325684\n",
      "Epoch 2, iter 27, loss 2.22407865524292, acc 0.25999999046325684\n",
      "Epoch 2, iter 28, loss 2.200789213180542, acc 0.3400000035762787\n",
      "Epoch 2, iter 29, loss 2.2251944541931152, acc 0.28999999165534973\n",
      "Epoch 2, iter 30, loss 2.2474727630615234, acc 0.23000000417232513\n",
      "Epoch 2, iter 31, loss 2.2722949981689453, acc 0.18000000715255737\n",
      "Epoch 2, iter 32, loss 2.226835012435913, acc 0.2800000011920929\n",
      "Epoch 2, iter 33, loss 2.243969202041626, acc 0.23999999463558197\n",
      "Epoch 2, iter 34, loss 2.2328929901123047, acc 0.30000001192092896\n",
      "Epoch 2, iter 35, loss 2.217038869857788, acc 0.25999999046325684\n",
      "Epoch 2, iter 36, loss 2.2367217540740967, acc 0.2800000011920929\n",
      "Epoch 2, iter 37, loss 2.2392051219940186, acc 0.27000001072883606\n",
      "Epoch 2, iter 38, loss 2.248154640197754, acc 0.2199999988079071\n",
      "Epoch 2, iter 39, loss 2.2230329513549805, acc 0.30000001192092896\n",
      "Epoch 2, iter 40, loss 2.195626974105835, acc 0.3400000035762787\n",
      "Epoch 2, iter 41, loss 2.2584967613220215, acc 0.20999999344348907\n",
      "Epoch 2, iter 42, loss 2.242093324661255, acc 0.28999999165534973\n",
      "Epoch 2, iter 43, loss 2.2063968181610107, acc 0.38999998569488525\n",
      "Epoch 2, iter 44, loss 2.2011935710906982, acc 0.3400000035762787\n",
      "Epoch 2, iter 45, loss 2.233802080154419, acc 0.23999999463558197\n",
      "Epoch 2, iter 46, loss 2.225904941558838, acc 0.25999999046325684\n",
      "Epoch 2, iter 47, loss 2.2457234859466553, acc 0.27000001072883606\n",
      "Epoch 2, iter 48, loss 2.2178993225097656, acc 0.36000001430511475\n",
      "Epoch 2, iter 49, loss 2.2270641326904297, acc 0.25999999046325684\n",
      "Epoch 2, iter 50, loss 2.2472007274627686, acc 0.2199999988079071\n",
      "Epoch 2, iter 51, loss 2.2130517959594727, acc 0.30000001192092896\n",
      "Epoch 2, iter 52, loss 2.2410788536071777, acc 0.25999999046325684\n",
      "Epoch 2, iter 53, loss 2.1979422569274902, acc 0.3199999928474426\n",
      "Epoch 2, iter 54, loss 2.231285810470581, acc 0.33000001311302185\n",
      "Epoch 2, iter 55, loss 2.280639886856079, acc 0.1599999964237213\n",
      "Epoch 2, iter 56, loss 2.236468553543091, acc 0.3100000023841858\n",
      "Epoch 2, iter 57, loss 2.255384922027588, acc 0.20000000298023224\n",
      "Epoch 2, iter 58, loss 2.248262405395508, acc 0.23000000417232513\n",
      "Epoch 2, iter 59, loss 2.221014976501465, acc 0.3199999928474426\n",
      "Epoch 2, iter 60, loss 2.242312431335449, acc 0.25999999046325684\n",
      "Epoch 2, iter 61, loss 2.233779191970825, acc 0.3100000023841858\n",
      "Epoch 2, iter 62, loss 2.2353525161743164, acc 0.25999999046325684\n",
      "Epoch 2, iter 63, loss 2.239645004272461, acc 0.20999999344348907\n",
      "Epoch 2, iter 64, loss 2.201446533203125, acc 0.2800000011920929\n",
      "Epoch 2, iter 65, loss 2.2209296226501465, acc 0.25999999046325684\n",
      "Epoch 2, iter 66, loss 2.207474708557129, acc 0.3400000035762787\n",
      "Epoch 2, iter 67, loss 2.2439537048339844, acc 0.30000001192092896\n",
      "Epoch 2, iter 68, loss 2.185396909713745, acc 0.2800000011920929\n",
      "Epoch 2, iter 69, loss 2.2329397201538086, acc 0.3199999928474426\n",
      "Epoch 2, iter 70, loss 2.2157204151153564, acc 0.2800000011920929\n",
      "Epoch 2, iter 71, loss 2.245520830154419, acc 0.25999999046325684\n",
      "Epoch 2, iter 72, loss 2.2225019931793213, acc 0.2800000011920929\n",
      "Epoch 2, iter 73, loss 2.2085089683532715, acc 0.3199999928474426\n",
      "Epoch 2, iter 74, loss 2.2155911922454834, acc 0.25\n",
      "Epoch 2, iter 75, loss 2.2359511852264404, acc 0.2800000011920929\n",
      "Epoch 2, iter 76, loss 2.2219603061676025, acc 0.23000000417232513\n",
      "Epoch 2, iter 77, loss 2.248199462890625, acc 0.2800000011920929\n",
      "Epoch 2, iter 78, loss 2.2183709144592285, acc 0.25\n",
      "Epoch 2, iter 79, loss 2.2193915843963623, acc 0.3100000023841858\n",
      "Epoch 2, iter 80, loss 2.2149834632873535, acc 0.28999999165534973\n",
      "Epoch 2, iter 81, loss 2.2422983646392822, acc 0.25999999046325684\n",
      "Epoch 2, iter 82, loss 2.2429416179656982, acc 0.2800000011920929\n",
      "Epoch 2, iter 83, loss 2.209299087524414, acc 0.3199999928474426\n",
      "Epoch 2, iter 84, loss 2.2580904960632324, acc 0.2199999988079071\n",
      "Epoch 2, iter 85, loss 2.248673915863037, acc 0.2199999988079071\n",
      "Epoch 2, iter 86, loss 2.220517158508301, acc 0.30000001192092896\n",
      "Epoch 2, iter 87, loss 2.2251436710357666, acc 0.2199999988079071\n",
      "Epoch 2, iter 88, loss 2.1961557865142822, acc 0.28999999165534973\n",
      "Epoch 2, iter 89, loss 2.2353127002716064, acc 0.27000001072883606\n",
      "Epoch 2, iter 90, loss 2.219175338745117, acc 0.2800000011920929\n",
      "Epoch 2, iter 91, loss 2.2174322605133057, acc 0.2800000011920929\n",
      "Epoch 2, iter 92, loss 2.248983860015869, acc 0.18000000715255737\n",
      "Epoch 2, iter 93, loss 2.2175307273864746, acc 0.2800000011920929\n",
      "Epoch 2, iter 94, loss 2.2288131713867188, acc 0.30000001192092896\n",
      "Epoch 2, iter 95, loss 2.212883234024048, acc 0.3199999928474426\n",
      "Epoch 2, iter 96, loss 2.2320525646209717, acc 0.23999999463558197\n",
      "Epoch 2, iter 97, loss 2.2353901863098145, acc 0.27000001072883606\n",
      "Epoch 2, iter 98, loss 2.2379415035247803, acc 0.30000001192092896\n",
      "Epoch 2, iter 99, loss 2.225686550140381, acc 0.2800000011920929\n",
      "Epoch 2, iter 100, loss 2.2109262943267822, acc 0.30000001192092896\n",
      "Epoch 2, iter 101, loss 2.2098796367645264, acc 0.27000001072883606\n",
      "Epoch 2, iter 102, loss 2.2207441329956055, acc 0.3199999928474426\n",
      "Epoch 2, iter 103, loss 2.2117464542388916, acc 0.2800000011920929\n",
      "Epoch 2, iter 104, loss 2.222661018371582, acc 0.2199999988079071\n",
      "Epoch 2, iter 105, loss 2.189070224761963, acc 0.38999998569488525\n",
      "Epoch 2, iter 106, loss 2.1993844509124756, acc 0.28999999165534973\n",
      "Epoch 2, iter 107, loss 2.209423065185547, acc 0.2800000011920929\n",
      "Epoch 2, iter 108, loss 2.2315542697906494, acc 0.30000001192092896\n",
      "Epoch 2, iter 109, loss 2.2131354808807373, acc 0.2800000011920929\n",
      "Epoch 2, iter 110, loss 2.2347865104675293, acc 0.23000000417232513\n",
      "Epoch 2, iter 111, loss 2.212447166442871, acc 0.3499999940395355\n",
      "Epoch 2, iter 112, loss 2.195143461227417, acc 0.28999999165534973\n",
      "Epoch 2, iter 113, loss 2.1895132064819336, acc 0.30000001192092896\n",
      "Epoch 2, iter 114, loss 2.197878122329712, acc 0.33000001311302185\n",
      "Epoch 2, iter 115, loss 2.19606876373291, acc 0.2800000011920929\n",
      "Epoch 2, iter 116, loss 2.1983237266540527, acc 0.27000001072883606\n",
      "Epoch 2, iter 117, loss 2.2389838695526123, acc 0.2800000011920929\n",
      "Epoch 2, iter 118, loss 2.2331998348236084, acc 0.2800000011920929\n",
      "Epoch 2, iter 119, loss 2.219271183013916, acc 0.28999999165534973\n",
      "Epoch 2, iter 120, loss 2.2220985889434814, acc 0.2800000011920929\n",
      "Epoch 2, iter 121, loss 2.2273762226104736, acc 0.25\n",
      "Epoch 2, iter 122, loss 2.2057723999023438, acc 0.3100000023841858\n",
      "Epoch 2, iter 123, loss 2.2361702919006348, acc 0.23000000417232513\n",
      "Epoch 2, iter 124, loss 2.2019262313842773, acc 0.33000001311302185\n",
      "Epoch 2, iter 125, loss 2.2267844676971436, acc 0.2800000011920929\n",
      "Epoch 2, iter 126, loss 2.2055366039276123, acc 0.3199999928474426\n",
      "Epoch 2, iter 127, loss 2.2170639038085938, acc 0.30000001192092896\n",
      "Epoch 2, iter 128, loss 2.2238996028900146, acc 0.28999999165534973\n",
      "Epoch 2, iter 129, loss 2.2438759803771973, acc 0.25\n",
      "Epoch 2, iter 130, loss 2.242554187774658, acc 0.2199999988079071\n",
      "Epoch 2, iter 131, loss 2.2578210830688477, acc 0.1899999976158142\n",
      "Epoch 2, iter 132, loss 2.2101776599884033, acc 0.28999999165534973\n",
      "Epoch 2, iter 133, loss 2.2229697704315186, acc 0.3199999928474426\n",
      "Epoch 2, iter 134, loss 2.253976821899414, acc 0.23999999463558197\n",
      "Epoch 2, iter 135, loss 2.223332405090332, acc 0.25\n",
      "Epoch 2, iter 136, loss 2.1770403385162354, acc 0.33000001311302185\n",
      "Epoch 2, iter 137, loss 2.203450918197632, acc 0.30000001192092896\n",
      "Epoch 2, iter 138, loss 2.2190585136413574, acc 0.25999999046325684\n",
      "Epoch 2, iter 139, loss 2.2178544998168945, acc 0.28999999165534973\n",
      "Epoch 2, iter 140, loss 2.219287633895874, acc 0.27000001072883606\n",
      "Epoch 2, iter 141, loss 2.221571683883667, acc 0.3199999928474426\n",
      "Epoch 2, iter 142, loss 2.2280960083007812, acc 0.3499999940395355\n",
      "Epoch 2, iter 143, loss 2.2182676792144775, acc 0.30000001192092896\n",
      "Epoch 2, iter 144, loss 2.2284257411956787, acc 0.28999999165534973\n",
      "Epoch 2, iter 145, loss 2.2121362686157227, acc 0.33000001311302185\n",
      "Epoch 2, iter 146, loss 2.2044920921325684, acc 0.28999999165534973\n",
      "Epoch 2, iter 147, loss 2.2174124717712402, acc 0.27000001072883606\n",
      "Epoch 2, iter 148, loss 2.191250801086426, acc 0.33000001311302185\n",
      "Epoch 2, iter 149, loss 2.187573194503784, acc 0.3499999940395355\n",
      "Epoch 2, iter 150, loss 2.208688735961914, acc 0.27000001072883606\n",
      "Epoch 2, iter 151, loss 2.158888578414917, acc 0.4399999976158142\n",
      "Epoch 2, iter 152, loss 2.224099636077881, acc 0.25999999046325684\n",
      "Epoch 2, iter 153, loss 2.215935707092285, acc 0.25999999046325684\n",
      "Epoch 2, iter 154, loss 2.2211570739746094, acc 0.27000001072883606\n",
      "Epoch 2, iter 155, loss 2.2192177772521973, acc 0.33000001311302185\n",
      "Epoch 2, iter 156, loss 2.222550630569458, acc 0.23000000417232513\n",
      "Epoch 2, iter 157, loss 2.2396512031555176, acc 0.27000001072883606\n",
      "Epoch 2, iter 158, loss 2.2250497341156006, acc 0.28999999165534973\n",
      "Epoch 2, iter 159, loss 2.21237850189209, acc 0.3100000023841858\n",
      "Epoch 2, iter 160, loss 2.2329812049865723, acc 0.25\n",
      "Epoch 2, iter 161, loss 2.195246696472168, acc 0.3400000035762787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, iter 162, loss 2.1709372997283936, acc 0.3100000023841858\n",
      "Epoch 2, iter 163, loss 2.234861373901367, acc 0.25\n",
      "Epoch 2, iter 164, loss 2.226963758468628, acc 0.25999999046325684\n",
      "Epoch 2, iter 165, loss 2.2459375858306885, acc 0.18000000715255737\n",
      "Epoch 2, iter 166, loss 2.1970341205596924, acc 0.3100000023841858\n",
      "Epoch 2, iter 167, loss 2.218292474746704, acc 0.25999999046325684\n",
      "Epoch 2, iter 168, loss 2.2043957710266113, acc 0.3100000023841858\n",
      "Epoch 2, iter 169, loss 2.177980661392212, acc 0.3700000047683716\n",
      "Epoch 2, iter 170, loss 2.226067066192627, acc 0.28999999165534973\n",
      "Epoch 2, iter 171, loss 2.2243170738220215, acc 0.2800000011920929\n",
      "Epoch 2, iter 172, loss 2.235614061355591, acc 0.27000001072883606\n",
      "Epoch 2, iter 173, loss 2.2390940189361572, acc 0.2199999988079071\n",
      "Epoch 2, iter 174, loss 2.2041430473327637, acc 0.27000001072883606\n",
      "Epoch 2, iter 175, loss 2.21201491355896, acc 0.27000001072883606\n",
      "Epoch 2, iter 176, loss 2.247291088104248, acc 0.2199999988079071\n",
      "Epoch 2, iter 177, loss 2.218691349029541, acc 0.23000000417232513\n",
      "Epoch 2, iter 178, loss 2.2158799171447754, acc 0.30000001192092896\n",
      "Epoch 2, iter 179, loss 2.233506917953491, acc 0.2199999988079071\n",
      "Epoch 2, iter 180, loss 2.2244019508361816, acc 0.23000000417232513\n",
      "Epoch 2, iter 181, loss 2.1893913745880127, acc 0.30000001192092896\n",
      "Epoch 2, iter 182, loss 2.2239551544189453, acc 0.20000000298023224\n",
      "Epoch 2, iter 183, loss 2.2207257747650146, acc 0.23000000417232513\n",
      "Epoch 2, iter 184, loss 2.203640937805176, acc 0.27000001072883606\n",
      "Epoch 2, iter 185, loss 2.200244188308716, acc 0.28999999165534973\n",
      "Epoch 2, iter 186, loss 2.2043497562408447, acc 0.30000001192092896\n",
      "Epoch 2, iter 187, loss 2.2055091857910156, acc 0.2800000011920929\n",
      "Epoch 2, iter 188, loss 2.2218759059906006, acc 0.27000001072883606\n",
      "Epoch 2, iter 189, loss 2.2612268924713135, acc 0.23000000417232513\n",
      "Epoch 2, iter 190, loss 2.2248575687408447, acc 0.2800000011920929\n",
      "Epoch 2, iter 191, loss 2.211642265319824, acc 0.30000001192092896\n",
      "Epoch 2, iter 192, loss 2.1972761154174805, acc 0.3499999940395355\n",
      "Epoch 2, iter 193, loss 2.196303129196167, acc 0.28999999165534973\n",
      "Epoch 2, iter 194, loss 2.2128756046295166, acc 0.3400000035762787\n",
      "Epoch 2, iter 195, loss 2.18173885345459, acc 0.3799999952316284\n",
      "Epoch 2, iter 196, loss 2.2355282306671143, acc 0.2199999988079071\n",
      "Epoch 2, iter 197, loss 2.2175557613372803, acc 0.2199999988079071\n",
      "Epoch 2, iter 198, loss 2.155505657196045, acc 0.3799999952316284\n",
      "Epoch 2, iter 199, loss 2.2223782539367676, acc 0.23000000417232513\n",
      "Epoch 2, iter 200, loss 2.2163538932800293, acc 0.23000000417232513\n",
      "Epoch 2, iter 201, loss 2.200862407684326, acc 0.23000000417232513\n",
      "Epoch 2, iter 202, loss 2.2102842330932617, acc 0.23999999463558197\n",
      "Epoch 2, iter 203, loss 2.2357490062713623, acc 0.23000000417232513\n",
      "Epoch 2, iter 204, loss 2.188169479370117, acc 0.28999999165534973\n",
      "Epoch 2, iter 205, loss 2.172112464904785, acc 0.3400000035762787\n",
      "Epoch 2, iter 206, loss 2.20082688331604, acc 0.25999999046325684\n",
      "Epoch 2, iter 207, loss 2.2371344566345215, acc 0.18000000715255737\n",
      "Epoch 2, iter 208, loss 2.251485824584961, acc 0.18000000715255737\n",
      "Epoch 2, iter 209, loss 2.233654022216797, acc 0.20000000298023224\n",
      "Epoch 2, iter 210, loss 2.2304325103759766, acc 0.1899999976158142\n",
      "Epoch 2, iter 211, loss 2.212862014770508, acc 0.25\n",
      "Epoch 2, iter 212, loss 2.230508327484131, acc 0.27000001072883606\n",
      "Epoch 2, iter 213, loss 2.2440879344940186, acc 0.2199999988079071\n",
      "Epoch 2, iter 214, loss 2.2282440662384033, acc 0.2199999988079071\n",
      "Epoch 2, iter 215, loss 2.2231264114379883, acc 0.23000000417232513\n",
      "Epoch 2, iter 216, loss 2.244051456451416, acc 0.23000000417232513\n",
      "Epoch 2, iter 217, loss 2.195211172103882, acc 0.25999999046325684\n",
      "Epoch 2, iter 218, loss 2.260382890701294, acc 0.15000000596046448\n",
      "Epoch 2, iter 219, loss 2.223823308944702, acc 0.27000001072883606\n",
      "Epoch 2, iter 220, loss 2.198646306991577, acc 0.3100000023841858\n",
      "Epoch 2, iter 221, loss 2.210026741027832, acc 0.27000001072883606\n",
      "Epoch 2, iter 222, loss 2.221595525741577, acc 0.2800000011920929\n",
      "Epoch 2, iter 223, loss 2.2004315853118896, acc 0.30000001192092896\n",
      "Epoch 2, iter 224, loss 2.2291460037231445, acc 0.2199999988079071\n",
      "Epoch 2, iter 225, loss 2.2069923877716064, acc 0.30000001192092896\n",
      "Epoch 2, iter 226, loss 2.1861684322357178, acc 0.28999999165534973\n",
      "Epoch 2, iter 227, loss 2.2131428718566895, acc 0.2199999988079071\n",
      "Epoch 2, iter 228, loss 2.210728406906128, acc 0.20000000298023224\n",
      "Epoch 2, iter 229, loss 2.210669755935669, acc 0.20000000298023224\n",
      "Epoch 2, iter 230, loss 2.194114923477173, acc 0.23999999463558197\n",
      "Epoch 2, iter 231, loss 2.194354772567749, acc 0.2800000011920929\n",
      "Epoch 2, iter 232, loss 2.235085964202881, acc 0.1899999976158142\n",
      "Epoch 2, iter 233, loss 2.177227020263672, acc 0.23999999463558197\n",
      "Epoch 2, iter 234, loss 2.1980698108673096, acc 0.25\n",
      "Epoch 2, iter 235, loss 2.219695568084717, acc 0.20999999344348907\n",
      "Epoch 2, iter 236, loss 2.2438042163848877, acc 0.20000000298023224\n",
      "Epoch 2, iter 237, loss 2.24594783782959, acc 0.15000000596046448\n",
      "Epoch 2, iter 238, loss 2.2223217487335205, acc 0.20000000298023224\n",
      "Epoch 2, iter 239, loss 2.2390787601470947, acc 0.1899999976158142\n",
      "Epoch 2, iter 240, loss 2.2491164207458496, acc 0.1599999964237213\n",
      "Epoch 2, iter 241, loss 2.224419355392456, acc 0.1899999976158142\n",
      "Epoch 2, iter 242, loss 2.243558406829834, acc 0.1599999964237213\n",
      "Epoch 2, iter 243, loss 2.260244369506836, acc 0.14000000059604645\n",
      "Epoch 2, iter 244, loss 2.184744358062744, acc 0.25\n",
      "Epoch 2, iter 245, loss 2.1962320804595947, acc 0.23000000417232513\n",
      "Epoch 2, iter 246, loss 2.2566041946411133, acc 0.14000000059604645\n",
      "Epoch 2, iter 247, loss 2.1898903846740723, acc 0.23999999463558197\n",
      "Epoch 2, iter 248, loss 2.224534749984741, acc 0.15000000596046448\n",
      "Epoch 2, iter 249, loss 2.2529428005218506, acc 0.11999999731779099\n",
      "Epoch 2, iter 250, loss 2.187716007232666, acc 0.25\n",
      "Epoch 2, iter 251, loss 2.221127986907959, acc 0.15000000596046448\n",
      "Epoch 2, iter 252, loss 2.2094435691833496, acc 0.20000000298023224\n",
      "Epoch 2, iter 253, loss 2.266601800918579, acc 0.11999999731779099\n",
      "Epoch 2, iter 254, loss 2.2289552688598633, acc 0.17000000178813934\n",
      "Epoch 2, iter 255, loss 2.2334609031677246, acc 0.1899999976158142\n",
      "Epoch 2, iter 256, loss 2.2141621112823486, acc 0.23000000417232513\n",
      "Epoch 2, iter 257, loss 2.220381736755371, acc 0.20000000298023224\n",
      "Epoch 2, iter 258, loss 2.214711904525757, acc 0.20000000298023224\n",
      "Epoch 2, iter 259, loss 2.230957269668579, acc 0.18000000715255737\n",
      "Epoch 2, iter 260, loss 2.2102112770080566, acc 0.2199999988079071\n",
      "Epoch 2, iter 261, loss 2.1906707286834717, acc 0.25999999046325684\n",
      "Epoch 2, iter 262, loss 2.2425127029418945, acc 0.15000000596046448\n",
      "Epoch 2, iter 263, loss 2.1830921173095703, acc 0.25999999046325684\n",
      "Epoch 2, iter 264, loss 2.191581964492798, acc 0.25999999046325684\n",
      "Epoch 2, iter 265, loss 2.2340502738952637, acc 0.1599999964237213\n",
      "Epoch 2, iter 266, loss 2.198842763900757, acc 0.25\n",
      "Epoch 2, iter 267, loss 2.1744439601898193, acc 0.23000000417232513\n",
      "Epoch 2, iter 268, loss 2.214247941970825, acc 0.20000000298023224\n",
      "Epoch 2, iter 269, loss 2.212792158126831, acc 0.1899999976158142\n",
      "Epoch 2, iter 270, loss 2.2118964195251465, acc 0.20000000298023224\n",
      "Epoch 2, iter 271, loss 2.244230270385742, acc 0.17000000178813934\n",
      "Epoch 2, iter 272, loss 2.221240282058716, acc 0.17000000178813934\n",
      "Epoch 2, iter 273, loss 2.222794532775879, acc 0.17000000178813934\n",
      "Epoch 2, iter 274, loss 2.1978142261505127, acc 0.23999999463558197\n",
      "Epoch 2, iter 275, loss 2.2398595809936523, acc 0.14000000059604645\n",
      "Epoch 2, iter 276, loss 2.2250165939331055, acc 0.1599999964237213\n",
      "Epoch 2, iter 277, loss 2.2071878910064697, acc 0.20999999344348907\n",
      "Epoch 2, iter 278, loss 2.210222005844116, acc 0.20999999344348907\n",
      "Epoch 2, iter 279, loss 2.183692693710327, acc 0.2199999988079071\n",
      "Epoch 2, iter 280, loss 2.1963655948638916, acc 0.23999999463558197\n",
      "Epoch 2, iter 281, loss 2.2002365589141846, acc 0.2199999988079071\n",
      "Epoch 2, iter 282, loss 2.2449541091918945, acc 0.11999999731779099\n",
      "Epoch 2, iter 283, loss 2.20059871673584, acc 0.23000000417232513\n",
      "Epoch 2, iter 284, loss 2.174100399017334, acc 0.25\n",
      "Epoch 2, iter 285, loss 2.180630683898926, acc 0.23000000417232513\n",
      "Epoch 2, iter 286, loss 2.1976099014282227, acc 0.20000000298023224\n",
      "Epoch 2, iter 287, loss 2.215088129043579, acc 0.17000000178813934\n",
      "Epoch 2, iter 288, loss 2.1808369159698486, acc 0.25999999046325684\n",
      "Epoch 2, iter 289, loss 2.220010280609131, acc 0.1599999964237213\n",
      "Epoch 2, iter 290, loss 2.1627402305603027, acc 0.23999999463558197\n",
      "Epoch 2, iter 291, loss 2.1959962844848633, acc 0.23000000417232513\n",
      "Epoch 2, iter 292, loss 2.1774094104766846, acc 0.23999999463558197\n",
      "Epoch 2, iter 293, loss 2.195977210998535, acc 0.2199999988079071\n",
      "Epoch 2, iter 294, loss 2.223297119140625, acc 0.14000000059604645\n",
      "Epoch 2, iter 295, loss 2.2171404361724854, acc 0.20000000298023224\n",
      "Epoch 2, iter 296, loss 2.188865900039673, acc 0.23999999463558197\n",
      "Epoch 2, iter 297, loss 2.2119626998901367, acc 0.1599999964237213\n",
      "Epoch 2, iter 298, loss 2.1879875659942627, acc 0.2199999988079071\n",
      "Epoch 2, iter 299, loss 2.257392644882202, acc 0.15000000596046448\n",
      "Epoch 2, iter 300, loss 2.217428207397461, acc 0.18000000715255737\n",
      "Epoch 2, iter 301, loss 2.2059524059295654, acc 0.17000000178813934\n",
      "Epoch 2, iter 302, loss 2.180506706237793, acc 0.23999999463558197\n",
      "Epoch 2, iter 303, loss 2.209214448928833, acc 0.1899999976158142\n",
      "Epoch 2, iter 304, loss 2.2362477779388428, acc 0.1599999964237213\n",
      "Epoch 2, iter 305, loss 2.2534143924713135, acc 0.10000000149011612\n",
      "Epoch 2, iter 306, loss 2.182119846343994, acc 0.25999999046325684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, iter 307, loss 2.18168568611145, acc 0.27000001072883606\n",
      "Epoch 2, iter 308, loss 2.228576898574829, acc 0.15000000596046448\n",
      "Epoch 2, iter 309, loss 2.2124359607696533, acc 0.20000000298023224\n",
      "Epoch 2, iter 310, loss 2.2099668979644775, acc 0.20000000298023224\n",
      "Epoch 2, iter 311, loss 2.1900384426116943, acc 0.23000000417232513\n",
      "Epoch 2, iter 312, loss 2.1808958053588867, acc 0.20000000298023224\n",
      "Epoch 2, iter 313, loss 2.2496557235717773, acc 0.10999999940395355\n",
      "Epoch 2, iter 314, loss 2.1595537662506104, acc 0.25\n",
      "Epoch 2, iter 315, loss 2.1994926929473877, acc 0.1899999976158142\n",
      "Epoch 2, iter 316, loss 2.234776020050049, acc 0.18000000715255737\n",
      "Epoch 2, iter 317, loss 2.2166831493377686, acc 0.2199999988079071\n",
      "Epoch 2, iter 318, loss 2.1887547969818115, acc 0.23000000417232513\n",
      "Epoch 2, iter 319, loss 2.2076609134674072, acc 0.2199999988079071\n",
      "Epoch 2, iter 320, loss 2.2565319538116455, acc 0.07999999821186066\n",
      "Epoch 2, iter 321, loss 2.2231786251068115, acc 0.20000000298023224\n",
      "Epoch 2, iter 322, loss 2.193938732147217, acc 0.2199999988079071\n",
      "Epoch 2, iter 323, loss 2.1992452144622803, acc 0.23000000417232513\n",
      "Epoch 2, iter 324, loss 2.148239850997925, acc 0.30000001192092896\n",
      "Epoch 2, iter 325, loss 2.2193565368652344, acc 0.15000000596046448\n",
      "Epoch 2, iter 326, loss 2.1903023719787598, acc 0.23999999463558197\n",
      "Epoch 2, iter 327, loss 2.2223873138427734, acc 0.1599999964237213\n",
      "Epoch 2, iter 328, loss 2.1627285480499268, acc 0.27000001072883606\n",
      "Epoch 2, iter 329, loss 2.1765241622924805, acc 0.25999999046325684\n",
      "Epoch 2, iter 330, loss 2.210373640060425, acc 0.1899999976158142\n",
      "Epoch 2, iter 331, loss 2.204780101776123, acc 0.20999999344348907\n",
      "Epoch 2, iter 332, loss 2.2184743881225586, acc 0.14000000059604645\n",
      "Epoch 2, iter 333, loss 2.201080083847046, acc 0.20999999344348907\n",
      "Epoch 2, iter 334, loss 2.2279443740844727, acc 0.14000000059604645\n",
      "Epoch 2, iter 335, loss 2.1509532928466797, acc 0.30000001192092896\n",
      "Epoch 2, iter 336, loss 2.1855363845825195, acc 0.2199999988079071\n",
      "Epoch 2, iter 337, loss 2.1947743892669678, acc 0.20999999344348907\n",
      "Epoch 2, iter 338, loss 2.2000324726104736, acc 0.20999999344348907\n",
      "Epoch 2, iter 339, loss 2.204104423522949, acc 0.1599999964237213\n",
      "Epoch 2, iter 340, loss 2.214120864868164, acc 0.17000000178813934\n",
      "Epoch 2, iter 341, loss 2.180720567703247, acc 0.1899999976158142\n",
      "Epoch 2, iter 342, loss 2.1871912479400635, acc 0.23999999463558197\n",
      "Epoch 2, iter 343, loss 2.22855281829834, acc 0.15000000596046448\n",
      "Epoch 2, iter 344, loss 2.164886951446533, acc 0.25999999046325684\n",
      "Epoch 2, iter 345, loss 2.230297803878784, acc 0.1599999964237213\n",
      "Epoch 2, iter 346, loss 2.148897647857666, acc 0.27000001072883606\n",
      "Epoch 2, iter 347, loss 2.2290985584259033, acc 0.12999999523162842\n",
      "Epoch 2, iter 348, loss 2.1663687229156494, acc 0.25\n",
      "Epoch 2, iter 349, loss 2.148953437805176, acc 0.28999999165534973\n",
      "Epoch 2, iter 350, loss 2.2014429569244385, acc 0.18000000715255737\n",
      "Epoch 2, iter 351, loss 2.208357334136963, acc 0.2199999988079071\n",
      "Epoch 2, iter 352, loss 2.2097158432006836, acc 0.18000000715255737\n",
      "Epoch 2, iter 353, loss 2.2068557739257812, acc 0.2199999988079071\n",
      "Epoch 2, iter 354, loss 2.1760878562927246, acc 0.25999999046325684\n",
      "Epoch 2, iter 355, loss 2.21885347366333, acc 0.14000000059604645\n",
      "Epoch 2, iter 356, loss 2.203984260559082, acc 0.1899999976158142\n",
      "Epoch 2, iter 357, loss 2.2127294540405273, acc 0.1899999976158142\n",
      "Epoch 2, iter 358, loss 2.2366743087768555, acc 0.14000000059604645\n",
      "Epoch 2, iter 359, loss 2.2192540168762207, acc 0.20000000298023224\n",
      "Epoch 2, iter 360, loss 2.1893160343170166, acc 0.18000000715255737\n",
      "Epoch 2, iter 361, loss 2.194711208343506, acc 0.25\n",
      "Epoch 2, iter 362, loss 2.2305822372436523, acc 0.15000000596046448\n",
      "Epoch 2, iter 363, loss 2.1841957569122314, acc 0.20999999344348907\n",
      "Epoch 2, iter 364, loss 2.214329719543457, acc 0.2199999988079071\n",
      "Epoch 2, iter 365, loss 2.1834053993225098, acc 0.25\n",
      "Epoch 2, iter 366, loss 2.152853012084961, acc 0.28999999165534973\n",
      "Epoch 2, iter 367, loss 2.179220676422119, acc 0.23000000417232513\n",
      "Epoch 2, iter 368, loss 2.184896945953369, acc 0.25999999046325684\n",
      "Epoch 2, iter 369, loss 2.1867215633392334, acc 0.23999999463558197\n",
      "Epoch 2, iter 370, loss 2.162461519241333, acc 0.25999999046325684\n",
      "Epoch 2, iter 371, loss 2.159149408340454, acc 0.28999999165534973\n",
      "Epoch 2, iter 372, loss 2.1880617141723633, acc 0.2199999988079071\n",
      "Epoch 2, iter 373, loss 2.2106690406799316, acc 0.20999999344348907\n",
      "Epoch 2, iter 374, loss 2.2049667835235596, acc 0.20000000298023224\n",
      "Epoch 2, iter 375, loss 2.1728458404541016, acc 0.20999999344348907\n",
      "Epoch 2, iter 376, loss 2.2030298709869385, acc 0.20000000298023224\n",
      "Epoch 2, iter 377, loss 2.1592209339141846, acc 0.2800000011920929\n",
      "Epoch 2, iter 378, loss 2.1882753372192383, acc 0.23999999463558197\n",
      "Epoch 2, iter 379, loss 2.2319836616516113, acc 0.10999999940395355\n",
      "Epoch 2, iter 380, loss 2.2137715816497803, acc 0.18000000715255737\n",
      "Epoch 2, iter 381, loss 2.2180793285369873, acc 0.20000000298023224\n",
      "Epoch 2, iter 382, loss 2.174523115158081, acc 0.23000000417232513\n",
      "Epoch 2, iter 383, loss 2.1822595596313477, acc 0.2199999988079071\n",
      "Epoch 2, iter 384, loss 2.209811210632324, acc 0.18000000715255737\n",
      "Epoch 2, iter 385, loss 2.179777145385742, acc 0.20000000298023224\n",
      "Epoch 2, iter 386, loss 2.1800291538238525, acc 0.20999999344348907\n",
      "Epoch 2, iter 387, loss 2.1940433979034424, acc 0.18000000715255737\n",
      "Epoch 2, iter 388, loss 2.2175142765045166, acc 0.20000000298023224\n",
      "Epoch 2, iter 389, loss 2.191598892211914, acc 0.20000000298023224\n",
      "Epoch 2, iter 390, loss 2.250513792037964, acc 0.10999999940395355\n",
      "Epoch 2, iter 391, loss 2.2095677852630615, acc 0.18000000715255737\n",
      "Epoch 2, iter 392, loss 2.215346336364746, acc 0.1599999964237213\n",
      "Epoch 2, iter 393, loss 2.2141716480255127, acc 0.15000000596046448\n",
      "Epoch 2, iter 394, loss 2.195767402648926, acc 0.20999999344348907\n",
      "Epoch 2, iter 395, loss 2.1414895057678223, acc 0.30000001192092896\n",
      "Epoch 2, iter 396, loss 2.208787679672241, acc 0.1599999964237213\n",
      "Epoch 2, iter 397, loss 2.1961188316345215, acc 0.2199999988079071\n",
      "Epoch 2, iter 398, loss 2.2266223430633545, acc 0.1599999964237213\n",
      "Epoch 2, iter 399, loss 2.1914751529693604, acc 0.20999999344348907\n",
      "Epoch 2, iter 400, loss 2.169827461242676, acc 0.2199999988079071\n",
      "Epoch 2, iter 401, loss 2.205392837524414, acc 0.20000000298023224\n",
      "Epoch 2, iter 402, loss 2.181377649307251, acc 0.25\n",
      "Epoch 2, iter 403, loss 2.206517219543457, acc 0.17000000178813934\n",
      "Epoch 2, iter 404, loss 2.2118477821350098, acc 0.1899999976158142\n",
      "Epoch 2, iter 405, loss 2.2175607681274414, acc 0.17000000178813934\n",
      "Epoch 2, iter 406, loss 2.2099952697753906, acc 0.20999999344348907\n",
      "Epoch 2, iter 407, loss 2.2107088565826416, acc 0.20000000298023224\n",
      "Epoch 2, iter 408, loss 2.211200714111328, acc 0.1599999964237213\n",
      "Epoch 2, iter 409, loss 2.1853268146514893, acc 0.20000000298023224\n",
      "Epoch 2, iter 410, loss 2.1834003925323486, acc 0.20999999344348907\n",
      "Epoch 2, iter 411, loss 2.1576638221740723, acc 0.23999999463558197\n",
      "Epoch 2, iter 412, loss 2.187028408050537, acc 0.20999999344348907\n",
      "Epoch 2, iter 413, loss 2.2006161212921143, acc 0.2199999988079071\n",
      "Epoch 2, iter 414, loss 2.2044804096221924, acc 0.20999999344348907\n",
      "Epoch 2, iter 415, loss 2.2034685611724854, acc 0.18000000715255737\n",
      "Epoch 2, iter 416, loss 2.17268967628479, acc 0.23999999463558197\n",
      "Epoch 2, iter 417, loss 2.163548231124878, acc 0.2199999988079071\n",
      "Epoch 2, iter 418, loss 2.1830215454101562, acc 0.23000000417232513\n",
      "Epoch 2, iter 419, loss 2.149432420730591, acc 0.25999999046325684\n",
      "Epoch 2, iter 420, loss 2.1791956424713135, acc 0.20000000298023224\n",
      "Epoch 3, iter 1, loss 2.172168254852295, acc 0.2199999988079071\n",
      "Epoch 3, iter 2, loss 2.223597288131714, acc 0.12999999523162842\n",
      "Epoch 3, iter 3, loss 2.2005574703216553, acc 0.1899999976158142\n",
      "Epoch 3, iter 4, loss 2.2327466011047363, acc 0.14000000059604645\n",
      "Epoch 3, iter 5, loss 2.201137065887451, acc 0.17000000178813934\n",
      "Epoch 3, iter 6, loss 2.213916301727295, acc 0.17000000178813934\n",
      "Epoch 3, iter 7, loss 2.196767568588257, acc 0.2199999988079071\n",
      "Epoch 3, iter 8, loss 2.186603307723999, acc 0.23000000417232513\n",
      "Epoch 3, iter 9, loss 2.2196733951568604, acc 0.18000000715255737\n",
      "Epoch 3, iter 10, loss 2.224778890609741, acc 0.1599999964237213\n",
      "Epoch 3, iter 11, loss 2.208873987197876, acc 0.1899999976158142\n",
      "Epoch 3, iter 12, loss 2.201843500137329, acc 0.1899999976158142\n",
      "Epoch 3, iter 13, loss 2.1877388954162598, acc 0.2199999988079071\n",
      "Epoch 3, iter 14, loss 2.160414218902588, acc 0.27000001072883606\n",
      "Epoch 3, iter 15, loss 2.135798692703247, acc 0.27000001072883606\n",
      "Epoch 3, iter 16, loss 2.1684908866882324, acc 0.23999999463558197\n",
      "Epoch 3, iter 17, loss 2.2029356956481934, acc 0.17000000178813934\n",
      "Epoch 3, iter 18, loss 2.2137861251831055, acc 0.1899999976158142\n",
      "Epoch 3, iter 19, loss 2.175665855407715, acc 0.25999999046325684\n",
      "Epoch 3, iter 20, loss 2.166687488555908, acc 0.2800000011920929\n",
      "Epoch 3, iter 21, loss 2.1550917625427246, acc 0.27000001072883606\n",
      "Epoch 3, iter 22, loss 2.196195125579834, acc 0.1899999976158142\n",
      "Epoch 3, iter 23, loss 2.161285161972046, acc 0.25999999046325684\n",
      "Epoch 3, iter 24, loss 2.1854701042175293, acc 0.20999999344348907\n",
      "Epoch 3, iter 25, loss 2.2079312801361084, acc 0.18000000715255737\n",
      "Epoch 3, iter 26, loss 2.205806255340576, acc 0.18000000715255737\n",
      "Epoch 3, iter 27, loss 2.197211265563965, acc 0.1899999976158142\n",
      "Epoch 3, iter 28, loss 2.1542835235595703, acc 0.27000001072883606\n",
      "Epoch 3, iter 29, loss 2.1961510181427, acc 0.1899999976158142\n",
      "Epoch 3, iter 30, loss 2.211300849914551, acc 0.20999999344348907\n",
      "Epoch 3, iter 31, loss 2.2520973682403564, acc 0.11999999731779099\n",
      "Epoch 3, iter 32, loss 2.184152841567993, acc 0.20000000298023224\n",
      "Epoch 3, iter 33, loss 2.213874101638794, acc 0.17000000178813934\n",
      "Epoch 3, iter 34, loss 2.189215660095215, acc 0.23000000417232513\n",
      "Epoch 3, iter 35, loss 2.1862573623657227, acc 0.20999999344348907\n",
      "Epoch 3, iter 36, loss 2.1897692680358887, acc 0.23999999463558197\n",
      "Epoch 3, iter 37, loss 2.217963933944702, acc 0.1599999964237213\n",
      "Epoch 3, iter 38, loss 2.210437059402466, acc 0.18000000715255737\n",
      "Epoch 3, iter 39, loss 2.173649549484253, acc 0.25999999046325684\n",
      "Epoch 3, iter 40, loss 2.1499507427215576, acc 0.25999999046325684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 41, loss 2.2294507026672363, acc 0.1599999964237213\n",
      "Epoch 3, iter 42, loss 2.1990342140197754, acc 0.20000000298023224\n",
      "Epoch 3, iter 43, loss 2.15263295173645, acc 0.27000001072883606\n",
      "Epoch 3, iter 44, loss 2.151308536529541, acc 0.25999999046325684\n",
      "Epoch 3, iter 45, loss 2.2041783332824707, acc 0.18000000715255737\n",
      "Epoch 3, iter 46, loss 2.1925554275512695, acc 0.18000000715255737\n",
      "Epoch 3, iter 47, loss 2.212899684906006, acc 0.17000000178813934\n",
      "Epoch 3, iter 48, loss 2.1666438579559326, acc 0.27000001072883606\n",
      "Epoch 3, iter 49, loss 2.1717936992645264, acc 0.23000000417232513\n",
      "Epoch 3, iter 50, loss 2.20706844329834, acc 0.1899999976158142\n",
      "Epoch 3, iter 51, loss 2.168907880783081, acc 0.23999999463558197\n",
      "Epoch 3, iter 52, loss 2.2107503414154053, acc 0.18000000715255737\n",
      "Epoch 3, iter 53, loss 2.1601974964141846, acc 0.23000000417232513\n",
      "Epoch 3, iter 54, loss 2.1869633197784424, acc 0.20999999344348907\n",
      "Epoch 3, iter 55, loss 2.25811505317688, acc 0.10000000149011612\n",
      "Epoch 3, iter 56, loss 2.1870689392089844, acc 0.20999999344348907\n",
      "Epoch 3, iter 57, loss 2.2352569103240967, acc 0.12999999523162842\n",
      "Epoch 3, iter 58, loss 2.2129712104797363, acc 0.1599999964237213\n",
      "Epoch 3, iter 59, loss 2.182293176651001, acc 0.1899999976158142\n",
      "Epoch 3, iter 60, loss 2.19303035736084, acc 0.2199999988079071\n",
      "Epoch 3, iter 61, loss 2.182603120803833, acc 0.2199999988079071\n",
      "Epoch 3, iter 62, loss 2.1969282627105713, acc 0.20000000298023224\n",
      "Epoch 3, iter 63, loss 2.2065703868865967, acc 0.1599999964237213\n",
      "Epoch 3, iter 64, loss 2.159445285797119, acc 0.2199999988079071\n",
      "Epoch 3, iter 65, loss 2.194727897644043, acc 0.17000000178813934\n",
      "Epoch 3, iter 66, loss 2.164547920227051, acc 0.23000000417232513\n",
      "Epoch 3, iter 67, loss 2.206240177154541, acc 0.1899999976158142\n",
      "Epoch 3, iter 68, loss 2.1491973400115967, acc 0.23000000417232513\n",
      "Epoch 3, iter 69, loss 2.1878914833068848, acc 0.2199999988079071\n",
      "Epoch 3, iter 70, loss 2.189196825027466, acc 0.18000000715255737\n",
      "Epoch 3, iter 71, loss 2.209512233734131, acc 0.1599999964237213\n",
      "Epoch 3, iter 72, loss 2.1816794872283936, acc 0.20000000298023224\n",
      "Epoch 3, iter 73, loss 2.165647506713867, acc 0.23999999463558197\n",
      "Epoch 3, iter 74, loss 2.1849381923675537, acc 0.20000000298023224\n",
      "Epoch 3, iter 75, loss 2.193845748901367, acc 0.20000000298023224\n",
      "Epoch 3, iter 76, loss 2.1874747276306152, acc 0.20000000298023224\n",
      "Epoch 3, iter 77, loss 2.229973793029785, acc 0.1599999964237213\n",
      "Epoch 3, iter 78, loss 2.1974079608917236, acc 0.18000000715255737\n",
      "Epoch 3, iter 79, loss 2.183323621749878, acc 0.20000000298023224\n",
      "Epoch 3, iter 80, loss 2.16644287109375, acc 0.25\n",
      "Epoch 3, iter 81, loss 2.2122695446014404, acc 0.18000000715255737\n",
      "Epoch 3, iter 82, loss 2.2048120498657227, acc 0.18000000715255737\n",
      "Epoch 3, iter 83, loss 2.1639938354492188, acc 0.23000000417232513\n",
      "Epoch 3, iter 84, loss 2.216121196746826, acc 0.20000000298023224\n",
      "Epoch 3, iter 85, loss 2.2237637042999268, acc 0.12999999523162842\n",
      "Epoch 3, iter 86, loss 2.1820390224456787, acc 0.1899999976158142\n",
      "Epoch 3, iter 87, loss 2.189751148223877, acc 0.20000000298023224\n",
      "Epoch 3, iter 88, loss 2.1533994674682617, acc 0.23999999463558197\n",
      "Epoch 3, iter 89, loss 2.1953063011169434, acc 0.1899999976158142\n",
      "Epoch 3, iter 90, loss 2.1769704818725586, acc 0.20999999344348907\n",
      "Epoch 3, iter 91, loss 2.1730799674987793, acc 0.2199999988079071\n",
      "Epoch 3, iter 92, loss 2.218839645385742, acc 0.17000000178813934\n",
      "Epoch 3, iter 93, loss 2.167738914489746, acc 0.27000001072883606\n",
      "Epoch 3, iter 94, loss 2.184814929962158, acc 0.20999999344348907\n",
      "Epoch 3, iter 95, loss 2.1676578521728516, acc 0.23000000417232513\n",
      "Epoch 3, iter 96, loss 2.204564094543457, acc 0.2800000011920929\n",
      "Epoch 3, iter 97, loss 2.1936562061309814, acc 0.20999999344348907\n",
      "Epoch 3, iter 98, loss 2.1969282627105713, acc 0.25999999046325684\n",
      "Epoch 3, iter 99, loss 2.179434299468994, acc 0.33000001311302185\n",
      "Epoch 3, iter 100, loss 2.1635894775390625, acc 0.3499999940395355\n",
      "Epoch 3, iter 101, loss 2.171109676361084, acc 0.2800000011920929\n",
      "Epoch 3, iter 102, loss 2.186023235321045, acc 0.28999999165534973\n",
      "Epoch 3, iter 103, loss 2.1675941944122314, acc 0.3400000035762787\n",
      "Epoch 3, iter 104, loss 2.2000746726989746, acc 0.33000001311302185\n",
      "Epoch 3, iter 105, loss 2.118260383605957, acc 0.36000001430511475\n",
      "Epoch 3, iter 106, loss 2.143634796142578, acc 0.3700000047683716\n",
      "Epoch 3, iter 107, loss 2.1571357250213623, acc 0.3400000035762787\n",
      "Epoch 3, iter 108, loss 2.1981654167175293, acc 0.20000000298023224\n",
      "Epoch 3, iter 109, loss 2.172112464904785, acc 0.3199999928474426\n",
      "Epoch 3, iter 110, loss 2.205665349960327, acc 0.20000000298023224\n",
      "Epoch 3, iter 111, loss 2.1773793697357178, acc 0.23999999463558197\n",
      "Epoch 3, iter 112, loss 2.164065361022949, acc 0.2800000011920929\n",
      "Epoch 3, iter 113, loss 2.1481616497039795, acc 0.33000001311302185\n",
      "Epoch 3, iter 114, loss 2.1418237686157227, acc 0.3199999928474426\n",
      "Epoch 3, iter 115, loss 2.1508383750915527, acc 0.3400000035762787\n",
      "Epoch 3, iter 116, loss 2.1589548587799072, acc 0.25999999046325684\n",
      "Epoch 3, iter 117, loss 2.194248914718628, acc 0.3199999928474426\n",
      "Epoch 3, iter 118, loss 2.190572500228882, acc 0.25\n",
      "Epoch 3, iter 119, loss 2.1897997856140137, acc 0.28999999165534973\n",
      "Epoch 3, iter 120, loss 2.1840708255767822, acc 0.3100000023841858\n",
      "Epoch 3, iter 121, loss 2.2016847133636475, acc 0.30000001192092896\n",
      "Epoch 3, iter 122, loss 2.169694185256958, acc 0.3799999952316284\n",
      "Epoch 3, iter 123, loss 2.2063934803009033, acc 0.2199999988079071\n",
      "Epoch 3, iter 124, loss 2.1505074501037598, acc 0.3499999940395355\n",
      "Epoch 3, iter 125, loss 2.1998510360717773, acc 0.25\n",
      "Epoch 3, iter 126, loss 2.1672327518463135, acc 0.27000001072883606\n",
      "Epoch 3, iter 127, loss 2.177713394165039, acc 0.3100000023841858\n",
      "Epoch 3, iter 128, loss 2.187896490097046, acc 0.2800000011920929\n",
      "Epoch 3, iter 129, loss 2.2076172828674316, acc 0.27000001072883606\n",
      "Epoch 3, iter 130, loss 2.2079551219940186, acc 0.25\n",
      "Epoch 3, iter 131, loss 2.240172863006592, acc 0.25\n",
      "Epoch 3, iter 132, loss 2.1803805828094482, acc 0.30000001192092896\n",
      "Epoch 3, iter 133, loss 2.1680898666381836, acc 0.3499999940395355\n",
      "Epoch 3, iter 134, loss 2.220374345779419, acc 0.23000000417232513\n",
      "Epoch 3, iter 135, loss 2.1946277618408203, acc 0.25999999046325684\n",
      "Epoch 3, iter 136, loss 2.157186985015869, acc 0.33000001311302185\n",
      "Epoch 3, iter 137, loss 2.1860921382904053, acc 0.27000001072883606\n",
      "Epoch 3, iter 138, loss 2.2062432765960693, acc 0.25\n",
      "Epoch 3, iter 139, loss 2.2018074989318848, acc 0.23999999463558197\n",
      "Epoch 3, iter 140, loss 2.1931846141815186, acc 0.2800000011920929\n",
      "Epoch 3, iter 141, loss 2.2012972831726074, acc 0.23999999463558197\n",
      "Epoch 3, iter 142, loss 2.195274591445923, acc 0.23999999463558197\n",
      "Epoch 3, iter 143, loss 2.1929118633270264, acc 0.27000001072883606\n",
      "Epoch 3, iter 144, loss 2.212373733520508, acc 0.23000000417232513\n",
      "Epoch 3, iter 145, loss 2.1807994842529297, acc 0.28999999165534973\n",
      "Epoch 3, iter 146, loss 2.178133964538574, acc 0.27000001072883606\n",
      "Epoch 3, iter 147, loss 2.18552303314209, acc 0.3100000023841858\n",
      "Epoch 3, iter 148, loss 2.144864559173584, acc 0.2800000011920929\n",
      "Epoch 3, iter 149, loss 2.13895320892334, acc 0.3100000023841858\n",
      "Epoch 3, iter 150, loss 2.1773505210876465, acc 0.2800000011920929\n",
      "Epoch 3, iter 151, loss 2.094114065170288, acc 0.38999998569488525\n",
      "Epoch 3, iter 152, loss 2.174619197845459, acc 0.3199999928474426\n",
      "Epoch 3, iter 153, loss 2.1786081790924072, acc 0.3199999928474426\n",
      "Epoch 3, iter 154, loss 2.200457811355591, acc 0.23000000417232513\n",
      "Epoch 3, iter 155, loss 2.1927690505981445, acc 0.23000000417232513\n",
      "Epoch 3, iter 156, loss 2.1925771236419678, acc 0.27000001072883606\n",
      "Epoch 3, iter 157, loss 2.2216274738311768, acc 0.17000000178813934\n",
      "Epoch 3, iter 158, loss 2.193232536315918, acc 0.25999999046325684\n",
      "Epoch 3, iter 159, loss 2.164252519607544, acc 0.2800000011920929\n",
      "Epoch 3, iter 160, loss 2.1972362995147705, acc 0.23000000417232513\n",
      "Epoch 3, iter 161, loss 2.157257556915283, acc 0.28999999165534973\n",
      "Epoch 3, iter 162, loss 2.1153528690338135, acc 0.41999998688697815\n",
      "Epoch 3, iter 163, loss 2.1957077980041504, acc 0.27000001072883606\n",
      "Epoch 3, iter 164, loss 2.197997808456421, acc 0.25\n",
      "Epoch 3, iter 165, loss 2.2212207317352295, acc 0.2800000011920929\n",
      "Epoch 3, iter 166, loss 2.16288161277771, acc 0.3199999928474426\n",
      "Epoch 3, iter 167, loss 2.1906185150146484, acc 0.2199999988079071\n",
      "Epoch 3, iter 168, loss 2.15561580657959, acc 0.33000001311302185\n",
      "Epoch 3, iter 169, loss 2.1286351680755615, acc 0.3100000023841858\n",
      "Epoch 3, iter 170, loss 2.188366651535034, acc 0.20999999344348907\n",
      "Epoch 3, iter 171, loss 2.1743524074554443, acc 0.3100000023841858\n",
      "Epoch 3, iter 172, loss 2.201864242553711, acc 0.23999999463558197\n",
      "Epoch 3, iter 173, loss 2.2097811698913574, acc 0.25\n",
      "Epoch 3, iter 174, loss 2.163907051086426, acc 0.2800000011920929\n",
      "Epoch 3, iter 175, loss 2.1590073108673096, acc 0.33000001311302185\n",
      "Epoch 3, iter 176, loss 2.218421220779419, acc 0.18000000715255737\n",
      "Epoch 3, iter 177, loss 2.1785402297973633, acc 0.3400000035762787\n",
      "Epoch 3, iter 178, loss 2.176556348800659, acc 0.28999999165534973\n",
      "Epoch 3, iter 179, loss 2.1841940879821777, acc 0.27000001072883606\n",
      "Epoch 3, iter 180, loss 2.205944776535034, acc 0.2800000011920929\n",
      "Epoch 3, iter 181, loss 2.1354405879974365, acc 0.3499999940395355\n",
      "Epoch 3, iter 182, loss 2.2111656665802, acc 0.23000000417232513\n",
      "Epoch 3, iter 183, loss 2.189929723739624, acc 0.25\n",
      "Epoch 3, iter 184, loss 2.173210620880127, acc 0.23999999463558197\n",
      "Epoch 3, iter 185, loss 2.1809043884277344, acc 0.23999999463558197\n",
      "Epoch 3, iter 186, loss 2.177945375442505, acc 0.25999999046325684\n",
      "Epoch 3, iter 187, loss 2.181420087814331, acc 0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 188, loss 2.1926822662353516, acc 0.20999999344348907\n",
      "Epoch 3, iter 189, loss 2.2475881576538086, acc 0.14000000059604645\n",
      "Epoch 3, iter 190, loss 2.179173469543457, acc 0.3199999928474426\n",
      "Epoch 3, iter 191, loss 2.189999580383301, acc 0.25999999046325684\n",
      "Epoch 3, iter 192, loss 2.1751606464385986, acc 0.25999999046325684\n",
      "Epoch 3, iter 193, loss 2.1601858139038086, acc 0.3100000023841858\n",
      "Epoch 3, iter 194, loss 2.180999994277954, acc 0.23999999463558197\n",
      "Epoch 3, iter 195, loss 2.1271326541900635, acc 0.3700000047683716\n",
      "Epoch 3, iter 196, loss 2.211932897567749, acc 0.23999999463558197\n",
      "Epoch 3, iter 197, loss 2.1799967288970947, acc 0.33000001311302185\n",
      "Epoch 3, iter 198, loss 2.11340594291687, acc 0.3799999952316284\n",
      "Epoch 3, iter 199, loss 2.182547092437744, acc 0.27000001072883606\n",
      "Epoch 3, iter 200, loss 2.188427209854126, acc 0.30000001192092896\n",
      "Epoch 3, iter 201, loss 2.168304204940796, acc 0.3199999928474426\n",
      "Epoch 3, iter 202, loss 2.1709835529327393, acc 0.25\n",
      "Epoch 3, iter 203, loss 2.1952531337738037, acc 0.23999999463558197\n",
      "Epoch 3, iter 204, loss 2.1464219093322754, acc 0.3700000047683716\n",
      "Epoch 3, iter 205, loss 2.1206424236297607, acc 0.3700000047683716\n",
      "Epoch 3, iter 206, loss 2.1746180057525635, acc 0.23000000417232513\n",
      "Epoch 3, iter 207, loss 2.2013137340545654, acc 0.25999999046325684\n",
      "Epoch 3, iter 208, loss 2.221544027328491, acc 0.23000000417232513\n",
      "Epoch 3, iter 209, loss 2.2093629837036133, acc 0.23000000417232513\n",
      "Epoch 3, iter 210, loss 2.2247869968414307, acc 0.20000000298023224\n",
      "Epoch 3, iter 211, loss 2.174917697906494, acc 0.28999999165534973\n",
      "Epoch 3, iter 212, loss 2.203986167907715, acc 0.2199999988079071\n",
      "Epoch 3, iter 213, loss 2.2017531394958496, acc 0.27000001072883606\n",
      "Epoch 3, iter 214, loss 2.19267201423645, acc 0.27000001072883606\n",
      "Epoch 3, iter 215, loss 2.182788848876953, acc 0.23000000417232513\n",
      "Epoch 3, iter 216, loss 2.2171120643615723, acc 0.20999999344348907\n",
      "Epoch 3, iter 217, loss 2.155874729156494, acc 0.3400000035762787\n",
      "Epoch 3, iter 218, loss 2.239945888519287, acc 0.25\n",
      "Epoch 3, iter 219, loss 2.1739935874938965, acc 0.27000001072883606\n",
      "Epoch 3, iter 220, loss 2.143679141998291, acc 0.36000001430511475\n",
      "Epoch 3, iter 221, loss 2.1771128177642822, acc 0.30000001192092896\n",
      "Epoch 3, iter 222, loss 2.180314779281616, acc 0.30000001192092896\n",
      "Epoch 3, iter 223, loss 2.155569553375244, acc 0.3499999940395355\n",
      "Epoch 3, iter 224, loss 2.2025508880615234, acc 0.28999999165534973\n",
      "Epoch 3, iter 225, loss 2.1600778102874756, acc 0.23999999463558197\n",
      "Epoch 3, iter 226, loss 2.1570522785186768, acc 0.28999999165534973\n",
      "Epoch 3, iter 227, loss 2.180711269378662, acc 0.28999999165534973\n",
      "Epoch 3, iter 228, loss 2.1943047046661377, acc 0.25999999046325684\n",
      "Epoch 3, iter 229, loss 2.1679084300994873, acc 0.3100000023841858\n",
      "Epoch 3, iter 230, loss 2.166667938232422, acc 0.28999999165534973\n",
      "Epoch 3, iter 231, loss 2.152355909347534, acc 0.3100000023841858\n",
      "Epoch 3, iter 232, loss 2.195237159729004, acc 0.23999999463558197\n",
      "Epoch 3, iter 233, loss 2.147705078125, acc 0.3199999928474426\n",
      "Epoch 3, iter 234, loss 2.144705295562744, acc 0.38999998569488525\n",
      "Epoch 3, iter 235, loss 2.164487361907959, acc 0.28999999165534973\n",
      "Epoch 3, iter 236, loss 2.1822142601013184, acc 0.28999999165534973\n",
      "Epoch 3, iter 237, loss 2.2117133140563965, acc 0.2199999988079071\n",
      "Epoch 3, iter 238, loss 2.1684601306915283, acc 0.3100000023841858\n",
      "Epoch 3, iter 239, loss 2.198967456817627, acc 0.2199999988079071\n",
      "Epoch 3, iter 240, loss 2.1971263885498047, acc 0.23999999463558197\n",
      "Epoch 3, iter 241, loss 2.1793787479400635, acc 0.25\n",
      "Epoch 3, iter 242, loss 2.2034051418304443, acc 0.30000001192092896\n",
      "Epoch 3, iter 243, loss 2.2256810665130615, acc 0.23999999463558197\n",
      "Epoch 3, iter 244, loss 2.1517333984375, acc 0.36000001430511475\n",
      "Epoch 3, iter 245, loss 2.161851644515991, acc 0.3100000023841858\n",
      "Epoch 3, iter 246, loss 2.2310216426849365, acc 0.18000000715255737\n",
      "Epoch 3, iter 247, loss 2.1573781967163086, acc 0.30000001192092896\n",
      "Epoch 3, iter 248, loss 2.199414014816284, acc 0.17000000178813934\n",
      "Epoch 3, iter 249, loss 2.2280077934265137, acc 0.15000000596046448\n",
      "Epoch 3, iter 250, loss 2.138960599899292, acc 0.3499999940395355\n",
      "Epoch 3, iter 251, loss 2.2007863521575928, acc 0.1899999976158142\n",
      "Epoch 3, iter 252, loss 2.1694774627685547, acc 0.30000001192092896\n",
      "Epoch 3, iter 253, loss 2.226160764694214, acc 0.23999999463558197\n",
      "Epoch 3, iter 254, loss 2.200141668319702, acc 0.25\n",
      "Epoch 3, iter 255, loss 2.1888675689697266, acc 0.2800000011920929\n",
      "Epoch 3, iter 256, loss 2.161769151687622, acc 0.3700000047683716\n",
      "Epoch 3, iter 257, loss 2.1826422214508057, acc 0.25\n",
      "Epoch 3, iter 258, loss 2.180598735809326, acc 0.2800000011920929\n",
      "Epoch 3, iter 259, loss 2.2058634757995605, acc 0.28999999165534973\n",
      "Epoch 3, iter 260, loss 2.187892198562622, acc 0.28999999165534973\n",
      "Epoch 3, iter 261, loss 2.1519713401794434, acc 0.3199999928474426\n",
      "Epoch 3, iter 262, loss 2.201845407485962, acc 0.23999999463558197\n",
      "Epoch 3, iter 263, loss 2.141216993331909, acc 0.33000001311302185\n",
      "Epoch 3, iter 264, loss 2.157047748565674, acc 0.3400000035762787\n",
      "Epoch 3, iter 265, loss 2.210177421569824, acc 0.3100000023841858\n",
      "Epoch 3, iter 266, loss 2.1462838649749756, acc 0.30000001192092896\n",
      "Epoch 3, iter 267, loss 2.1362099647521973, acc 0.3499999940395355\n",
      "Epoch 3, iter 268, loss 2.1894850730895996, acc 0.23000000417232513\n",
      "Epoch 3, iter 269, loss 2.1867568492889404, acc 0.27000001072883606\n",
      "Epoch 3, iter 270, loss 2.185594081878662, acc 0.25999999046325684\n",
      "Epoch 3, iter 271, loss 2.2056643962860107, acc 0.30000001192092896\n",
      "Epoch 3, iter 272, loss 2.199122190475464, acc 0.20999999344348907\n",
      "Epoch 3, iter 273, loss 2.1952948570251465, acc 0.25999999046325684\n",
      "Epoch 3, iter 274, loss 2.1635282039642334, acc 0.30000001192092896\n",
      "Epoch 3, iter 275, loss 2.215909481048584, acc 0.25999999046325684\n",
      "Epoch 3, iter 276, loss 2.202531337738037, acc 0.27000001072883606\n",
      "Epoch 3, iter 277, loss 2.167630434036255, acc 0.3100000023841858\n",
      "Epoch 3, iter 278, loss 2.1706438064575195, acc 0.30000001192092896\n",
      "Epoch 3, iter 279, loss 2.157280921936035, acc 0.3499999940395355\n",
      "Epoch 3, iter 280, loss 2.15165638923645, acc 0.30000001192092896\n",
      "Epoch 3, iter 281, loss 2.1692702770233154, acc 0.3700000047683716\n",
      "Epoch 3, iter 282, loss 2.223242998123169, acc 0.20999999344348907\n",
      "Epoch 3, iter 283, loss 2.1767449378967285, acc 0.27000001072883606\n",
      "Epoch 3, iter 284, loss 2.140345811843872, acc 0.36000001430511475\n",
      "Epoch 3, iter 285, loss 2.1452291011810303, acc 0.2800000011920929\n",
      "Epoch 3, iter 286, loss 2.171130895614624, acc 0.30000001192092896\n",
      "Epoch 3, iter 287, loss 2.196479558944702, acc 0.27000001072883606\n",
      "Epoch 3, iter 288, loss 2.1386938095092773, acc 0.33000001311302185\n",
      "Epoch 3, iter 289, loss 2.2012031078338623, acc 0.25999999046325684\n",
      "Epoch 3, iter 290, loss 2.1478219032287598, acc 0.28999999165534973\n",
      "Epoch 3, iter 291, loss 2.1641945838928223, acc 0.3100000023841858\n",
      "Epoch 3, iter 292, loss 2.142665147781372, acc 0.3199999928474426\n",
      "Epoch 3, iter 293, loss 2.1598308086395264, acc 0.30000001192092896\n",
      "Epoch 3, iter 294, loss 2.218038558959961, acc 0.17000000178813934\n",
      "Epoch 3, iter 295, loss 2.185758113861084, acc 0.28999999165534973\n",
      "Epoch 3, iter 296, loss 2.158463954925537, acc 0.3199999928474426\n",
      "Epoch 3, iter 297, loss 2.2142860889434814, acc 0.2199999988079071\n",
      "Epoch 3, iter 298, loss 2.174506425857544, acc 0.2800000011920929\n",
      "Epoch 3, iter 299, loss 2.2290146350860596, acc 0.20999999344348907\n",
      "Epoch 3, iter 300, loss 2.2034919261932373, acc 0.20999999344348907\n",
      "Epoch 3, iter 301, loss 2.1958751678466797, acc 0.23999999463558197\n",
      "Epoch 3, iter 302, loss 2.15655779838562, acc 0.3100000023841858\n",
      "Epoch 3, iter 303, loss 2.173497438430786, acc 0.2800000011920929\n",
      "Epoch 3, iter 304, loss 2.2201077938079834, acc 0.1899999976158142\n",
      "Epoch 3, iter 305, loss 2.235814094543457, acc 0.17000000178813934\n",
      "Epoch 3, iter 306, loss 2.1430442333221436, acc 0.28999999165534973\n",
      "Epoch 3, iter 307, loss 2.1510169506073, acc 0.33000001311302185\n",
      "Epoch 3, iter 308, loss 2.2161805629730225, acc 0.25\n",
      "Epoch 3, iter 309, loss 2.1731173992156982, acc 0.27000001072883606\n",
      "Epoch 3, iter 310, loss 2.192981243133545, acc 0.25\n",
      "Epoch 3, iter 311, loss 2.170959711074829, acc 0.27000001072883606\n",
      "Epoch 3, iter 312, loss 2.169491767883301, acc 0.30000001192092896\n",
      "Epoch 3, iter 313, loss 2.2375004291534424, acc 0.15000000596046448\n",
      "Epoch 3, iter 314, loss 2.141582727432251, acc 0.33000001311302185\n",
      "Epoch 3, iter 315, loss 2.1800880432128906, acc 0.30000001192092896\n",
      "Epoch 3, iter 316, loss 2.2000341415405273, acc 0.25999999046325684\n",
      "Epoch 3, iter 317, loss 2.1734209060668945, acc 0.3499999940395355\n",
      "Epoch 3, iter 318, loss 2.177960157394409, acc 0.25999999046325684\n",
      "Epoch 3, iter 319, loss 2.1749744415283203, acc 0.2800000011920929\n",
      "Epoch 3, iter 320, loss 2.250197410583496, acc 0.1599999964237213\n",
      "Epoch 3, iter 321, loss 2.196254014968872, acc 0.2800000011920929\n",
      "Epoch 3, iter 322, loss 2.1672050952911377, acc 0.2800000011920929\n",
      "Epoch 3, iter 323, loss 2.1643145084381104, acc 0.3199999928474426\n",
      "Epoch 3, iter 324, loss 2.1107680797576904, acc 0.3400000035762787\n",
      "Epoch 3, iter 325, loss 2.2014167308807373, acc 0.25\n",
      "Epoch 3, iter 326, loss 2.158292293548584, acc 0.3100000023841858\n",
      "Epoch 3, iter 327, loss 2.2037155628204346, acc 0.2199999988079071\n",
      "Epoch 3, iter 328, loss 2.1315224170684814, acc 0.3499999940395355\n",
      "Epoch 3, iter 329, loss 2.1450536251068115, acc 0.30000001192092896\n",
      "Epoch 3, iter 330, loss 2.1898441314697266, acc 0.30000001192092896\n",
      "Epoch 3, iter 331, loss 2.196096420288086, acc 0.23000000417232513\n",
      "Epoch 3, iter 332, loss 2.193080186843872, acc 0.28999999165534973\n",
      "Epoch 3, iter 333, loss 2.1690595149993896, acc 0.3100000023841858\n",
      "Epoch 3, iter 334, loss 2.2071526050567627, acc 0.25999999046325684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iter 335, loss 2.109499454498291, acc 0.36000001430511475\n",
      "Epoch 3, iter 336, loss 2.162052869796753, acc 0.3100000023841858\n",
      "Epoch 3, iter 337, loss 2.1889450550079346, acc 0.23999999463558197\n",
      "Epoch 3, iter 338, loss 2.1610045433044434, acc 0.3100000023841858\n",
      "Epoch 3, iter 339, loss 2.1890087127685547, acc 0.25\n",
      "Epoch 3, iter 340, loss 2.1878600120544434, acc 0.28999999165534973\n",
      "Epoch 3, iter 341, loss 2.159515142440796, acc 0.2800000011920929\n",
      "Epoch 3, iter 342, loss 2.161776542663574, acc 0.30000001192092896\n",
      "Epoch 3, iter 343, loss 2.2108113765716553, acc 0.23999999463558197\n",
      "Epoch 3, iter 344, loss 2.1336944103240967, acc 0.33000001311302185\n",
      "Epoch 3, iter 345, loss 2.207810401916504, acc 0.2199999988079071\n",
      "Epoch 3, iter 346, loss 2.118921995162964, acc 0.3499999940395355\n",
      "Epoch 3, iter 347, loss 2.2221524715423584, acc 0.23000000417232513\n",
      "Epoch 3, iter 348, loss 2.1409361362457275, acc 0.3700000047683716\n",
      "Epoch 3, iter 349, loss 2.1113121509552, acc 0.38999998569488525\n",
      "Epoch 3, iter 350, loss 2.1824145317077637, acc 0.30000001192092896\n",
      "Epoch 3, iter 351, loss 2.1668481826782227, acc 0.30000001192092896\n",
      "Epoch 3, iter 352, loss 2.183262586593628, acc 0.27000001072883606\n",
      "Epoch 3, iter 353, loss 2.1711974143981934, acc 0.38999998569488525\n",
      "Epoch 3, iter 354, loss 2.1410646438598633, acc 0.3499999940395355\n",
      "Epoch 3, iter 355, loss 2.194599151611328, acc 0.27000001072883606\n",
      "Epoch 3, iter 356, loss 2.1929454803466797, acc 0.30000001192092896\n",
      "Epoch 3, iter 357, loss 2.188606023788452, acc 0.27000001072883606\n",
      "Epoch 3, iter 358, loss 2.229308843612671, acc 0.2199999988079071\n",
      "Epoch 3, iter 359, loss 2.1829726696014404, acc 0.27000001072883606\n",
      "Epoch 3, iter 360, loss 2.18388032913208, acc 0.25999999046325684\n",
      "Epoch 3, iter 361, loss 2.1602461338043213, acc 0.33000001311302185\n",
      "Epoch 3, iter 362, loss 2.208739995956421, acc 0.23999999463558197\n",
      "Epoch 3, iter 363, loss 2.1639580726623535, acc 0.33000001311302185\n",
      "Epoch 3, iter 364, loss 2.168792486190796, acc 0.27000001072883606\n",
      "Epoch 3, iter 365, loss 2.1410982608795166, acc 0.3499999940395355\n",
      "Epoch 3, iter 366, loss 2.132624864578247, acc 0.3199999928474426\n",
      "Epoch 3, iter 367, loss 2.155266523361206, acc 0.3100000023841858\n",
      "Epoch 3, iter 368, loss 2.144930362701416, acc 0.36000001430511475\n",
      "Epoch 3, iter 369, loss 2.1562318801879883, acc 0.3499999940395355\n",
      "Epoch 3, iter 370, loss 2.1300084590911865, acc 0.33000001311302185\n",
      "Epoch 3, iter 371, loss 2.125169038772583, acc 0.3400000035762787\n",
      "Epoch 3, iter 372, loss 2.159416437149048, acc 0.3100000023841858\n",
      "Epoch 3, iter 373, loss 2.1749918460845947, acc 0.25\n",
      "Epoch 3, iter 374, loss 2.178828239440918, acc 0.30000001192092896\n",
      "Epoch 3, iter 375, loss 2.1597819328308105, acc 0.3100000023841858\n",
      "Epoch 3, iter 376, loss 2.173452854156494, acc 0.25\n",
      "Epoch 3, iter 377, loss 2.120894193649292, acc 0.3700000047683716\n",
      "Epoch 3, iter 378, loss 2.1491470336914062, acc 0.3499999940395355\n",
      "Epoch 3, iter 379, loss 2.220418930053711, acc 0.20000000298023224\n",
      "Epoch 3, iter 380, loss 2.1878626346588135, acc 0.27000001072883606\n",
      "Epoch 3, iter 381, loss 2.1827404499053955, acc 0.28999999165534973\n",
      "Epoch 3, iter 382, loss 2.1446099281311035, acc 0.3100000023841858\n",
      "Epoch 3, iter 383, loss 2.15458345413208, acc 0.36000001430511475\n",
      "Epoch 3, iter 384, loss 2.1829607486724854, acc 0.2800000011920929\n",
      "Epoch 3, iter 385, loss 2.1642000675201416, acc 0.27000001072883606\n",
      "Epoch 3, iter 386, loss 2.154170036315918, acc 0.27000001072883606\n",
      "Epoch 3, iter 387, loss 2.172574758529663, acc 0.30000001192092896\n",
      "Epoch 3, iter 388, loss 2.188257932662964, acc 0.2800000011920929\n",
      "Epoch 3, iter 389, loss 2.17539119720459, acc 0.25\n",
      "Epoch 3, iter 390, loss 2.2336130142211914, acc 0.17000000178813934\n",
      "Epoch 3, iter 391, loss 2.1792736053466797, acc 0.28999999165534973\n",
      "Epoch 3, iter 392, loss 2.181825876235962, acc 0.25999999046325684\n",
      "Epoch 3, iter 393, loss 2.191577672958374, acc 0.23999999463558197\n",
      "Epoch 3, iter 394, loss 2.1592352390289307, acc 0.33000001311302185\n",
      "Epoch 3, iter 395, loss 2.0976412296295166, acc 0.4099999964237213\n",
      "Epoch 3, iter 396, loss 2.1846272945404053, acc 0.23999999463558197\n",
      "Epoch 3, iter 397, loss 2.1664915084838867, acc 0.30000001192092896\n",
      "Epoch 3, iter 398, loss 2.2019660472869873, acc 0.2199999988079071\n",
      "Epoch 3, iter 399, loss 2.1515331268310547, acc 0.3400000035762787\n",
      "Epoch 3, iter 400, loss 2.133028507232666, acc 0.3799999952316284\n",
      "Epoch 3, iter 401, loss 2.1453135013580322, acc 0.36000001430511475\n",
      "Epoch 3, iter 402, loss 2.1420986652374268, acc 0.3199999928474426\n",
      "Epoch 3, iter 403, loss 2.1843769550323486, acc 0.2800000011920929\n",
      "Epoch 3, iter 404, loss 2.181825637817383, acc 0.25\n",
      "Epoch 3, iter 405, loss 2.190066337585449, acc 0.3199999928474426\n",
      "Epoch 3, iter 406, loss 2.1707346439361572, acc 0.27000001072883606\n",
      "Epoch 3, iter 407, loss 2.1663818359375, acc 0.25999999046325684\n",
      "Epoch 3, iter 408, loss 2.195392608642578, acc 0.2800000011920929\n",
      "Epoch 3, iter 409, loss 2.151658058166504, acc 0.3400000035762787\n",
      "Epoch 3, iter 410, loss 2.1439437866210938, acc 0.28999999165534973\n",
      "Epoch 3, iter 411, loss 2.1365833282470703, acc 0.3400000035762787\n",
      "Epoch 3, iter 412, loss 2.1552774906158447, acc 0.36000001430511475\n",
      "Epoch 3, iter 413, loss 2.1627063751220703, acc 0.30000001192092896\n",
      "Epoch 3, iter 414, loss 2.1593666076660156, acc 0.2800000011920929\n",
      "Epoch 3, iter 415, loss 2.1885833740234375, acc 0.25999999046325684\n",
      "Epoch 3, iter 416, loss 2.1448028087615967, acc 0.30000001192092896\n",
      "Epoch 3, iter 417, loss 2.1339330673217773, acc 0.3799999952316284\n",
      "Epoch 3, iter 418, loss 2.1476714611053467, acc 0.2800000011920929\n",
      "Epoch 3, iter 419, loss 2.1228559017181396, acc 0.3400000035762787\n",
      "Epoch 3, iter 420, loss 2.151038885116577, acc 0.2800000011920929\n",
      "Epoch 4, iter 1, loss 2.1433961391448975, acc 0.28999999165534973\n",
      "Epoch 4, iter 2, loss 2.1984336376190186, acc 0.2800000011920929\n",
      "Epoch 4, iter 3, loss 2.1737899780273438, acc 0.30000001192092896\n",
      "Epoch 4, iter 4, loss 2.2060887813568115, acc 0.27000001072883606\n",
      "Epoch 4, iter 5, loss 2.1788876056671143, acc 0.2199999988079071\n",
      "Epoch 4, iter 6, loss 2.1780688762664795, acc 0.23999999463558197\n",
      "Epoch 4, iter 7, loss 2.1715753078460693, acc 0.30000001192092896\n",
      "Epoch 4, iter 8, loss 2.1583750247955322, acc 0.2800000011920929\n",
      "Epoch 4, iter 9, loss 2.1918210983276367, acc 0.2800000011920929\n",
      "Epoch 4, iter 10, loss 2.1995959281921387, acc 0.2800000011920929\n",
      "Epoch 4, iter 11, loss 2.1812210083007812, acc 0.28999999165534973\n",
      "Epoch 4, iter 12, loss 2.175452470779419, acc 0.27000001072883606\n",
      "Epoch 4, iter 13, loss 2.1599414348602295, acc 0.28999999165534973\n",
      "Epoch 4, iter 14, loss 2.125378370285034, acc 0.3799999952316284\n",
      "Epoch 4, iter 15, loss 2.111525058746338, acc 0.33000001311302185\n",
      "Epoch 4, iter 16, loss 2.1369218826293945, acc 0.30000001192092896\n",
      "Epoch 4, iter 17, loss 2.176759719848633, acc 0.23000000417232513\n",
      "Epoch 4, iter 18, loss 2.1787643432617188, acc 0.27000001072883606\n",
      "Epoch 4, iter 19, loss 2.136375665664673, acc 0.3100000023841858\n",
      "Epoch 4, iter 20, loss 2.1237943172454834, acc 0.3700000047683716\n",
      "Epoch 4, iter 21, loss 2.1243274211883545, acc 0.3100000023841858\n",
      "Epoch 4, iter 22, loss 2.161168098449707, acc 0.2800000011920929\n",
      "Epoch 4, iter 23, loss 2.1300835609436035, acc 0.3400000035762787\n",
      "Epoch 4, iter 24, loss 2.163527727127075, acc 0.23000000417232513\n",
      "Epoch 4, iter 25, loss 2.1821095943450928, acc 0.28999999165534973\n",
      "Epoch 4, iter 26, loss 2.178925037384033, acc 0.2800000011920929\n",
      "Epoch 4, iter 27, loss 2.176870107650757, acc 0.3700000047683716\n",
      "Epoch 4, iter 28, loss 2.1125476360321045, acc 0.4000000059604645\n",
      "Epoch 4, iter 29, loss 2.162681818008423, acc 0.30000001192092896\n",
      "Epoch 4, iter 30, loss 2.170844316482544, acc 0.33000001311302185\n",
      "Epoch 4, iter 31, loss 2.2313921451568604, acc 0.20999999344348907\n",
      "Epoch 4, iter 32, loss 2.1656148433685303, acc 0.25999999046325684\n",
      "Epoch 4, iter 33, loss 2.1907799243927, acc 0.30000001192092896\n",
      "Epoch 4, iter 34, loss 2.1451900005340576, acc 0.3499999940395355\n",
      "Epoch 4, iter 35, loss 2.182745933532715, acc 0.27000001072883606\n",
      "Epoch 4, iter 36, loss 2.160384178161621, acc 0.30000001192092896\n",
      "Epoch 4, iter 37, loss 2.201948881149292, acc 0.23000000417232513\n",
      "Epoch 4, iter 38, loss 2.194105625152588, acc 0.3100000023841858\n",
      "Epoch 4, iter 39, loss 2.1355206966400146, acc 0.33000001311302185\n",
      "Epoch 4, iter 40, loss 2.121485710144043, acc 0.30000001192092896\n",
      "Epoch 4, iter 41, loss 2.20290207862854, acc 0.2199999988079071\n",
      "Epoch 4, iter 42, loss 2.170140266418457, acc 0.2800000011920929\n",
      "Epoch 4, iter 43, loss 2.108274221420288, acc 0.3400000035762787\n",
      "Epoch 4, iter 44, loss 2.120044469833374, acc 0.3100000023841858\n",
      "Epoch 4, iter 45, loss 2.1731903553009033, acc 0.27000001072883606\n",
      "Epoch 4, iter 46, loss 2.1732966899871826, acc 0.33000001311302185\n",
      "Epoch 4, iter 47, loss 2.1872870922088623, acc 0.20999999344348907\n",
      "Epoch 4, iter 48, loss 2.1336441040039062, acc 0.30000001192092896\n",
      "Epoch 4, iter 49, loss 2.149923801422119, acc 0.3199999928474426\n",
      "Epoch 4, iter 50, loss 2.192352533340454, acc 0.25\n",
      "Epoch 4, iter 51, loss 2.1393849849700928, acc 0.3400000035762787\n",
      "Epoch 4, iter 52, loss 2.1932201385498047, acc 0.2199999988079071\n",
      "Epoch 4, iter 53, loss 2.1430327892303467, acc 0.3400000035762787\n",
      "Epoch 4, iter 54, loss 2.166494369506836, acc 0.25999999046325684\n",
      "Epoch 4, iter 55, loss 2.243725061416626, acc 0.17000000178813934\n",
      "Epoch 4, iter 56, loss 2.1540639400482178, acc 0.30000001192092896\n",
      "Epoch 4, iter 57, loss 2.218142509460449, acc 0.20999999344348907\n",
      "Epoch 4, iter 58, loss 2.187429428100586, acc 0.27000001072883606\n",
      "Epoch 4, iter 59, loss 2.160576343536377, acc 0.30000001192092896\n",
      "Epoch 4, iter 60, loss 2.165252447128296, acc 0.3700000047683716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 61, loss 2.1582674980163574, acc 0.2800000011920929\n",
      "Epoch 4, iter 62, loss 2.1678524017333984, acc 0.2800000011920929\n",
      "Epoch 4, iter 63, loss 2.194559335708618, acc 0.2800000011920929\n",
      "Epoch 4, iter 64, loss 2.145280361175537, acc 0.25\n",
      "Epoch 4, iter 65, loss 2.1737444400787354, acc 0.3199999928474426\n",
      "Epoch 4, iter 66, loss 2.1485369205474854, acc 0.2800000011920929\n",
      "Epoch 4, iter 67, loss 2.178328037261963, acc 0.28999999165534973\n",
      "Epoch 4, iter 68, loss 2.134901523590088, acc 0.3199999928474426\n",
      "Epoch 4, iter 69, loss 2.1644856929779053, acc 0.2800000011920929\n",
      "Epoch 4, iter 70, loss 2.1688787937164307, acc 0.3100000023841858\n",
      "Epoch 4, iter 71, loss 2.1828293800354004, acc 0.27000001072883606\n",
      "Epoch 4, iter 72, loss 2.1559417247772217, acc 0.23999999463558197\n",
      "Epoch 4, iter 73, loss 2.1443581581115723, acc 0.3199999928474426\n",
      "Epoch 4, iter 74, loss 2.1678848266601562, acc 0.27000001072883606\n",
      "Epoch 4, iter 75, loss 2.1640377044677734, acc 0.23999999463558197\n",
      "Epoch 4, iter 76, loss 2.1672756671905518, acc 0.2800000011920929\n",
      "Epoch 4, iter 77, loss 2.1949515342712402, acc 0.27000001072883606\n",
      "Epoch 4, iter 78, loss 2.1725316047668457, acc 0.3199999928474426\n",
      "Epoch 4, iter 79, loss 2.1616568565368652, acc 0.3100000023841858\n",
      "Epoch 4, iter 80, loss 2.145589590072632, acc 0.28999999165534973\n",
      "Epoch 4, iter 81, loss 2.18509578704834, acc 0.25999999046325684\n",
      "Epoch 4, iter 82, loss 2.199812889099121, acc 0.23000000417232513\n",
      "Epoch 4, iter 83, loss 2.138322591781616, acc 0.3199999928474426\n",
      "Epoch 4, iter 84, loss 2.1772541999816895, acc 0.27000001072883606\n",
      "Epoch 4, iter 85, loss 2.207024574279785, acc 0.20000000298023224\n",
      "Epoch 4, iter 86, loss 2.1568195819854736, acc 0.30000001192092896\n",
      "Epoch 4, iter 87, loss 2.1719791889190674, acc 0.33000001311302185\n",
      "Epoch 4, iter 88, loss 2.133080005645752, acc 0.3400000035762787\n",
      "Epoch 4, iter 89, loss 2.1677496433258057, acc 0.30000001192092896\n",
      "Epoch 4, iter 90, loss 2.1538541316986084, acc 0.2800000011920929\n",
      "Epoch 4, iter 91, loss 2.1499433517456055, acc 0.28999999165534973\n",
      "Epoch 4, iter 92, loss 2.2068138122558594, acc 0.25999999046325684\n",
      "Epoch 4, iter 93, loss 2.1298468112945557, acc 0.3799999952316284\n",
      "Epoch 4, iter 94, loss 2.159726858139038, acc 0.2800000011920929\n",
      "Epoch 4, iter 95, loss 2.142163038253784, acc 0.3199999928474426\n",
      "Epoch 4, iter 96, loss 2.1883022785186768, acc 0.30000001192092896\n",
      "Epoch 4, iter 97, loss 2.175712823867798, acc 0.2199999988079071\n",
      "Epoch 4, iter 98, loss 2.1660032272338867, acc 0.2800000011920929\n",
      "Epoch 4, iter 99, loss 2.1510169506073, acc 0.3499999940395355\n",
      "Epoch 4, iter 100, loss 2.1366617679595947, acc 0.3499999940395355\n",
      "Epoch 4, iter 101, loss 2.1442759037017822, acc 0.30000001192092896\n",
      "Epoch 4, iter 102, loss 2.1672396659851074, acc 0.30000001192092896\n",
      "Epoch 4, iter 103, loss 2.149505615234375, acc 0.36000001430511475\n",
      "Epoch 4, iter 104, loss 2.1804733276367188, acc 0.3400000035762787\n",
      "Epoch 4, iter 105, loss 2.081681728363037, acc 0.36000001430511475\n",
      "Epoch 4, iter 106, loss 2.1327064037323, acc 0.3700000047683716\n",
      "Epoch 4, iter 107, loss 2.1363365650177, acc 0.3499999940395355\n",
      "Epoch 4, iter 108, loss 2.191016435623169, acc 0.20000000298023224\n",
      "Epoch 4, iter 109, loss 2.1425347328186035, acc 0.3400000035762787\n",
      "Epoch 4, iter 110, loss 2.181654930114746, acc 0.23999999463558197\n",
      "Epoch 4, iter 111, loss 2.1522376537323, acc 0.27000001072883606\n",
      "Epoch 4, iter 112, loss 2.148578405380249, acc 0.30000001192092896\n",
      "Epoch 4, iter 113, loss 2.12445068359375, acc 0.3400000035762787\n",
      "Epoch 4, iter 114, loss 2.1183993816375732, acc 0.33000001311302185\n",
      "Epoch 4, iter 115, loss 2.140331506729126, acc 0.3400000035762787\n",
      "Epoch 4, iter 116, loss 2.1401500701904297, acc 0.25999999046325684\n",
      "Epoch 4, iter 117, loss 2.1666109561920166, acc 0.3199999928474426\n",
      "Epoch 4, iter 118, loss 2.160287618637085, acc 0.25999999046325684\n",
      "Epoch 4, iter 119, loss 2.1648199558258057, acc 0.28999999165534973\n",
      "Epoch 4, iter 120, loss 2.1622753143310547, acc 0.3199999928474426\n",
      "Epoch 4, iter 121, loss 2.1788523197174072, acc 0.30000001192092896\n",
      "Epoch 4, iter 122, loss 2.137857675552368, acc 0.4099999964237213\n",
      "Epoch 4, iter 123, loss 2.1881086826324463, acc 0.20999999344348907\n",
      "Epoch 4, iter 124, loss 2.1210670471191406, acc 0.3700000047683716\n",
      "Epoch 4, iter 125, loss 2.179299831390381, acc 0.25999999046325684\n",
      "Epoch 4, iter 126, loss 2.1432323455810547, acc 0.30000001192092896\n",
      "Epoch 4, iter 127, loss 2.155482530593872, acc 0.30000001192092896\n",
      "Epoch 4, iter 128, loss 2.1702795028686523, acc 0.28999999165534973\n",
      "Epoch 4, iter 129, loss 2.1833388805389404, acc 0.30000001192092896\n",
      "Epoch 4, iter 130, loss 2.183579206466675, acc 0.3100000023841858\n",
      "Epoch 4, iter 131, loss 2.222837448120117, acc 0.27000001072883606\n",
      "Epoch 4, iter 132, loss 2.1649694442749023, acc 0.30000001192092896\n",
      "Epoch 4, iter 133, loss 2.156703472137451, acc 0.3499999940395355\n",
      "Epoch 4, iter 134, loss 2.188836097717285, acc 0.2800000011920929\n",
      "Epoch 4, iter 135, loss 2.179706335067749, acc 0.3199999928474426\n",
      "Epoch 4, iter 136, loss 2.1196160316467285, acc 0.3499999940395355\n",
      "Epoch 4, iter 137, loss 2.152012586593628, acc 0.2800000011920929\n",
      "Epoch 4, iter 138, loss 2.1600804328918457, acc 0.30000001192092896\n",
      "Epoch 4, iter 139, loss 2.1850240230560303, acc 0.23000000417232513\n",
      "Epoch 4, iter 140, loss 2.1684629917144775, acc 0.27000001072883606\n",
      "Epoch 4, iter 141, loss 2.1616697311401367, acc 0.30000001192092896\n",
      "Epoch 4, iter 142, loss 2.171172857284546, acc 0.25\n",
      "Epoch 4, iter 143, loss 2.171995162963867, acc 0.25999999046325684\n",
      "Epoch 4, iter 144, loss 2.1912808418273926, acc 0.23000000417232513\n",
      "Epoch 4, iter 145, loss 2.1585519313812256, acc 0.30000001192092896\n",
      "Epoch 4, iter 146, loss 2.171422243118286, acc 0.25999999046325684\n",
      "Epoch 4, iter 147, loss 2.1621601581573486, acc 0.3100000023841858\n",
      "Epoch 4, iter 148, loss 2.1247150897979736, acc 0.28999999165534973\n",
      "Epoch 4, iter 149, loss 2.1168112754821777, acc 0.3100000023841858\n",
      "Epoch 4, iter 150, loss 2.1783368587493896, acc 0.25999999046325684\n",
      "Epoch 4, iter 151, loss 2.067770004272461, acc 0.3799999952316284\n",
      "Epoch 4, iter 152, loss 2.149001359939575, acc 0.33000001311302185\n",
      "Epoch 4, iter 153, loss 2.1637465953826904, acc 0.3100000023841858\n",
      "Epoch 4, iter 154, loss 2.1701772212982178, acc 0.23999999463558197\n",
      "Epoch 4, iter 155, loss 2.1606709957122803, acc 0.3100000023841858\n",
      "Epoch 4, iter 156, loss 2.1737096309661865, acc 0.27000001072883606\n",
      "Epoch 4, iter 157, loss 2.194821357727051, acc 0.20999999344348907\n",
      "Epoch 4, iter 158, loss 2.1669249534606934, acc 0.3100000023841858\n",
      "Epoch 4, iter 159, loss 2.1498570442199707, acc 0.2800000011920929\n",
      "Epoch 4, iter 160, loss 2.1831440925598145, acc 0.23999999463558197\n",
      "Epoch 4, iter 161, loss 2.1281960010528564, acc 0.28999999165534973\n",
      "Epoch 4, iter 162, loss 2.095414161682129, acc 0.4099999964237213\n",
      "Epoch 4, iter 163, loss 2.1793406009674072, acc 0.28999999165534973\n",
      "Epoch 4, iter 164, loss 2.1827504634857178, acc 0.25999999046325684\n",
      "Epoch 4, iter 165, loss 2.196094036102295, acc 0.3100000023841858\n",
      "Epoch 4, iter 166, loss 2.1447296142578125, acc 0.3199999928474426\n",
      "Epoch 4, iter 167, loss 2.1716790199279785, acc 0.23999999463558197\n",
      "Epoch 4, iter 168, loss 2.1359364986419678, acc 0.3400000035762787\n",
      "Epoch 4, iter 169, loss 2.0955452919006348, acc 0.3199999928474426\n",
      "Epoch 4, iter 170, loss 2.166583776473999, acc 0.20999999344348907\n",
      "Epoch 4, iter 171, loss 2.1481330394744873, acc 0.3199999928474426\n",
      "Epoch 4, iter 172, loss 2.1834497451782227, acc 0.23999999463558197\n",
      "Epoch 4, iter 173, loss 2.185784339904785, acc 0.2800000011920929\n",
      "Epoch 4, iter 174, loss 2.1453464031219482, acc 0.27000001072883606\n",
      "Epoch 4, iter 175, loss 2.1443169116973877, acc 0.3199999928474426\n",
      "Epoch 4, iter 176, loss 2.205211877822876, acc 0.18000000715255737\n",
      "Epoch 4, iter 177, loss 2.159291982650757, acc 0.33000001311302185\n",
      "Epoch 4, iter 178, loss 2.1628646850585938, acc 0.2800000011920929\n",
      "Epoch 4, iter 179, loss 2.1774277687072754, acc 0.2800000011920929\n",
      "Epoch 4, iter 180, loss 2.1932456493377686, acc 0.27000001072883606\n",
      "Epoch 4, iter 181, loss 2.104731559753418, acc 0.36000001430511475\n",
      "Epoch 4, iter 182, loss 2.1901967525482178, acc 0.25\n",
      "Epoch 4, iter 183, loss 2.167959451675415, acc 0.2800000011920929\n",
      "Epoch 4, iter 184, loss 2.152451276779175, acc 0.25\n",
      "Epoch 4, iter 185, loss 2.1513757705688477, acc 0.2800000011920929\n",
      "Epoch 4, iter 186, loss 2.1560065746307373, acc 0.3199999928474426\n",
      "Epoch 4, iter 187, loss 2.161111831665039, acc 0.27000001072883606\n",
      "Epoch 4, iter 188, loss 2.1760828495025635, acc 0.27000001072883606\n",
      "Epoch 4, iter 189, loss 2.2305970191955566, acc 0.1599999964237213\n",
      "Epoch 4, iter 190, loss 2.1484642028808594, acc 0.3400000035762787\n",
      "Epoch 4, iter 191, loss 2.1700103282928467, acc 0.25999999046325684\n",
      "Epoch 4, iter 192, loss 2.159126043319702, acc 0.2800000011920929\n",
      "Epoch 4, iter 193, loss 2.1377909183502197, acc 0.33000001311302185\n",
      "Epoch 4, iter 194, loss 2.1578657627105713, acc 0.25999999046325684\n",
      "Epoch 4, iter 195, loss 2.1083455085754395, acc 0.3799999952316284\n",
      "Epoch 4, iter 196, loss 2.1988861560821533, acc 0.25\n",
      "Epoch 4, iter 197, loss 2.1647679805755615, acc 0.33000001311302185\n",
      "Epoch 4, iter 198, loss 2.095945358276367, acc 0.38999998569488525\n",
      "Epoch 4, iter 199, loss 2.166557550430298, acc 0.28999999165534973\n",
      "Epoch 4, iter 200, loss 2.172422409057617, acc 0.30000001192092896\n",
      "Epoch 4, iter 201, loss 2.148658514022827, acc 0.3100000023841858\n",
      "Epoch 4, iter 202, loss 2.1460649967193604, acc 0.25999999046325684\n",
      "Epoch 4, iter 203, loss 2.1645452976226807, acc 0.27000001072883606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 204, loss 2.1306324005126953, acc 0.3700000047683716\n",
      "Epoch 4, iter 205, loss 2.0943803787231445, acc 0.36000001430511475\n",
      "Epoch 4, iter 206, loss 2.163205146789551, acc 0.23000000417232513\n",
      "Epoch 4, iter 207, loss 2.1755075454711914, acc 0.27000001072883606\n",
      "Epoch 4, iter 208, loss 2.200956344604492, acc 0.25999999046325684\n",
      "Epoch 4, iter 209, loss 2.1980104446411133, acc 0.23000000417232513\n",
      "Epoch 4, iter 210, loss 2.2076849937438965, acc 0.20000000298023224\n",
      "Epoch 4, iter 211, loss 2.1516594886779785, acc 0.28999999165534973\n",
      "Epoch 4, iter 212, loss 2.1845247745513916, acc 0.23000000417232513\n",
      "Epoch 4, iter 213, loss 2.1771907806396484, acc 0.28999999165534973\n",
      "Epoch 4, iter 214, loss 2.18963623046875, acc 0.27000001072883606\n",
      "Epoch 4, iter 215, loss 2.1661362648010254, acc 0.23000000417232513\n",
      "Epoch 4, iter 216, loss 2.1941394805908203, acc 0.20000000298023224\n",
      "Epoch 4, iter 217, loss 2.135535478591919, acc 0.36000001430511475\n",
      "Epoch 4, iter 218, loss 2.2233998775482178, acc 0.25999999046325684\n",
      "Epoch 4, iter 219, loss 2.153149366378784, acc 0.28999999165534973\n",
      "Epoch 4, iter 220, loss 2.1144015789031982, acc 0.4000000059604645\n",
      "Epoch 4, iter 221, loss 2.1474246978759766, acc 0.3199999928474426\n",
      "Epoch 4, iter 222, loss 2.1633565425872803, acc 0.3100000023841858\n",
      "Epoch 4, iter 223, loss 2.1260454654693604, acc 0.38999998569488525\n",
      "Epoch 4, iter 224, loss 2.187962055206299, acc 0.3100000023841858\n",
      "Epoch 4, iter 225, loss 2.1341423988342285, acc 0.30000001192092896\n",
      "Epoch 4, iter 226, loss 2.168766975402832, acc 0.30000001192092896\n",
      "Epoch 4, iter 227, loss 2.161595344543457, acc 0.3400000035762787\n",
      "Epoch 4, iter 228, loss 2.171966314315796, acc 0.2800000011920929\n",
      "Epoch 4, iter 229, loss 2.152539014816284, acc 0.3199999928474426\n",
      "Epoch 4, iter 230, loss 2.152970314025879, acc 0.3199999928474426\n",
      "Epoch 4, iter 231, loss 2.1331229209899902, acc 0.3400000035762787\n",
      "Epoch 4, iter 232, loss 2.1808454990386963, acc 0.23999999463558197\n",
      "Epoch 4, iter 233, loss 2.1299991607666016, acc 0.3199999928474426\n",
      "Epoch 4, iter 234, loss 2.1159660816192627, acc 0.4099999964237213\n",
      "Epoch 4, iter 235, loss 2.150650978088379, acc 0.3100000023841858\n",
      "Epoch 4, iter 236, loss 2.1704154014587402, acc 0.2800000011920929\n",
      "Epoch 4, iter 237, loss 2.2017405033111572, acc 0.2199999988079071\n",
      "Epoch 4, iter 238, loss 2.149022102355957, acc 0.3100000023841858\n",
      "Epoch 4, iter 239, loss 2.1793689727783203, acc 0.23000000417232513\n",
      "Epoch 4, iter 240, loss 2.180298089981079, acc 0.25\n",
      "Epoch 4, iter 241, loss 2.1684648990631104, acc 0.25\n",
      "Epoch 4, iter 242, loss 2.1840734481811523, acc 0.3199999928474426\n",
      "Epoch 4, iter 243, loss 2.2092783451080322, acc 0.23999999463558197\n",
      "Epoch 4, iter 244, loss 2.130295753479004, acc 0.3799999952316284\n",
      "Epoch 4, iter 245, loss 2.137974262237549, acc 0.3100000023841858\n",
      "Epoch 4, iter 246, loss 2.219768762588501, acc 0.20999999344348907\n",
      "Epoch 4, iter 247, loss 2.128889799118042, acc 0.3499999940395355\n",
      "Epoch 4, iter 248, loss 2.1809446811676025, acc 0.20999999344348907\n",
      "Epoch 4, iter 249, loss 2.208097219467163, acc 0.1899999976158142\n",
      "Epoch 4, iter 250, loss 2.113396406173706, acc 0.38999998569488525\n",
      "Epoch 4, iter 251, loss 2.1844546794891357, acc 0.2199999988079071\n",
      "Epoch 4, iter 252, loss 2.1496212482452393, acc 0.33000001311302185\n",
      "Epoch 4, iter 253, loss 2.211338996887207, acc 0.25999999046325684\n",
      "Epoch 4, iter 254, loss 2.1813011169433594, acc 0.27000001072883606\n",
      "Epoch 4, iter 255, loss 2.1655688285827637, acc 0.3100000023841858\n",
      "Epoch 4, iter 256, loss 2.142237424850464, acc 0.3700000047683716\n",
      "Epoch 4, iter 257, loss 2.1613264083862305, acc 0.25999999046325684\n",
      "Epoch 4, iter 258, loss 2.155508518218994, acc 0.2800000011920929\n",
      "Epoch 4, iter 259, loss 2.1745920181274414, acc 0.30000001192092896\n",
      "Epoch 4, iter 260, loss 2.144840955734253, acc 0.30000001192092896\n",
      "Epoch 4, iter 261, loss 2.1224472522735596, acc 0.3400000035762787\n",
      "Epoch 4, iter 262, loss 2.1901354789733887, acc 0.23000000417232513\n",
      "Epoch 4, iter 263, loss 2.123745918273926, acc 0.33000001311302185\n",
      "Epoch 4, iter 264, loss 2.135575771331787, acc 0.3400000035762787\n",
      "Epoch 4, iter 265, loss 2.188626766204834, acc 0.30000001192092896\n",
      "Epoch 4, iter 266, loss 2.128655195236206, acc 0.30000001192092896\n",
      "Epoch 4, iter 267, loss 2.1200270652770996, acc 0.3499999940395355\n",
      "Epoch 4, iter 268, loss 2.162254810333252, acc 0.23000000417232513\n",
      "Epoch 4, iter 269, loss 2.1691694259643555, acc 0.25999999046325684\n",
      "Epoch 4, iter 270, loss 2.1544032096862793, acc 0.27000001072883606\n",
      "Epoch 4, iter 271, loss 2.18162202835083, acc 0.3199999928474426\n",
      "Epoch 4, iter 272, loss 2.1886754035949707, acc 0.23000000417232513\n",
      "Epoch 4, iter 273, loss 2.1846346855163574, acc 0.23999999463558197\n",
      "Epoch 4, iter 274, loss 2.1514384746551514, acc 0.30000001192092896\n",
      "Epoch 4, iter 275, loss 2.2000582218170166, acc 0.25999999046325684\n",
      "Epoch 4, iter 276, loss 2.1894607543945312, acc 0.2800000011920929\n",
      "Epoch 4, iter 277, loss 2.1441867351531982, acc 0.3199999928474426\n",
      "Epoch 4, iter 278, loss 2.1355974674224854, acc 0.3100000023841858\n",
      "Epoch 4, iter 279, loss 2.1380324363708496, acc 0.3499999940395355\n",
      "Epoch 4, iter 280, loss 2.137416124343872, acc 0.30000001192092896\n",
      "Epoch 4, iter 281, loss 2.1525559425354004, acc 0.38999998569488525\n",
      "Epoch 4, iter 282, loss 2.201474666595459, acc 0.23000000417232513\n",
      "Epoch 4, iter 283, loss 2.139225959777832, acc 0.28999999165534973\n",
      "Epoch 4, iter 284, loss 2.120152235031128, acc 0.36000001430511475\n",
      "Epoch 4, iter 285, loss 2.130117177963257, acc 0.28999999165534973\n",
      "Epoch 4, iter 286, loss 2.1470773220062256, acc 0.3199999928474426\n",
      "Epoch 4, iter 287, loss 2.1673266887664795, acc 0.2800000011920929\n",
      "Epoch 4, iter 288, loss 2.1136603355407715, acc 0.3400000035762787\n",
      "Epoch 4, iter 289, loss 2.1867198944091797, acc 0.27000001072883606\n",
      "Epoch 4, iter 290, loss 2.1166393756866455, acc 0.30000001192092896\n",
      "Epoch 4, iter 291, loss 2.142458915710449, acc 0.33000001311302185\n",
      "Epoch 4, iter 292, loss 2.133040428161621, acc 0.33000001311302185\n",
      "Epoch 4, iter 293, loss 2.1321115493774414, acc 0.30000001192092896\n",
      "Epoch 4, iter 294, loss 2.1976981163024902, acc 0.1899999976158142\n",
      "Epoch 4, iter 295, loss 2.16970157623291, acc 0.28999999165534973\n",
      "Epoch 4, iter 296, loss 2.127617835998535, acc 0.33000001311302185\n",
      "Epoch 4, iter 297, loss 2.188809394836426, acc 0.25\n",
      "Epoch 4, iter 298, loss 2.139054536819458, acc 0.30000001192092896\n",
      "Epoch 4, iter 299, loss 2.2079455852508545, acc 0.20999999344348907\n",
      "Epoch 4, iter 300, loss 2.1714694499969482, acc 0.25\n",
      "Epoch 4, iter 301, loss 2.176253080368042, acc 0.25999999046325684\n",
      "Epoch 4, iter 302, loss 2.132105827331543, acc 0.3700000047683716\n",
      "Epoch 4, iter 303, loss 2.1555068492889404, acc 0.2800000011920929\n",
      "Epoch 4, iter 304, loss 2.194525957107544, acc 0.20999999344348907\n",
      "Epoch 4, iter 305, loss 2.22727632522583, acc 0.17000000178813934\n",
      "Epoch 4, iter 306, loss 2.113591194152832, acc 0.3199999928474426\n",
      "Epoch 4, iter 307, loss 2.127014398574829, acc 0.3400000035762787\n",
      "Epoch 4, iter 308, loss 2.2033002376556396, acc 0.27000001072883606\n",
      "Epoch 4, iter 309, loss 2.157660484313965, acc 0.2800000011920929\n",
      "Epoch 4, iter 310, loss 2.1550774574279785, acc 0.25999999046325684\n",
      "Epoch 4, iter 311, loss 2.1388869285583496, acc 0.3100000023841858\n",
      "Epoch 4, iter 312, loss 2.1409621238708496, acc 0.3199999928474426\n",
      "Epoch 4, iter 313, loss 2.221343755722046, acc 0.15000000596046448\n",
      "Epoch 4, iter 314, loss 2.1071979999542236, acc 0.3400000035762787\n",
      "Epoch 4, iter 315, loss 2.1584978103637695, acc 0.3100000023841858\n",
      "Epoch 4, iter 316, loss 2.1771788597106934, acc 0.25999999046325684\n",
      "Epoch 4, iter 317, loss 2.153242588043213, acc 0.3499999940395355\n",
      "Epoch 4, iter 318, loss 2.136883497238159, acc 0.3199999928474426\n",
      "Epoch 4, iter 319, loss 2.1461195945739746, acc 0.30000001192092896\n",
      "Epoch 4, iter 320, loss 2.2341599464416504, acc 0.1899999976158142\n",
      "Epoch 4, iter 321, loss 2.1659231185913086, acc 0.3100000023841858\n",
      "Epoch 4, iter 322, loss 2.1482138633728027, acc 0.27000001072883606\n",
      "Epoch 4, iter 323, loss 2.1416800022125244, acc 0.3199999928474426\n",
      "Epoch 4, iter 324, loss 2.0783193111419678, acc 0.36000001430511475\n",
      "Epoch 4, iter 325, loss 2.1797690391540527, acc 0.30000001192092896\n",
      "Epoch 4, iter 326, loss 2.1339409351348877, acc 0.30000001192092896\n",
      "Epoch 4, iter 327, loss 2.1803743839263916, acc 0.23000000417232513\n",
      "Epoch 4, iter 328, loss 2.1073355674743652, acc 0.36000001430511475\n",
      "Epoch 4, iter 329, loss 2.128723382949829, acc 0.3100000023841858\n",
      "Epoch 4, iter 330, loss 2.1655068397521973, acc 0.30000001192092896\n",
      "Epoch 4, iter 331, loss 2.155897617340088, acc 0.27000001072883606\n",
      "Epoch 4, iter 332, loss 2.1787118911743164, acc 0.28999999165534973\n",
      "Epoch 4, iter 333, loss 2.1465251445770264, acc 0.3199999928474426\n",
      "Epoch 4, iter 334, loss 2.192225933074951, acc 0.27000001072883606\n",
      "Epoch 4, iter 335, loss 2.0828232765197754, acc 0.3700000047683716\n",
      "Epoch 4, iter 336, loss 2.129781723022461, acc 0.3100000023841858\n",
      "Epoch 4, iter 337, loss 2.150617837905884, acc 0.2800000011920929\n",
      "Epoch 4, iter 338, loss 2.139936685562134, acc 0.3100000023841858\n",
      "Epoch 4, iter 339, loss 2.16866397857666, acc 0.27000001072883606\n",
      "Epoch 4, iter 340, loss 2.1668176651000977, acc 0.3100000023841858\n",
      "Epoch 4, iter 341, loss 2.1454038619995117, acc 0.27000001072883606\n",
      "Epoch 4, iter 342, loss 2.1410322189331055, acc 0.3100000023841858\n",
      "Epoch 4, iter 343, loss 2.1932430267333984, acc 0.23999999463558197\n",
      "Epoch 4, iter 344, loss 2.1073412895202637, acc 0.3499999940395355\n",
      "Epoch 4, iter 345, loss 2.1847851276397705, acc 0.23000000417232513\n",
      "Epoch 4, iter 346, loss 2.0941011905670166, acc 0.3499999940395355\n",
      "Epoch 4, iter 347, loss 2.2017765045166016, acc 0.23000000417232513\n",
      "Epoch 4, iter 348, loss 2.1146738529205322, acc 0.3799999952316284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iter 349, loss 2.0905425548553467, acc 0.3799999952316284\n",
      "Epoch 4, iter 350, loss 2.167222738265991, acc 0.28999999165534973\n",
      "Epoch 4, iter 351, loss 2.1460366249084473, acc 0.30000001192092896\n",
      "Epoch 4, iter 352, loss 2.16204833984375, acc 0.2800000011920929\n",
      "Epoch 4, iter 353, loss 2.1637632846832275, acc 0.38999998569488525\n",
      "Epoch 4, iter 354, loss 2.121244430541992, acc 0.3799999952316284\n",
      "Epoch 4, iter 355, loss 2.1839029788970947, acc 0.25999999046325684\n",
      "Epoch 4, iter 356, loss 2.175370693206787, acc 0.28999999165534973\n",
      "Epoch 4, iter 357, loss 2.172703504562378, acc 0.28999999165534973\n",
      "Epoch 4, iter 358, loss 2.217259407043457, acc 0.2199999988079071\n",
      "Epoch 4, iter 359, loss 2.1664068698883057, acc 0.25999999046325684\n",
      "Epoch 4, iter 360, loss 2.158282518386841, acc 0.2800000011920929\n",
      "Epoch 4, iter 361, loss 2.137383222579956, acc 0.33000001311302185\n",
      "Epoch 4, iter 362, loss 2.2045254707336426, acc 0.23000000417232513\n",
      "Epoch 4, iter 363, loss 2.139190912246704, acc 0.3400000035762787\n",
      "Epoch 4, iter 364, loss 2.1466317176818848, acc 0.27000001072883606\n",
      "Epoch 4, iter 365, loss 2.1276180744171143, acc 0.36000001430511475\n",
      "Epoch 4, iter 366, loss 2.1023917198181152, acc 0.33000001311302185\n",
      "Epoch 4, iter 367, loss 2.1269922256469727, acc 0.3199999928474426\n",
      "Epoch 4, iter 368, loss 2.124741315841675, acc 0.3499999940395355\n",
      "Epoch 4, iter 369, loss 2.1418211460113525, acc 0.3499999940395355\n",
      "Epoch 4, iter 370, loss 2.1152822971343994, acc 0.33000001311302185\n",
      "Epoch 4, iter 371, loss 2.1093087196350098, acc 0.3400000035762787\n",
      "Epoch 4, iter 372, loss 2.143315315246582, acc 0.3100000023841858\n",
      "Epoch 4, iter 373, loss 2.169687271118164, acc 0.25\n",
      "Epoch 4, iter 374, loss 2.1676316261291504, acc 0.3100000023841858\n",
      "Epoch 4, iter 375, loss 2.1508102416992188, acc 0.3199999928474426\n",
      "Epoch 4, iter 376, loss 2.1604418754577637, acc 0.25\n",
      "Epoch 4, iter 377, loss 2.114013195037842, acc 0.36000001430511475\n",
      "Epoch 4, iter 378, loss 2.137896776199341, acc 0.3199999928474426\n",
      "Epoch 4, iter 379, loss 2.2125725746154785, acc 0.1899999976158142\n",
      "Epoch 4, iter 380, loss 2.175841808319092, acc 0.2199999988079071\n",
      "Epoch 4, iter 381, loss 2.1722612380981445, acc 0.28999999165534973\n",
      "Epoch 4, iter 382, loss 2.133355140686035, acc 0.3100000023841858\n",
      "Epoch 4, iter 383, loss 2.1475043296813965, acc 0.3400000035762787\n",
      "Epoch 4, iter 384, loss 2.1691744327545166, acc 0.2800000011920929\n",
      "Epoch 4, iter 385, loss 2.1477036476135254, acc 0.27000001072883606\n",
      "Epoch 4, iter 386, loss 2.1399827003479004, acc 0.25999999046325684\n",
      "Epoch 4, iter 387, loss 2.1561806201934814, acc 0.25999999046325684\n",
      "Epoch 4, iter 388, loss 2.1737558841705322, acc 0.2800000011920929\n",
      "Epoch 4, iter 389, loss 2.1514406204223633, acc 0.27000001072883606\n",
      "Epoch 4, iter 390, loss 2.218721866607666, acc 0.17000000178813934\n",
      "Epoch 4, iter 391, loss 2.1640632152557373, acc 0.28999999165534973\n",
      "Epoch 4, iter 392, loss 2.163870096206665, acc 0.25999999046325684\n",
      "Epoch 4, iter 393, loss 2.169278144836426, acc 0.23999999463558197\n",
      "Epoch 4, iter 394, loss 2.1443021297454834, acc 0.33000001311302185\n",
      "Epoch 4, iter 395, loss 2.078097343444824, acc 0.4099999964237213\n",
      "Epoch 4, iter 396, loss 2.168837070465088, acc 0.2199999988079071\n",
      "Epoch 4, iter 397, loss 2.141791582107544, acc 0.3100000023841858\n",
      "Epoch 4, iter 398, loss 2.185295343399048, acc 0.2199999988079071\n",
      "Epoch 4, iter 399, loss 2.1461188793182373, acc 0.3199999928474426\n",
      "Epoch 4, iter 400, loss 2.1331937313079834, acc 0.3499999940395355\n",
      "Epoch 4, iter 401, loss 2.154803991317749, acc 0.28999999165534973\n",
      "Epoch 4, iter 402, loss 2.1300876140594482, acc 0.30000001192092896\n",
      "Epoch 4, iter 403, loss 2.1746320724487305, acc 0.25999999046325684\n",
      "Epoch 4, iter 404, loss 2.1671767234802246, acc 0.27000001072883606\n",
      "Epoch 4, iter 405, loss 2.175027370452881, acc 0.3100000023841858\n",
      "Epoch 4, iter 406, loss 2.154461145401001, acc 0.27000001072883606\n",
      "Epoch 4, iter 407, loss 2.1593470573425293, acc 0.25\n",
      "Epoch 4, iter 408, loss 2.1797428131103516, acc 0.2800000011920929\n",
      "Epoch 4, iter 409, loss 2.1320128440856934, acc 0.33000001311302185\n",
      "Epoch 4, iter 410, loss 2.127795696258545, acc 0.2800000011920929\n",
      "Epoch 4, iter 411, loss 2.1284990310668945, acc 0.3100000023841858\n",
      "Epoch 4, iter 412, loss 2.1395347118377686, acc 0.3499999940395355\n",
      "Epoch 4, iter 413, loss 2.1410415172576904, acc 0.30000001192092896\n",
      "Epoch 4, iter 414, loss 2.1485209465026855, acc 0.27000001072883606\n",
      "Epoch 4, iter 415, loss 2.180182695388794, acc 0.25\n",
      "Epoch 4, iter 416, loss 2.127239227294922, acc 0.28999999165534973\n",
      "Epoch 4, iter 417, loss 2.118846893310547, acc 0.3700000047683716\n",
      "Epoch 4, iter 418, loss 2.1361608505249023, acc 0.2800000011920929\n",
      "Epoch 4, iter 419, loss 2.110309600830078, acc 0.3499999940395355\n",
      "Epoch 4, iter 420, loss 2.1464951038360596, acc 0.2800000011920929\n",
      "Epoch 5, iter 1, loss 2.121102809906006, acc 0.30000001192092896\n",
      "Epoch 5, iter 2, loss 2.1866397857666016, acc 0.2800000011920929\n",
      "Epoch 5, iter 3, loss 2.159776210784912, acc 0.30000001192092896\n",
      "Epoch 5, iter 4, loss 2.1928300857543945, acc 0.25\n",
      "Epoch 5, iter 5, loss 2.170370101928711, acc 0.18000000715255737\n",
      "Epoch 5, iter 6, loss 2.174898624420166, acc 0.23999999463558197\n",
      "Epoch 5, iter 7, loss 2.1624996662139893, acc 0.28999999165534973\n",
      "Epoch 5, iter 8, loss 2.137537956237793, acc 0.2800000011920929\n",
      "Epoch 5, iter 9, loss 2.1778554916381836, acc 0.28999999165534973\n",
      "Epoch 5, iter 10, loss 2.1887552738189697, acc 0.30000001192092896\n",
      "Epoch 5, iter 11, loss 2.170896053314209, acc 0.2800000011920929\n",
      "Epoch 5, iter 12, loss 2.1599791049957275, acc 0.2800000011920929\n",
      "Epoch 5, iter 13, loss 2.1380603313446045, acc 0.2800000011920929\n",
      "Epoch 5, iter 14, loss 2.096177816390991, acc 0.3799999952316284\n",
      "Epoch 5, iter 15, loss 2.1004178524017334, acc 0.3400000035762787\n",
      "Epoch 5, iter 16, loss 2.1207892894744873, acc 0.2800000011920929\n",
      "Epoch 5, iter 17, loss 2.1655938625335693, acc 0.23000000417232513\n",
      "Epoch 5, iter 18, loss 2.167402744293213, acc 0.27000001072883606\n",
      "Epoch 5, iter 19, loss 2.1190896034240723, acc 0.3100000023841858\n",
      "Epoch 5, iter 20, loss 2.1169207096099854, acc 0.3700000047683716\n",
      "Epoch 5, iter 21, loss 2.102116584777832, acc 0.3100000023841858\n",
      "Epoch 5, iter 22, loss 2.153247594833374, acc 0.30000001192092896\n",
      "Epoch 5, iter 23, loss 2.1145639419555664, acc 0.33000001311302185\n",
      "Epoch 5, iter 24, loss 2.160529851913452, acc 0.20999999344348907\n",
      "Epoch 5, iter 25, loss 2.1652495861053467, acc 0.30000001192092896\n",
      "Epoch 5, iter 26, loss 2.16410756111145, acc 0.27000001072883606\n",
      "Epoch 5, iter 27, loss 2.1480910778045654, acc 0.3499999940395355\n",
      "Epoch 5, iter 28, loss 2.0949158668518066, acc 0.38999998569488525\n",
      "Epoch 5, iter 29, loss 2.1515228748321533, acc 0.28999999165534973\n",
      "Epoch 5, iter 30, loss 2.1556501388549805, acc 0.3199999928474426\n",
      "Epoch 5, iter 31, loss 2.2110724449157715, acc 0.20999999344348907\n",
      "Epoch 5, iter 32, loss 2.1498568058013916, acc 0.25999999046325684\n",
      "Epoch 5, iter 33, loss 2.181988000869751, acc 0.2800000011920929\n",
      "Epoch 5, iter 34, loss 2.1254258155822754, acc 0.3199999928474426\n",
      "Epoch 5, iter 35, loss 2.1571760177612305, acc 0.28999999165534973\n",
      "Epoch 5, iter 36, loss 2.1393611431121826, acc 0.33000001311302185\n",
      "Epoch 5, iter 37, loss 2.1844985485076904, acc 0.23999999463558197\n",
      "Epoch 5, iter 38, loss 2.171135663986206, acc 0.3499999940395355\n",
      "Epoch 5, iter 39, loss 2.1276237964630127, acc 0.3400000035762787\n",
      "Epoch 5, iter 40, loss 2.103959560394287, acc 0.30000001192092896\n",
      "Epoch 5, iter 41, loss 2.1927459239959717, acc 0.20999999344348907\n",
      "Epoch 5, iter 42, loss 2.1552915573120117, acc 0.2800000011920929\n",
      "Epoch 5, iter 43, loss 2.095015525817871, acc 0.3400000035762787\n",
      "Epoch 5, iter 44, loss 2.106701135635376, acc 0.3100000023841858\n",
      "Epoch 5, iter 45, loss 2.16969633102417, acc 0.2800000011920929\n",
      "Epoch 5, iter 46, loss 2.1598429679870605, acc 0.3199999928474426\n",
      "Epoch 5, iter 47, loss 2.1790246963500977, acc 0.20999999344348907\n",
      "Epoch 5, iter 48, loss 2.112318992614746, acc 0.3100000023841858\n",
      "Epoch 5, iter 49, loss 2.1448917388916016, acc 0.3199999928474426\n",
      "Epoch 5, iter 50, loss 2.1812851428985596, acc 0.25999999046325684\n",
      "Epoch 5, iter 51, loss 2.122145652770996, acc 0.3400000035762787\n",
      "Epoch 5, iter 52, loss 2.172333002090454, acc 0.23999999463558197\n",
      "Epoch 5, iter 53, loss 2.1245572566986084, acc 0.3700000047683716\n",
      "Epoch 5, iter 54, loss 2.146601676940918, acc 0.25999999046325684\n",
      "Epoch 5, iter 55, loss 2.226449728012085, acc 0.1899999976158142\n",
      "Epoch 5, iter 56, loss 2.1475255489349365, acc 0.28999999165534973\n",
      "Epoch 5, iter 57, loss 2.2095422744750977, acc 0.2199999988079071\n",
      "Epoch 5, iter 58, loss 2.1762945652008057, acc 0.33000001311302185\n",
      "Epoch 5, iter 59, loss 2.1433629989624023, acc 0.4300000071525574\n",
      "Epoch 5, iter 60, loss 2.147967576980591, acc 0.41999998688697815\n",
      "Epoch 5, iter 61, loss 2.1402430534362793, acc 0.3400000035762787\n",
      "Epoch 5, iter 62, loss 2.158102035522461, acc 0.3499999940395355\n",
      "Epoch 5, iter 63, loss 2.1771466732025146, acc 0.38999998569488525\n",
      "Epoch 5, iter 64, loss 2.123537540435791, acc 0.3799999952316284\n",
      "Epoch 5, iter 65, loss 2.1640214920043945, acc 0.38999998569488525\n",
      "Epoch 5, iter 66, loss 2.1234583854675293, acc 0.4300000071525574\n",
      "Epoch 5, iter 67, loss 2.155457019805908, acc 0.41999998688697815\n",
      "Epoch 5, iter 68, loss 2.1241860389709473, acc 0.38999998569488525\n",
      "Epoch 5, iter 69, loss 2.1455321311950684, acc 0.3700000047683716\n",
      "Epoch 5, iter 70, loss 2.1576573848724365, acc 0.4099999964237213\n",
      "Epoch 5, iter 71, loss 2.1665008068084717, acc 0.3700000047683716\n",
      "Epoch 5, iter 72, loss 2.1432390213012695, acc 0.3199999928474426\n",
      "Epoch 5, iter 73, loss 2.126756191253662, acc 0.38999998569488525\n",
      "Epoch 5, iter 74, loss 2.1524393558502197, acc 0.3100000023841858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 75, loss 2.1530580520629883, acc 0.3499999940395355\n",
      "Epoch 5, iter 76, loss 2.15755558013916, acc 0.3199999928474426\n",
      "Epoch 5, iter 77, loss 2.1940903663635254, acc 0.3400000035762787\n",
      "Epoch 5, iter 78, loss 2.1607534885406494, acc 0.3799999952316284\n",
      "Epoch 5, iter 79, loss 2.142428159713745, acc 0.4000000059604645\n",
      "Epoch 5, iter 80, loss 2.1337730884552, acc 0.3199999928474426\n",
      "Epoch 5, iter 81, loss 2.1783149242401123, acc 0.33000001311302185\n",
      "Epoch 5, iter 82, loss 2.1705031394958496, acc 0.33000001311302185\n",
      "Epoch 5, iter 83, loss 2.130507707595825, acc 0.3799999952316284\n",
      "Epoch 5, iter 84, loss 2.1768839359283447, acc 0.28999999165534973\n",
      "Epoch 5, iter 85, loss 2.2004342079162598, acc 0.27000001072883606\n",
      "Epoch 5, iter 86, loss 2.141761541366577, acc 0.4000000059604645\n",
      "Epoch 5, iter 87, loss 2.1620099544525146, acc 0.3499999940395355\n",
      "Epoch 5, iter 88, loss 2.1251909732818604, acc 0.4099999964237213\n",
      "Epoch 5, iter 89, loss 2.1618874073028564, acc 0.36000001430511475\n",
      "Epoch 5, iter 90, loss 2.1474814414978027, acc 0.3499999940395355\n",
      "Epoch 5, iter 91, loss 2.15198016166687, acc 0.3400000035762787\n",
      "Epoch 5, iter 92, loss 2.1933600902557373, acc 0.33000001311302185\n",
      "Epoch 5, iter 93, loss 2.123972177505493, acc 0.4300000071525574\n",
      "Epoch 5, iter 94, loss 2.149104595184326, acc 0.3799999952316284\n",
      "Epoch 5, iter 95, loss 2.136617422103882, acc 0.4000000059604645\n",
      "Epoch 5, iter 96, loss 2.1754653453826904, acc 0.3700000047683716\n",
      "Epoch 5, iter 97, loss 2.1652638912200928, acc 0.2800000011920929\n",
      "Epoch 5, iter 98, loss 2.1702420711517334, acc 0.3700000047683716\n",
      "Epoch 5, iter 99, loss 2.1387670040130615, acc 0.4000000059604645\n",
      "Epoch 5, iter 100, loss 2.1321518421173096, acc 0.4300000071525574\n",
      "Epoch 5, iter 101, loss 2.1304759979248047, acc 0.36000001430511475\n",
      "Epoch 5, iter 102, loss 2.148785352706909, acc 0.4099999964237213\n",
      "Epoch 5, iter 103, loss 2.130324363708496, acc 0.4099999964237213\n",
      "Epoch 5, iter 104, loss 2.157233715057373, acc 0.38999998569488525\n",
      "Epoch 5, iter 105, loss 2.0681345462799072, acc 0.4300000071525574\n",
      "Epoch 5, iter 106, loss 2.1151182651519775, acc 0.4099999964237213\n",
      "Epoch 5, iter 107, loss 2.1146745681762695, acc 0.4099999964237213\n",
      "Epoch 5, iter 108, loss 2.1713924407958984, acc 0.3400000035762787\n",
      "Epoch 5, iter 109, loss 2.1365935802459717, acc 0.3799999952316284\n",
      "Epoch 5, iter 110, loss 2.1683788299560547, acc 0.27000001072883606\n",
      "Epoch 5, iter 111, loss 2.13921856880188, acc 0.38999998569488525\n",
      "Epoch 5, iter 112, loss 2.137645959854126, acc 0.3799999952316284\n",
      "Epoch 5, iter 113, loss 2.105109453201294, acc 0.4099999964237213\n",
      "Epoch 5, iter 114, loss 2.0983617305755615, acc 0.4300000071525574\n",
      "Epoch 5, iter 115, loss 2.128282308578491, acc 0.3700000047683716\n",
      "Epoch 5, iter 116, loss 2.1281487941741943, acc 0.30000001192092896\n",
      "Epoch 5, iter 117, loss 2.1552834510803223, acc 0.38999998569488525\n",
      "Epoch 5, iter 118, loss 2.1467177867889404, acc 0.3199999928474426\n",
      "Epoch 5, iter 119, loss 2.1463780403137207, acc 0.38999998569488525\n",
      "Epoch 5, iter 120, loss 2.1525208950042725, acc 0.36000001430511475\n",
      "Epoch 5, iter 121, loss 2.1639418601989746, acc 0.3700000047683716\n",
      "Epoch 5, iter 122, loss 2.1246345043182373, acc 0.47999998927116394\n",
      "Epoch 5, iter 123, loss 2.1769206523895264, acc 0.27000001072883606\n",
      "Epoch 5, iter 124, loss 2.1031453609466553, acc 0.41999998688697815\n",
      "Epoch 5, iter 125, loss 2.1618056297302246, acc 0.38999998569488525\n",
      "Epoch 5, iter 126, loss 2.125220775604248, acc 0.38999998569488525\n",
      "Epoch 5, iter 127, loss 2.1471402645111084, acc 0.3799999952316284\n",
      "Epoch 5, iter 128, loss 2.1545190811157227, acc 0.36000001430511475\n",
      "Epoch 5, iter 129, loss 2.1702048778533936, acc 0.33000001311302185\n",
      "Epoch 5, iter 130, loss 2.181311845779419, acc 0.28999999165534973\n",
      "Epoch 5, iter 131, loss 2.2102010250091553, acc 0.33000001311302185\n",
      "Epoch 5, iter 132, loss 2.14338755607605, acc 0.4000000059604645\n",
      "Epoch 5, iter 133, loss 2.1196298599243164, acc 0.4300000071525574\n",
      "Epoch 5, iter 134, loss 2.179997205734253, acc 0.3199999928474426\n",
      "Epoch 5, iter 135, loss 2.170332908630371, acc 0.3499999940395355\n",
      "Epoch 5, iter 136, loss 2.0949697494506836, acc 0.44999998807907104\n",
      "Epoch 5, iter 137, loss 2.128525495529175, acc 0.36000001430511475\n",
      "Epoch 5, iter 138, loss 2.1434576511383057, acc 0.3700000047683716\n",
      "Epoch 5, iter 139, loss 2.1466825008392334, acc 0.4000000059604645\n",
      "Epoch 5, iter 140, loss 2.1546835899353027, acc 0.3499999940395355\n",
      "Epoch 5, iter 141, loss 2.137507438659668, acc 0.41999998688697815\n",
      "Epoch 5, iter 142, loss 2.1500089168548584, acc 0.4000000059604645\n",
      "Epoch 5, iter 143, loss 2.140571355819702, acc 0.38999998569488525\n",
      "Epoch 5, iter 144, loss 2.1594464778900146, acc 0.36000001430511475\n",
      "Epoch 5, iter 145, loss 2.1312143802642822, acc 0.4300000071525574\n",
      "Epoch 5, iter 146, loss 2.1369807720184326, acc 0.3499999940395355\n",
      "Epoch 5, iter 147, loss 2.142860174179077, acc 0.4000000059604645\n",
      "Epoch 5, iter 148, loss 2.1096696853637695, acc 0.3799999952316284\n",
      "Epoch 5, iter 149, loss 2.0958774089813232, acc 0.41999998688697815\n",
      "Epoch 5, iter 150, loss 2.1541996002197266, acc 0.36000001430511475\n",
      "Epoch 5, iter 151, loss 2.041206121444702, acc 0.47999998927116394\n",
      "Epoch 5, iter 152, loss 2.1370363235473633, acc 0.3700000047683716\n",
      "Epoch 5, iter 153, loss 2.1356589794158936, acc 0.36000001430511475\n",
      "Epoch 5, iter 154, loss 2.1524853706359863, acc 0.3400000035762787\n",
      "Epoch 5, iter 155, loss 2.1449708938598633, acc 0.4300000071525574\n",
      "Epoch 5, iter 156, loss 2.1508655548095703, acc 0.3400000035762787\n",
      "Epoch 5, iter 157, loss 2.184565544128418, acc 0.3400000035762787\n",
      "Epoch 5, iter 158, loss 2.156273126602173, acc 0.3799999952316284\n",
      "Epoch 5, iter 159, loss 2.1280159950256348, acc 0.3799999952316284\n",
      "Epoch 5, iter 160, loss 2.1579153537750244, acc 0.33000001311302185\n",
      "Epoch 5, iter 161, loss 2.11234974861145, acc 0.3799999952316284\n",
      "Epoch 5, iter 162, loss 2.0808331966400146, acc 0.41999998688697815\n",
      "Epoch 5, iter 163, loss 2.1633129119873047, acc 0.3499999940395355\n",
      "Epoch 5, iter 164, loss 2.159348964691162, acc 0.36000001430511475\n",
      "Epoch 5, iter 165, loss 2.1826372146606445, acc 0.33000001311302185\n",
      "Epoch 5, iter 166, loss 2.118350028991699, acc 0.4399999976158142\n",
      "Epoch 5, iter 167, loss 2.1585114002227783, acc 0.3400000035762787\n",
      "Epoch 5, iter 168, loss 2.1137876510620117, acc 0.4300000071525574\n",
      "Epoch 5, iter 169, loss 2.082705497741699, acc 0.4099999964237213\n",
      "Epoch 5, iter 170, loss 2.1533336639404297, acc 0.3400000035762787\n",
      "Epoch 5, iter 171, loss 2.1257338523864746, acc 0.4399999976158142\n",
      "Epoch 5, iter 172, loss 2.1644468307495117, acc 0.3799999952316284\n",
      "Epoch 5, iter 173, loss 2.175463914871216, acc 0.3400000035762787\n",
      "Epoch 5, iter 174, loss 2.1200482845306396, acc 0.36000001430511475\n",
      "Epoch 5, iter 175, loss 2.1277012825012207, acc 0.38999998569488525\n",
      "Epoch 5, iter 176, loss 2.1788506507873535, acc 0.3100000023841858\n",
      "Epoch 5, iter 177, loss 2.145089864730835, acc 0.3700000047683716\n",
      "Epoch 5, iter 178, loss 2.13808012008667, acc 0.4000000059604645\n",
      "Epoch 5, iter 179, loss 2.155214309692383, acc 0.28999999165534973\n",
      "Epoch 5, iter 180, loss 2.1786370277404785, acc 0.3700000047683716\n",
      "Epoch 5, iter 181, loss 2.0833373069763184, acc 0.41999998688697815\n",
      "Epoch 5, iter 182, loss 2.174333333969116, acc 0.3499999940395355\n",
      "Epoch 5, iter 183, loss 2.1547915935516357, acc 0.3400000035762787\n",
      "Epoch 5, iter 184, loss 2.151224374771118, acc 0.33000001311302185\n",
      "Epoch 5, iter 185, loss 2.1437344551086426, acc 0.3499999940395355\n",
      "Epoch 5, iter 186, loss 2.155144214630127, acc 0.36000001430511475\n",
      "Epoch 5, iter 187, loss 2.1505653858184814, acc 0.3700000047683716\n",
      "Epoch 5, iter 188, loss 2.1733269691467285, acc 0.3400000035762787\n",
      "Epoch 5, iter 189, loss 2.2217767238616943, acc 0.27000001072883606\n",
      "Epoch 5, iter 190, loss 2.1397876739501953, acc 0.4300000071525574\n",
      "Epoch 5, iter 191, loss 2.16507625579834, acc 0.3100000023841858\n",
      "Epoch 5, iter 192, loss 2.1464061737060547, acc 0.4000000059604645\n",
      "Epoch 5, iter 193, loss 2.1372432708740234, acc 0.3400000035762787\n",
      "Epoch 5, iter 194, loss 2.143110990524292, acc 0.3799999952316284\n",
      "Epoch 5, iter 195, loss 2.1100189685821533, acc 0.4000000059604645\n",
      "Epoch 5, iter 196, loss 2.18669056892395, acc 0.30000001192092896\n",
      "Epoch 5, iter 197, loss 2.162742853164673, acc 0.3199999928474426\n",
      "Epoch 5, iter 198, loss 2.086117744445801, acc 0.47999998927116394\n",
      "Epoch 5, iter 199, loss 2.1727190017700195, acc 0.36000001430511475\n",
      "Epoch 5, iter 200, loss 2.1775152683258057, acc 0.33000001311302185\n",
      "Epoch 5, iter 201, loss 2.13687801361084, acc 0.3799999952316284\n",
      "Epoch 5, iter 202, loss 2.136167049407959, acc 0.3400000035762787\n",
      "Epoch 5, iter 203, loss 2.1553421020507812, acc 0.3400000035762787\n",
      "Epoch 5, iter 204, loss 2.119480848312378, acc 0.4099999964237213\n",
      "Epoch 5, iter 205, loss 2.0893306732177734, acc 0.4099999964237213\n",
      "Epoch 5, iter 206, loss 2.1607141494750977, acc 0.33000001311302185\n",
      "Epoch 5, iter 207, loss 2.162045955657959, acc 0.33000001311302185\n",
      "Epoch 5, iter 208, loss 2.193108320236206, acc 0.36000001430511475\n",
      "Epoch 5, iter 209, loss 2.188908815383911, acc 0.30000001192092896\n",
      "Epoch 5, iter 210, loss 2.193819522857666, acc 0.28999999165534973\n",
      "Epoch 5, iter 211, loss 2.1353654861450195, acc 0.4000000059604645\n",
      "Epoch 5, iter 212, loss 2.176804542541504, acc 0.3199999928474426\n",
      "Epoch 5, iter 213, loss 2.1663525104522705, acc 0.36000001430511475\n",
      "Epoch 5, iter 214, loss 2.17869234085083, acc 0.3100000023841858\n",
      "Epoch 5, iter 215, loss 2.1501853466033936, acc 0.3199999928474426\n",
      "Epoch 5, iter 216, loss 2.181856155395508, acc 0.3199999928474426\n",
      "Epoch 5, iter 217, loss 2.124518394470215, acc 0.4099999964237213\n",
      "Epoch 5, iter 218, loss 2.2106008529663086, acc 0.33000001311302185\n",
      "Epoch 5, iter 219, loss 2.1557507514953613, acc 0.3199999928474426\n",
      "Epoch 5, iter 220, loss 2.111417293548584, acc 0.41999998688697815\n",
      "Epoch 5, iter 221, loss 2.147488594055176, acc 0.3499999940395355\n",
      "Epoch 5, iter 222, loss 2.145432949066162, acc 0.4000000059604645\n",
      "Epoch 5, iter 223, loss 2.1204776763916016, acc 0.4300000071525574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 224, loss 2.1795742511749268, acc 0.3400000035762787\n",
      "Epoch 5, iter 225, loss 2.1328530311584473, acc 0.3400000035762787\n",
      "Epoch 5, iter 226, loss 2.133901357650757, acc 0.36000001430511475\n",
      "Epoch 5, iter 227, loss 2.148252248764038, acc 0.3799999952316284\n",
      "Epoch 5, iter 228, loss 2.1515603065490723, acc 0.3100000023841858\n",
      "Epoch 5, iter 229, loss 2.1257948875427246, acc 0.4000000059604645\n",
      "Epoch 5, iter 230, loss 2.1276164054870605, acc 0.3700000047683716\n",
      "Epoch 5, iter 231, loss 2.113593339920044, acc 0.4300000071525574\n",
      "Epoch 5, iter 232, loss 2.1635892391204834, acc 0.33000001311302185\n",
      "Epoch 5, iter 233, loss 2.104407548904419, acc 0.3700000047683716\n",
      "Epoch 5, iter 234, loss 2.102616310119629, acc 0.46000000834465027\n",
      "Epoch 5, iter 235, loss 2.1287856101989746, acc 0.4300000071525574\n",
      "Epoch 5, iter 236, loss 2.1548216342926025, acc 0.33000001311302185\n",
      "Epoch 5, iter 237, loss 2.190707206726074, acc 0.28999999165534973\n",
      "Epoch 5, iter 238, loss 2.142293691635132, acc 0.3700000047683716\n",
      "Epoch 5, iter 239, loss 2.154005527496338, acc 0.3499999940395355\n",
      "Epoch 5, iter 240, loss 2.1663646697998047, acc 0.3700000047683716\n",
      "Epoch 5, iter 241, loss 2.1445229053497314, acc 0.3799999952316284\n",
      "Epoch 5, iter 242, loss 2.169473171234131, acc 0.3799999952316284\n",
      "Epoch 5, iter 243, loss 2.214707136154175, acc 0.23000000417232513\n",
      "Epoch 5, iter 244, loss 2.116529941558838, acc 0.46000000834465027\n",
      "Epoch 5, iter 245, loss 2.116086006164551, acc 0.38999998569488525\n",
      "Epoch 5, iter 246, loss 2.2042741775512695, acc 0.28999999165534973\n",
      "Epoch 5, iter 247, loss 2.112224817276001, acc 0.4099999964237213\n",
      "Epoch 5, iter 248, loss 2.1675634384155273, acc 0.30000001192092896\n",
      "Epoch 5, iter 249, loss 2.186537265777588, acc 0.3199999928474426\n",
      "Epoch 5, iter 250, loss 2.110618829727173, acc 0.4000000059604645\n",
      "Epoch 5, iter 251, loss 2.1691014766693115, acc 0.33000001311302185\n",
      "Epoch 5, iter 252, loss 2.1475930213928223, acc 0.3499999940395355\n",
      "Epoch 5, iter 253, loss 2.194073438644409, acc 0.28999999165534973\n",
      "Epoch 5, iter 254, loss 2.1745798587799072, acc 0.2800000011920929\n",
      "Epoch 5, iter 255, loss 2.1540017127990723, acc 0.3400000035762787\n",
      "Epoch 5, iter 256, loss 2.1286187171936035, acc 0.38999998569488525\n",
      "Epoch 5, iter 257, loss 2.1519689559936523, acc 0.3199999928474426\n",
      "Epoch 5, iter 258, loss 2.1432535648345947, acc 0.3400000035762787\n",
      "Epoch 5, iter 259, loss 2.1629815101623535, acc 0.3700000047683716\n",
      "Epoch 5, iter 260, loss 2.135822296142578, acc 0.4099999964237213\n",
      "Epoch 5, iter 261, loss 2.1104698181152344, acc 0.38999998569488525\n",
      "Epoch 5, iter 262, loss 2.1723127365112305, acc 0.3700000047683716\n",
      "Epoch 5, iter 263, loss 2.097745895385742, acc 0.4399999976158142\n",
      "Epoch 5, iter 264, loss 2.124039888381958, acc 0.3499999940395355\n",
      "Epoch 5, iter 265, loss 2.176086902618408, acc 0.3700000047683716\n",
      "Epoch 5, iter 266, loss 2.1261420249938965, acc 0.3499999940395355\n",
      "Epoch 5, iter 267, loss 2.1105921268463135, acc 0.46000000834465027\n",
      "Epoch 5, iter 268, loss 2.1447126865386963, acc 0.33000001311302185\n",
      "Epoch 5, iter 269, loss 2.165390729904175, acc 0.33000001311302185\n",
      "Epoch 5, iter 270, loss 2.151824951171875, acc 0.3499999940395355\n",
      "Epoch 5, iter 271, loss 2.192063570022583, acc 0.3100000023841858\n",
      "Epoch 5, iter 272, loss 2.1808135509490967, acc 0.3199999928474426\n",
      "Epoch 5, iter 273, loss 2.1793181896209717, acc 0.36000001430511475\n",
      "Epoch 5, iter 274, loss 2.1514761447906494, acc 0.36000001430511475\n",
      "Epoch 5, iter 275, loss 2.2021305561065674, acc 0.3100000023841858\n",
      "Epoch 5, iter 276, loss 2.1889307498931885, acc 0.3400000035762787\n",
      "Epoch 5, iter 277, loss 2.1396279335021973, acc 0.38999998569488525\n",
      "Epoch 5, iter 278, loss 2.142820358276367, acc 0.33000001311302185\n",
      "Epoch 5, iter 279, loss 2.13261079788208, acc 0.4099999964237213\n",
      "Epoch 5, iter 280, loss 2.128298282623291, acc 0.3799999952316284\n",
      "Epoch 5, iter 281, loss 2.143784999847412, acc 0.4300000071525574\n",
      "Epoch 5, iter 282, loss 2.188586950302124, acc 0.3499999940395355\n",
      "Epoch 5, iter 283, loss 2.126561403274536, acc 0.4099999964237213\n",
      "Epoch 5, iter 284, loss 2.118356227874756, acc 0.3700000047683716\n",
      "Epoch 5, iter 285, loss 2.124058723449707, acc 0.3400000035762787\n",
      "Epoch 5, iter 286, loss 2.132701873779297, acc 0.4099999964237213\n",
      "Epoch 5, iter 287, loss 2.157724618911743, acc 0.3700000047683716\n",
      "Epoch 5, iter 288, loss 2.1082584857940674, acc 0.3799999952316284\n",
      "Epoch 5, iter 289, loss 2.189781904220581, acc 0.3400000035762787\n",
      "Epoch 5, iter 290, loss 2.1043574810028076, acc 0.4300000071525574\n",
      "Epoch 5, iter 291, loss 2.130051374435425, acc 0.3700000047683716\n",
      "Epoch 5, iter 292, loss 2.1219594478607178, acc 0.38999998569488525\n",
      "Epoch 5, iter 293, loss 2.1277804374694824, acc 0.4099999964237213\n",
      "Epoch 5, iter 294, loss 2.1868293285369873, acc 0.30000001192092896\n",
      "Epoch 5, iter 295, loss 2.169312000274658, acc 0.3499999940395355\n",
      "Epoch 5, iter 296, loss 2.1210083961486816, acc 0.38999998569488525\n",
      "Epoch 5, iter 297, loss 2.1758010387420654, acc 0.3199999928474426\n",
      "Epoch 5, iter 298, loss 2.119860887527466, acc 0.38999998569488525\n",
      "Epoch 5, iter 299, loss 2.1941442489624023, acc 0.25999999046325684\n",
      "Epoch 5, iter 300, loss 2.161517858505249, acc 0.3499999940395355\n",
      "Epoch 5, iter 301, loss 2.1695191860198975, acc 0.33000001311302185\n",
      "Epoch 5, iter 302, loss 2.114751100540161, acc 0.4399999976158142\n",
      "Epoch 5, iter 303, loss 2.1379735469818115, acc 0.4099999964237213\n",
      "Epoch 5, iter 304, loss 2.185781955718994, acc 0.2800000011920929\n",
      "Epoch 5, iter 305, loss 2.2154805660247803, acc 0.27000001072883606\n",
      "Epoch 5, iter 306, loss 2.0982279777526855, acc 0.44999998807907104\n",
      "Epoch 5, iter 307, loss 2.105309247970581, acc 0.41999998688697815\n",
      "Epoch 5, iter 308, loss 2.1804656982421875, acc 0.38999998569488525\n",
      "Epoch 5, iter 309, loss 2.1403732299804688, acc 0.4000000059604645\n",
      "Epoch 5, iter 310, loss 2.1459875106811523, acc 0.3499999940395355\n",
      "Epoch 5, iter 311, loss 2.1285572052001953, acc 0.38999998569488525\n",
      "Epoch 5, iter 312, loss 2.131039619445801, acc 0.41999998688697815\n",
      "Epoch 5, iter 313, loss 2.211034059524536, acc 0.2800000011920929\n",
      "Epoch 5, iter 314, loss 2.091552972793579, acc 0.4399999976158142\n",
      "Epoch 5, iter 315, loss 2.1446502208709717, acc 0.4000000059604645\n",
      "Epoch 5, iter 316, loss 2.1649086475372314, acc 0.3100000023841858\n",
      "Epoch 5, iter 317, loss 2.1460039615631104, acc 0.38999998569488525\n",
      "Epoch 5, iter 318, loss 2.1295368671417236, acc 0.3400000035762787\n",
      "Epoch 5, iter 319, loss 2.1432526111602783, acc 0.3700000047683716\n",
      "Epoch 5, iter 320, loss 2.226360321044922, acc 0.30000001192092896\n",
      "Epoch 5, iter 321, loss 2.165560722351074, acc 0.36000001430511475\n",
      "Epoch 5, iter 322, loss 2.146179437637329, acc 0.3400000035762787\n",
      "Epoch 5, iter 323, loss 2.1418497562408447, acc 0.3700000047683716\n",
      "Epoch 5, iter 324, loss 2.0760622024536133, acc 0.44999998807907104\n",
      "Epoch 5, iter 325, loss 2.181032180786133, acc 0.3700000047683716\n",
      "Epoch 5, iter 326, loss 2.1164615154266357, acc 0.41999998688697815\n",
      "Epoch 5, iter 327, loss 2.1824097633361816, acc 0.30000001192092896\n",
      "Epoch 5, iter 328, loss 2.1062967777252197, acc 0.4099999964237213\n",
      "Epoch 5, iter 329, loss 2.1156036853790283, acc 0.38999998569488525\n",
      "Epoch 5, iter 330, loss 2.167861223220825, acc 0.33000001311302185\n",
      "Epoch 5, iter 331, loss 2.152433156967163, acc 0.33000001311302185\n",
      "Epoch 5, iter 332, loss 2.1776156425476074, acc 0.3400000035762787\n",
      "Epoch 5, iter 333, loss 2.1422340869903564, acc 0.3499999940395355\n",
      "Epoch 5, iter 334, loss 2.193619728088379, acc 0.3700000047683716\n",
      "Epoch 5, iter 335, loss 2.0735790729522705, acc 0.4300000071525574\n",
      "Epoch 5, iter 336, loss 2.1253550052642822, acc 0.4000000059604645\n",
      "Epoch 5, iter 337, loss 2.130279779434204, acc 0.3799999952316284\n",
      "Epoch 5, iter 338, loss 2.1275582313537598, acc 0.4699999988079071\n",
      "Epoch 5, iter 339, loss 2.152259588241577, acc 0.4000000059604645\n",
      "Epoch 5, iter 340, loss 2.1545612812042236, acc 0.38999998569488525\n",
      "Epoch 5, iter 341, loss 2.131402015686035, acc 0.3700000047683716\n",
      "Epoch 5, iter 342, loss 2.1238927841186523, acc 0.41999998688697815\n",
      "Epoch 5, iter 343, loss 2.186537981033325, acc 0.3400000035762787\n",
      "Epoch 5, iter 344, loss 2.098966598510742, acc 0.4399999976158142\n",
      "Epoch 5, iter 345, loss 2.1762421131134033, acc 0.3499999940395355\n",
      "Epoch 5, iter 346, loss 2.0836427211761475, acc 0.41999998688697815\n",
      "Epoch 5, iter 347, loss 2.1946778297424316, acc 0.3100000023841858\n",
      "Epoch 5, iter 348, loss 2.096816062927246, acc 0.4699999988079071\n",
      "Epoch 5, iter 349, loss 2.0797712802886963, acc 0.44999998807907104\n",
      "Epoch 5, iter 350, loss 2.1598994731903076, acc 0.36000001430511475\n",
      "Epoch 5, iter 351, loss 2.138356924057007, acc 0.3499999940395355\n",
      "Epoch 5, iter 352, loss 2.161654233932495, acc 0.3199999928474426\n",
      "Epoch 5, iter 353, loss 2.141831636428833, acc 0.4300000071525574\n",
      "Epoch 5, iter 354, loss 2.108543872833252, acc 0.4099999964237213\n",
      "Epoch 5, iter 355, loss 2.1649410724639893, acc 0.38999998569488525\n",
      "Epoch 5, iter 356, loss 2.144918918609619, acc 0.36000001430511475\n",
      "Epoch 5, iter 357, loss 2.1630899906158447, acc 0.33000001311302185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iter 358, loss 2.2086846828460693, acc 0.27000001072883606\n",
      "Epoch 5, iter 359, loss 2.1482715606689453, acc 0.38999998569488525\n",
      "Epoch 5, iter 360, loss 2.1458523273468018, acc 0.3700000047683716\n",
      "Epoch 5, iter 361, loss 2.128235101699829, acc 0.36000001430511475\n",
      "Epoch 5, iter 362, loss 2.185542345046997, acc 0.3199999928474426\n",
      "Epoch 5, iter 363, loss 2.1391167640686035, acc 0.4099999964237213\n",
      "Epoch 5, iter 364, loss 2.141211986541748, acc 0.3100000023841858\n",
      "Epoch 5, iter 365, loss 2.1154513359069824, acc 0.4000000059604645\n",
      "Epoch 5, iter 366, loss 2.0937047004699707, acc 0.36000001430511475\n",
      "Epoch 5, iter 367, loss 2.1145148277282715, acc 0.38999998569488525\n",
      "Epoch 5, iter 368, loss 2.10990834236145, acc 0.4300000071525574\n",
      "Epoch 5, iter 369, loss 2.125741958618164, acc 0.38999998569488525\n",
      "Epoch 5, iter 370, loss 2.097196102142334, acc 0.4300000071525574\n",
      "Epoch 5, iter 371, loss 2.0928914546966553, acc 0.41999998688697815\n",
      "Epoch 5, iter 372, loss 2.136306047439575, acc 0.36000001430511475\n",
      "Epoch 5, iter 373, loss 2.1545019149780273, acc 0.33000001311302185\n",
      "Epoch 5, iter 374, loss 2.151329278945923, acc 0.36000001430511475\n",
      "Epoch 5, iter 375, loss 2.1367714405059814, acc 0.4300000071525574\n",
      "Epoch 5, iter 376, loss 2.1558749675750732, acc 0.36000001430511475\n",
      "Epoch 5, iter 377, loss 2.0972580909729004, acc 0.46000000834465027\n",
      "Epoch 5, iter 378, loss 2.142165184020996, acc 0.3400000035762787\n",
      "Epoch 5, iter 379, loss 2.1938483715057373, acc 0.33000001311302185\n",
      "Epoch 5, iter 380, loss 2.167957067489624, acc 0.30000001192092896\n",
      "Epoch 5, iter 381, loss 2.152188777923584, acc 0.3799999952316284\n",
      "Epoch 5, iter 382, loss 2.1175765991210938, acc 0.38999998569488525\n",
      "Epoch 5, iter 383, loss 2.1248013973236084, acc 0.38999998569488525\n",
      "Epoch 5, iter 384, loss 2.163351058959961, acc 0.3499999940395355\n",
      "Epoch 5, iter 385, loss 2.134455442428589, acc 0.38999998569488525\n",
      "Epoch 5, iter 386, loss 2.1334481239318848, acc 0.3799999952316284\n",
      "Epoch 5, iter 387, loss 2.1497440338134766, acc 0.36000001430511475\n",
      "Epoch 5, iter 388, loss 2.152259349822998, acc 0.3799999952316284\n",
      "Epoch 5, iter 389, loss 2.1568427085876465, acc 0.3100000023841858\n",
      "Epoch 5, iter 390, loss 2.2143654823303223, acc 0.25\n",
      "Epoch 5, iter 391, loss 2.1535887718200684, acc 0.3799999952316284\n",
      "Epoch 5, iter 392, loss 2.159181594848633, acc 0.33000001311302185\n",
      "Epoch 5, iter 393, loss 2.159325361251831, acc 0.3499999940395355\n",
      "Epoch 5, iter 394, loss 2.131213426589966, acc 0.4099999964237213\n",
      "Epoch 5, iter 395, loss 2.082432746887207, acc 0.47999998927116394\n",
      "Epoch 5, iter 396, loss 2.162130832672119, acc 0.33000001311302185\n",
      "Epoch 5, iter 397, loss 2.139547348022461, acc 0.3499999940395355\n",
      "Epoch 5, iter 398, loss 2.1736347675323486, acc 0.2800000011920929\n",
      "Epoch 5, iter 399, loss 2.1385581493377686, acc 0.3700000047683716\n",
      "Epoch 5, iter 400, loss 2.108886957168579, acc 0.44999998807907104\n",
      "Epoch 5, iter 401, loss 2.1111409664154053, acc 0.4300000071525574\n",
      "Epoch 5, iter 402, loss 2.107435941696167, acc 0.3799999952316284\n",
      "Epoch 5, iter 403, loss 2.1573243141174316, acc 0.36000001430511475\n",
      "Epoch 5, iter 404, loss 2.157318353652954, acc 0.36000001430511475\n",
      "Epoch 5, iter 405, loss 2.160787582397461, acc 0.41999998688697815\n",
      "Epoch 5, iter 406, loss 2.1464719772338867, acc 0.36000001430511475\n",
      "Epoch 5, iter 407, loss 2.1473803520202637, acc 0.33000001311302185\n",
      "Epoch 5, iter 408, loss 2.1803033351898193, acc 0.33000001311302185\n",
      "Epoch 5, iter 409, loss 2.1233224868774414, acc 0.41999998688697815\n",
      "Epoch 5, iter 410, loss 2.1109209060668945, acc 0.3499999940395355\n",
      "Epoch 5, iter 411, loss 2.1134626865386963, acc 0.4300000071525574\n",
      "Epoch 5, iter 412, loss 2.128425121307373, acc 0.4099999964237213\n",
      "Epoch 5, iter 413, loss 2.153804063796997, acc 0.33000001311302185\n",
      "Epoch 5, iter 414, loss 2.1475706100463867, acc 0.3799999952316284\n",
      "Epoch 5, iter 415, loss 2.1690120697021484, acc 0.3100000023841858\n",
      "Epoch 5, iter 416, loss 2.119511604309082, acc 0.3700000047683716\n",
      "Epoch 5, iter 417, loss 2.093871593475342, acc 0.5\n",
      "Epoch 5, iter 418, loss 2.129763126373291, acc 0.3100000023841858\n",
      "Epoch 5, iter 419, loss 2.1059062480926514, acc 0.38999998569488525\n",
      "Epoch 5, iter 420, loss 2.1346123218536377, acc 0.3700000047683716\n",
      "Epoch 6, iter 1, loss 2.1025328636169434, acc 0.4099999964237213\n",
      "Epoch 6, iter 2, loss 2.167654514312744, acc 0.33000001311302185\n",
      "Epoch 6, iter 3, loss 2.1431686878204346, acc 0.3499999940395355\n",
      "Epoch 6, iter 4, loss 2.1811351776123047, acc 0.3400000035762787\n",
      "Epoch 6, iter 5, loss 2.1616337299346924, acc 0.30000001192092896\n",
      "Epoch 6, iter 6, loss 2.1633141040802, acc 0.3199999928474426\n",
      "Epoch 6, iter 7, loss 2.1489193439483643, acc 0.36000001430511475\n",
      "Epoch 6, iter 8, loss 2.1267249584198, acc 0.33000001311302185\n",
      "Epoch 6, iter 9, loss 2.166943073272705, acc 0.3499999940395355\n",
      "Epoch 6, iter 10, loss 2.1804006099700928, acc 0.3700000047683716\n",
      "Epoch 6, iter 11, loss 2.162947654724121, acc 0.3199999928474426\n",
      "Epoch 6, iter 12, loss 2.1529572010040283, acc 0.3499999940395355\n",
      "Epoch 6, iter 13, loss 2.130392074584961, acc 0.3799999952316284\n",
      "Epoch 6, iter 14, loss 2.0975427627563477, acc 0.46000000834465027\n",
      "Epoch 6, iter 15, loss 2.0817575454711914, acc 0.4000000059604645\n",
      "Epoch 6, iter 16, loss 2.1031572818756104, acc 0.41999998688697815\n",
      "Epoch 6, iter 17, loss 2.1541690826416016, acc 0.3100000023841858\n",
      "Epoch 6, iter 18, loss 2.14518666267395, acc 0.3700000047683716\n",
      "Epoch 6, iter 19, loss 2.107271432876587, acc 0.38999998569488525\n",
      "Epoch 6, iter 20, loss 2.095057487487793, acc 0.4099999964237213\n",
      "Epoch 6, iter 21, loss 2.1029868125915527, acc 0.3700000047683716\n",
      "Epoch 6, iter 22, loss 2.137904167175293, acc 0.3799999952316284\n",
      "Epoch 6, iter 23, loss 2.0994904041290283, acc 0.38999998569488525\n",
      "Epoch 6, iter 24, loss 2.1343164443969727, acc 0.3199999928474426\n",
      "Epoch 6, iter 25, loss 2.1500539779663086, acc 0.3700000047683716\n",
      "Epoch 6, iter 26, loss 2.1512787342071533, acc 0.3199999928474426\n",
      "Epoch 6, iter 27, loss 2.142261266708374, acc 0.4099999964237213\n",
      "Epoch 6, iter 28, loss 2.1037611961364746, acc 0.4300000071525574\n",
      "Epoch 6, iter 29, loss 2.136126756668091, acc 0.3700000047683716\n",
      "Epoch 6, iter 30, loss 2.1418862342834473, acc 0.3700000047683716\n",
      "Epoch 6, iter 31, loss 2.2007036209106445, acc 0.2800000011920929\n",
      "Epoch 6, iter 32, loss 2.1299731731414795, acc 0.3400000035762787\n",
      "Epoch 6, iter 33, loss 2.158207654953003, acc 0.36000001430511475\n",
      "Epoch 6, iter 34, loss 2.115654706954956, acc 0.36000001430511475\n",
      "Epoch 6, iter 35, loss 2.146430015563965, acc 0.3199999928474426\n",
      "Epoch 6, iter 36, loss 2.1295998096466064, acc 0.36000001430511475\n",
      "Epoch 6, iter 37, loss 2.1699275970458984, acc 0.3199999928474426\n",
      "Epoch 6, iter 38, loss 2.1594207286834717, acc 0.3799999952316284\n",
      "Epoch 6, iter 39, loss 2.104769706726074, acc 0.4300000071525574\n",
      "Epoch 6, iter 40, loss 2.0873939990997314, acc 0.41999998688697815\n",
      "Epoch 6, iter 41, loss 2.178176164627075, acc 0.27000001072883606\n",
      "Epoch 6, iter 42, loss 2.135998487472534, acc 0.3799999952316284\n",
      "Epoch 6, iter 43, loss 2.069265365600586, acc 0.46000000834465027\n",
      "Epoch 6, iter 44, loss 2.093561887741089, acc 0.3799999952316284\n",
      "Epoch 6, iter 45, loss 2.148642063140869, acc 0.3100000023841858\n",
      "Epoch 6, iter 46, loss 2.1422324180603027, acc 0.4099999964237213\n",
      "Epoch 6, iter 47, loss 2.1650688648223877, acc 0.3100000023841858\n",
      "Epoch 6, iter 48, loss 2.1033647060394287, acc 0.38999998569488525\n",
      "Epoch 6, iter 49, loss 2.1235780715942383, acc 0.3700000047683716\n",
      "Epoch 6, iter 50, loss 2.1662192344665527, acc 0.28999999165534973\n",
      "Epoch 6, iter 51, loss 2.1197948455810547, acc 0.3700000047683716\n",
      "Epoch 6, iter 52, loss 2.1653432846069336, acc 0.3100000023841858\n",
      "Epoch 6, iter 53, loss 2.1108193397521973, acc 0.46000000834465027\n",
      "Epoch 6, iter 54, loss 2.128523111343384, acc 0.3799999952316284\n",
      "Epoch 6, iter 55, loss 2.211820125579834, acc 0.23999999463558197\n",
      "Epoch 6, iter 56, loss 2.1318912506103516, acc 0.38999998569488525\n",
      "Epoch 6, iter 57, loss 2.1910653114318848, acc 0.2800000011920929\n",
      "Epoch 6, iter 58, loss 2.1653871536254883, acc 0.3199999928474426\n",
      "Epoch 6, iter 59, loss 2.1380679607391357, acc 0.4000000059604645\n",
      "Epoch 6, iter 60, loss 2.130841016769409, acc 0.41999998688697815\n",
      "Epoch 6, iter 61, loss 2.127885580062866, acc 0.3499999940395355\n",
      "Epoch 6, iter 62, loss 2.1453161239624023, acc 0.3400000035762787\n",
      "Epoch 6, iter 63, loss 2.185934543609619, acc 0.3499999940395355\n",
      "Epoch 6, iter 64, loss 2.1266274452209473, acc 0.3700000047683716\n",
      "Epoch 6, iter 65, loss 2.1573703289031982, acc 0.3700000047683716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 66, loss 2.119436025619507, acc 0.4099999964237213\n",
      "Epoch 6, iter 67, loss 2.156599521636963, acc 0.3799999952316284\n",
      "Epoch 6, iter 68, loss 2.1225388050079346, acc 0.3799999952316284\n",
      "Epoch 6, iter 69, loss 2.1561315059661865, acc 0.3400000035762787\n",
      "Epoch 6, iter 70, loss 2.157562017440796, acc 0.3700000047683716\n",
      "Epoch 6, iter 71, loss 2.169586420059204, acc 0.3400000035762787\n",
      "Epoch 6, iter 72, loss 2.143512487411499, acc 0.28999999165534973\n",
      "Epoch 6, iter 73, loss 2.128170967102051, acc 0.36000001430511475\n",
      "Epoch 6, iter 74, loss 2.147334098815918, acc 0.3100000023841858\n",
      "Epoch 6, iter 75, loss 2.1533560752868652, acc 0.3100000023841858\n",
      "Epoch 6, iter 76, loss 2.1522562503814697, acc 0.3100000023841858\n",
      "Epoch 6, iter 77, loss 2.1850426197052, acc 0.28999999165534973\n",
      "Epoch 6, iter 78, loss 2.1394455432891846, acc 0.4000000059604645\n",
      "Epoch 6, iter 79, loss 2.146090507507324, acc 0.3799999952316284\n",
      "Epoch 6, iter 80, loss 2.1317899227142334, acc 0.3199999928474426\n",
      "Epoch 6, iter 81, loss 2.1728358268737793, acc 0.3199999928474426\n",
      "Epoch 6, iter 82, loss 2.1720523834228516, acc 0.3199999928474426\n",
      "Epoch 6, iter 83, loss 2.1149630546569824, acc 0.3499999940395355\n",
      "Epoch 6, iter 84, loss 2.1564676761627197, acc 0.3100000023841858\n",
      "Epoch 6, iter 85, loss 2.1880056858062744, acc 0.25999999046325684\n",
      "Epoch 6, iter 86, loss 2.137737989425659, acc 0.3700000047683716\n",
      "Epoch 6, iter 87, loss 2.14968204498291, acc 0.3499999940395355\n",
      "Epoch 6, iter 88, loss 2.108703374862671, acc 0.41999998688697815\n",
      "Epoch 6, iter 89, loss 2.1432554721832275, acc 0.36000001430511475\n",
      "Epoch 6, iter 90, loss 2.131352186203003, acc 0.3700000047683716\n",
      "Epoch 6, iter 91, loss 2.1293413639068604, acc 0.36000001430511475\n",
      "Epoch 6, iter 92, loss 2.1745455265045166, acc 0.33000001311302185\n",
      "Epoch 6, iter 93, loss 2.0945255756378174, acc 0.44999998807907104\n",
      "Epoch 6, iter 94, loss 2.1372742652893066, acc 0.3700000047683716\n",
      "Epoch 6, iter 95, loss 2.11826491355896, acc 0.4000000059604645\n",
      "Epoch 6, iter 96, loss 2.155855178833008, acc 0.3799999952316284\n",
      "Epoch 6, iter 97, loss 2.143956422805786, acc 0.33000001311302185\n",
      "Epoch 6, iter 98, loss 2.149824857711792, acc 0.3799999952316284\n",
      "Epoch 6, iter 99, loss 2.129208564758301, acc 0.4099999964237213\n",
      "Epoch 6, iter 100, loss 2.115746021270752, acc 0.4399999976158142\n",
      "Epoch 6, iter 101, loss 2.119821548461914, acc 0.36000001430511475\n",
      "Epoch 6, iter 102, loss 2.138293504714966, acc 0.4099999964237213\n",
      "Epoch 6, iter 103, loss 2.1161720752716064, acc 0.4000000059604645\n",
      "Epoch 6, iter 104, loss 2.150259494781494, acc 0.4000000059604645\n",
      "Epoch 6, iter 105, loss 2.0549535751342773, acc 0.4300000071525574\n",
      "Epoch 6, iter 106, loss 2.1072580814361572, acc 0.38999998569488525\n",
      "Epoch 6, iter 107, loss 2.1008996963500977, acc 0.41999998688697815\n",
      "Epoch 6, iter 108, loss 2.164876937866211, acc 0.30000001192092896\n",
      "Epoch 6, iter 109, loss 2.118492841720581, acc 0.38999998569488525\n",
      "Epoch 6, iter 110, loss 2.1541330814361572, acc 0.2800000011920929\n",
      "Epoch 6, iter 111, loss 2.127340793609619, acc 0.36000001430511475\n",
      "Epoch 6, iter 112, loss 2.1174733638763428, acc 0.4000000059604645\n",
      "Epoch 6, iter 113, loss 2.0926260948181152, acc 0.4099999964237213\n",
      "Epoch 6, iter 114, loss 2.0927083492279053, acc 0.4099999964237213\n",
      "Epoch 6, iter 115, loss 2.1271114349365234, acc 0.3400000035762787\n",
      "Epoch 6, iter 116, loss 2.1243484020233154, acc 0.30000001192092896\n",
      "Epoch 6, iter 117, loss 2.1497750282287598, acc 0.38999998569488525\n",
      "Epoch 6, iter 118, loss 2.148094892501831, acc 0.3100000023841858\n",
      "Epoch 6, iter 119, loss 2.1561684608459473, acc 0.36000001430511475\n",
      "Epoch 6, iter 120, loss 2.146824836730957, acc 0.3700000047683716\n",
      "Epoch 6, iter 121, loss 2.1580147743225098, acc 0.3799999952316284\n",
      "Epoch 6, iter 122, loss 2.124617576599121, acc 0.4300000071525574\n",
      "Epoch 6, iter 123, loss 2.172039031982422, acc 0.28999999165534973\n",
      "Epoch 6, iter 124, loss 2.0988411903381348, acc 0.41999998688697815\n",
      "Epoch 6, iter 125, loss 2.158362627029419, acc 0.36000001430511475\n",
      "Epoch 6, iter 126, loss 2.1163341999053955, acc 0.38999998569488525\n",
      "Epoch 6, iter 127, loss 2.1289055347442627, acc 0.38999998569488525\n",
      "Epoch 6, iter 128, loss 2.1597490310668945, acc 0.36000001430511475\n",
      "Epoch 6, iter 129, loss 2.1683270931243896, acc 0.3400000035762787\n",
      "Epoch 6, iter 130, loss 2.1894643306732178, acc 0.25\n",
      "Epoch 6, iter 131, loss 2.208190441131592, acc 0.3100000023841858\n",
      "Epoch 6, iter 132, loss 2.1400911808013916, acc 0.4000000059604645\n",
      "Epoch 6, iter 133, loss 2.1010048389434814, acc 0.4399999976158142\n",
      "Epoch 6, iter 134, loss 2.1794943809509277, acc 0.3100000023841858\n",
      "Epoch 6, iter 135, loss 2.164659261703491, acc 0.3499999940395355\n",
      "Epoch 6, iter 136, loss 2.0941503047943115, acc 0.41999998688697815\n",
      "Epoch 6, iter 137, loss 2.125863790512085, acc 0.33000001311302185\n",
      "Epoch 6, iter 138, loss 2.1362175941467285, acc 0.36000001430511475\n",
      "Epoch 6, iter 139, loss 2.1497321128845215, acc 0.38999998569488525\n",
      "Epoch 6, iter 140, loss 2.146756887435913, acc 0.36000001430511475\n",
      "Epoch 6, iter 141, loss 2.15653920173645, acc 0.3499999940395355\n",
      "Epoch 6, iter 142, loss 2.134834051132202, acc 0.4099999964237213\n",
      "Epoch 6, iter 143, loss 2.1368601322174072, acc 0.3799999952316284\n",
      "Epoch 6, iter 144, loss 2.1609296798706055, acc 0.3499999940395355\n",
      "Epoch 6, iter 145, loss 2.1184520721435547, acc 0.4300000071525574\n",
      "Epoch 6, iter 146, loss 2.1348390579223633, acc 0.3400000035762787\n",
      "Epoch 6, iter 147, loss 2.138967990875244, acc 0.38999998569488525\n",
      "Epoch 6, iter 148, loss 2.1028997898101807, acc 0.36000001430511475\n",
      "Epoch 6, iter 149, loss 2.0895133018493652, acc 0.41999998688697815\n",
      "Epoch 6, iter 150, loss 2.1483194828033447, acc 0.36000001430511475\n",
      "Epoch 6, iter 151, loss 2.033686399459839, acc 0.4699999988079071\n",
      "Epoch 6, iter 152, loss 2.120256185531616, acc 0.4000000059604645\n",
      "Epoch 6, iter 153, loss 2.1384289264678955, acc 0.3499999940395355\n",
      "Epoch 6, iter 154, loss 2.1465237140655518, acc 0.36000001430511475\n",
      "Epoch 6, iter 155, loss 2.1450462341308594, acc 0.3799999952316284\n",
      "Epoch 6, iter 156, loss 2.1455020904541016, acc 0.33000001311302185\n",
      "Epoch 6, iter 157, loss 2.1827123165130615, acc 0.33000001311302185\n",
      "Epoch 6, iter 158, loss 2.14750075340271, acc 0.3799999952316284\n",
      "Epoch 6, iter 159, loss 2.120370388031006, acc 0.38999998569488525\n",
      "Epoch 6, iter 160, loss 2.162851095199585, acc 0.3100000023841858\n",
      "Epoch 6, iter 161, loss 2.1111714839935303, acc 0.3799999952316284\n",
      "Epoch 6, iter 162, loss 2.075090169906616, acc 0.4099999964237213\n",
      "Epoch 6, iter 163, loss 2.1716434955596924, acc 0.33000001311302185\n",
      "Epoch 6, iter 164, loss 2.1541388034820557, acc 0.33000001311302185\n",
      "Epoch 6, iter 165, loss 2.1807427406311035, acc 0.33000001311302185\n",
      "Epoch 6, iter 166, loss 2.1214449405670166, acc 0.4099999964237213\n",
      "Epoch 6, iter 167, loss 2.1583046913146973, acc 0.3400000035762787\n",
      "Epoch 6, iter 168, loss 2.1087374687194824, acc 0.4099999964237213\n",
      "Epoch 6, iter 169, loss 2.0818262100219727, acc 0.4000000059604645\n",
      "Epoch 6, iter 170, loss 2.151141881942749, acc 0.3199999928474426\n",
      "Epoch 6, iter 171, loss 2.1261167526245117, acc 0.4099999964237213\n",
      "Epoch 6, iter 172, loss 2.1605842113494873, acc 0.3700000047683716\n",
      "Epoch 6, iter 173, loss 2.164303779602051, acc 0.3400000035762787\n",
      "Epoch 6, iter 174, loss 2.117659091949463, acc 0.3400000035762787\n",
      "Epoch 6, iter 175, loss 2.106602668762207, acc 0.41999998688697815\n",
      "Epoch 6, iter 176, loss 2.169201612472534, acc 0.30000001192092896\n",
      "Epoch 6, iter 177, loss 2.1321752071380615, acc 0.3799999952316284\n",
      "Epoch 6, iter 178, loss 2.1272318363189697, acc 0.3799999952316284\n",
      "Epoch 6, iter 179, loss 2.1468629837036133, acc 0.3100000023841858\n",
      "Epoch 6, iter 180, loss 2.1786282062530518, acc 0.3400000035762787\n",
      "Epoch 6, iter 181, loss 2.0693001747131348, acc 0.4300000071525574\n",
      "Epoch 6, iter 182, loss 2.166322946548462, acc 0.33000001311302185\n",
      "Epoch 6, iter 183, loss 2.1482245922088623, acc 0.33000001311302185\n",
      "Epoch 6, iter 184, loss 2.135087013244629, acc 0.33000001311302185\n",
      "Epoch 6, iter 185, loss 2.1270787715911865, acc 0.33000001311302185\n",
      "Epoch 6, iter 186, loss 2.132319211959839, acc 0.3799999952316284\n",
      "Epoch 6, iter 187, loss 2.135502576828003, acc 0.3700000047683716\n",
      "Epoch 6, iter 188, loss 2.1549956798553467, acc 0.33000001311302185\n",
      "Epoch 6, iter 189, loss 2.2090349197387695, acc 0.27000001072883606\n",
      "Epoch 6, iter 190, loss 2.1272809505462646, acc 0.4300000071525574\n",
      "Epoch 6, iter 191, loss 2.1525001525878906, acc 0.3199999928474426\n",
      "Epoch 6, iter 192, loss 2.127105474472046, acc 0.4099999964237213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 193, loss 2.1219534873962402, acc 0.3499999940395355\n",
      "Epoch 6, iter 194, loss 2.128615617752075, acc 0.3799999952316284\n",
      "Epoch 6, iter 195, loss 2.089380979537964, acc 0.41999998688697815\n",
      "Epoch 6, iter 196, loss 2.174933433532715, acc 0.3100000023841858\n",
      "Epoch 6, iter 197, loss 2.153181552886963, acc 0.33000001311302185\n",
      "Epoch 6, iter 198, loss 2.0730130672454834, acc 0.5\n",
      "Epoch 6, iter 199, loss 2.1589062213897705, acc 0.3400000035762787\n",
      "Epoch 6, iter 200, loss 2.155224084854126, acc 0.36000001430511475\n",
      "Epoch 6, iter 201, loss 2.1301937103271484, acc 0.3799999952316284\n",
      "Epoch 6, iter 202, loss 2.1234519481658936, acc 0.33000001311302185\n",
      "Epoch 6, iter 203, loss 2.1387431621551514, acc 0.3499999940395355\n",
      "Epoch 6, iter 204, loss 2.1060667037963867, acc 0.41999998688697815\n",
      "Epoch 6, iter 205, loss 2.066943883895874, acc 0.4099999964237213\n",
      "Epoch 6, iter 206, loss 2.1468000411987305, acc 0.3499999940395355\n",
      "Epoch 6, iter 207, loss 2.150789260864258, acc 0.3199999928474426\n",
      "Epoch 6, iter 208, loss 2.183823585510254, acc 0.3400000035762787\n",
      "Epoch 6, iter 209, loss 2.173248529434204, acc 0.3199999928474426\n",
      "Epoch 6, iter 210, loss 2.1910758018493652, acc 0.28999999165534973\n",
      "Epoch 6, iter 211, loss 2.1195523738861084, acc 0.4000000059604645\n",
      "Epoch 6, iter 212, loss 2.1694791316986084, acc 0.3199999928474426\n",
      "Epoch 6, iter 213, loss 2.155067205429077, acc 0.3499999940395355\n",
      "Epoch 6, iter 214, loss 2.165513038635254, acc 0.33000001311302185\n",
      "Epoch 6, iter 215, loss 2.1389949321746826, acc 0.3199999928474426\n",
      "Epoch 6, iter 216, loss 2.1721320152282715, acc 0.3199999928474426\n",
      "Epoch 6, iter 217, loss 2.107438564300537, acc 0.41999998688697815\n",
      "Epoch 6, iter 218, loss 2.1969802379608154, acc 0.3499999940395355\n",
      "Epoch 6, iter 219, loss 2.151541233062744, acc 0.33000001311302185\n",
      "Epoch 6, iter 220, loss 2.0955934524536133, acc 0.4099999964237213\n",
      "Epoch 6, iter 221, loss 2.1165590286254883, acc 0.3700000047683716\n",
      "Epoch 6, iter 222, loss 2.1438794136047363, acc 0.38999998569488525\n",
      "Epoch 6, iter 223, loss 2.09780216217041, acc 0.44999998807907104\n",
      "Epoch 6, iter 224, loss 2.1551315784454346, acc 0.3700000047683716\n",
      "Epoch 6, iter 225, loss 2.1172847747802734, acc 0.3700000047683716\n",
      "Epoch 6, iter 226, loss 2.1230437755584717, acc 0.3799999952316284\n",
      "Epoch 6, iter 227, loss 2.142446756362915, acc 0.3700000047683716\n",
      "Epoch 6, iter 228, loss 2.145425796508789, acc 0.3100000023841858\n",
      "Epoch 6, iter 229, loss 2.1127712726593018, acc 0.41999998688697815\n",
      "Epoch 6, iter 230, loss 2.1218490600585938, acc 0.3799999952316284\n",
      "Epoch 6, iter 231, loss 2.1082818508148193, acc 0.41999998688697815\n",
      "Epoch 6, iter 232, loss 2.1474480628967285, acc 0.33000001311302185\n",
      "Epoch 6, iter 233, loss 2.0922558307647705, acc 0.3700000047683716\n",
      "Epoch 6, iter 234, loss 2.0842182636260986, acc 0.4699999988079071\n",
      "Epoch 6, iter 235, loss 2.1163949966430664, acc 0.4300000071525574\n",
      "Epoch 6, iter 236, loss 2.13439679145813, acc 0.33000001311302185\n",
      "Epoch 6, iter 237, loss 2.170199394226074, acc 0.3100000023841858\n",
      "Epoch 6, iter 238, loss 2.123804807662964, acc 0.3700000047683716\n",
      "Epoch 6, iter 239, loss 2.1445870399475098, acc 0.3499999940395355\n",
      "Epoch 6, iter 240, loss 2.1537387371063232, acc 0.3700000047683716\n",
      "Epoch 6, iter 241, loss 2.1411526203155518, acc 0.3700000047683716\n",
      "Epoch 6, iter 242, loss 2.1589138507843018, acc 0.4000000059604645\n",
      "Epoch 6, iter 243, loss 2.185330390930176, acc 0.28999999165534973\n",
      "Epoch 6, iter 244, loss 2.1064789295196533, acc 0.46000000834465027\n",
      "Epoch 6, iter 245, loss 2.1057188510894775, acc 0.4000000059604645\n",
      "Epoch 6, iter 246, loss 2.1941423416137695, acc 0.30000001192092896\n",
      "Epoch 6, iter 247, loss 2.109557867050171, acc 0.4000000059604645\n",
      "Epoch 6, iter 248, loss 2.1591877937316895, acc 0.3100000023841858\n",
      "Epoch 6, iter 249, loss 2.179178237915039, acc 0.3100000023841858\n",
      "Epoch 6, iter 250, loss 2.0907368659973145, acc 0.4399999976158142\n",
      "Epoch 6, iter 251, loss 2.1566808223724365, acc 0.36000001430511475\n",
      "Epoch 6, iter 252, loss 2.1268856525421143, acc 0.3700000047683716\n",
      "Epoch 6, iter 253, loss 2.1794309616088867, acc 0.30000001192092896\n",
      "Epoch 6, iter 254, loss 2.1577045917510986, acc 0.3100000023841858\n",
      "Epoch 6, iter 255, loss 2.1418204307556152, acc 0.36000001430511475\n",
      "Epoch 6, iter 256, loss 2.117957830429077, acc 0.41999998688697815\n",
      "Epoch 6, iter 257, loss 2.1380972862243652, acc 0.36000001430511475\n",
      "Epoch 6, iter 258, loss 2.1308274269104004, acc 0.3700000047683716\n",
      "Epoch 6, iter 259, loss 2.162855625152588, acc 0.36000001430511475\n",
      "Epoch 6, iter 260, loss 2.119152307510376, acc 0.41999998688697815\n",
      "Epoch 6, iter 261, loss 2.094675302505493, acc 0.4000000059604645\n",
      "Epoch 6, iter 262, loss 2.158474922180176, acc 0.3499999940395355\n",
      "Epoch 6, iter 263, loss 2.0841517448425293, acc 0.46000000834465027\n",
      "Epoch 6, iter 264, loss 2.1169257164001465, acc 0.36000001430511475\n",
      "Epoch 6, iter 265, loss 2.18146014213562, acc 0.3400000035762787\n",
      "Epoch 6, iter 266, loss 2.1085033416748047, acc 0.3700000047683716\n",
      "Epoch 6, iter 267, loss 2.114530324935913, acc 0.4300000071525574\n",
      "Epoch 6, iter 268, loss 2.132073402404785, acc 0.33000001311302185\n",
      "Epoch 6, iter 269, loss 2.13968825340271, acc 0.3400000035762787\n",
      "Epoch 6, iter 270, loss 2.1216351985931396, acc 0.3799999952316284\n",
      "Epoch 6, iter 271, loss 2.1547691822052, acc 0.3700000047683716\n",
      "Epoch 6, iter 272, loss 2.1582491397857666, acc 0.3499999940395355\n",
      "Epoch 6, iter 273, loss 2.1588263511657715, acc 0.3499999940395355\n",
      "Epoch 6, iter 274, loss 2.127638339996338, acc 0.3400000035762787\n",
      "Epoch 6, iter 275, loss 2.17205548286438, acc 0.36000001430511475\n",
      "Epoch 6, iter 276, loss 2.169192314147949, acc 0.36000001430511475\n",
      "Epoch 6, iter 277, loss 2.1244449615478516, acc 0.41999998688697815\n",
      "Epoch 6, iter 278, loss 2.1054484844207764, acc 0.3799999952316284\n",
      "Epoch 6, iter 279, loss 2.115039348602295, acc 0.4300000071525574\n",
      "Epoch 6, iter 280, loss 2.1068828105926514, acc 0.3799999952316284\n",
      "Epoch 6, iter 281, loss 2.119015693664551, acc 0.44999998807907104\n",
      "Epoch 6, iter 282, loss 2.1756081581115723, acc 0.33000001311302185\n",
      "Epoch 6, iter 283, loss 2.1117868423461914, acc 0.4099999964237213\n",
      "Epoch 6, iter 284, loss 2.0950942039489746, acc 0.38999998569488525\n",
      "Epoch 6, iter 285, loss 2.1030173301696777, acc 0.3700000047683716\n",
      "Epoch 6, iter 286, loss 2.1132984161376953, acc 0.38999998569488525\n",
      "Epoch 6, iter 287, loss 2.1441991329193115, acc 0.3400000035762787\n",
      "Epoch 6, iter 288, loss 2.078754186630249, acc 0.4000000059604645\n",
      "Epoch 6, iter 289, loss 2.176791191101074, acc 0.3400000035762787\n",
      "Epoch 6, iter 290, loss 2.1000492572784424, acc 0.4099999964237213\n",
      "Epoch 6, iter 291, loss 2.1191203594207764, acc 0.36000001430511475\n",
      "Epoch 6, iter 292, loss 2.118856430053711, acc 0.3799999952316284\n",
      "Epoch 6, iter 293, loss 2.1130945682525635, acc 0.41999998688697815\n",
      "Epoch 6, iter 294, loss 2.1858463287353516, acc 0.30000001192092896\n",
      "Epoch 6, iter 295, loss 2.148369550704956, acc 0.3700000047683716\n",
      "Epoch 6, iter 296, loss 2.1121985912323, acc 0.38999998569488525\n",
      "Epoch 6, iter 297, loss 2.180011034011841, acc 0.28999999165534973\n",
      "Epoch 6, iter 298, loss 2.1161630153656006, acc 0.38999998569488525\n",
      "Epoch 6, iter 299, loss 2.1902456283569336, acc 0.25999999046325684\n",
      "Epoch 6, iter 300, loss 2.1427810192108154, acc 0.3700000047683716\n",
      "Epoch 6, iter 301, loss 2.1576406955718994, acc 0.3400000035762787\n",
      "Epoch 6, iter 302, loss 2.103982448577881, acc 0.4399999976158142\n",
      "Epoch 6, iter 303, loss 2.129708766937256, acc 0.38999998569488525\n",
      "Epoch 6, iter 304, loss 2.180899143218994, acc 0.25\n",
      "Epoch 6, iter 305, loss 2.2095115184783936, acc 0.25999999046325684\n",
      "Epoch 6, iter 306, loss 2.087904930114746, acc 0.41999998688697815\n",
      "Epoch 6, iter 307, loss 2.1033735275268555, acc 0.4099999964237213\n",
      "Epoch 6, iter 308, loss 2.1803030967712402, acc 0.36000001430511475\n",
      "Epoch 6, iter 309, loss 2.1342508792877197, acc 0.3400000035762787\n",
      "Epoch 6, iter 310, loss 2.138018846511841, acc 0.3199999928474426\n",
      "Epoch 6, iter 311, loss 2.1233646869659424, acc 0.3499999940395355\n",
      "Epoch 6, iter 312, loss 2.1123127937316895, acc 0.4300000071525574\n",
      "Epoch 6, iter 313, loss 2.205554962158203, acc 0.2800000011920929\n",
      "Epoch 6, iter 314, loss 2.079953908920288, acc 0.4000000059604645\n",
      "Epoch 6, iter 315, loss 2.134347438812256, acc 0.38999998569488525\n",
      "Epoch 6, iter 316, loss 2.1586244106292725, acc 0.28999999165534973\n",
      "Epoch 6, iter 317, loss 2.1384782791137695, acc 0.3700000047683716\n",
      "Epoch 6, iter 318, loss 2.118032932281494, acc 0.3400000035762787\n",
      "Epoch 6, iter 319, loss 2.125514507293701, acc 0.36000001430511475\n",
      "Epoch 6, iter 320, loss 2.2102198600769043, acc 0.28999999165534973\n",
      "Epoch 6, iter 321, loss 2.150590419769287, acc 0.3499999940395355\n",
      "Epoch 6, iter 322, loss 2.139296531677246, acc 0.3199999928474426\n",
      "Epoch 6, iter 323, loss 2.127437114715576, acc 0.3499999940395355\n",
      "Epoch 6, iter 324, loss 2.0610687732696533, acc 0.44999998807907104\n",
      "Epoch 6, iter 325, loss 2.1628687381744385, acc 0.3700000047683716\n",
      "Epoch 6, iter 326, loss 2.108160972595215, acc 0.36000001430511475\n",
      "Epoch 6, iter 327, loss 2.1760098934173584, acc 0.27000001072883606\n",
      "Epoch 6, iter 328, loss 2.096928358078003, acc 0.4000000059604645\n",
      "Epoch 6, iter 329, loss 2.105788469314575, acc 0.3799999952316284\n",
      "Epoch 6, iter 330, loss 2.157177686691284, acc 0.33000001311302185\n",
      "Epoch 6, iter 331, loss 2.1491971015930176, acc 0.3100000023841858\n",
      "Epoch 6, iter 332, loss 2.168788194656372, acc 0.3400000035762787\n",
      "Epoch 6, iter 333, loss 2.132277488708496, acc 0.3499999940395355\n",
      "Epoch 6, iter 334, loss 2.1854825019836426, acc 0.3400000035762787\n",
      "Epoch 6, iter 335, loss 2.0718719959259033, acc 0.38999998569488525\n",
      "Epoch 6, iter 336, loss 2.128471612930298, acc 0.3799999952316284\n",
      "Epoch 6, iter 337, loss 2.1315419673919678, acc 0.3199999928474426\n",
      "Epoch 6, iter 338, loss 2.122476577758789, acc 0.38999998569488525\n",
      "Epoch 6, iter 339, loss 2.146214246749878, acc 0.3400000035762787\n",
      "Epoch 6, iter 340, loss 2.1539363861083984, acc 0.3700000047683716\n",
      "Epoch 6, iter 341, loss 2.1240386962890625, acc 0.33000001311302185\n",
      "Epoch 6, iter 342, loss 2.1210384368896484, acc 0.36000001430511475\n",
      "Epoch 6, iter 343, loss 2.1818387508392334, acc 0.2800000011920929\n",
      "Epoch 6, iter 344, loss 2.102461814880371, acc 0.3700000047683716\n",
      "Epoch 6, iter 345, loss 2.180678606033325, acc 0.2800000011920929\n",
      "Epoch 6, iter 346, loss 2.076280355453491, acc 0.3799999952316284\n",
      "Epoch 6, iter 347, loss 2.185204029083252, acc 0.2800000011920929\n",
      "Epoch 6, iter 348, loss 2.0928893089294434, acc 0.44999998807907104\n",
      "Epoch 6, iter 349, loss 2.0790648460388184, acc 0.4099999964237213\n",
      "Epoch 6, iter 350, loss 2.1479380130767822, acc 0.3199999928474426\n",
      "Epoch 6, iter 351, loss 2.1298723220825195, acc 0.3199999928474426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iter 352, loss 2.147827625274658, acc 0.3100000023841858\n",
      "Epoch 6, iter 353, loss 2.1364924907684326, acc 0.4099999964237213\n",
      "Epoch 6, iter 354, loss 2.0985372066497803, acc 0.3799999952316284\n",
      "Epoch 6, iter 355, loss 2.148876667022705, acc 0.3700000047683716\n",
      "Epoch 6, iter 356, loss 2.155263900756836, acc 0.33000001311302185\n",
      "Epoch 6, iter 357, loss 2.1455392837524414, acc 0.33000001311302185\n",
      "Epoch 6, iter 358, loss 2.2028298377990723, acc 0.23999999463558197\n",
      "Epoch 6, iter 359, loss 2.158264398574829, acc 0.3100000023841858\n",
      "Epoch 6, iter 360, loss 2.143066167831421, acc 0.3400000035762787\n",
      "Epoch 6, iter 361, loss 2.124830961227417, acc 0.3400000035762787\n",
      "Epoch 6, iter 362, loss 2.1810805797576904, acc 0.30000001192092896\n",
      "Epoch 6, iter 363, loss 2.122014045715332, acc 0.41999998688697815\n",
      "Epoch 6, iter 364, loss 2.1285624504089355, acc 0.3100000023841858\n",
      "Epoch 6, iter 365, loss 2.1036384105682373, acc 0.4000000059604645\n",
      "Epoch 6, iter 366, loss 2.0912697315216064, acc 0.3499999940395355\n",
      "Epoch 6, iter 367, loss 2.095585584640503, acc 0.38999998569488525\n",
      "Epoch 6, iter 368, loss 2.1013970375061035, acc 0.41999998688697815\n",
      "Epoch 6, iter 369, loss 2.1151132583618164, acc 0.4000000059604645\n",
      "Epoch 6, iter 370, loss 2.0876832008361816, acc 0.4300000071525574\n",
      "Epoch 6, iter 371, loss 2.090623378753662, acc 0.4000000059604645\n",
      "Epoch 6, iter 372, loss 2.1179583072662354, acc 0.36000001430511475\n",
      "Epoch 6, iter 373, loss 2.1352126598358154, acc 0.3499999940395355\n",
      "Epoch 6, iter 374, loss 2.1554017066955566, acc 0.33000001311302185\n",
      "Epoch 6, iter 375, loss 2.1252031326293945, acc 0.4099999964237213\n",
      "Epoch 6, iter 376, loss 2.134005546569824, acc 0.36000001430511475\n",
      "Epoch 6, iter 377, loss 2.0799760818481445, acc 0.49000000953674316\n",
      "Epoch 6, iter 378, loss 2.111353874206543, acc 0.4000000059604645\n",
      "Epoch 6, iter 379, loss 2.1745429039001465, acc 0.3100000023841858\n",
      "Epoch 6, iter 380, loss 2.1623194217681885, acc 0.30000001192092896\n",
      "Epoch 6, iter 381, loss 2.1391541957855225, acc 0.3700000047683716\n",
      "Epoch 6, iter 382, loss 2.103046178817749, acc 0.38999998569488525\n",
      "Epoch 6, iter 383, loss 2.106410264968872, acc 0.3799999952316284\n",
      "Epoch 6, iter 384, loss 2.148397922515869, acc 0.3499999940395355\n",
      "Epoch 6, iter 385, loss 2.1339516639709473, acc 0.33000001311302185\n",
      "Epoch 6, iter 386, loss 2.110936164855957, acc 0.4000000059604645\n",
      "Epoch 6, iter 387, loss 2.145103931427002, acc 0.38999998569488525\n",
      "Epoch 6, iter 388, loss 2.147744655609131, acc 0.3499999940395355\n",
      "Epoch 6, iter 389, loss 2.139627456665039, acc 0.3199999928474426\n",
      "Epoch 6, iter 390, loss 2.1989665031433105, acc 0.25\n",
      "Epoch 6, iter 391, loss 2.136751651763916, acc 0.3799999952316284\n",
      "Epoch 6, iter 392, loss 2.134549379348755, acc 0.3499999940395355\n",
      "Epoch 6, iter 393, loss 2.1380233764648438, acc 0.3499999940395355\n",
      "Epoch 6, iter 394, loss 2.112433671951294, acc 0.38999998569488525\n",
      "Epoch 6, iter 395, loss 2.055230140686035, acc 0.49000000953674316\n",
      "Epoch 6, iter 396, loss 2.1371190547943115, acc 0.3400000035762787\n",
      "Epoch 6, iter 397, loss 2.1225602626800537, acc 0.36000001430511475\n",
      "Epoch 6, iter 398, loss 2.1627516746520996, acc 0.27000001072883606\n",
      "Epoch 6, iter 399, loss 2.1185638904571533, acc 0.38999998569488525\n",
      "Epoch 6, iter 400, loss 2.0935754776000977, acc 0.44999998807907104\n",
      "Epoch 6, iter 401, loss 2.108731985092163, acc 0.41999998688697815\n",
      "Epoch 6, iter 402, loss 2.0937650203704834, acc 0.38999998569488525\n",
      "Epoch 6, iter 403, loss 2.1571667194366455, acc 0.30000001192092896\n",
      "Epoch 6, iter 404, loss 2.148775339126587, acc 0.3199999928474426\n",
      "Epoch 6, iter 405, loss 2.148888349533081, acc 0.4099999964237213\n",
      "Epoch 6, iter 406, loss 2.130510091781616, acc 0.3499999940395355\n",
      "Epoch 6, iter 407, loss 2.138777732849121, acc 0.3100000023841858\n",
      "Epoch 6, iter 408, loss 2.1679420471191406, acc 0.3400000035762787\n",
      "Epoch 6, iter 409, loss 2.110548734664917, acc 0.41999998688697815\n",
      "Epoch 6, iter 410, loss 2.0954625606536865, acc 0.3400000035762787\n",
      "Epoch 6, iter 411, loss 2.108234167098999, acc 0.38999998569488525\n",
      "Epoch 6, iter 412, loss 2.1155478954315186, acc 0.38999998569488525\n",
      "Epoch 6, iter 413, loss 2.139561891555786, acc 0.33000001311302185\n",
      "Epoch 6, iter 414, loss 2.1475625038146973, acc 0.36000001430511475\n",
      "Epoch 6, iter 415, loss 2.163456678390503, acc 0.3100000023841858\n",
      "Epoch 6, iter 416, loss 2.1019632816314697, acc 0.36000001430511475\n",
      "Epoch 6, iter 417, loss 2.0829269886016846, acc 0.49000000953674316\n",
      "Epoch 6, iter 418, loss 2.104379177093506, acc 0.3400000035762787\n",
      "Epoch 6, iter 419, loss 2.093266248703003, acc 0.38999998569488525\n",
      "Epoch 6, iter 420, loss 2.1371347904205322, acc 0.3499999940395355\n",
      "Epoch 7, iter 1, loss 2.1130192279815674, acc 0.36000001430511475\n",
      "Epoch 7, iter 2, loss 2.1619911193847656, acc 0.3199999928474426\n",
      "Epoch 7, iter 3, loss 2.1319212913513184, acc 0.36000001430511475\n",
      "Epoch 7, iter 4, loss 2.176764965057373, acc 0.33000001311302185\n",
      "Epoch 7, iter 5, loss 2.1581010818481445, acc 0.25999999046325684\n",
      "Epoch 7, iter 6, loss 2.1582019329071045, acc 0.30000001192092896\n",
      "Epoch 7, iter 7, loss 2.1438934803009033, acc 0.3400000035762787\n",
      "Epoch 7, iter 8, loss 2.129828453063965, acc 0.3100000023841858\n",
      "Epoch 7, iter 9, loss 2.1522727012634277, acc 0.36000001430511475\n",
      "Epoch 7, iter 10, loss 2.158085584640503, acc 0.3799999952316284\n",
      "Epoch 7, iter 11, loss 2.154958963394165, acc 0.3199999928474426\n",
      "Epoch 7, iter 12, loss 2.145378589630127, acc 0.36000001430511475\n",
      "Epoch 7, iter 13, loss 2.119187831878662, acc 0.3799999952316284\n",
      "Epoch 7, iter 14, loss 2.0694775581359863, acc 0.5\n",
      "Epoch 7, iter 15, loss 2.0756499767303467, acc 0.38999998569488525\n",
      "Epoch 7, iter 16, loss 2.0978763103485107, acc 0.4099999964237213\n",
      "Epoch 7, iter 17, loss 2.15336537361145, acc 0.33000001311302185\n",
      "Epoch 7, iter 18, loss 2.1453516483306885, acc 0.36000001430511475\n",
      "Epoch 7, iter 19, loss 2.1051485538482666, acc 0.38999998569488525\n",
      "Epoch 7, iter 20, loss 2.089111566543579, acc 0.4000000059604645\n",
      "Epoch 7, iter 21, loss 2.081433057785034, acc 0.38999998569488525\n",
      "Epoch 7, iter 22, loss 2.1246585845947266, acc 0.38999998569488525\n",
      "Epoch 7, iter 23, loss 2.096045732498169, acc 0.3700000047683716\n",
      "Epoch 7, iter 24, loss 2.150099515914917, acc 0.30000001192092896\n",
      "Epoch 7, iter 25, loss 2.144629716873169, acc 0.3799999952316284\n",
      "Epoch 7, iter 26, loss 2.141639471054077, acc 0.3400000035762787\n",
      "Epoch 7, iter 27, loss 2.123758316040039, acc 0.4300000071525574\n",
      "Epoch 7, iter 28, loss 2.08359432220459, acc 0.4399999976158142\n",
      "Epoch 7, iter 29, loss 2.1317505836486816, acc 0.3799999952316284\n",
      "Epoch 7, iter 30, loss 2.134815216064453, acc 0.36000001430511475\n",
      "Epoch 7, iter 31, loss 2.1962547302246094, acc 0.30000001192092896\n",
      "Epoch 7, iter 32, loss 2.1253273487091064, acc 0.36000001430511475\n",
      "Epoch 7, iter 33, loss 2.153388261795044, acc 0.3700000047683716\n",
      "Epoch 7, iter 34, loss 2.0966930389404297, acc 0.4099999964237213\n",
      "Epoch 7, iter 35, loss 2.1325650215148926, acc 0.3499999940395355\n",
      "Epoch 7, iter 36, loss 2.1165103912353516, acc 0.38999998569488525\n",
      "Epoch 7, iter 37, loss 2.162834882736206, acc 0.3499999940395355\n",
      "Epoch 7, iter 38, loss 2.1497116088867188, acc 0.3799999952316284\n",
      "Epoch 7, iter 39, loss 2.0946357250213623, acc 0.41999998688697815\n",
      "Epoch 7, iter 40, loss 2.0723743438720703, acc 0.4000000059604645\n",
      "Epoch 7, iter 41, loss 2.1675500869750977, acc 0.25999999046325684\n",
      "Epoch 7, iter 42, loss 2.1265981197357178, acc 0.3700000047683716\n",
      "Epoch 7, iter 43, loss 2.0604536533355713, acc 0.46000000834465027\n",
      "Epoch 7, iter 44, loss 2.0816097259521484, acc 0.3700000047683716\n",
      "Epoch 7, iter 45, loss 2.136429786682129, acc 0.33000001311302185\n",
      "Epoch 7, iter 46, loss 2.1380302906036377, acc 0.38999998569488525\n",
      "Epoch 7, iter 47, loss 2.165496349334717, acc 0.30000001192092896\n",
      "Epoch 7, iter 48, loss 2.0946898460388184, acc 0.38999998569488525\n",
      "Epoch 7, iter 49, loss 2.117828369140625, acc 0.36000001430511475\n",
      "Epoch 7, iter 50, loss 2.1612424850463867, acc 0.2800000011920929\n",
      "Epoch 7, iter 51, loss 2.101928472518921, acc 0.4000000059604645\n",
      "Epoch 7, iter 52, loss 2.15407657623291, acc 0.3400000035762787\n",
      "Epoch 7, iter 53, loss 2.114497184753418, acc 0.4099999964237213\n",
      "Epoch 7, iter 54, loss 2.1177730560302734, acc 0.38999998569488525\n",
      "Epoch 7, iter 55, loss 2.2123191356658936, acc 0.2800000011920929\n",
      "Epoch 7, iter 56, loss 2.1101255416870117, acc 0.4300000071525574\n",
      "Epoch 7, iter 57, loss 2.1846864223480225, acc 0.30000001192092896\n",
      "Epoch 7, iter 58, loss 2.146918296813965, acc 0.3400000035762787\n",
      "Epoch 7, iter 59, loss 2.1184587478637695, acc 0.4099999964237213\n",
      "Epoch 7, iter 60, loss 2.124732732772827, acc 0.41999998688697815\n",
      "Epoch 7, iter 61, loss 2.1182351112365723, acc 0.3499999940395355\n",
      "Epoch 7, iter 62, loss 2.1297245025634766, acc 0.3499999940395355\n",
      "Epoch 7, iter 63, loss 2.163830041885376, acc 0.3799999952316284\n",
      "Epoch 7, iter 64, loss 2.107281446456909, acc 0.38999998569488525\n",
      "Epoch 7, iter 65, loss 2.121501922607422, acc 0.4300000071525574\n",
      "Epoch 7, iter 66, loss 2.1072511672973633, acc 0.4300000071525574\n",
      "Epoch 7, iter 67, loss 2.144625425338745, acc 0.38999998569488525\n",
      "Epoch 7, iter 68, loss 2.0964202880859375, acc 0.3799999952316284\n",
      "Epoch 7, iter 69, loss 2.146608591079712, acc 0.3499999940395355\n",
      "Epoch 7, iter 70, loss 2.1323845386505127, acc 0.4000000059604645\n",
      "Epoch 7, iter 71, loss 2.1370363235473633, acc 0.4000000059604645\n",
      "Epoch 7, iter 72, loss 2.1198205947875977, acc 0.33000001311302185\n",
      "Epoch 7, iter 73, loss 2.103602647781372, acc 0.4000000059604645\n",
      "Epoch 7, iter 74, loss 2.1310513019561768, acc 0.3199999928474426\n",
      "Epoch 7, iter 75, loss 2.1228644847869873, acc 0.3499999940395355\n",
      "Epoch 7, iter 76, loss 2.1318557262420654, acc 0.3199999928474426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 77, loss 2.1559202671051025, acc 0.3700000047683716\n",
      "Epoch 7, iter 78, loss 2.136976480484009, acc 0.4000000059604645\n",
      "Epoch 7, iter 79, loss 2.1264522075653076, acc 0.4000000059604645\n",
      "Epoch 7, iter 80, loss 2.119929313659668, acc 0.30000001192092896\n",
      "Epoch 7, iter 81, loss 2.1595234870910645, acc 0.3400000035762787\n",
      "Epoch 7, iter 82, loss 2.165825128555298, acc 0.33000001311302185\n",
      "Epoch 7, iter 83, loss 2.0891871452331543, acc 0.4099999964237213\n",
      "Epoch 7, iter 84, loss 2.1326444149017334, acc 0.36000001430511475\n",
      "Epoch 7, iter 85, loss 2.1610779762268066, acc 0.3100000023841858\n",
      "Epoch 7, iter 86, loss 2.117940664291382, acc 0.4000000059604645\n",
      "Epoch 7, iter 87, loss 2.1386539936065674, acc 0.36000001430511475\n",
      "Epoch 7, iter 88, loss 2.082707643508911, acc 0.4300000071525574\n",
      "Epoch 7, iter 89, loss 2.1284401416778564, acc 0.4000000059604645\n",
      "Epoch 7, iter 90, loss 2.1182141304016113, acc 0.3799999952316284\n",
      "Epoch 7, iter 91, loss 2.118511438369751, acc 0.3700000047683716\n",
      "Epoch 7, iter 92, loss 2.175055980682373, acc 0.30000001192092896\n",
      "Epoch 7, iter 93, loss 2.076395034790039, acc 0.4399999976158142\n",
      "Epoch 7, iter 94, loss 2.1241257190704346, acc 0.3700000047683716\n",
      "Epoch 7, iter 95, loss 2.10646915435791, acc 0.4099999964237213\n",
      "Epoch 7, iter 96, loss 2.159471035003662, acc 0.3499999940395355\n",
      "Epoch 7, iter 97, loss 2.1376888751983643, acc 0.3199999928474426\n",
      "Epoch 7, iter 98, loss 2.1368885040283203, acc 0.3799999952316284\n",
      "Epoch 7, iter 99, loss 2.1274147033691406, acc 0.3799999952316284\n",
      "Epoch 7, iter 100, loss 2.111034393310547, acc 0.4300000071525574\n",
      "Epoch 7, iter 101, loss 2.105682611465454, acc 0.36000001430511475\n",
      "Epoch 7, iter 102, loss 2.1244566440582275, acc 0.4099999964237213\n",
      "Epoch 7, iter 103, loss 2.094160556793213, acc 0.41999998688697815\n",
      "Epoch 7, iter 104, loss 2.156512498855591, acc 0.36000001430511475\n",
      "Epoch 7, iter 105, loss 2.044121503829956, acc 0.4300000071525574\n",
      "Epoch 7, iter 106, loss 2.0956249237060547, acc 0.4099999964237213\n",
      "Epoch 7, iter 107, loss 2.1029555797576904, acc 0.38999998569488525\n",
      "Epoch 7, iter 108, loss 2.1457860469818115, acc 0.36000001430511475\n",
      "Epoch 7, iter 109, loss 2.106329917907715, acc 0.3799999952316284\n",
      "Epoch 7, iter 110, loss 2.159843921661377, acc 0.25999999046325684\n",
      "Epoch 7, iter 111, loss 2.1133904457092285, acc 0.4099999964237213\n",
      "Epoch 7, iter 112, loss 2.1200780868530273, acc 0.36000001430511475\n",
      "Epoch 7, iter 113, loss 2.075272798538208, acc 0.4099999964237213\n",
      "Epoch 7, iter 114, loss 2.0778770446777344, acc 0.41999998688697815\n",
      "Epoch 7, iter 115, loss 2.107213020324707, acc 0.36000001430511475\n",
      "Epoch 7, iter 116, loss 2.1052539348602295, acc 0.3100000023841858\n",
      "Epoch 7, iter 117, loss 2.1318776607513428, acc 0.4000000059604645\n",
      "Epoch 7, iter 118, loss 2.1251440048217773, acc 0.33000001311302185\n",
      "Epoch 7, iter 119, loss 2.1307499408721924, acc 0.38999998569488525\n",
      "Epoch 7, iter 120, loss 2.127932071685791, acc 0.3799999952316284\n",
      "Epoch 7, iter 121, loss 2.152951955795288, acc 0.3700000047683716\n",
      "Epoch 7, iter 122, loss 2.1033687591552734, acc 0.4699999988079071\n",
      "Epoch 7, iter 123, loss 2.157991886138916, acc 0.2800000011920929\n",
      "Epoch 7, iter 124, loss 2.080166816711426, acc 0.4300000071525574\n",
      "Epoch 7, iter 125, loss 2.13466739654541, acc 0.38999998569488525\n",
      "Epoch 7, iter 126, loss 2.1041932106018066, acc 0.3700000047683716\n",
      "Epoch 7, iter 127, loss 2.1267812252044678, acc 0.38999998569488525\n",
      "Epoch 7, iter 128, loss 2.1317298412323, acc 0.4000000059604645\n",
      "Epoch 7, iter 129, loss 2.1486809253692627, acc 0.36000001430511475\n",
      "Epoch 7, iter 130, loss 2.159022808074951, acc 0.30000001192092896\n",
      "Epoch 7, iter 131, loss 2.191443920135498, acc 0.3400000035762787\n",
      "Epoch 7, iter 132, loss 2.139932155609131, acc 0.3799999952316284\n",
      "Epoch 7, iter 133, loss 2.1046886444091797, acc 0.4000000059604645\n",
      "Epoch 7, iter 134, loss 2.1525402069091797, acc 0.3499999940395355\n",
      "Epoch 7, iter 135, loss 2.145843029022217, acc 0.36000001430511475\n",
      "Epoch 7, iter 136, loss 2.0798122882843018, acc 0.4399999976158142\n",
      "Epoch 7, iter 137, loss 2.1096527576446533, acc 0.36000001430511475\n",
      "Epoch 7, iter 138, loss 2.115668535232544, acc 0.36000001430511475\n",
      "Epoch 7, iter 139, loss 2.135559558868408, acc 0.3700000047683716\n",
      "Epoch 7, iter 140, loss 2.143545627593994, acc 0.33000001311302185\n",
      "Epoch 7, iter 141, loss 2.1140079498291016, acc 0.4000000059604645\n",
      "Epoch 7, iter 142, loss 2.128614664077759, acc 0.4099999964237213\n",
      "Epoch 7, iter 143, loss 2.126335859298706, acc 0.38999998569488525\n",
      "Epoch 7, iter 144, loss 2.1508471965789795, acc 0.3400000035762787\n",
      "Epoch 7, iter 145, loss 2.1044318675994873, acc 0.4099999964237213\n",
      "Epoch 7, iter 146, loss 2.1278858184814453, acc 0.3400000035762787\n",
      "Epoch 7, iter 147, loss 2.1227915287017822, acc 0.38999998569488525\n",
      "Epoch 7, iter 148, loss 2.0938215255737305, acc 0.3700000047683716\n",
      "Epoch 7, iter 149, loss 2.0740134716033936, acc 0.41999998688697815\n",
      "Epoch 7, iter 150, loss 2.1320950984954834, acc 0.3700000047683716\n",
      "Epoch 7, iter 151, loss 2.0166661739349365, acc 0.47999998927116394\n",
      "Epoch 7, iter 152, loss 2.104336738586426, acc 0.4000000059604645\n",
      "Epoch 7, iter 153, loss 2.1219658851623535, acc 0.3700000047683716\n",
      "Epoch 7, iter 154, loss 2.1368045806884766, acc 0.36000001430511475\n",
      "Epoch 7, iter 155, loss 2.1292967796325684, acc 0.4099999964237213\n",
      "Epoch 7, iter 156, loss 2.135175943374634, acc 0.3400000035762787\n",
      "Epoch 7, iter 157, loss 2.164658308029175, acc 0.36000001430511475\n",
      "Epoch 7, iter 158, loss 2.1332826614379883, acc 0.3799999952316284\n",
      "Epoch 7, iter 159, loss 2.1174418926239014, acc 0.3799999952316284\n",
      "Epoch 7, iter 160, loss 2.143547773361206, acc 0.3400000035762787\n",
      "Epoch 7, iter 161, loss 2.101485013961792, acc 0.3799999952316284\n",
      "Epoch 7, iter 162, loss 2.050610303878784, acc 0.4099999964237213\n",
      "Epoch 7, iter 163, loss 2.1487865447998047, acc 0.3400000035762787\n",
      "Epoch 7, iter 164, loss 2.1497275829315186, acc 0.30000001192092896\n",
      "Epoch 7, iter 165, loss 2.1669352054595947, acc 0.33000001311302185\n",
      "Epoch 7, iter 166, loss 2.1085925102233887, acc 0.41999998688697815\n",
      "Epoch 7, iter 167, loss 2.152215003967285, acc 0.28999999165534973\n",
      "Epoch 7, iter 168, loss 2.108797788619995, acc 0.3700000047683716\n",
      "Epoch 7, iter 169, loss 2.0696299076080322, acc 0.38999998569488525\n",
      "Epoch 7, iter 170, loss 2.1312007904052734, acc 0.30000001192092896\n",
      "Epoch 7, iter 171, loss 2.11200213432312, acc 0.38999998569488525\n",
      "Epoch 7, iter 172, loss 2.1507954597473145, acc 0.3499999940395355\n",
      "Epoch 7, iter 173, loss 2.156153917312622, acc 0.3100000023841858\n",
      "Epoch 7, iter 174, loss 2.1046223640441895, acc 0.33000001311302185\n",
      "Epoch 7, iter 175, loss 2.099637508392334, acc 0.4000000059604645\n",
      "Epoch 7, iter 176, loss 2.1562352180480957, acc 0.30000001192092896\n",
      "Epoch 7, iter 177, loss 2.1271800994873047, acc 0.3700000047683716\n",
      "Epoch 7, iter 178, loss 2.116145610809326, acc 0.38999998569488525\n",
      "Epoch 7, iter 179, loss 2.135611057281494, acc 0.3100000023841858\n",
      "Epoch 7, iter 180, loss 2.172386884689331, acc 0.33000001311302185\n",
      "Epoch 7, iter 181, loss 2.0573813915252686, acc 0.41999998688697815\n",
      "Epoch 7, iter 182, loss 2.1539270877838135, acc 0.3400000035762787\n",
      "Epoch 7, iter 183, loss 2.1341025829315186, acc 0.3499999940395355\n",
      "Epoch 7, iter 184, loss 2.1238179206848145, acc 0.33000001311302185\n",
      "Epoch 7, iter 185, loss 2.1145427227020264, acc 0.36000001430511475\n",
      "Epoch 7, iter 186, loss 2.1191916465759277, acc 0.3799999952316284\n",
      "Epoch 7, iter 187, loss 2.1364543437957764, acc 0.3700000047683716\n",
      "Epoch 7, iter 188, loss 2.161884069442749, acc 0.3100000023841858\n",
      "Epoch 7, iter 189, loss 2.193314552307129, acc 0.30000001192092896\n",
      "Epoch 7, iter 190, loss 2.109076499938965, acc 0.4300000071525574\n",
      "Epoch 7, iter 191, loss 2.138507604598999, acc 0.3499999940395355\n",
      "Epoch 7, iter 192, loss 2.1284291744232178, acc 0.4000000059604645\n",
      "Epoch 7, iter 193, loss 2.110227108001709, acc 0.3499999940395355\n",
      "Epoch 7, iter 194, loss 2.123459577560425, acc 0.3700000047683716\n",
      "Epoch 7, iter 195, loss 2.076653242111206, acc 0.4300000071525574\n",
      "Epoch 7, iter 196, loss 2.166314125061035, acc 0.3199999928474426\n",
      "Epoch 7, iter 197, loss 2.146466016769409, acc 0.3199999928474426\n",
      "Epoch 7, iter 198, loss 2.0626025199890137, acc 0.49000000953674316\n",
      "Epoch 7, iter 199, loss 2.155195474624634, acc 0.36000001430511475\n",
      "Epoch 7, iter 200, loss 2.157135009765625, acc 0.3400000035762787\n",
      "Epoch 7, iter 201, loss 2.116865396499634, acc 0.36000001430511475\n",
      "Epoch 7, iter 202, loss 2.11279559135437, acc 0.3100000023841858\n",
      "Epoch 7, iter 203, loss 2.1304585933685303, acc 0.3499999940395355\n",
      "Epoch 7, iter 204, loss 2.0974395275115967, acc 0.4300000071525574\n",
      "Epoch 7, iter 205, loss 2.056114673614502, acc 0.4300000071525574\n",
      "Epoch 7, iter 206, loss 2.141627550125122, acc 0.3499999940395355\n",
      "Epoch 7, iter 207, loss 2.1504411697387695, acc 0.33000001311302185\n",
      "Epoch 7, iter 208, loss 2.169252634048462, acc 0.3499999940395355\n",
      "Epoch 7, iter 209, loss 2.1716387271881104, acc 0.3100000023841858\n",
      "Epoch 7, iter 210, loss 2.1922521591186523, acc 0.2800000011920929\n",
      "Epoch 7, iter 211, loss 2.103677749633789, acc 0.4000000059604645\n",
      "Epoch 7, iter 212, loss 2.1580851078033447, acc 0.3400000035762787\n",
      "Epoch 7, iter 213, loss 2.147780656814575, acc 0.3499999940395355\n",
      "Epoch 7, iter 214, loss 2.1621129512786865, acc 0.33000001311302185\n",
      "Epoch 7, iter 215, loss 2.135420322418213, acc 0.3100000023841858\n",
      "Epoch 7, iter 216, loss 2.164454221725464, acc 0.33000001311302185\n",
      "Epoch 7, iter 217, loss 2.107386827468872, acc 0.4099999964237213\n",
      "Epoch 7, iter 218, loss 2.1964690685272217, acc 0.3100000023841858\n",
      "Epoch 7, iter 219, loss 2.134526014328003, acc 0.3400000035762787\n",
      "Epoch 7, iter 220, loss 2.085151195526123, acc 0.41999998688697815\n",
      "Epoch 7, iter 221, loss 2.1104397773742676, acc 0.3799999952316284\n",
      "Epoch 7, iter 222, loss 2.1328248977661133, acc 0.38999998569488525\n",
      "Epoch 7, iter 223, loss 2.0918214321136475, acc 0.4300000071525574\n",
      "Epoch 7, iter 224, loss 2.149867534637451, acc 0.36000001430511475\n",
      "Epoch 7, iter 225, loss 2.114773750305176, acc 0.36000001430511475\n",
      "Epoch 7, iter 226, loss 2.1101372241973877, acc 0.38999998569488525\n",
      "Epoch 7, iter 227, loss 2.1257545948028564, acc 0.3799999952316284\n",
      "Epoch 7, iter 228, loss 2.1400251388549805, acc 0.3199999928474426\n",
      "Epoch 7, iter 229, loss 2.110243320465088, acc 0.41999998688697815\n",
      "Epoch 7, iter 230, loss 2.1122281551361084, acc 0.38999998569488525\n",
      "Epoch 7, iter 231, loss 2.091991901397705, acc 0.44999998807907104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 232, loss 2.1508536338806152, acc 0.3199999928474426\n",
      "Epoch 7, iter 233, loss 2.078840732574463, acc 0.3799999952316284\n",
      "Epoch 7, iter 234, loss 2.0713775157928467, acc 0.4699999988079071\n",
      "Epoch 7, iter 235, loss 2.1077165603637695, acc 0.41999998688697815\n",
      "Epoch 7, iter 236, loss 2.1329636573791504, acc 0.3499999940395355\n",
      "Epoch 7, iter 237, loss 2.163012742996216, acc 0.30000001192092896\n",
      "Epoch 7, iter 238, loss 2.1151275634765625, acc 0.3799999952316284\n",
      "Epoch 7, iter 239, loss 2.146253824234009, acc 0.3100000023841858\n",
      "Epoch 7, iter 240, loss 2.1429903507232666, acc 0.3799999952316284\n",
      "Epoch 7, iter 241, loss 2.129868745803833, acc 0.36000001430511475\n",
      "Epoch 7, iter 242, loss 2.146243095397949, acc 0.38999998569488525\n",
      "Epoch 7, iter 243, loss 2.193230152130127, acc 0.25999999046325684\n",
      "Epoch 7, iter 244, loss 2.0931806564331055, acc 0.46000000834465027\n",
      "Epoch 7, iter 245, loss 2.0896944999694824, acc 0.3799999952316284\n",
      "Epoch 7, iter 246, loss 2.1987547874450684, acc 0.27000001072883606\n",
      "Epoch 7, iter 247, loss 2.1028337478637695, acc 0.38999998569488525\n",
      "Epoch 7, iter 248, loss 2.153160810470581, acc 0.30000001192092896\n",
      "Epoch 7, iter 249, loss 2.1708810329437256, acc 0.30000001192092896\n",
      "Epoch 7, iter 250, loss 2.0840609073638916, acc 0.41999998688697815\n",
      "Epoch 7, iter 251, loss 2.1531167030334473, acc 0.33000001311302185\n",
      "Epoch 7, iter 252, loss 2.125782012939453, acc 0.3400000035762787\n",
      "Epoch 7, iter 253, loss 2.1866583824157715, acc 0.27000001072883606\n",
      "Epoch 7, iter 254, loss 2.1526827812194824, acc 0.2800000011920929\n",
      "Epoch 7, iter 255, loss 2.1440482139587402, acc 0.33000001311302185\n",
      "Epoch 7, iter 256, loss 2.106948137283325, acc 0.4000000059604645\n",
      "Epoch 7, iter 257, loss 2.138801097869873, acc 0.3400000035762787\n",
      "Epoch 7, iter 258, loss 2.1240477561950684, acc 0.36000001430511475\n",
      "Epoch 7, iter 259, loss 2.151278018951416, acc 0.36000001430511475\n",
      "Epoch 7, iter 260, loss 2.129768133163452, acc 0.38999998569488525\n",
      "Epoch 7, iter 261, loss 2.0851480960845947, acc 0.4000000059604645\n",
      "Epoch 7, iter 262, loss 2.1652443408966064, acc 0.33000001311302185\n",
      "Epoch 7, iter 263, loss 2.0693199634552, acc 0.46000000834465027\n",
      "Epoch 7, iter 264, loss 2.136528491973877, acc 0.28999999165534973\n",
      "Epoch 7, iter 265, loss 2.159707546234131, acc 0.3700000047683716\n",
      "Epoch 7, iter 266, loss 2.0981996059417725, acc 0.3700000047683716\n",
      "Epoch 7, iter 267, loss 2.093914031982422, acc 0.44999998807907104\n",
      "Epoch 7, iter 268, loss 2.1295108795166016, acc 0.3199999928474426\n",
      "Epoch 7, iter 269, loss 2.126330614089966, acc 0.3499999940395355\n",
      "Epoch 7, iter 270, loss 2.129075050354004, acc 0.3499999940395355\n",
      "Epoch 7, iter 271, loss 2.1564688682556152, acc 0.3100000023841858\n",
      "Epoch 7, iter 272, loss 2.1578543186187744, acc 0.33000001311302185\n",
      "Epoch 7, iter 273, loss 2.1553049087524414, acc 0.3499999940395355\n",
      "Epoch 7, iter 274, loss 2.1405909061431885, acc 0.33000001311302185\n",
      "Epoch 7, iter 275, loss 2.18235445022583, acc 0.3199999928474426\n",
      "Epoch 7, iter 276, loss 2.1501076221466064, acc 0.3700000047683716\n",
      "Epoch 7, iter 277, loss 2.1080589294433594, acc 0.4300000071525574\n",
      "Epoch 7, iter 278, loss 2.103984832763672, acc 0.36000001430511475\n",
      "Epoch 7, iter 279, loss 2.099637269973755, acc 0.44999998807907104\n",
      "Epoch 7, iter 280, loss 2.103801965713501, acc 0.3700000047683716\n",
      "Epoch 7, iter 281, loss 2.109032392501831, acc 0.44999998807907104\n",
      "Epoch 7, iter 282, loss 2.169142723083496, acc 0.3400000035762787\n",
      "Epoch 7, iter 283, loss 2.105551242828369, acc 0.4099999964237213\n",
      "Epoch 7, iter 284, loss 2.0785672664642334, acc 0.4000000059604645\n",
      "Epoch 7, iter 285, loss 2.099421739578247, acc 0.3700000047683716\n",
      "Epoch 7, iter 286, loss 2.0954549312591553, acc 0.4099999964237213\n",
      "Epoch 7, iter 287, loss 2.139106035232544, acc 0.3499999940395355\n",
      "Epoch 7, iter 288, loss 2.0845448970794678, acc 0.38999998569488525\n",
      "Epoch 7, iter 289, loss 2.1563966274261475, acc 0.3400000035762787\n",
      "Epoch 7, iter 290, loss 2.090534210205078, acc 0.4099999964237213\n",
      "Epoch 7, iter 291, loss 2.1163742542266846, acc 0.3400000035762787\n",
      "Epoch 7, iter 292, loss 2.0964932441711426, acc 0.3799999952316284\n",
      "Epoch 7, iter 293, loss 2.116279363632202, acc 0.4000000059604645\n",
      "Epoch 7, iter 294, loss 2.1609954833984375, acc 0.3199999928474426\n",
      "Epoch 7, iter 295, loss 2.131929397583008, acc 0.36000001430511475\n",
      "Epoch 7, iter 296, loss 2.0910844802856445, acc 0.4099999964237213\n",
      "Epoch 7, iter 297, loss 2.1585042476654053, acc 0.30000001192092896\n",
      "Epoch 7, iter 298, loss 2.094184160232544, acc 0.4000000059604645\n",
      "Epoch 7, iter 299, loss 2.185096025466919, acc 0.25\n",
      "Epoch 7, iter 300, loss 2.1506712436676025, acc 0.3199999928474426\n",
      "Epoch 7, iter 301, loss 2.137108087539673, acc 0.33000001311302185\n",
      "Epoch 7, iter 302, loss 2.095560073852539, acc 0.4399999976158142\n",
      "Epoch 7, iter 303, loss 2.115527391433716, acc 0.4300000071525574\n",
      "Epoch 7, iter 304, loss 2.1757330894470215, acc 0.25999999046325684\n",
      "Epoch 7, iter 305, loss 2.1980597972869873, acc 0.2800000011920929\n",
      "Epoch 7, iter 306, loss 2.068100929260254, acc 0.4399999976158142\n",
      "Epoch 7, iter 307, loss 2.095005512237549, acc 0.4300000071525574\n",
      "Epoch 7, iter 308, loss 2.1666321754455566, acc 0.36000001430511475\n",
      "Epoch 7, iter 309, loss 2.1123464107513428, acc 0.3799999952316284\n",
      "Epoch 7, iter 310, loss 2.151376247406006, acc 0.30000001192092896\n",
      "Epoch 7, iter 311, loss 2.1096842288970947, acc 0.3700000047683716\n",
      "Epoch 7, iter 312, loss 2.106396198272705, acc 0.41999998688697815\n",
      "Epoch 7, iter 313, loss 2.1912293434143066, acc 0.28999999165534973\n",
      "Epoch 7, iter 314, loss 2.081408739089966, acc 0.41999998688697815\n",
      "Epoch 7, iter 315, loss 2.1207189559936523, acc 0.4000000059604645\n",
      "Epoch 7, iter 316, loss 2.1527099609375, acc 0.30000001192092896\n",
      "Epoch 7, iter 317, loss 2.1308045387268066, acc 0.4000000059604645\n",
      "Epoch 7, iter 318, loss 2.1052393913269043, acc 0.3499999940395355\n",
      "Epoch 7, iter 319, loss 2.119041919708252, acc 0.3700000047683716\n",
      "Epoch 7, iter 320, loss 2.1969993114471436, acc 0.3100000023841858\n",
      "Epoch 7, iter 321, loss 2.140901803970337, acc 0.36000001430511475\n",
      "Epoch 7, iter 322, loss 2.123588800430298, acc 0.3400000035762787\n",
      "Epoch 7, iter 323, loss 2.1096370220184326, acc 0.4000000059604645\n",
      "Epoch 7, iter 324, loss 2.0353829860687256, acc 0.47999998927116394\n",
      "Epoch 7, iter 325, loss 2.153456687927246, acc 0.3799999952316284\n",
      "Epoch 7, iter 326, loss 2.096102476119995, acc 0.38999998569488525\n",
      "Epoch 7, iter 327, loss 2.1536927223205566, acc 0.28999999165534973\n",
      "Epoch 7, iter 328, loss 2.087024450302124, acc 0.4099999964237213\n",
      "Epoch 7, iter 329, loss 2.101968288421631, acc 0.3799999952316284\n",
      "Epoch 7, iter 330, loss 2.1408138275146484, acc 0.3400000035762787\n",
      "Epoch 7, iter 331, loss 2.128525733947754, acc 0.3199999928474426\n",
      "Epoch 7, iter 332, loss 2.1373958587646484, acc 0.3799999952316284\n",
      "Epoch 7, iter 333, loss 2.1239802837371826, acc 0.36000001430511475\n",
      "Epoch 7, iter 334, loss 2.160353899002075, acc 0.3799999952316284\n",
      "Epoch 7, iter 335, loss 2.055041551589966, acc 0.41999998688697815\n",
      "Epoch 7, iter 336, loss 2.1112821102142334, acc 0.4099999964237213\n",
      "Epoch 7, iter 337, loss 2.1157259941101074, acc 0.3799999952316284\n",
      "Epoch 7, iter 338, loss 2.1149826049804688, acc 0.46000000834465027\n",
      "Epoch 7, iter 339, loss 2.1285219192504883, acc 0.38999998569488525\n",
      "Epoch 7, iter 340, loss 2.1190690994262695, acc 0.41999998688697815\n",
      "Epoch 7, iter 341, loss 2.1001393795013428, acc 0.38999998569488525\n",
      "Epoch 7, iter 342, loss 2.109769582748413, acc 0.4099999964237213\n",
      "Epoch 7, iter 343, loss 2.1684279441833496, acc 0.3499999940395355\n",
      "Epoch 7, iter 344, loss 2.0838706493377686, acc 0.4399999976158142\n",
      "Epoch 7, iter 345, loss 2.1615524291992188, acc 0.3199999928474426\n",
      "Epoch 7, iter 346, loss 2.0607407093048096, acc 0.4300000071525574\n",
      "Epoch 7, iter 347, loss 2.184046983718872, acc 0.30000001192092896\n",
      "Epoch 7, iter 348, loss 2.0688445568084717, acc 0.4699999988079071\n",
      "Epoch 7, iter 349, loss 2.0662827491760254, acc 0.4399999976158142\n",
      "Epoch 7, iter 350, loss 2.1234188079833984, acc 0.36000001430511475\n",
      "Epoch 7, iter 351, loss 2.112002372741699, acc 0.3400000035762787\n",
      "Epoch 7, iter 352, loss 2.1323277950286865, acc 0.3400000035762787\n",
      "Epoch 7, iter 353, loss 2.135948419570923, acc 0.38999998569488525\n",
      "Epoch 7, iter 354, loss 2.0820038318634033, acc 0.41999998688697815\n",
      "Epoch 7, iter 355, loss 2.1319451332092285, acc 0.4099999964237213\n",
      "Epoch 7, iter 356, loss 2.126706123352051, acc 0.3499999940395355\n",
      "Epoch 7, iter 357, loss 2.135626792907715, acc 0.3400000035762787\n",
      "Epoch 7, iter 358, loss 2.189664363861084, acc 0.27000001072883606\n",
      "Epoch 7, iter 359, loss 2.130485773086548, acc 0.3799999952316284\n",
      "Epoch 7, iter 360, loss 2.1334280967712402, acc 0.3400000035762787\n",
      "Epoch 7, iter 361, loss 2.126980781555176, acc 0.3199999928474426\n",
      "Epoch 7, iter 362, loss 2.1755950450897217, acc 0.30000001192092896\n",
      "Epoch 7, iter 363, loss 2.105323076248169, acc 0.4399999976158142\n",
      "Epoch 7, iter 364, loss 2.1194167137145996, acc 0.3100000023841858\n",
      "Epoch 7, iter 365, loss 2.099571466445923, acc 0.4099999964237213\n",
      "Epoch 7, iter 366, loss 2.071869373321533, acc 0.3700000047683716\n",
      "Epoch 7, iter 367, loss 2.093010663986206, acc 0.3799999952316284\n",
      "Epoch 7, iter 368, loss 2.0931785106658936, acc 0.41999998688697815\n",
      "Epoch 7, iter 369, loss 2.1081008911132812, acc 0.3799999952316284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iter 370, loss 2.089815616607666, acc 0.38999998569488525\n",
      "Epoch 7, iter 371, loss 2.0779616832733154, acc 0.4000000059604645\n",
      "Epoch 7, iter 372, loss 2.1144933700561523, acc 0.33000001311302185\n",
      "Epoch 7, iter 373, loss 2.1393916606903076, acc 0.3100000023841858\n",
      "Epoch 7, iter 374, loss 2.1299638748168945, acc 0.36000001430511475\n",
      "Epoch 7, iter 375, loss 2.1175191402435303, acc 0.4300000071525574\n",
      "Epoch 7, iter 376, loss 2.1349761486053467, acc 0.36000001430511475\n",
      "Epoch 7, iter 377, loss 2.066723346710205, acc 0.5\n",
      "Epoch 7, iter 378, loss 2.1024365425109863, acc 0.4000000059604645\n",
      "Epoch 7, iter 379, loss 2.1672511100769043, acc 0.3199999928474426\n",
      "Epoch 7, iter 380, loss 2.150636672973633, acc 0.30000001192092896\n",
      "Epoch 7, iter 381, loss 2.1394355297088623, acc 0.3700000047683716\n",
      "Epoch 7, iter 382, loss 2.0916659832000732, acc 0.38999998569488525\n",
      "Epoch 7, iter 383, loss 2.090860366821289, acc 0.3799999952316284\n",
      "Epoch 7, iter 384, loss 2.1425161361694336, acc 0.36000001430511475\n",
      "Epoch 7, iter 385, loss 2.118809461593628, acc 0.3700000047683716\n",
      "Epoch 7, iter 386, loss 2.1123480796813965, acc 0.38999998569488525\n",
      "Epoch 7, iter 387, loss 2.151552677154541, acc 0.36000001430511475\n",
      "Epoch 7, iter 388, loss 2.145665168762207, acc 0.3499999940395355\n",
      "Epoch 7, iter 389, loss 2.14228892326355, acc 0.33000001311302185\n",
      "Epoch 7, iter 390, loss 2.1984784603118896, acc 0.23000000417232513\n",
      "Epoch 7, iter 391, loss 2.1361825466156006, acc 0.36000001430511475\n",
      "Epoch 7, iter 392, loss 2.1541802883148193, acc 0.3199999928474426\n",
      "Epoch 7, iter 393, loss 2.1429126262664795, acc 0.3499999940395355\n",
      "Epoch 7, iter 394, loss 2.1090331077575684, acc 0.4000000059604645\n",
      "Epoch 7, iter 395, loss 2.0627191066741943, acc 0.4699999988079071\n",
      "Epoch 7, iter 396, loss 2.1384453773498535, acc 0.33000001311302185\n",
      "Epoch 7, iter 397, loss 2.1247060298919678, acc 0.3499999940395355\n",
      "Epoch 7, iter 398, loss 2.161224603652954, acc 0.3799999952316284\n",
      "Epoch 7, iter 399, loss 2.1280856132507324, acc 0.38999998569488525\n",
      "Epoch 7, iter 400, loss 2.080819606781006, acc 0.49000000953674316\n",
      "Epoch 7, iter 401, loss 2.1003570556640625, acc 0.4000000059604645\n",
      "Epoch 7, iter 402, loss 2.0975022315979004, acc 0.4399999976158142\n",
      "Epoch 7, iter 403, loss 2.1372787952423096, acc 0.4000000059604645\n",
      "Epoch 7, iter 404, loss 2.1463217735290527, acc 0.3499999940395355\n",
      "Epoch 7, iter 405, loss 2.1318721771240234, acc 0.41999998688697815\n",
      "Epoch 7, iter 406, loss 2.13376784324646, acc 0.33000001311302185\n",
      "Epoch 7, iter 407, loss 2.135998010635376, acc 0.33000001311302185\n",
      "Epoch 7, iter 408, loss 2.1602866649627686, acc 0.3400000035762787\n",
      "Epoch 7, iter 409, loss 2.1225504875183105, acc 0.4000000059604645\n",
      "Epoch 7, iter 410, loss 2.096789598464966, acc 0.4399999976158142\n",
      "Epoch 7, iter 411, loss 2.0858876705169678, acc 0.4099999964237213\n",
      "Epoch 7, iter 412, loss 2.108705520629883, acc 0.46000000834465027\n",
      "Epoch 7, iter 413, loss 2.1155097484588623, acc 0.41999998688697815\n",
      "Epoch 7, iter 414, loss 2.1232924461364746, acc 0.3400000035762787\n",
      "Epoch 7, iter 415, loss 2.1691722869873047, acc 0.3100000023841858\n",
      "Epoch 7, iter 416, loss 2.096299886703491, acc 0.4099999964237213\n",
      "Epoch 7, iter 417, loss 2.0883710384368896, acc 0.46000000834465027\n",
      "Epoch 7, iter 418, loss 2.118619441986084, acc 0.3400000035762787\n",
      "Epoch 7, iter 419, loss 2.0856270790100098, acc 0.4099999964237213\n",
      "Epoch 7, iter 420, loss 2.126281976699829, acc 0.36000001430511475\n",
      "Epoch 8, iter 1, loss 2.0920872688293457, acc 0.38999998569488525\n",
      "Epoch 8, iter 2, loss 2.1439294815063477, acc 0.4000000059604645\n",
      "Epoch 8, iter 3, loss 2.1086490154266357, acc 0.46000000834465027\n",
      "Epoch 8, iter 4, loss 2.168642520904541, acc 0.33000001311302185\n",
      "Epoch 8, iter 5, loss 2.1662137508392334, acc 0.27000001072883606\n",
      "Epoch 8, iter 6, loss 2.1494195461273193, acc 0.3199999928474426\n",
      "Epoch 8, iter 7, loss 2.134619951248169, acc 0.36000001430511475\n",
      "Epoch 8, iter 8, loss 2.1093740463256836, acc 0.4099999964237213\n",
      "Epoch 8, iter 9, loss 2.1499273777008057, acc 0.4099999964237213\n",
      "Epoch 8, iter 10, loss 2.1507883071899414, acc 0.38999998569488525\n",
      "Epoch 8, iter 11, loss 2.1544580459594727, acc 0.33000001311302185\n",
      "Epoch 8, iter 12, loss 2.146946668624878, acc 0.3199999928474426\n",
      "Epoch 8, iter 13, loss 2.1264896392822266, acc 0.36000001430511475\n",
      "Epoch 8, iter 14, loss 2.081371545791626, acc 0.4300000071525574\n",
      "Epoch 8, iter 15, loss 2.065808057785034, acc 0.4699999988079071\n",
      "Epoch 8, iter 16, loss 2.0990865230560303, acc 0.4099999964237213\n",
      "Epoch 8, iter 17, loss 2.1535747051239014, acc 0.30000001192092896\n",
      "Epoch 8, iter 18, loss 2.137010335922241, acc 0.36000001430511475\n",
      "Epoch 8, iter 19, loss 2.101088523864746, acc 0.33000001311302185\n",
      "Epoch 8, iter 20, loss 2.086871385574341, acc 0.4099999964237213\n",
      "Epoch 8, iter 21, loss 2.0703399181365967, acc 0.4399999976158142\n",
      "Epoch 8, iter 22, loss 2.123579502105713, acc 0.38999998569488525\n",
      "Epoch 8, iter 23, loss 2.086981773376465, acc 0.4300000071525574\n",
      "Epoch 8, iter 24, loss 2.1385583877563477, acc 0.3199999928474426\n",
      "Epoch 8, iter 25, loss 2.1387643814086914, acc 0.3700000047683716\n",
      "Epoch 8, iter 26, loss 2.1299026012420654, acc 0.3799999952316284\n",
      "Epoch 8, iter 27, loss 2.1156814098358154, acc 0.44999998807907104\n",
      "Epoch 8, iter 28, loss 2.0634026527404785, acc 0.5\n",
      "Epoch 8, iter 29, loss 2.128761053085327, acc 0.3799999952316284\n",
      "Epoch 8, iter 30, loss 2.128655433654785, acc 0.3700000047683716\n",
      "Epoch 8, iter 31, loss 2.1879138946533203, acc 0.3100000023841858\n",
      "Epoch 8, iter 32, loss 2.116576910018921, acc 0.38999998569488525\n",
      "Epoch 8, iter 33, loss 2.220500946044922, acc 0.28999999165534973\n",
      "Epoch 8, iter 34, loss 2.153982400894165, acc 0.3400000035762787\n",
      "Epoch 8, iter 35, loss 2.196927547454834, acc 0.25\n",
      "Epoch 8, iter 36, loss 2.160984992980957, acc 0.3499999940395355\n",
      "Epoch 8, iter 37, loss 2.2230710983276367, acc 0.23999999463558197\n",
      "Epoch 8, iter 38, loss 2.1848630905151367, acc 0.3700000047683716\n",
      "Epoch 8, iter 39, loss 2.1260831356048584, acc 0.3700000047683716\n",
      "Epoch 8, iter 40, loss 2.1334640979766846, acc 0.36000001430511475\n",
      "Epoch 8, iter 41, loss 2.213008165359497, acc 0.25999999046325684\n",
      "Epoch 8, iter 42, loss 2.1739025115966797, acc 0.3499999940395355\n",
      "Epoch 8, iter 43, loss 2.117027759552002, acc 0.3799999952316284\n",
      "Epoch 8, iter 44, loss 2.1315102577209473, acc 0.3400000035762787\n",
      "Epoch 8, iter 45, loss 2.1705803871154785, acc 0.3499999940395355\n",
      "Epoch 8, iter 46, loss 2.164963722229004, acc 0.38999998569488525\n",
      "Epoch 8, iter 47, loss 2.2033448219299316, acc 0.25999999046325684\n",
      "Epoch 8, iter 48, loss 2.129814863204956, acc 0.33000001311302185\n",
      "Epoch 8, iter 49, loss 2.1468465328216553, acc 0.33000001311302185\n",
      "Epoch 8, iter 50, loss 2.1866044998168945, acc 0.3100000023841858\n",
      "Epoch 8, iter 51, loss 2.119117498397827, acc 0.4000000059604645\n",
      "Epoch 8, iter 52, loss 2.1826465129852295, acc 0.3100000023841858\n",
      "Epoch 8, iter 53, loss 2.1276462078094482, acc 0.38999998569488525\n",
      "Epoch 8, iter 54, loss 2.1586928367614746, acc 0.3199999928474426\n",
      "Epoch 8, iter 55, loss 2.2412667274475098, acc 0.23000000417232513\n",
      "Epoch 8, iter 56, loss 2.154231071472168, acc 0.3499999940395355\n",
      "Epoch 8, iter 57, loss 2.1992454528808594, acc 0.33000001311302185\n",
      "Epoch 8, iter 58, loss 2.180396795272827, acc 0.3700000047683716\n",
      "Epoch 8, iter 59, loss 2.1409971714019775, acc 0.3799999952316284\n",
      "Epoch 8, iter 60, loss 2.1245288848876953, acc 0.41999998688697815\n",
      "Epoch 8, iter 61, loss 2.1211771965026855, acc 0.3700000047683716\n",
      "Epoch 8, iter 62, loss 2.1157429218292236, acc 0.41999998688697815\n",
      "Epoch 8, iter 63, loss 2.1513521671295166, acc 0.3700000047683716\n",
      "Epoch 8, iter 64, loss 2.0999021530151367, acc 0.3499999940395355\n",
      "Epoch 8, iter 65, loss 2.115901231765747, acc 0.44999998807907104\n",
      "Epoch 8, iter 66, loss 2.10854434967041, acc 0.33000001311302185\n",
      "Epoch 8, iter 67, loss 2.1429195404052734, acc 0.3100000023841858\n",
      "Epoch 8, iter 68, loss 2.0874457359313965, acc 0.44999998807907104\n",
      "Epoch 8, iter 69, loss 2.125453233718872, acc 0.3400000035762787\n",
      "Epoch 8, iter 70, loss 2.12368106842041, acc 0.4099999964237213\n",
      "Epoch 8, iter 71, loss 2.147406578063965, acc 0.3700000047683716\n",
      "Epoch 8, iter 72, loss 2.1142308712005615, acc 0.3400000035762787\n",
      "Epoch 8, iter 73, loss 2.0963525772094727, acc 0.41999998688697815\n",
      "Epoch 8, iter 74, loss 2.132530450820923, acc 0.3799999952316284\n",
      "Epoch 8, iter 75, loss 2.121516227722168, acc 0.3700000047683716\n",
      "Epoch 8, iter 76, loss 2.124047040939331, acc 0.3799999952316284\n",
      "Epoch 8, iter 77, loss 2.164097309112549, acc 0.3100000023841858\n",
      "Epoch 8, iter 78, loss 2.1247365474700928, acc 0.4099999964237213\n",
      "Epoch 8, iter 79, loss 2.1186299324035645, acc 0.3700000047683716\n",
      "Epoch 8, iter 80, loss 2.1108689308166504, acc 0.4000000059604645\n",
      "Epoch 8, iter 81, loss 2.15313458442688, acc 0.33000001311302185\n",
      "Epoch 8, iter 82, loss 2.1499452590942383, acc 0.28999999165534973\n",
      "Epoch 8, iter 83, loss 2.0782434940338135, acc 0.46000000834465027\n",
      "Epoch 8, iter 84, loss 2.1297385692596436, acc 0.38999998569488525\n",
      "Epoch 8, iter 85, loss 2.1673636436462402, acc 0.3100000023841858\n",
      "Epoch 8, iter 86, loss 2.113316535949707, acc 0.4000000059604645\n",
      "Epoch 8, iter 87, loss 2.1284544467926025, acc 0.41999998688697815\n",
      "Epoch 8, iter 88, loss 2.075876474380493, acc 0.44999998807907104\n",
      "Epoch 8, iter 89, loss 2.1304187774658203, acc 0.3799999952316284\n",
      "Epoch 8, iter 90, loss 2.1110949516296387, acc 0.38999998569488525\n",
      "Epoch 8, iter 91, loss 2.1025424003601074, acc 0.3700000047683716\n",
      "Epoch 8, iter 92, loss 2.1561527252197266, acc 0.38999998569488525\n",
      "Epoch 8, iter 93, loss 2.0644357204437256, acc 0.49000000953674316\n",
      "Epoch 8, iter 94, loss 2.12237811088562, acc 0.3400000035762787\n",
      "Epoch 8, iter 95, loss 2.0982165336608887, acc 0.4000000059604645\n",
      "Epoch 8, iter 96, loss 2.128783941268921, acc 0.38999998569488525\n",
      "Epoch 8, iter 97, loss 2.122189998626709, acc 0.3499999940395355\n",
      "Epoch 8, iter 98, loss 2.124547004699707, acc 0.3400000035762787\n",
      "Epoch 8, iter 99, loss 2.1133670806884766, acc 0.3799999952316284\n",
      "Epoch 8, iter 100, loss 2.100053310394287, acc 0.38999998569488525\n",
      "Epoch 8, iter 101, loss 2.0867083072662354, acc 0.4399999976158142\n",
      "Epoch 8, iter 102, loss 2.112086296081543, acc 0.3700000047683716\n",
      "Epoch 8, iter 103, loss 2.082108974456787, acc 0.47999998927116394\n",
      "Epoch 8, iter 104, loss 2.1397452354431152, acc 0.3799999952316284\n",
      "Epoch 8, iter 105, loss 2.035168170928955, acc 0.4399999976158142\n",
      "Epoch 8, iter 106, loss 2.091376543045044, acc 0.3799999952316284\n",
      "Epoch 8, iter 107, loss 2.0853586196899414, acc 0.4099999964237213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 108, loss 2.1456868648529053, acc 0.28999999165534973\n",
      "Epoch 8, iter 109, loss 2.0974130630493164, acc 0.4300000071525574\n",
      "Epoch 8, iter 110, loss 2.131593704223633, acc 0.3799999952316284\n",
      "Epoch 8, iter 111, loss 2.116467237472534, acc 0.3199999928474426\n",
      "Epoch 8, iter 112, loss 2.1051669120788574, acc 0.3499999940395355\n",
      "Epoch 8, iter 113, loss 2.0630970001220703, acc 0.5099999904632568\n",
      "Epoch 8, iter 114, loss 2.071505308151245, acc 0.3799999952316284\n",
      "Epoch 8, iter 115, loss 2.0957939624786377, acc 0.41999998688697815\n",
      "Epoch 8, iter 116, loss 2.0849616527557373, acc 0.4399999976158142\n",
      "Epoch 8, iter 117, loss 2.1195359230041504, acc 0.4099999964237213\n",
      "Epoch 8, iter 118, loss 2.1182186603546143, acc 0.3400000035762787\n",
      "Epoch 8, iter 119, loss 2.120176315307617, acc 0.38999998569488525\n",
      "Epoch 8, iter 120, loss 2.124610662460327, acc 0.3700000047683716\n",
      "Epoch 8, iter 121, loss 2.129406690597534, acc 0.4099999964237213\n",
      "Epoch 8, iter 122, loss 2.0998728275299072, acc 0.41999998688697815\n",
      "Epoch 8, iter 123, loss 2.1558330059051514, acc 0.3100000023841858\n",
      "Epoch 8, iter 124, loss 2.0572240352630615, acc 0.5\n",
      "Epoch 8, iter 125, loss 2.143561601638794, acc 0.36000001430511475\n",
      "Epoch 8, iter 126, loss 2.099195957183838, acc 0.3700000047683716\n",
      "Epoch 8, iter 127, loss 2.112577438354492, acc 0.4000000059604645\n",
      "Epoch 8, iter 128, loss 2.1241626739501953, acc 0.38999998569488525\n",
      "Epoch 8, iter 129, loss 2.144882917404175, acc 0.36000001430511475\n",
      "Epoch 8, iter 130, loss 2.145036458969116, acc 0.3700000047683716\n",
      "Epoch 8, iter 131, loss 2.176497459411621, acc 0.3700000047683716\n",
      "Epoch 8, iter 132, loss 2.1217267513275146, acc 0.3700000047683716\n",
      "Epoch 8, iter 133, loss 2.0871458053588867, acc 0.4399999976158142\n",
      "Epoch 8, iter 134, loss 2.140643835067749, acc 0.3700000047683716\n",
      "Epoch 8, iter 135, loss 2.1415038108825684, acc 0.3799999952316284\n",
      "Epoch 8, iter 136, loss 2.0746190547943115, acc 0.4099999964237213\n",
      "Epoch 8, iter 137, loss 2.1027235984802246, acc 0.36000001430511475\n",
      "Epoch 8, iter 138, loss 2.1110477447509766, acc 0.4300000071525574\n",
      "Epoch 8, iter 139, loss 2.140054941177368, acc 0.3199999928474426\n",
      "Epoch 8, iter 140, loss 2.1308884620666504, acc 0.36000001430511475\n",
      "Epoch 8, iter 141, loss 2.106668710708618, acc 0.3799999952316284\n",
      "Epoch 8, iter 142, loss 2.1232261657714844, acc 0.33000001311302185\n",
      "Epoch 8, iter 143, loss 2.120419979095459, acc 0.33000001311302185\n",
      "Epoch 8, iter 144, loss 2.1483211517333984, acc 0.2800000011920929\n",
      "Epoch 8, iter 145, loss 2.09755277633667, acc 0.38999998569488525\n",
      "Epoch 8, iter 146, loss 2.126229763031006, acc 0.33000001311302185\n",
      "Epoch 8, iter 147, loss 2.127772331237793, acc 0.3799999952316284\n",
      "Epoch 8, iter 148, loss 2.10465669631958, acc 0.36000001430511475\n",
      "Epoch 8, iter 149, loss 2.0782768726348877, acc 0.3799999952316284\n",
      "Epoch 8, iter 150, loss 2.1494486331939697, acc 0.3100000023841858\n",
      "Epoch 8, iter 151, loss 2.024346351623535, acc 0.44999998807907104\n",
      "Epoch 8, iter 152, loss 2.109795570373535, acc 0.4099999964237213\n",
      "Epoch 8, iter 153, loss 2.119162082672119, acc 0.4099999964237213\n",
      "Epoch 8, iter 154, loss 2.1460158824920654, acc 0.3400000035762787\n",
      "Epoch 8, iter 155, loss 2.137570858001709, acc 0.3199999928474426\n",
      "Epoch 8, iter 156, loss 2.133837938308716, acc 0.38999998569488525\n",
      "Epoch 8, iter 157, loss 2.1654694080352783, acc 0.27000001072883606\n",
      "Epoch 8, iter 158, loss 2.1409859657287598, acc 0.3400000035762787\n",
      "Epoch 8, iter 159, loss 2.1048338413238525, acc 0.36000001430511475\n",
      "Epoch 8, iter 160, loss 2.143571376800537, acc 0.3400000035762787\n",
      "Epoch 8, iter 161, loss 2.098130702972412, acc 0.3499999940395355\n",
      "Epoch 8, iter 162, loss 2.0394012928009033, acc 0.5099999904632568\n",
      "Epoch 8, iter 163, loss 2.1335794925689697, acc 0.3700000047683716\n",
      "Epoch 8, iter 164, loss 2.136596918106079, acc 0.3700000047683716\n",
      "Epoch 8, iter 165, loss 2.160323143005371, acc 0.3799999952316284\n",
      "Epoch 8, iter 166, loss 2.099728584289551, acc 0.41999998688697815\n",
      "Epoch 8, iter 167, loss 2.1340997219085693, acc 0.3199999928474426\n",
      "Epoch 8, iter 168, loss 2.087447166442871, acc 0.4300000071525574\n",
      "Epoch 8, iter 169, loss 2.046698808670044, acc 0.41999998688697815\n",
      "Epoch 8, iter 170, loss 2.121180772781372, acc 0.3499999940395355\n",
      "Epoch 8, iter 171, loss 2.1013965606689453, acc 0.4300000071525574\n",
      "Epoch 8, iter 172, loss 2.1355016231536865, acc 0.3499999940395355\n",
      "Epoch 8, iter 173, loss 2.1488938331604004, acc 0.36000001430511475\n",
      "Epoch 8, iter 174, loss 2.0874531269073486, acc 0.41999998688697815\n",
      "Epoch 8, iter 175, loss 2.089566469192505, acc 0.4399999976158142\n",
      "Epoch 8, iter 176, loss 2.1569125652313232, acc 0.30000001192092896\n",
      "Epoch 8, iter 177, loss 2.106243371963501, acc 0.4099999964237213\n",
      "Epoch 8, iter 178, loss 2.107028007507324, acc 0.4099999964237213\n",
      "Epoch 8, iter 179, loss 2.1169164180755615, acc 0.3700000047683716\n",
      "Epoch 8, iter 180, loss 2.1611342430114746, acc 0.3400000035762787\n",
      "Epoch 8, iter 181, loss 2.0362770557403564, acc 0.5199999809265137\n",
      "Epoch 8, iter 182, loss 2.132483959197998, acc 0.44999998807907104\n",
      "Epoch 8, iter 183, loss 2.1251533031463623, acc 0.4000000059604645\n",
      "Epoch 8, iter 184, loss 2.118783473968506, acc 0.3700000047683716\n",
      "Epoch 8, iter 185, loss 2.110518455505371, acc 0.4099999964237213\n",
      "Epoch 8, iter 186, loss 2.1267523765563965, acc 0.36000001430511475\n",
      "Epoch 8, iter 187, loss 2.115405321121216, acc 0.3700000047683716\n",
      "Epoch 8, iter 188, loss 2.140749454498291, acc 0.3499999940395355\n",
      "Epoch 8, iter 189, loss 2.1819913387298584, acc 0.28999999165534973\n",
      "Epoch 8, iter 190, loss 2.102619171142578, acc 0.4399999976158142\n",
      "Epoch 8, iter 191, loss 2.1343367099761963, acc 0.3499999940395355\n",
      "Epoch 8, iter 192, loss 2.110726833343506, acc 0.38999998569488525\n",
      "Epoch 8, iter 193, loss 2.098055601119995, acc 0.4300000071525574\n",
      "Epoch 8, iter 194, loss 2.115274667739868, acc 0.3700000047683716\n",
      "Epoch 8, iter 195, loss 2.0720553398132324, acc 0.4399999976158142\n",
      "Epoch 8, iter 196, loss 2.151413917541504, acc 0.3700000047683716\n",
      "Epoch 8, iter 197, loss 2.121988534927368, acc 0.41999998688697815\n",
      "Epoch 8, iter 198, loss 2.051297664642334, acc 0.44999998807907104\n",
      "Epoch 8, iter 199, loss 2.1413445472717285, acc 0.3400000035762787\n",
      "Epoch 8, iter 200, loss 2.1314024925231934, acc 0.4000000059604645\n",
      "Epoch 8, iter 201, loss 2.0899829864501953, acc 0.5099999904632568\n",
      "Epoch 8, iter 202, loss 2.1095235347747803, acc 0.4000000059604645\n",
      "Epoch 8, iter 203, loss 2.118673086166382, acc 0.3700000047683716\n",
      "Epoch 8, iter 204, loss 2.0773637294769287, acc 0.4399999976158142\n",
      "Epoch 8, iter 205, loss 2.0376205444335938, acc 0.5\n",
      "Epoch 8, iter 206, loss 2.127326250076294, acc 0.3100000023841858\n",
      "Epoch 8, iter 207, loss 2.128788709640503, acc 0.38999998569488525\n",
      "Epoch 8, iter 208, loss 2.1604607105255127, acc 0.36000001430511475\n",
      "Epoch 8, iter 209, loss 2.151984453201294, acc 0.33000001311302185\n",
      "Epoch 8, iter 210, loss 2.1756839752197266, acc 0.2800000011920929\n",
      "Epoch 8, iter 211, loss 2.093442916870117, acc 0.41999998688697815\n",
      "Epoch 8, iter 212, loss 2.148310422897339, acc 0.28999999165534973\n",
      "Epoch 8, iter 213, loss 2.1272318363189697, acc 0.4399999976158142\n",
      "Epoch 8, iter 214, loss 2.134307622909546, acc 0.3799999952316284\n",
      "Epoch 8, iter 215, loss 2.1347498893737793, acc 0.3199999928474426\n",
      "Epoch 8, iter 216, loss 2.1658051013946533, acc 0.30000001192092896\n",
      "Epoch 8, iter 217, loss 2.085160970687866, acc 0.47999998927116394\n",
      "Epoch 8, iter 218, loss 2.1839303970336914, acc 0.3199999928474426\n",
      "Epoch 8, iter 219, loss 2.1226401329040527, acc 0.33000001311302185\n",
      "Epoch 8, iter 220, loss 2.069852352142334, acc 0.5\n",
      "Epoch 8, iter 221, loss 2.096423625946045, acc 0.4399999976158142\n",
      "Epoch 8, iter 222, loss 2.1179347038269043, acc 0.38999998569488525\n",
      "Epoch 8, iter 223, loss 2.069671869277954, acc 0.5199999809265137\n",
      "Epoch 8, iter 224, loss 2.123649835586548, acc 0.4099999964237213\n",
      "Epoch 8, iter 225, loss 2.0961737632751465, acc 0.3799999952316284\n",
      "Epoch 8, iter 226, loss 2.0974912643432617, acc 0.38999998569488525\n",
      "Epoch 8, iter 227, loss 2.120828628540039, acc 0.4000000059604645\n",
      "Epoch 8, iter 228, loss 2.1333930492401123, acc 0.3499999940395355\n",
      "Epoch 8, iter 229, loss 2.106198310852051, acc 0.3799999952316284\n",
      "Epoch 8, iter 230, loss 2.1109609603881836, acc 0.3799999952316284\n",
      "Epoch 8, iter 231, loss 2.0870232582092285, acc 0.38999998569488525\n",
      "Epoch 8, iter 232, loss 2.1449012756347656, acc 0.3100000023841858\n",
      "Epoch 8, iter 233, loss 2.0640203952789307, acc 0.46000000834465027\n",
      "Epoch 8, iter 234, loss 2.0611112117767334, acc 0.5\n",
      "Epoch 8, iter 235, loss 2.105799674987793, acc 0.36000001430511475\n",
      "Epoch 8, iter 236, loss 2.1279079914093018, acc 0.3499999940395355\n",
      "Epoch 8, iter 237, loss 2.1584932804107666, acc 0.3199999928474426\n",
      "Epoch 8, iter 238, loss 2.1041078567504883, acc 0.4300000071525574\n",
      "Epoch 8, iter 239, loss 2.1153602600097656, acc 0.41999998688697815\n",
      "Epoch 8, iter 240, loss 2.138357639312744, acc 0.3199999928474426\n",
      "Epoch 8, iter 241, loss 2.1192078590393066, acc 0.33000001311302185\n",
      "Epoch 8, iter 242, loss 2.132507562637329, acc 0.4099999964237213\n",
      "Epoch 8, iter 243, loss 2.178894281387329, acc 0.3100000023841858\n",
      "Epoch 8, iter 244, loss 2.07352352142334, acc 0.46000000834465027\n",
      "Epoch 8, iter 245, loss 2.085448741912842, acc 0.4399999976158142\n",
      "Epoch 8, iter 246, loss 2.184225082397461, acc 0.25999999046325684\n",
      "Epoch 8, iter 247, loss 2.0819993019104004, acc 0.47999998927116394\n",
      "Epoch 8, iter 248, loss 2.1440279483795166, acc 0.3100000023841858\n",
      "Epoch 8, iter 249, loss 2.157463788986206, acc 0.3100000023841858\n",
      "Epoch 8, iter 250, loss 2.085134506225586, acc 0.46000000834465027\n",
      "Epoch 8, iter 251, loss 2.13840389251709, acc 0.3199999928474426\n",
      "Epoch 8, iter 252, loss 2.105259895324707, acc 0.4000000059604645\n",
      "Epoch 8, iter 253, loss 2.1656713485717773, acc 0.36000001430511475\n",
      "Epoch 8, iter 254, loss 2.1433284282684326, acc 0.3700000047683716\n",
      "Epoch 8, iter 255, loss 2.1295571327209473, acc 0.36000001430511475\n",
      "Epoch 8, iter 256, loss 2.09627628326416, acc 0.44999998807907104\n",
      "Epoch 8, iter 257, loss 2.1399528980255127, acc 0.28999999165534973\n",
      "Epoch 8, iter 258, loss 2.120701551437378, acc 0.36000001430511475\n",
      "Epoch 8, iter 259, loss 2.1562438011169434, acc 0.3400000035762787\n",
      "Epoch 8, iter 260, loss 2.120253562927246, acc 0.3400000035762787\n",
      "Epoch 8, iter 261, loss 2.081754684448242, acc 0.4300000071525574\n",
      "Epoch 8, iter 262, loss 2.149785041809082, acc 0.3400000035762787\n",
      "Epoch 8, iter 263, loss 2.064321279525757, acc 0.44999998807907104\n",
      "Epoch 8, iter 264, loss 2.1049654483795166, acc 0.4000000059604645\n",
      "Epoch 8, iter 265, loss 2.1544251441955566, acc 0.36000001430511475\n",
      "Epoch 8, iter 266, loss 2.0860507488250732, acc 0.3799999952316284\n",
      "Epoch 8, iter 267, loss 2.0758016109466553, acc 0.4399999976158142\n",
      "Epoch 8, iter 268, loss 2.121657371520996, acc 0.33000001311302185\n",
      "Epoch 8, iter 269, loss 2.106397867202759, acc 0.38999998569488525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 270, loss 2.1229097843170166, acc 0.36000001430511475\n",
      "Epoch 8, iter 271, loss 2.128237724304199, acc 0.4099999964237213\n",
      "Epoch 8, iter 272, loss 2.1451117992401123, acc 0.3400000035762787\n",
      "Epoch 8, iter 273, loss 2.14370059967041, acc 0.3499999940395355\n",
      "Epoch 8, iter 274, loss 2.1209638118743896, acc 0.3400000035762787\n",
      "Epoch 8, iter 275, loss 2.1675734519958496, acc 0.3100000023841858\n",
      "Epoch 8, iter 276, loss 2.14180850982666, acc 0.3799999952316284\n",
      "Epoch 8, iter 277, loss 2.0948479175567627, acc 0.38999998569488525\n",
      "Epoch 8, iter 278, loss 2.083050489425659, acc 0.4699999988079071\n",
      "Epoch 8, iter 279, loss 2.0899012088775635, acc 0.4399999976158142\n",
      "Epoch 8, iter 280, loss 2.0970609188079834, acc 0.3799999952316284\n",
      "Epoch 8, iter 281, loss 2.108083963394165, acc 0.4300000071525574\n",
      "Epoch 8, iter 282, loss 2.1552486419677734, acc 0.3499999940395355\n",
      "Epoch 8, iter 283, loss 2.102170467376709, acc 0.3499999940395355\n",
      "Epoch 8, iter 284, loss 2.0692272186279297, acc 0.5\n",
      "Epoch 8, iter 285, loss 2.098205804824829, acc 0.36000001430511475\n",
      "Epoch 8, iter 286, loss 2.108095169067383, acc 0.4300000071525574\n",
      "Epoch 8, iter 287, loss 2.1325721740722656, acc 0.38999998569488525\n",
      "Epoch 8, iter 288, loss 2.097158432006836, acc 0.3799999952316284\n",
      "Epoch 8, iter 289, loss 2.1521353721618652, acc 0.33000001311302185\n",
      "Epoch 8, iter 290, loss 2.0893170833587646, acc 0.3700000047683716\n",
      "Epoch 8, iter 291, loss 2.113637685775757, acc 0.4000000059604645\n",
      "Epoch 8, iter 292, loss 2.086465358734131, acc 0.4099999964237213\n",
      "Epoch 8, iter 293, loss 2.0957717895507812, acc 0.3700000047683716\n",
      "Epoch 8, iter 294, loss 2.148710250854492, acc 0.30000001192092896\n",
      "Epoch 8, iter 295, loss 2.1211109161376953, acc 0.38999998569488525\n",
      "Epoch 8, iter 296, loss 2.084817409515381, acc 0.4099999964237213\n",
      "Epoch 8, iter 297, loss 2.1562600135803223, acc 0.3700000047683716\n",
      "Epoch 8, iter 298, loss 2.0898849964141846, acc 0.4399999976158142\n",
      "Epoch 8, iter 299, loss 2.1944141387939453, acc 0.27000001072883606\n",
      "Epoch 8, iter 300, loss 2.133898973464966, acc 0.33000001311302185\n",
      "Epoch 8, iter 301, loss 2.1381239891052246, acc 0.36000001430511475\n",
      "Epoch 8, iter 302, loss 2.1033589839935303, acc 0.38999998569488525\n",
      "Epoch 8, iter 303, loss 2.1166775226593018, acc 0.3700000047683716\n",
      "Epoch 8, iter 304, loss 2.1642627716064453, acc 0.3100000023841858\n",
      "Epoch 8, iter 305, loss 2.19996976852417, acc 0.25999999046325684\n",
      "Epoch 8, iter 306, loss 2.070633888244629, acc 0.41999998688697815\n",
      "Epoch 8, iter 307, loss 2.0924909114837646, acc 0.3700000047683716\n",
      "Epoch 8, iter 308, loss 2.1956472396850586, acc 0.25\n",
      "Epoch 8, iter 309, loss 2.1066930294036865, acc 0.3700000047683716\n",
      "Epoch 8, iter 310, loss 2.1422672271728516, acc 0.3199999928474426\n",
      "Epoch 8, iter 311, loss 2.12579607963562, acc 0.3400000035762787\n",
      "Epoch 8, iter 312, loss 2.1054139137268066, acc 0.3799999952316284\n",
      "Epoch 8, iter 313, loss 2.2041432857513428, acc 0.1899999976158142\n",
      "Epoch 8, iter 314, loss 2.0784082412719727, acc 0.4099999964237213\n",
      "Epoch 8, iter 315, loss 2.1151087284088135, acc 0.4300000071525574\n",
      "Epoch 8, iter 316, loss 2.1554622650146484, acc 0.3400000035762787\n",
      "Epoch 8, iter 317, loss 2.1362438201904297, acc 0.3700000047683716\n",
      "Epoch 8, iter 318, loss 2.103020668029785, acc 0.38999998569488525\n",
      "Epoch 8, iter 319, loss 2.1043169498443604, acc 0.3700000047683716\n",
      "Epoch 8, iter 320, loss 2.20173716545105, acc 0.28999999165534973\n",
      "Epoch 8, iter 321, loss 2.1529035568237305, acc 0.30000001192092896\n",
      "Epoch 8, iter 322, loss 2.125236749649048, acc 0.3499999940395355\n",
      "Epoch 8, iter 323, loss 2.1242687702178955, acc 0.3199999928474426\n",
      "Epoch 8, iter 324, loss 2.0462589263916016, acc 0.4399999976158142\n",
      "Epoch 8, iter 325, loss 2.154876708984375, acc 0.33000001311302185\n",
      "Epoch 8, iter 326, loss 2.0734829902648926, acc 0.4699999988079071\n",
      "Epoch 8, iter 327, loss 2.1525983810424805, acc 0.3499999940395355\n",
      "Epoch 8, iter 328, loss 2.084681272506714, acc 0.4000000059604645\n",
      "Epoch 8, iter 329, loss 2.1061208248138428, acc 0.3400000035762787\n",
      "Epoch 8, iter 330, loss 2.1327295303344727, acc 0.38999998569488525\n",
      "Epoch 8, iter 331, loss 2.126315116882324, acc 0.3499999940395355\n",
      "Epoch 8, iter 332, loss 2.1412911415100098, acc 0.4000000059604645\n",
      "Epoch 8, iter 333, loss 2.1175997257232666, acc 0.4000000059604645\n",
      "Epoch 8, iter 334, loss 2.1674320697784424, acc 0.3100000023841858\n",
      "Epoch 8, iter 335, loss 2.036461591720581, acc 0.46000000834465027\n",
      "Epoch 8, iter 336, loss 2.103152275085449, acc 0.3499999940395355\n",
      "Epoch 8, iter 337, loss 2.115400791168213, acc 0.3700000047683716\n",
      "Epoch 8, iter 338, loss 2.106541395187378, acc 0.3400000035762787\n",
      "Epoch 8, iter 339, loss 2.1147964000701904, acc 0.4000000059604645\n",
      "Epoch 8, iter 340, loss 2.1172432899475098, acc 0.41999998688697815\n",
      "Epoch 8, iter 341, loss 2.0878725051879883, acc 0.44999998807907104\n",
      "Epoch 8, iter 342, loss 2.0973339080810547, acc 0.3799999952316284\n",
      "Epoch 8, iter 343, loss 2.170722007751465, acc 0.2800000011920929\n",
      "Epoch 8, iter 344, loss 2.0799012184143066, acc 0.3799999952316284\n",
      "Epoch 8, iter 345, loss 2.157041072845459, acc 0.30000001192092896\n",
      "Epoch 8, iter 346, loss 2.0672173500061035, acc 0.4300000071525574\n",
      "Epoch 8, iter 347, loss 2.176198959350586, acc 0.2800000011920929\n",
      "Epoch 8, iter 348, loss 2.0662953853607178, acc 0.44999998807907104\n",
      "Epoch 8, iter 349, loss 2.0517570972442627, acc 0.46000000834465027\n",
      "Epoch 8, iter 350, loss 2.1223790645599365, acc 0.41999998688697815\n",
      "Epoch 8, iter 351, loss 2.1005051136016846, acc 0.41999998688697815\n",
      "Epoch 8, iter 352, loss 2.1210556030273438, acc 0.3799999952316284\n",
      "Epoch 8, iter 353, loss 2.115304946899414, acc 0.4300000071525574\n",
      "Epoch 8, iter 354, loss 2.0786430835723877, acc 0.41999998688697815\n",
      "Epoch 8, iter 355, loss 2.155351161956787, acc 0.28999999165534973\n",
      "Epoch 8, iter 356, loss 2.1199042797088623, acc 0.4000000059604645\n",
      "Epoch 8, iter 357, loss 2.1355695724487305, acc 0.3499999940395355\n",
      "Epoch 8, iter 358, loss 2.196357011795044, acc 0.25999999046325684\n",
      "Epoch 8, iter 359, loss 2.1258857250213623, acc 0.33000001311302185\n",
      "Epoch 8, iter 360, loss 2.1191272735595703, acc 0.3799999952316284\n",
      "Epoch 8, iter 361, loss 2.102147102355957, acc 0.41999998688697815\n",
      "Epoch 8, iter 362, loss 2.176793098449707, acc 0.25\n",
      "Epoch 8, iter 363, loss 2.114449977874756, acc 0.3799999952316284\n",
      "Epoch 8, iter 364, loss 2.118971347808838, acc 0.3700000047683716\n",
      "Epoch 8, iter 365, loss 2.092425584793091, acc 0.4099999964237213\n",
      "Epoch 8, iter 366, loss 2.068286418914795, acc 0.4300000071525574\n",
      "Epoch 8, iter 367, loss 2.0769689083099365, acc 0.4399999976158142\n",
      "Epoch 8, iter 368, loss 2.0889036655426025, acc 0.41999998688697815\n",
      "Epoch 8, iter 369, loss 2.093501567840576, acc 0.4300000071525574\n",
      "Epoch 8, iter 370, loss 2.0744528770446777, acc 0.38999998569488525\n",
      "Epoch 8, iter 371, loss 2.06038236618042, acc 0.46000000834465027\n",
      "Epoch 8, iter 372, loss 2.0919976234436035, acc 0.4099999964237213\n",
      "Epoch 8, iter 373, loss 2.132477045059204, acc 0.3100000023841858\n",
      "Epoch 8, iter 374, loss 2.1238155364990234, acc 0.38999998569488525\n",
      "Epoch 8, iter 375, loss 2.1236515045166016, acc 0.36000001430511475\n",
      "Epoch 8, iter 376, loss 2.1215736865997314, acc 0.33000001311302185\n",
      "Epoch 8, iter 377, loss 2.08259654045105, acc 0.4000000059604645\n",
      "Epoch 8, iter 378, loss 2.0901269912719727, acc 0.4300000071525574\n",
      "Epoch 8, iter 379, loss 2.1751368045806885, acc 0.30000001192092896\n",
      "Epoch 8, iter 380, loss 2.131138563156128, acc 0.36000001430511475\n",
      "Epoch 8, iter 381, loss 2.133234977722168, acc 0.3400000035762787\n",
      "Epoch 8, iter 382, loss 2.077669382095337, acc 0.4300000071525574\n",
      "Epoch 8, iter 383, loss 2.088034152984619, acc 0.5\n",
      "Epoch 8, iter 384, loss 2.1423707008361816, acc 0.3400000035762787\n",
      "Epoch 8, iter 385, loss 2.114706516265869, acc 0.3700000047683716\n",
      "Epoch 8, iter 386, loss 2.1085033416748047, acc 0.3499999940395355\n",
      "Epoch 8, iter 387, loss 2.1341309547424316, acc 0.33000001311302185\n",
      "Epoch 8, iter 388, loss 2.1210520267486572, acc 0.38999998569488525\n",
      "Epoch 8, iter 389, loss 2.124175786972046, acc 0.36000001430511475\n",
      "Epoch 8, iter 390, loss 2.1863863468170166, acc 0.27000001072883606\n",
      "Epoch 8, iter 391, loss 2.1266281604766846, acc 0.3700000047683716\n",
      "Epoch 8, iter 392, loss 2.1227235794067383, acc 0.4000000059604645\n",
      "Epoch 8, iter 393, loss 2.1169850826263428, acc 0.3799999952316284\n",
      "Epoch 8, iter 394, loss 2.093508243560791, acc 0.4300000071525574\n",
      "Epoch 8, iter 395, loss 2.049323797225952, acc 0.46000000834465027\n",
      "Epoch 8, iter 396, loss 2.135056972503662, acc 0.33000001311302185\n",
      "Epoch 8, iter 397, loss 2.111309766769409, acc 0.4000000059604645\n",
      "Epoch 8, iter 398, loss 2.145927906036377, acc 0.3499999940395355\n",
      "Epoch 8, iter 399, loss 2.096158981323242, acc 0.4300000071525574\n",
      "Epoch 8, iter 400, loss 2.0725879669189453, acc 0.4699999988079071\n",
      "Epoch 8, iter 401, loss 2.0983927249908447, acc 0.4000000059604645\n",
      "Epoch 8, iter 402, loss 2.0748133659362793, acc 0.4399999976158142\n",
      "Epoch 8, iter 403, loss 2.1292450428009033, acc 0.3700000047683716\n",
      "Epoch 8, iter 404, loss 2.1547019481658936, acc 0.3100000023841858\n",
      "Epoch 8, iter 405, loss 2.1402268409729004, acc 0.3799999952316284\n",
      "Epoch 8, iter 406, loss 2.129908561706543, acc 0.3199999928474426\n",
      "Epoch 8, iter 407, loss 2.1363718509674072, acc 0.3199999928474426\n",
      "Epoch 8, iter 408, loss 2.151634454727173, acc 0.3400000035762787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iter 409, loss 2.099141836166382, acc 0.4399999976158142\n",
      "Epoch 8, iter 410, loss 2.0753302574157715, acc 0.4399999976158142\n",
      "Epoch 8, iter 411, loss 2.091675043106079, acc 0.38999998569488525\n",
      "Epoch 8, iter 412, loss 2.092634439468384, acc 0.46000000834465027\n",
      "Epoch 8, iter 413, loss 2.121792793273926, acc 0.4000000059604645\n",
      "Epoch 8, iter 414, loss 2.130235433578491, acc 0.3199999928474426\n",
      "Epoch 8, iter 415, loss 2.152763605117798, acc 0.33000001311302185\n",
      "Epoch 8, iter 416, loss 2.1023340225219727, acc 0.38999998569488525\n",
      "Epoch 8, iter 417, loss 2.0625576972961426, acc 0.4699999988079071\n",
      "Epoch 8, iter 418, loss 2.098842144012451, acc 0.36000001430511475\n",
      "Epoch 8, iter 419, loss 2.0777666568756104, acc 0.4099999964237213\n",
      "Epoch 8, iter 420, loss 2.1254541873931885, acc 0.3400000035762787\n",
      "Epoch 9, iter 1, loss 2.0889499187469482, acc 0.3700000047683716\n",
      "Epoch 9, iter 2, loss 2.1379401683807373, acc 0.4000000059604645\n",
      "Epoch 9, iter 3, loss 2.1024537086486816, acc 0.4399999976158142\n",
      "Epoch 9, iter 4, loss 2.1751770973205566, acc 0.28999999165534973\n",
      "Epoch 9, iter 5, loss 2.153256416320801, acc 0.27000001072883606\n",
      "Epoch 9, iter 6, loss 2.139080762863159, acc 0.3100000023841858\n",
      "Epoch 9, iter 7, loss 2.1215429306030273, acc 0.3700000047683716\n",
      "Epoch 9, iter 8, loss 2.1008944511413574, acc 0.4099999964237213\n",
      "Epoch 9, iter 9, loss 2.1425766944885254, acc 0.3799999952316284\n",
      "Epoch 9, iter 10, loss 2.1473264694213867, acc 0.3700000047683716\n",
      "Epoch 9, iter 11, loss 2.1469340324401855, acc 0.3499999940395355\n",
      "Epoch 9, iter 12, loss 2.1312906742095947, acc 0.33000001311302185\n",
      "Epoch 9, iter 13, loss 2.1163535118103027, acc 0.3400000035762787\n",
      "Epoch 9, iter 14, loss 2.0563764572143555, acc 0.4399999976158142\n",
      "Epoch 9, iter 15, loss 2.0443198680877686, acc 0.47999998927116394\n",
      "Epoch 9, iter 16, loss 2.0730113983154297, acc 0.4300000071525574\n",
      "Epoch 9, iter 17, loss 2.140221118927002, acc 0.3100000023841858\n",
      "Epoch 9, iter 18, loss 2.118201971054077, acc 0.38999998569488525\n",
      "Epoch 9, iter 19, loss 2.0981595516204834, acc 0.33000001311302185\n",
      "Epoch 9, iter 20, loss 2.08817195892334, acc 0.4000000059604645\n",
      "Epoch 9, iter 21, loss 2.0664093494415283, acc 0.4300000071525574\n",
      "Epoch 9, iter 22, loss 2.112642526626587, acc 0.3700000047683716\n",
      "Epoch 9, iter 23, loss 2.075488328933716, acc 0.4300000071525574\n",
      "Epoch 9, iter 24, loss 2.1153602600097656, acc 0.3199999928474426\n",
      "Epoch 9, iter 25, loss 2.124703884124756, acc 0.3799999952316284\n",
      "Epoch 9, iter 26, loss 2.123478651046753, acc 0.36000001430511475\n",
      "Epoch 9, iter 27, loss 2.1001322269439697, acc 0.44999998807907104\n",
      "Epoch 9, iter 28, loss 2.0441389083862305, acc 0.5\n",
      "Epoch 9, iter 29, loss 2.1199193000793457, acc 0.36000001430511475\n",
      "Epoch 9, iter 30, loss 2.119236469268799, acc 0.3700000047683716\n",
      "Epoch 9, iter 31, loss 2.1773157119750977, acc 0.30000001192092896\n",
      "Epoch 9, iter 32, loss 2.103729486465454, acc 0.3799999952316284\n",
      "Epoch 9, iter 33, loss 2.130685806274414, acc 0.4000000059604645\n",
      "Epoch 9, iter 34, loss 2.0761256217956543, acc 0.4399999976158142\n",
      "Epoch 9, iter 35, loss 2.1380550861358643, acc 0.33000001311302185\n",
      "Epoch 9, iter 36, loss 2.1009228229522705, acc 0.38999998569488525\n",
      "Epoch 9, iter 37, loss 2.1462926864624023, acc 0.3100000023841858\n",
      "Epoch 9, iter 38, loss 2.1350913047790527, acc 0.4099999964237213\n",
      "Epoch 9, iter 39, loss 2.0788278579711914, acc 0.4099999964237213\n",
      "Epoch 9, iter 40, loss 2.059464454650879, acc 0.41999998688697815\n",
      "Epoch 9, iter 41, loss 2.1634061336517334, acc 0.30000001192092896\n",
      "Epoch 9, iter 42, loss 2.1024420261383057, acc 0.4099999964237213\n",
      "Epoch 9, iter 43, loss 2.046583414077759, acc 0.4300000071525574\n",
      "Epoch 9, iter 44, loss 2.0628926753997803, acc 0.4099999964237213\n",
      "Epoch 9, iter 45, loss 2.1199066638946533, acc 0.3700000047683716\n",
      "Epoch 9, iter 46, loss 2.1185450553894043, acc 0.4099999964237213\n",
      "Epoch 9, iter 47, loss 2.162858247756958, acc 0.25999999046325684\n",
      "Epoch 9, iter 48, loss 2.0874319076538086, acc 0.3799999952316284\n",
      "Epoch 9, iter 49, loss 2.1015102863311768, acc 0.3799999952316284\n",
      "Epoch 9, iter 50, loss 2.145581007003784, acc 0.3499999940395355\n",
      "Epoch 9, iter 51, loss 2.0729572772979736, acc 0.4300000071525574\n",
      "Epoch 9, iter 52, loss 2.143491268157959, acc 0.3100000023841858\n",
      "Epoch 9, iter 53, loss 2.089355945587158, acc 0.4000000059604645\n",
      "Epoch 9, iter 54, loss 2.10789155960083, acc 0.36000001430511475\n",
      "Epoch 9, iter 55, loss 2.201289653778076, acc 0.25999999046325684\n",
      "Epoch 9, iter 56, loss 2.094102382659912, acc 0.38999998569488525\n",
      "Epoch 9, iter 57, loss 2.164332389831543, acc 0.33000001311302185\n",
      "Epoch 9, iter 58, loss 2.1243419647216797, acc 0.4000000059604645\n",
      "Epoch 9, iter 59, loss 2.094782829284668, acc 0.4000000059604645\n",
      "Epoch 9, iter 60, loss 2.1020054817199707, acc 0.4399999976158142\n",
      "Epoch 9, iter 61, loss 2.0956852436065674, acc 0.38999998569488525\n",
      "Epoch 9, iter 62, loss 2.1076455116271973, acc 0.4000000059604645\n",
      "Epoch 9, iter 63, loss 2.1361300945281982, acc 0.3799999952316284\n",
      "Epoch 9, iter 64, loss 2.0987436771392822, acc 0.33000001311302185\n",
      "Epoch 9, iter 65, loss 2.109029769897461, acc 0.4300000071525574\n",
      "Epoch 9, iter 66, loss 2.103483200073242, acc 0.33000001311302185\n",
      "Epoch 9, iter 67, loss 2.1252121925354004, acc 0.33000001311302185\n",
      "Epoch 9, iter 68, loss 2.0629165172576904, acc 0.47999998927116394\n",
      "Epoch 9, iter 69, loss 2.1086504459381104, acc 0.3499999940395355\n",
      "Epoch 9, iter 70, loss 2.113247871398926, acc 0.41999998688697815\n",
      "Epoch 9, iter 71, loss 2.1238319873809814, acc 0.3799999952316284\n",
      "Epoch 9, iter 72, loss 2.100128412246704, acc 0.3700000047683716\n",
      "Epoch 9, iter 73, loss 2.0803046226501465, acc 0.4300000071525574\n",
      "Epoch 9, iter 74, loss 2.110560417175293, acc 0.3799999952316284\n",
      "Epoch 9, iter 75, loss 2.1074423789978027, acc 0.3799999952316284\n",
      "Epoch 9, iter 76, loss 2.116255760192871, acc 0.3799999952316284\n",
      "Epoch 9, iter 77, loss 2.1565754413604736, acc 0.30000001192092896\n",
      "Epoch 9, iter 78, loss 2.117361545562744, acc 0.4099999964237213\n",
      "Epoch 9, iter 79, loss 2.105210304260254, acc 0.3700000047683716\n",
      "Epoch 9, iter 80, loss 2.1100172996520996, acc 0.3799999952316284\n",
      "Epoch 9, iter 81, loss 2.139700412750244, acc 0.33000001311302185\n",
      "Epoch 9, iter 82, loss 2.1374928951263428, acc 0.30000001192092896\n",
      "Epoch 9, iter 83, loss 2.072901964187622, acc 0.44999998807907104\n",
      "Epoch 9, iter 84, loss 2.1400089263916016, acc 0.3400000035762787\n",
      "Epoch 9, iter 85, loss 2.1554605960845947, acc 0.3199999928474426\n",
      "Epoch 9, iter 86, loss 2.1095402240753174, acc 0.38999998569488525\n",
      "Epoch 9, iter 87, loss 2.1263587474823, acc 0.4099999964237213\n",
      "Epoch 9, iter 88, loss 2.0778656005859375, acc 0.41999998688697815\n",
      "Epoch 9, iter 89, loss 2.1176950931549072, acc 0.3799999952316284\n",
      "Epoch 9, iter 90, loss 2.102266788482666, acc 0.38999998569488525\n",
      "Epoch 9, iter 91, loss 2.1086807250976562, acc 0.3700000047683716\n",
      "Epoch 9, iter 92, loss 2.147721290588379, acc 0.3799999952316284\n",
      "Epoch 9, iter 93, loss 2.050429344177246, acc 0.5099999904632568\n",
      "Epoch 9, iter 94, loss 2.116886615753174, acc 0.3400000035762787\n",
      "Epoch 9, iter 95, loss 2.0952541828155518, acc 0.38999998569488525\n",
      "Epoch 9, iter 96, loss 2.1310007572174072, acc 0.3799999952316284\n",
      "Epoch 9, iter 97, loss 2.123051643371582, acc 0.3400000035762787\n",
      "Epoch 9, iter 98, loss 2.116171360015869, acc 0.3499999940395355\n",
      "Epoch 9, iter 99, loss 2.107571601867676, acc 0.3700000047683716\n",
      "Epoch 9, iter 100, loss 2.0997886657714844, acc 0.3799999952316284\n",
      "Epoch 9, iter 101, loss 2.08349347114563, acc 0.4300000071525574\n",
      "Epoch 9, iter 102, loss 2.1116538047790527, acc 0.3499999940395355\n",
      "Epoch 9, iter 103, loss 2.0846359729766846, acc 0.46000000834465027\n",
      "Epoch 9, iter 104, loss 2.1226320266723633, acc 0.4000000059604645\n",
      "Epoch 9, iter 105, loss 2.0315499305725098, acc 0.4399999976158142\n",
      "Epoch 9, iter 106, loss 2.08823299407959, acc 0.3799999952316284\n",
      "Epoch 9, iter 107, loss 2.0859038829803467, acc 0.3799999952316284\n",
      "Epoch 9, iter 108, loss 2.1526949405670166, acc 0.27000001072883606\n",
      "Epoch 9, iter 109, loss 2.1004607677459717, acc 0.38999998569488525\n",
      "Epoch 9, iter 110, loss 2.1219398975372314, acc 0.3799999952316284\n",
      "Epoch 9, iter 111, loss 2.1229963302612305, acc 0.30000001192092896\n",
      "Epoch 9, iter 112, loss 2.0970866680145264, acc 0.36000001430511475\n",
      "Epoch 9, iter 113, loss 2.062329053878784, acc 0.47999998927116394\n",
      "Epoch 9, iter 114, loss 2.0714364051818848, acc 0.3799999952316284\n",
      "Epoch 9, iter 115, loss 2.0965847969055176, acc 0.4000000059604645\n",
      "Epoch 9, iter 116, loss 2.08424711227417, acc 0.4099999964237213\n",
      "Epoch 9, iter 117, loss 2.116898775100708, acc 0.4000000059604645\n",
      "Epoch 9, iter 118, loss 2.125694513320923, acc 0.3400000035762787\n",
      "Epoch 9, iter 119, loss 2.1215097904205322, acc 0.3799999952316284\n",
      "Epoch 9, iter 120, loss 2.1279282569885254, acc 0.33000001311302185\n",
      "Epoch 9, iter 121, loss 2.125314950942993, acc 0.4000000059604645\n",
      "Epoch 9, iter 122, loss 2.0782079696655273, acc 0.44999998807907104\n",
      "Epoch 9, iter 123, loss 2.1477365493774414, acc 0.3100000023841858\n",
      "Epoch 9, iter 124, loss 2.051892042160034, acc 0.5\n",
      "Epoch 9, iter 125, loss 2.1239287853240967, acc 0.36000001430511475\n",
      "Epoch 9, iter 126, loss 2.0861918926239014, acc 0.3799999952316284\n",
      "Epoch 9, iter 127, loss 2.1002490520477295, acc 0.4099999964237213\n",
      "Epoch 9, iter 128, loss 2.126091241836548, acc 0.36000001430511475\n",
      "Epoch 9, iter 129, loss 2.1369519233703613, acc 0.36000001430511475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 130, loss 2.1431620121002197, acc 0.3400000035762787\n",
      "Epoch 9, iter 131, loss 2.169595718383789, acc 0.36000001430511475\n",
      "Epoch 9, iter 132, loss 2.102912425994873, acc 0.38999998569488525\n",
      "Epoch 9, iter 133, loss 2.067901372909546, acc 0.44999998807907104\n",
      "Epoch 9, iter 134, loss 2.135573625564575, acc 0.36000001430511475\n",
      "Epoch 9, iter 135, loss 2.117816209793091, acc 0.4000000059604645\n",
      "Epoch 9, iter 136, loss 2.066222906112671, acc 0.4099999964237213\n",
      "Epoch 9, iter 137, loss 2.0964581966400146, acc 0.3700000047683716\n",
      "Epoch 9, iter 138, loss 2.104483127593994, acc 0.41999998688697815\n",
      "Epoch 9, iter 139, loss 2.1315407752990723, acc 0.3199999928474426\n",
      "Epoch 9, iter 140, loss 2.1193974018096924, acc 0.3700000047683716\n",
      "Epoch 9, iter 141, loss 2.101824998855591, acc 0.3799999952316284\n",
      "Epoch 9, iter 142, loss 2.113236904144287, acc 0.3400000035762787\n",
      "Epoch 9, iter 143, loss 2.1182494163513184, acc 0.3100000023841858\n",
      "Epoch 9, iter 144, loss 2.147305488586426, acc 0.2800000011920929\n",
      "Epoch 9, iter 145, loss 2.094891309738159, acc 0.38999998569488525\n",
      "Epoch 9, iter 146, loss 2.1119062900543213, acc 0.3400000035762787\n",
      "Epoch 9, iter 147, loss 2.105755567550659, acc 0.3799999952316284\n",
      "Epoch 9, iter 148, loss 2.076639175415039, acc 0.38999998569488525\n",
      "Epoch 9, iter 149, loss 2.0639424324035645, acc 0.3799999952316284\n",
      "Epoch 9, iter 150, loss 2.1140975952148438, acc 0.3700000047683716\n",
      "Epoch 9, iter 151, loss 2.003208875656128, acc 0.46000000834465027\n",
      "Epoch 9, iter 152, loss 2.0952062606811523, acc 0.4099999964237213\n",
      "Epoch 9, iter 153, loss 2.097825288772583, acc 0.4300000071525574\n",
      "Epoch 9, iter 154, loss 2.115309238433838, acc 0.3499999940395355\n",
      "Epoch 9, iter 155, loss 2.1148362159729004, acc 0.33000001311302185\n",
      "Epoch 9, iter 156, loss 2.1118407249450684, acc 0.4099999964237213\n",
      "Epoch 9, iter 157, loss 2.165627956390381, acc 0.25999999046325684\n",
      "Epoch 9, iter 158, loss 2.133899211883545, acc 0.3499999940395355\n",
      "Epoch 9, iter 159, loss 2.088387966156006, acc 0.3799999952316284\n",
      "Epoch 9, iter 160, loss 2.129591941833496, acc 0.3400000035762787\n",
      "Epoch 9, iter 161, loss 2.0930776596069336, acc 0.3499999940395355\n",
      "Epoch 9, iter 162, loss 2.0205535888671875, acc 0.5199999809265137\n",
      "Epoch 9, iter 163, loss 2.127633810043335, acc 0.3700000047683716\n",
      "Epoch 9, iter 164, loss 2.1218011379241943, acc 0.3799999952316284\n",
      "Epoch 9, iter 165, loss 2.1629624366760254, acc 0.33000001311302185\n",
      "Epoch 9, iter 166, loss 2.098997116088867, acc 0.4099999964237213\n",
      "Epoch 9, iter 167, loss 2.1346325874328613, acc 0.3100000023841858\n",
      "Epoch 9, iter 168, loss 2.076572895050049, acc 0.4300000071525574\n",
      "Epoch 9, iter 169, loss 2.0404343605041504, acc 0.41999998688697815\n",
      "Epoch 9, iter 170, loss 2.112717628479004, acc 0.3400000035762787\n",
      "Epoch 9, iter 171, loss 2.083590030670166, acc 0.44999998807907104\n",
      "Epoch 9, iter 172, loss 2.1295111179351807, acc 0.3400000035762787\n",
      "Epoch 9, iter 173, loss 2.1375322341918945, acc 0.3499999940395355\n",
      "Epoch 9, iter 174, loss 2.0802741050720215, acc 0.4099999964237213\n",
      "Epoch 9, iter 175, loss 2.0757594108581543, acc 0.4399999976158142\n",
      "Epoch 9, iter 176, loss 2.144787549972534, acc 0.30000001192092896\n",
      "Epoch 9, iter 177, loss 2.0976979732513428, acc 0.41999998688697815\n",
      "Epoch 9, iter 178, loss 2.098045587539673, acc 0.38999998569488525\n",
      "Epoch 9, iter 179, loss 2.1136667728424072, acc 0.3499999940395355\n",
      "Epoch 9, iter 180, loss 2.1403419971466064, acc 0.3400000035762787\n",
      "Epoch 9, iter 181, loss 2.0327353477478027, acc 0.5099999904632568\n",
      "Epoch 9, iter 182, loss 2.134166955947876, acc 0.4099999964237213\n",
      "Epoch 9, iter 183, loss 2.115602970123291, acc 0.3700000047683716\n",
      "Epoch 9, iter 184, loss 2.1118626594543457, acc 0.36000001430511475\n",
      "Epoch 9, iter 185, loss 2.099092721939087, acc 0.4000000059604645\n",
      "Epoch 9, iter 186, loss 2.1106443405151367, acc 0.3700000047683716\n",
      "Epoch 9, iter 187, loss 2.1082851886749268, acc 0.3799999952316284\n",
      "Epoch 9, iter 188, loss 2.1430892944335938, acc 0.3199999928474426\n",
      "Epoch 9, iter 189, loss 2.18689227104187, acc 0.2800000011920929\n",
      "Epoch 9, iter 190, loss 2.071361541748047, acc 0.44999998807907104\n",
      "Epoch 9, iter 191, loss 2.1260087490081787, acc 0.3400000035762787\n",
      "Epoch 9, iter 192, loss 2.1050145626068115, acc 0.3799999952316284\n",
      "Epoch 9, iter 193, loss 2.078455924987793, acc 0.4399999976158142\n",
      "Epoch 9, iter 194, loss 2.1079061031341553, acc 0.36000001430511475\n",
      "Epoch 9, iter 195, loss 2.0504238605499268, acc 0.4399999976158142\n",
      "Epoch 9, iter 196, loss 2.1444501876831055, acc 0.36000001430511475\n",
      "Epoch 9, iter 197, loss 2.120199203491211, acc 0.4000000059604645\n",
      "Epoch 9, iter 198, loss 2.047943353652954, acc 0.4300000071525574\n",
      "Epoch 9, iter 199, loss 2.1261651515960693, acc 0.3499999940395355\n",
      "Epoch 9, iter 200, loss 2.1309211254119873, acc 0.3700000047683716\n",
      "Epoch 9, iter 201, loss 2.0710206031799316, acc 0.5099999904632568\n",
      "Epoch 9, iter 202, loss 2.095876932144165, acc 0.4000000059604645\n",
      "Epoch 9, iter 203, loss 2.1132586002349854, acc 0.36000001430511475\n",
      "Epoch 9, iter 204, loss 2.0802886486053467, acc 0.4300000071525574\n",
      "Epoch 9, iter 205, loss 2.026409864425659, acc 0.5\n",
      "Epoch 9, iter 206, loss 2.137862205505371, acc 0.27000001072883606\n",
      "Epoch 9, iter 207, loss 2.117464065551758, acc 0.3700000047683716\n",
      "Epoch 9, iter 208, loss 2.155353307723999, acc 0.36000001430511475\n",
      "Epoch 9, iter 209, loss 2.1533429622650146, acc 0.30000001192092896\n",
      "Epoch 9, iter 210, loss 2.1706931591033936, acc 0.27000001072883606\n",
      "Epoch 9, iter 211, loss 2.088728427886963, acc 0.4099999964237213\n",
      "Epoch 9, iter 212, loss 2.1336259841918945, acc 0.3100000023841858\n",
      "Epoch 9, iter 213, loss 2.123145341873169, acc 0.4099999964237213\n",
      "Epoch 9, iter 214, loss 2.150902032852173, acc 0.3400000035762787\n",
      "Epoch 9, iter 215, loss 2.1217424869537354, acc 0.33000001311302185\n",
      "Epoch 9, iter 216, loss 2.1573550701141357, acc 0.28999999165534973\n",
      "Epoch 9, iter 217, loss 2.073615074157715, acc 0.4699999988079071\n",
      "Epoch 9, iter 218, loss 2.1689765453338623, acc 0.33000001311302185\n",
      "Epoch 9, iter 219, loss 2.1166985034942627, acc 0.33000001311302185\n",
      "Epoch 9, iter 220, loss 2.0751006603240967, acc 0.44999998807907104\n",
      "Epoch 9, iter 221, loss 2.098482608795166, acc 0.4300000071525574\n",
      "Epoch 9, iter 222, loss 2.1107232570648193, acc 0.38999998569488525\n",
      "Epoch 9, iter 223, loss 2.0604069232940674, acc 0.5\n",
      "Epoch 9, iter 224, loss 2.121654510498047, acc 0.38999998569488525\n",
      "Epoch 9, iter 225, loss 2.0998964309692383, acc 0.36000001430511475\n",
      "Epoch 9, iter 226, loss 2.099808692932129, acc 0.3799999952316284\n",
      "Epoch 9, iter 227, loss 2.116605520248413, acc 0.38999998569488525\n",
      "Epoch 9, iter 228, loss 2.1212809085845947, acc 0.3499999940395355\n",
      "Epoch 9, iter 229, loss 2.0945847034454346, acc 0.3799999952316284\n",
      "Epoch 9, iter 230, loss 2.1128478050231934, acc 0.3499999940395355\n",
      "Epoch 9, iter 231, loss 2.0902576446533203, acc 0.3700000047683716\n",
      "Epoch 9, iter 232, loss 2.1500582695007324, acc 0.30000001192092896\n",
      "Epoch 9, iter 233, loss 2.068086624145508, acc 0.4399999976158142\n",
      "Epoch 9, iter 234, loss 2.060899019241333, acc 0.49000000953674316\n",
      "Epoch 9, iter 235, loss 2.103600025177002, acc 0.3700000047683716\n",
      "Epoch 9, iter 236, loss 2.1183347702026367, acc 0.36000001430511475\n",
      "Epoch 9, iter 237, loss 2.161044120788574, acc 0.3100000023841858\n",
      "Epoch 9, iter 238, loss 2.0943875312805176, acc 0.4300000071525574\n",
      "Epoch 9, iter 239, loss 2.094301700592041, acc 0.4399999976158142\n",
      "Epoch 9, iter 240, loss 2.1414012908935547, acc 0.30000001192092896\n",
      "Epoch 9, iter 241, loss 2.11295223236084, acc 0.33000001311302185\n",
      "Epoch 9, iter 242, loss 2.137453079223633, acc 0.3799999952316284\n",
      "Epoch 9, iter 243, loss 2.173901319503784, acc 0.30000001192092896\n",
      "Epoch 9, iter 244, loss 2.06699538230896, acc 0.44999998807907104\n",
      "Epoch 9, iter 245, loss 2.0801918506622314, acc 0.4300000071525574\n",
      "Epoch 9, iter 246, loss 2.1808295249938965, acc 0.27000001072883606\n",
      "Epoch 9, iter 247, loss 2.0698492527008057, acc 0.47999998927116394\n",
      "Epoch 9, iter 248, loss 2.139002561569214, acc 0.33000001311302185\n",
      "Epoch 9, iter 249, loss 2.1545095443725586, acc 0.30000001192092896\n",
      "Epoch 9, iter 250, loss 2.0591793060302734, acc 0.49000000953674316\n",
      "Epoch 9, iter 251, loss 2.1327297687530518, acc 0.3199999928474426\n",
      "Epoch 9, iter 252, loss 2.097971200942993, acc 0.4000000059604645\n",
      "Epoch 9, iter 253, loss 2.153390407562256, acc 0.36000001430511475\n",
      "Epoch 9, iter 254, loss 2.1307897567749023, acc 0.38999998569488525\n",
      "Epoch 9, iter 255, loss 2.124842882156372, acc 0.33000001311302185\n",
      "Epoch 9, iter 256, loss 2.0804271697998047, acc 0.46000000834465027\n",
      "Epoch 9, iter 257, loss 2.1331567764282227, acc 0.30000001192092896\n",
      "Epoch 9, iter 258, loss 2.11153507232666, acc 0.3700000047683716\n",
      "Epoch 9, iter 259, loss 2.1451172828674316, acc 0.3499999940395355\n",
      "Epoch 9, iter 260, loss 2.1164026260375977, acc 0.3400000035762787\n",
      "Epoch 9, iter 261, loss 2.0713493824005127, acc 0.4000000059604645\n",
      "Epoch 9, iter 262, loss 2.1540229320526123, acc 0.3100000023841858\n",
      "Epoch 9, iter 263, loss 2.0471324920654297, acc 0.44999998807907104\n",
      "Epoch 9, iter 264, loss 2.115277051925659, acc 0.36000001430511475\n",
      "Epoch 9, iter 265, loss 2.1487956047058105, acc 0.3400000035762787\n",
      "Epoch 9, iter 266, loss 2.0865514278411865, acc 0.3700000047683716\n",
      "Epoch 9, iter 267, loss 2.0966429710388184, acc 0.36000001430511475\n",
      "Epoch 9, iter 268, loss 2.1194300651550293, acc 0.3400000035762787\n",
      "Epoch 9, iter 269, loss 2.1209559440612793, acc 0.3499999940395355\n",
      "Epoch 9, iter 270, loss 2.1099915504455566, acc 0.3400000035762787\n",
      "Epoch 9, iter 271, loss 2.1313109397888184, acc 0.36000001430511475\n",
      "Epoch 9, iter 272, loss 2.140326499938965, acc 0.3100000023841858\n",
      "Epoch 9, iter 273, loss 2.1452205181121826, acc 0.33000001311302185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 274, loss 2.127560615539551, acc 0.3400000035762787\n",
      "Epoch 9, iter 275, loss 2.161324977874756, acc 0.3100000023841858\n",
      "Epoch 9, iter 276, loss 2.136467456817627, acc 0.3799999952316284\n",
      "Epoch 9, iter 277, loss 2.098576545715332, acc 0.3700000047683716\n",
      "Epoch 9, iter 278, loss 2.0728282928466797, acc 0.46000000834465027\n",
      "Epoch 9, iter 279, loss 2.0873966217041016, acc 0.4300000071525574\n",
      "Epoch 9, iter 280, loss 2.0939524173736572, acc 0.3799999952316284\n",
      "Epoch 9, iter 281, loss 2.1126880645751953, acc 0.4000000059604645\n",
      "Epoch 9, iter 282, loss 2.1482491493225098, acc 0.3400000035762787\n",
      "Epoch 9, iter 283, loss 2.092223882675171, acc 0.3400000035762787\n",
      "Epoch 9, iter 284, loss 2.058969497680664, acc 0.5099999904632568\n",
      "Epoch 9, iter 285, loss 2.079519271850586, acc 0.3799999952316284\n",
      "Epoch 9, iter 286, loss 2.076387405395508, acc 0.46000000834465027\n",
      "Epoch 9, iter 287, loss 2.1111021041870117, acc 0.4099999964237213\n",
      "Epoch 9, iter 288, loss 2.0620248317718506, acc 0.41999998688697815\n",
      "Epoch 9, iter 289, loss 2.142124891281128, acc 0.3400000035762787\n",
      "Epoch 9, iter 290, loss 2.0697944164276123, acc 0.4000000059604645\n",
      "Epoch 9, iter 291, loss 2.0878608226776123, acc 0.4399999976158142\n",
      "Epoch 9, iter 292, loss 2.08197021484375, acc 0.4000000059604645\n",
      "Epoch 9, iter 293, loss 2.101409673690796, acc 0.36000001430511475\n",
      "Epoch 9, iter 294, loss 2.1484341621398926, acc 0.28999999165534973\n",
      "Epoch 9, iter 295, loss 2.10677433013916, acc 0.4000000059604645\n",
      "Epoch 9, iter 296, loss 2.0674822330474854, acc 0.4399999976158142\n",
      "Epoch 9, iter 297, loss 2.1481266021728516, acc 0.36000001430511475\n",
      "Epoch 9, iter 298, loss 2.0818681716918945, acc 0.41999998688697815\n",
      "Epoch 9, iter 299, loss 2.168583631515503, acc 0.3100000023841858\n",
      "Epoch 9, iter 300, loss 2.1236953735351562, acc 0.33000001311302185\n",
      "Epoch 9, iter 301, loss 2.118656873703003, acc 0.3700000047683716\n",
      "Epoch 9, iter 302, loss 2.0784573554992676, acc 0.41999998688697815\n",
      "Epoch 9, iter 303, loss 2.101773262023926, acc 0.36000001430511475\n",
      "Epoch 9, iter 304, loss 2.1517324447631836, acc 0.3199999928474426\n",
      "Epoch 9, iter 305, loss 2.191622734069824, acc 0.25999999046325684\n",
      "Epoch 9, iter 306, loss 2.0650484561920166, acc 0.4099999964237213\n",
      "Epoch 9, iter 307, loss 2.092017889022827, acc 0.36000001430511475\n",
      "Epoch 9, iter 308, loss 2.170602321624756, acc 0.28999999165534973\n",
      "Epoch 9, iter 309, loss 2.0986592769622803, acc 0.3700000047683716\n",
      "Epoch 9, iter 310, loss 2.1384170055389404, acc 0.3100000023841858\n",
      "Epoch 9, iter 311, loss 2.1079583168029785, acc 0.36000001430511475\n",
      "Epoch 9, iter 312, loss 2.0903799533843994, acc 0.4000000059604645\n",
      "Epoch 9, iter 313, loss 2.1946494579315186, acc 0.1899999976158142\n",
      "Epoch 9, iter 314, loss 2.063840866088867, acc 0.4099999964237213\n",
      "Epoch 9, iter 315, loss 2.0993824005126953, acc 0.4300000071525574\n",
      "Epoch 9, iter 316, loss 2.1397407054901123, acc 0.36000001430511475\n",
      "Epoch 9, iter 317, loss 2.1168222427368164, acc 0.38999998569488525\n",
      "Epoch 9, iter 318, loss 2.090433120727539, acc 0.4000000059604645\n",
      "Epoch 9, iter 319, loss 2.088006019592285, acc 0.3700000047683716\n",
      "Epoch 9, iter 320, loss 2.1885883808135986, acc 0.28999999165534973\n",
      "Epoch 9, iter 321, loss 2.1296935081481934, acc 0.3400000035762787\n",
      "Epoch 9, iter 322, loss 2.113416910171509, acc 0.3499999940395355\n",
      "Epoch 9, iter 323, loss 2.0994744300842285, acc 0.3700000047683716\n",
      "Epoch 9, iter 324, loss 2.0430142879486084, acc 0.41999998688697815\n",
      "Epoch 9, iter 325, loss 2.1356441974639893, acc 0.36000001430511475\n",
      "Epoch 9, iter 326, loss 2.071467638015747, acc 0.46000000834465027\n",
      "Epoch 9, iter 327, loss 2.1299784183502197, acc 0.3700000047683716\n",
      "Epoch 9, iter 328, loss 2.0814948081970215, acc 0.4000000059604645\n",
      "Epoch 9, iter 329, loss 2.0936760902404785, acc 0.36000001430511475\n",
      "Epoch 9, iter 330, loss 2.1100053787231445, acc 0.4099999964237213\n",
      "Epoch 9, iter 331, loss 2.126631736755371, acc 0.33000001311302185\n",
      "Epoch 9, iter 332, loss 2.125851631164551, acc 0.4099999964237213\n",
      "Epoch 9, iter 333, loss 2.0923757553100586, acc 0.4300000071525574\n",
      "Epoch 9, iter 334, loss 2.144749879837036, acc 0.3400000035762787\n",
      "Epoch 9, iter 335, loss 2.0277974605560303, acc 0.4699999988079071\n",
      "Epoch 9, iter 336, loss 2.098055362701416, acc 0.36000001430511475\n",
      "Epoch 9, iter 337, loss 2.103942394256592, acc 0.3799999952316284\n",
      "Epoch 9, iter 338, loss 2.0994856357574463, acc 0.3400000035762787\n",
      "Epoch 9, iter 339, loss 2.1101601123809814, acc 0.4000000059604645\n",
      "Epoch 9, iter 340, loss 2.103131055831909, acc 0.4300000071525574\n",
      "Epoch 9, iter 341, loss 2.0789406299591064, acc 0.44999998807907104\n",
      "Epoch 9, iter 342, loss 2.0868706703186035, acc 0.38999998569488525\n",
      "Epoch 9, iter 343, loss 2.1573429107666016, acc 0.30000001192092896\n",
      "Epoch 9, iter 344, loss 2.071469306945801, acc 0.3799999952316284\n",
      "Epoch 9, iter 345, loss 2.152376413345337, acc 0.28999999165534973\n",
      "Epoch 9, iter 346, loss 2.0595462322235107, acc 0.4300000071525574\n",
      "Epoch 9, iter 347, loss 2.159273862838745, acc 0.30000001192092896\n",
      "Epoch 9, iter 348, loss 2.0654759407043457, acc 0.4399999976158142\n",
      "Epoch 9, iter 349, loss 2.035935640335083, acc 0.4699999988079071\n",
      "Epoch 9, iter 350, loss 2.0957188606262207, acc 0.44999998807907104\n",
      "Epoch 9, iter 351, loss 2.0921428203582764, acc 0.4099999964237213\n",
      "Epoch 9, iter 352, loss 2.1182801723480225, acc 0.3700000047683716\n",
      "Epoch 9, iter 353, loss 2.0967438220977783, acc 0.4399999976158142\n",
      "Epoch 9, iter 354, loss 2.066582441329956, acc 0.41999998688697815\n",
      "Epoch 9, iter 355, loss 2.1280360221862793, acc 0.3499999940395355\n",
      "Epoch 9, iter 356, loss 2.106426954269409, acc 0.4099999964237213\n",
      "Epoch 9, iter 357, loss 2.1187028884887695, acc 0.3700000047683716\n",
      "Epoch 9, iter 358, loss 2.1726386547088623, acc 0.30000001192092896\n",
      "Epoch 9, iter 359, loss 2.1088390350341797, acc 0.3400000035762787\n",
      "Epoch 9, iter 360, loss 2.1115667819976807, acc 0.4000000059604645\n",
      "Epoch 9, iter 361, loss 2.084618330001831, acc 0.4300000071525574\n",
      "Epoch 9, iter 362, loss 2.1591732501983643, acc 0.2800000011920929\n",
      "Epoch 9, iter 363, loss 2.109348773956299, acc 0.3799999952316284\n",
      "Epoch 9, iter 364, loss 2.1082117557525635, acc 0.36000001430511475\n",
      "Epoch 9, iter 365, loss 2.088083505630493, acc 0.41999998688697815\n",
      "Epoch 9, iter 366, loss 2.0581696033477783, acc 0.41999998688697815\n",
      "Epoch 9, iter 367, loss 2.0701799392700195, acc 0.4399999976158142\n",
      "Epoch 9, iter 368, loss 2.082129955291748, acc 0.41999998688697815\n",
      "Epoch 9, iter 369, loss 2.0882184505462646, acc 0.4300000071525574\n",
      "Epoch 9, iter 370, loss 2.0713868141174316, acc 0.4000000059604645\n",
      "Epoch 9, iter 371, loss 2.0567853450775146, acc 0.44999998807907104\n",
      "Epoch 9, iter 372, loss 2.096066951751709, acc 0.4000000059604645\n",
      "Epoch 9, iter 373, loss 2.1178274154663086, acc 0.3400000035762787\n",
      "Epoch 9, iter 374, loss 2.1219284534454346, acc 0.38999998569488525\n",
      "Epoch 9, iter 375, loss 2.114579200744629, acc 0.3700000047683716\n",
      "Epoch 9, iter 376, loss 2.1265175342559814, acc 0.3100000023841858\n",
      "Epoch 9, iter 377, loss 2.0795960426330566, acc 0.4000000059604645\n",
      "Epoch 9, iter 378, loss 2.0741183757781982, acc 0.4399999976158142\n",
      "Epoch 9, iter 379, loss 2.150055408477783, acc 0.33000001311302185\n",
      "Epoch 9, iter 380, loss 2.1275525093078613, acc 0.3499999940395355\n",
      "Epoch 9, iter 381, loss 2.1181037425994873, acc 0.3499999940395355\n",
      "Epoch 9, iter 382, loss 2.073047161102295, acc 0.4300000071525574\n",
      "Epoch 9, iter 383, loss 2.0679492950439453, acc 0.5\n",
      "Epoch 9, iter 384, loss 2.1345601081848145, acc 0.3499999940395355\n",
      "Epoch 9, iter 385, loss 2.109989643096924, acc 0.3700000047683716\n",
      "Epoch 9, iter 386, loss 2.1025688648223877, acc 0.3499999940395355\n",
      "Epoch 9, iter 387, loss 2.112358808517456, acc 0.3700000047683716\n",
      "Epoch 9, iter 388, loss 2.105477809906006, acc 0.3799999952316284\n",
      "Epoch 9, iter 389, loss 2.114072322845459, acc 0.3700000047683716\n",
      "Epoch 9, iter 390, loss 2.174744129180908, acc 0.28999999165534973\n",
      "Epoch 9, iter 391, loss 2.1071553230285645, acc 0.4000000059604645\n",
      "Epoch 9, iter 392, loss 2.1191940307617188, acc 0.3700000047683716\n",
      "Epoch 9, iter 393, loss 2.1106550693511963, acc 0.3799999952316284\n",
      "Epoch 9, iter 394, loss 2.076620101928711, acc 0.4399999976158142\n",
      "Epoch 9, iter 395, loss 2.0366199016571045, acc 0.46000000834465027\n",
      "Epoch 9, iter 396, loss 2.1090314388275146, acc 0.3700000047683716\n",
      "Epoch 9, iter 397, loss 2.1010637283325195, acc 0.41999998688697815\n",
      "Epoch 9, iter 398, loss 2.131075382232666, acc 0.3799999952316284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iter 399, loss 2.0995397567749023, acc 0.4000000059604645\n",
      "Epoch 9, iter 400, loss 2.051668643951416, acc 0.5\n",
      "Epoch 9, iter 401, loss 2.0744385719299316, acc 0.41999998688697815\n",
      "Epoch 9, iter 402, loss 2.070394992828369, acc 0.4399999976158142\n",
      "Epoch 9, iter 403, loss 2.1104471683502197, acc 0.4000000059604645\n",
      "Epoch 9, iter 404, loss 2.1286213397979736, acc 0.3400000035762787\n",
      "Epoch 9, iter 405, loss 2.1126556396484375, acc 0.4099999964237213\n",
      "Epoch 9, iter 406, loss 2.133089303970337, acc 0.3100000023841858\n",
      "Epoch 9, iter 407, loss 2.123231887817383, acc 0.33000001311302185\n",
      "Epoch 9, iter 408, loss 2.1449084281921387, acc 0.33000001311302185\n",
      "Epoch 9, iter 409, loss 2.1002461910247803, acc 0.4099999964237213\n",
      "Epoch 9, iter 410, loss 2.0687127113342285, acc 0.4399999976158142\n",
      "Epoch 9, iter 411, loss 2.084475040435791, acc 0.38999998569488525\n",
      "Epoch 9, iter 412, loss 2.081815719604492, acc 0.46000000834465027\n",
      "Epoch 9, iter 413, loss 2.1107091903686523, acc 0.4000000059604645\n",
      "Epoch 9, iter 414, loss 2.125227928161621, acc 0.3199999928474426\n",
      "Epoch 9, iter 415, loss 2.1470787525177, acc 0.33000001311302185\n",
      "Epoch 9, iter 416, loss 2.0886478424072266, acc 0.38999998569488525\n",
      "Epoch 9, iter 417, loss 2.0480668544769287, acc 0.47999998927116394\n",
      "Epoch 9, iter 418, loss 2.0842998027801514, acc 0.3799999952316284\n",
      "Epoch 9, iter 419, loss 2.0674047470092773, acc 0.4099999964237213\n",
      "Epoch 9, iter 420, loss 2.1170756816864014, acc 0.3400000035762787\n",
      "Epoch 10, iter 1, loss 2.059237241744995, acc 0.4099999964237213\n",
      "Epoch 10, iter 2, loss 2.127945899963379, acc 0.4099999964237213\n",
      "Epoch 10, iter 3, loss 2.0783238410949707, acc 0.46000000834465027\n",
      "Epoch 10, iter 4, loss 2.1711504459381104, acc 0.28999999165534973\n",
      "Epoch 10, iter 5, loss 2.15510630607605, acc 0.27000001072883606\n",
      "Epoch 10, iter 6, loss 2.152522087097168, acc 0.2800000011920929\n",
      "Epoch 10, iter 7, loss 2.1140449047088623, acc 0.3799999952316284\n",
      "Epoch 10, iter 8, loss 2.0917418003082275, acc 0.4099999964237213\n",
      "Epoch 10, iter 9, loss 2.1393113136291504, acc 0.3799999952316284\n",
      "Epoch 10, iter 10, loss 2.161590337753296, acc 0.3199999928474426\n",
      "Epoch 10, iter 11, loss 2.152559280395508, acc 0.3199999928474426\n",
      "Epoch 10, iter 12, loss 2.128535509109497, acc 0.3199999928474426\n",
      "Epoch 10, iter 13, loss 2.1241464614868164, acc 0.3199999928474426\n",
      "Epoch 10, iter 14, loss 2.060105800628662, acc 0.4300000071525574\n",
      "Epoch 10, iter 15, loss 2.0590226650238037, acc 0.4399999976158142\n",
      "Epoch 10, iter 16, loss 2.094860315322876, acc 0.3700000047683716\n",
      "Epoch 10, iter 17, loss 2.152179718017578, acc 0.3199999928474426\n",
      "Epoch 10, iter 18, loss 2.1367392539978027, acc 0.3400000035762787\n",
      "Epoch 10, iter 19, loss 2.100879192352295, acc 0.3400000035762787\n",
      "Epoch 10, iter 20, loss 2.0719380378723145, acc 0.4399999976158142\n",
      "Epoch 10, iter 21, loss 2.0705809593200684, acc 0.41999998688697815\n",
      "Epoch 10, iter 22, loss 2.1258928775787354, acc 0.36000001430511475\n",
      "Epoch 10, iter 23, loss 2.079587459564209, acc 0.41999998688697815\n",
      "Epoch 10, iter 24, loss 2.1375393867492676, acc 0.28999999165534973\n",
      "Epoch 10, iter 25, loss 2.122903823852539, acc 0.3799999952316284\n",
      "Epoch 10, iter 26, loss 2.1263773441314697, acc 0.3700000047683716\n",
      "Epoch 10, iter 27, loss 2.0980007648468018, acc 0.4399999976158142\n",
      "Epoch 10, iter 28, loss 2.035538911819458, acc 0.5099999904632568\n",
      "Epoch 10, iter 29, loss 2.11777663230896, acc 0.3799999952316284\n",
      "Epoch 10, iter 30, loss 2.128241539001465, acc 0.3400000035762787\n",
      "Epoch 10, iter 31, loss 2.178560256958008, acc 0.30000001192092896\n",
      "Epoch 10, iter 32, loss 2.0941169261932373, acc 0.4000000059604645\n",
      "Epoch 10, iter 33, loss 2.1187174320220947, acc 0.41999998688697815\n",
      "Epoch 10, iter 34, loss 2.0680320262908936, acc 0.4399999976158142\n",
      "Epoch 10, iter 35, loss 2.1102468967437744, acc 0.3700000047683716\n",
      "Epoch 10, iter 36, loss 2.0995726585388184, acc 0.38999998569488525\n",
      "Epoch 10, iter 37, loss 2.1477346420288086, acc 0.30000001192092896\n",
      "Epoch 10, iter 38, loss 2.1245200634002686, acc 0.4099999964237213\n",
      "Epoch 10, iter 39, loss 2.074366569519043, acc 0.4000000059604645\n",
      "Epoch 10, iter 40, loss 2.0450708866119385, acc 0.4300000071525574\n",
      "Epoch 10, iter 41, loss 2.144615411758423, acc 0.33000001311302185\n",
      "Epoch 10, iter 42, loss 2.0894501209259033, acc 0.41999998688697815\n",
      "Epoch 10, iter 43, loss 2.0398929119110107, acc 0.4300000071525574\n",
      "Epoch 10, iter 44, loss 2.053199291229248, acc 0.4099999964237213\n",
      "Epoch 10, iter 45, loss 2.113671064376831, acc 0.3700000047683716\n",
      "Epoch 10, iter 46, loss 2.103224039077759, acc 0.4300000071525574\n",
      "Epoch 10, iter 47, loss 2.1564230918884277, acc 0.27000001072883606\n",
      "Epoch 10, iter 48, loss 2.0794577598571777, acc 0.3700000047683716\n",
      "Epoch 10, iter 49, loss 2.107165575027466, acc 0.36000001430511475\n",
      "Epoch 10, iter 50, loss 2.1364798545837402, acc 0.3400000035762787\n",
      "Epoch 10, iter 51, loss 2.0804266929626465, acc 0.4000000059604645\n",
      "Epoch 10, iter 52, loss 2.138766288757324, acc 0.3100000023841858\n",
      "Epoch 10, iter 53, loss 2.0866293907165527, acc 0.38999998569488525\n",
      "Epoch 10, iter 54, loss 2.0906190872192383, acc 0.38999998569488525\n",
      "Epoch 10, iter 55, loss 2.190707206726074, acc 0.2800000011920929\n",
      "Epoch 10, iter 56, loss 2.0826146602630615, acc 0.4000000059604645\n",
      "Epoch 10, iter 57, loss 2.163590908050537, acc 0.3100000023841858\n",
      "Epoch 10, iter 58, loss 2.1073355674743652, acc 0.4099999964237213\n",
      "Epoch 10, iter 59, loss 2.0835392475128174, acc 0.41999998688697815\n",
      "Epoch 10, iter 60, loss 2.093775987625122, acc 0.4399999976158142\n",
      "Epoch 10, iter 61, loss 2.0847885608673096, acc 0.4099999964237213\n",
      "Epoch 10, iter 62, loss 2.1067721843719482, acc 0.3799999952316284\n",
      "Epoch 10, iter 63, loss 2.1258504390716553, acc 0.3799999952316284\n",
      "Epoch 10, iter 64, loss 2.0825235843658447, acc 0.36000001430511475\n",
      "Epoch 10, iter 65, loss 2.099423885345459, acc 0.4399999976158142\n",
      "Epoch 10, iter 66, loss 2.100583553314209, acc 0.33000001311302185\n",
      "Epoch 10, iter 67, loss 2.123090982437134, acc 0.3199999928474426\n",
      "Epoch 10, iter 68, loss 2.054783582687378, acc 0.47999998927116394\n",
      "Epoch 10, iter 69, loss 2.102438449859619, acc 0.36000001430511475\n",
      "Epoch 10, iter 70, loss 2.1014227867126465, acc 0.4099999964237213\n",
      "Epoch 10, iter 71, loss 2.116255283355713, acc 0.38999998569488525\n",
      "Epoch 10, iter 72, loss 2.088515520095825, acc 0.3700000047683716\n",
      "Epoch 10, iter 73, loss 2.0676915645599365, acc 0.4399999976158142\n",
      "Epoch 10, iter 74, loss 2.1151363849639893, acc 0.3700000047683716\n",
      "Epoch 10, iter 75, loss 2.0992910861968994, acc 0.3799999952316284\n",
      "Epoch 10, iter 76, loss 2.106308698654175, acc 0.3799999952316284\n",
      "Epoch 10, iter 77, loss 2.1506147384643555, acc 0.30000001192092896\n",
      "Epoch 10, iter 78, loss 2.095579147338867, acc 0.4399999976158142\n",
      "Epoch 10, iter 79, loss 2.1071648597717285, acc 0.3499999940395355\n",
      "Epoch 10, iter 80, loss 2.0977323055267334, acc 0.3799999952316284\n",
      "Epoch 10, iter 81, loss 2.140202522277832, acc 0.3199999928474426\n",
      "Epoch 10, iter 82, loss 2.142714023590088, acc 0.2800000011920929\n",
      "Epoch 10, iter 83, loss 2.055314064025879, acc 0.46000000834465027\n",
      "Epoch 10, iter 84, loss 2.1241002082824707, acc 0.3499999940395355\n",
      "Epoch 10, iter 85, loss 2.150789976119995, acc 0.3199999928474426\n",
      "Epoch 10, iter 86, loss 2.102839469909668, acc 0.38999998569488525\n",
      "Epoch 10, iter 87, loss 2.112684488296509, acc 0.4099999964237213\n",
      "Epoch 10, iter 88, loss 2.052661895751953, acc 0.44999998807907104\n",
      "Epoch 10, iter 89, loss 2.112962245941162, acc 0.3799999952316284\n",
      "Epoch 10, iter 90, loss 2.096555709838867, acc 0.3799999952316284\n",
      "Epoch 10, iter 91, loss 2.085299253463745, acc 0.3799999952316284\n",
      "Epoch 10, iter 92, loss 2.13084077835083, acc 0.3799999952316284\n",
      "Epoch 10, iter 93, loss 2.0411133766174316, acc 0.5\n",
      "Epoch 10, iter 94, loss 2.1129612922668457, acc 0.3400000035762787\n",
      "Epoch 10, iter 95, loss 2.092743158340454, acc 0.3799999952316284\n",
      "Epoch 10, iter 96, loss 2.1270763874053955, acc 0.36000001430511475\n",
      "Epoch 10, iter 97, loss 2.1144003868103027, acc 0.3400000035762787\n",
      "Epoch 10, iter 98, loss 2.1089954376220703, acc 0.3400000035762787\n",
      "Epoch 10, iter 99, loss 2.1104681491851807, acc 0.36000001430511475\n",
      "Epoch 10, iter 100, loss 2.1011993885040283, acc 0.3799999952316284\n",
      "Epoch 10, iter 101, loss 2.086940050125122, acc 0.41999998688697815\n",
      "Epoch 10, iter 102, loss 2.113635301589966, acc 0.3499999940395355\n",
      "Epoch 10, iter 103, loss 2.0778985023498535, acc 0.44999998807907104\n",
      "Epoch 10, iter 104, loss 2.149827241897583, acc 0.33000001311302185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 105, loss 2.0234382152557373, acc 0.4399999976158142\n",
      "Epoch 10, iter 106, loss 2.0907764434814453, acc 0.3700000047683716\n",
      "Epoch 10, iter 107, loss 2.097010612487793, acc 0.3499999940395355\n",
      "Epoch 10, iter 108, loss 2.1496803760528564, acc 0.2800000011920929\n",
      "Epoch 10, iter 109, loss 2.1061298847198486, acc 0.38999998569488525\n",
      "Epoch 10, iter 110, loss 2.1347765922546387, acc 0.36000001430511475\n",
      "Epoch 10, iter 111, loss 2.1134674549102783, acc 0.3199999928474426\n",
      "Epoch 10, iter 112, loss 2.1165337562561035, acc 0.3100000023841858\n",
      "Epoch 10, iter 113, loss 2.047872543334961, acc 0.5\n",
      "Epoch 10, iter 114, loss 2.0763394832611084, acc 0.36000001430511475\n",
      "Epoch 10, iter 115, loss 2.0867435932159424, acc 0.4000000059604645\n",
      "Epoch 10, iter 116, loss 2.075977087020874, acc 0.41999998688697815\n",
      "Epoch 10, iter 117, loss 2.1083152294158936, acc 0.4000000059604645\n",
      "Epoch 10, iter 118, loss 2.1156461238861084, acc 0.33000001311302185\n",
      "Epoch 10, iter 119, loss 2.117030143737793, acc 0.3799999952316284\n",
      "Epoch 10, iter 120, loss 2.1280105113983154, acc 0.3400000035762787\n",
      "Epoch 10, iter 121, loss 2.120983839035034, acc 0.38999998569488525\n",
      "Epoch 10, iter 122, loss 2.079073429107666, acc 0.4399999976158142\n",
      "Epoch 10, iter 123, loss 2.142059087753296, acc 0.3100000023841858\n",
      "Epoch 10, iter 124, loss 2.032029867172241, acc 0.5199999809265137\n",
      "Epoch 10, iter 125, loss 2.123272180557251, acc 0.36000001430511475\n",
      "Epoch 10, iter 126, loss 2.0850467681884766, acc 0.3700000047683716\n",
      "Epoch 10, iter 127, loss 2.0894370079040527, acc 0.41999998688697815\n",
      "Epoch 10, iter 128, loss 2.125140905380249, acc 0.36000001430511475\n",
      "Epoch 10, iter 129, loss 2.141355037689209, acc 0.33000001311302185\n",
      "Epoch 10, iter 130, loss 2.151705265045166, acc 0.33000001311302185\n",
      "Epoch 10, iter 131, loss 2.1597390174865723, acc 0.3700000047683716\n",
      "Epoch 10, iter 132, loss 2.1190061569213867, acc 0.36000001430511475\n",
      "Epoch 10, iter 133, loss 2.094245195388794, acc 0.41999998688697815\n",
      "Epoch 10, iter 134, loss 2.144498348236084, acc 0.3199999928474426\n",
      "Epoch 10, iter 135, loss 2.1263298988342285, acc 0.3700000047683716\n",
      "Epoch 10, iter 136, loss 2.0779199600219727, acc 0.4000000059604645\n",
      "Epoch 10, iter 137, loss 2.1056222915649414, acc 0.3700000047683716\n",
      "Epoch 10, iter 138, loss 2.1107358932495117, acc 0.4000000059604645\n",
      "Epoch 10, iter 139, loss 2.1428334712982178, acc 0.30000001192092896\n",
      "Epoch 10, iter 140, loss 2.113748073577881, acc 0.3700000047683716\n",
      "Epoch 10, iter 141, loss 2.0939009189605713, acc 0.38999998569488525\n",
      "Epoch 10, iter 142, loss 2.115196466445923, acc 0.33000001311302185\n",
      "Epoch 10, iter 143, loss 2.1044068336486816, acc 0.3400000035762787\n",
      "Epoch 10, iter 144, loss 2.145082712173462, acc 0.2800000011920929\n",
      "Epoch 10, iter 145, loss 2.0822806358337402, acc 0.4099999964237213\n",
      "Epoch 10, iter 146, loss 2.1075634956359863, acc 0.3400000035762787\n",
      "Epoch 10, iter 147, loss 2.1046793460845947, acc 0.3700000047683716\n",
      "Epoch 10, iter 148, loss 2.066305160522461, acc 0.41999998688697815\n",
      "Epoch 10, iter 149, loss 2.0600061416625977, acc 0.38999998569488525\n",
      "Epoch 10, iter 150, loss 2.1266531944274902, acc 0.3499999940395355\n",
      "Epoch 10, iter 151, loss 2.006492853164673, acc 0.46000000834465027\n",
      "Epoch 10, iter 152, loss 2.091671943664551, acc 0.41999998688697815\n",
      "Epoch 10, iter 153, loss 2.091127872467041, acc 0.4300000071525574\n",
      "Epoch 10, iter 154, loss 2.109800338745117, acc 0.3499999940395355\n",
      "Epoch 10, iter 155, loss 2.1162047386169434, acc 0.3100000023841858\n",
      "Epoch 10, iter 156, loss 2.0998311042785645, acc 0.41999998688697815\n",
      "Epoch 10, iter 157, loss 2.159409284591675, acc 0.27000001072883606\n",
      "Epoch 10, iter 158, loss 2.1235930919647217, acc 0.36000001430511475\n",
      "Epoch 10, iter 159, loss 2.084300994873047, acc 0.3799999952316284\n",
      "Epoch 10, iter 160, loss 2.122929811477661, acc 0.3499999940395355\n",
      "Epoch 10, iter 161, loss 2.0903358459472656, acc 0.3499999940395355\n",
      "Epoch 10, iter 162, loss 2.008352041244507, acc 0.5199999809265137\n",
      "Epoch 10, iter 163, loss 2.1176772117614746, acc 0.3700000047683716\n",
      "Epoch 10, iter 164, loss 2.107039451599121, acc 0.38999998569488525\n",
      "Epoch 10, iter 165, loss 2.1569998264312744, acc 0.3499999940395355\n",
      "Epoch 10, iter 166, loss 2.0951149463653564, acc 0.4099999964237213\n",
      "Epoch 10, iter 167, loss 2.124884605407715, acc 0.3100000023841858\n",
      "Epoch 10, iter 168, loss 2.0749568939208984, acc 0.41999998688697815\n",
      "Epoch 10, iter 169, loss 2.037665367126465, acc 0.41999998688697815\n",
      "Epoch 10, iter 170, loss 2.105102777481079, acc 0.3400000035762787\n",
      "Epoch 10, iter 171, loss 2.0739922523498535, acc 0.44999998807907104\n",
      "Epoch 10, iter 172, loss 2.1176345348358154, acc 0.36000001430511475\n",
      "Epoch 10, iter 173, loss 2.1315109729766846, acc 0.36000001430511475\n",
      "Epoch 10, iter 174, loss 2.065157413482666, acc 0.41999998688697815\n",
      "Epoch 10, iter 175, loss 2.0736496448516846, acc 0.4300000071525574\n",
      "Epoch 10, iter 176, loss 2.140327215194702, acc 0.30000001192092896\n",
      "Epoch 10, iter 177, loss 2.092233657836914, acc 0.41999998688697815\n",
      "Epoch 10, iter 178, loss 2.0943820476531982, acc 0.38999998569488525\n",
      "Epoch 10, iter 179, loss 2.115494728088379, acc 0.3400000035762787\n",
      "Epoch 10, iter 180, loss 2.1389694213867188, acc 0.3400000035762787\n",
      "Epoch 10, iter 181, loss 2.0206234455108643, acc 0.5099999904632568\n",
      "Epoch 10, iter 182, loss 2.125883102416992, acc 0.4099999964237213\n",
      "Epoch 10, iter 183, loss 2.1033949851989746, acc 0.38999998569488525\n",
      "Epoch 10, iter 184, loss 2.099041223526001, acc 0.3700000047683716\n",
      "Epoch 10, iter 185, loss 2.0828123092651367, acc 0.4300000071525574\n",
      "Epoch 10, iter 186, loss 2.1038777828216553, acc 0.36000001430511475\n",
      "Epoch 10, iter 187, loss 2.105849504470825, acc 0.3700000047683716\n",
      "Epoch 10, iter 188, loss 2.1399130821228027, acc 0.33000001311302185\n",
      "Epoch 10, iter 189, loss 2.178342342376709, acc 0.2800000011920929\n",
      "Epoch 10, iter 190, loss 2.0656557083129883, acc 0.44999998807907104\n",
      "Epoch 10, iter 191, loss 2.12086820602417, acc 0.33000001311302185\n",
      "Epoch 10, iter 192, loss 2.1000521183013916, acc 0.3799999952316284\n",
      "Epoch 10, iter 193, loss 2.0765161514282227, acc 0.4300000071525574\n",
      "Epoch 10, iter 194, loss 2.0992870330810547, acc 0.3700000047683716\n",
      "Epoch 10, iter 195, loss 2.042757034301758, acc 0.4399999976158142\n",
      "Epoch 10, iter 196, loss 2.138352394104004, acc 0.36000001430511475\n",
      "Epoch 10, iter 197, loss 2.0985894203186035, acc 0.4300000071525574\n",
      "Epoch 10, iter 198, loss 2.0339860916137695, acc 0.44999998807907104\n",
      "Epoch 10, iter 199, loss 2.128882646560669, acc 0.3499999940395355\n",
      "Epoch 10, iter 200, loss 2.1257879734039307, acc 0.3799999952316284\n",
      "Epoch 10, iter 201, loss 2.0577902793884277, acc 0.5099999904632568\n",
      "Epoch 10, iter 202, loss 2.0804853439331055, acc 0.4300000071525574\n",
      "Epoch 10, iter 203, loss 2.1130216121673584, acc 0.3700000047683716\n",
      "Epoch 10, iter 204, loss 2.0630409717559814, acc 0.44999998807907104\n",
      "Epoch 10, iter 205, loss 2.0272836685180664, acc 0.49000000953674316\n",
      "Epoch 10, iter 206, loss 2.123244285583496, acc 0.30000001192092896\n",
      "Epoch 10, iter 207, loss 2.111184597015381, acc 0.3700000047683716\n",
      "Epoch 10, iter 208, loss 2.1372649669647217, acc 0.3700000047683716\n",
      "Epoch 10, iter 209, loss 2.142582416534424, acc 0.3100000023841858\n",
      "Epoch 10, iter 210, loss 2.1743361949920654, acc 0.27000001072883606\n",
      "Epoch 10, iter 211, loss 2.089491367340088, acc 0.4099999964237213\n",
      "Epoch 10, iter 212, loss 2.1409244537353516, acc 0.28999999165534973\n",
      "Epoch 10, iter 213, loss 2.1216893196105957, acc 0.38999998569488525\n",
      "Epoch 10, iter 214, loss 2.1352105140686035, acc 0.3499999940395355\n",
      "Epoch 10, iter 215, loss 2.1117866039276123, acc 0.3499999940395355\n",
      "Epoch 10, iter 216, loss 2.153587579727173, acc 0.2800000011920929\n",
      "Epoch 10, iter 217, loss 2.0736663341522217, acc 0.41999998688697815\n",
      "Epoch 10, iter 218, loss 2.171002149581909, acc 0.3100000023841858\n",
      "Epoch 10, iter 219, loss 2.116608142852783, acc 0.33000001311302185\n",
      "Epoch 10, iter 220, loss 2.0569329261779785, acc 0.4699999988079071\n",
      "Epoch 10, iter 221, loss 2.070260524749756, acc 0.44999998807907104\n",
      "Epoch 10, iter 222, loss 2.1145071983337402, acc 0.3700000047683716\n",
      "Epoch 10, iter 223, loss 2.0503764152526855, acc 0.5\n",
      "Epoch 10, iter 224, loss 2.1201179027557373, acc 0.4000000059604645\n",
      "Epoch 10, iter 225, loss 2.080690383911133, acc 0.3700000047683716\n",
      "Epoch 10, iter 226, loss 2.099247694015503, acc 0.3700000047683716\n",
      "Epoch 10, iter 227, loss 2.0977141857147217, acc 0.4099999964237213\n",
      "Epoch 10, iter 228, loss 2.116887092590332, acc 0.3499999940395355\n",
      "Epoch 10, iter 229, loss 2.0878419876098633, acc 0.38999998569488525\n",
      "Epoch 10, iter 230, loss 2.0976674556732178, acc 0.3799999952316284\n",
      "Epoch 10, iter 231, loss 2.0818276405334473, acc 0.3799999952316284\n",
      "Epoch 10, iter 232, loss 2.1205544471740723, acc 0.3400000035762787\n",
      "Epoch 10, iter 233, loss 2.064424753189087, acc 0.4300000071525574\n",
      "Epoch 10, iter 234, loss 2.0320611000061035, acc 0.5199999809265137\n",
      "Epoch 10, iter 235, loss 2.0944855213165283, acc 0.38999998569488525\n",
      "Epoch 10, iter 236, loss 2.118502140045166, acc 0.36000001430511475\n",
      "Epoch 10, iter 237, loss 2.138749599456787, acc 0.3400000035762787\n",
      "Epoch 10, iter 238, loss 2.0895471572875977, acc 0.4300000071525574\n",
      "Epoch 10, iter 239, loss 2.093839645385742, acc 0.4300000071525574\n",
      "Epoch 10, iter 240, loss 2.123015880584717, acc 0.33000001311302185\n",
      "Epoch 10, iter 241, loss 2.11673641204834, acc 0.3400000035762787\n",
      "Epoch 10, iter 242, loss 2.1221718788146973, acc 0.4099999964237213\n",
      "Epoch 10, iter 243, loss 2.1644418239593506, acc 0.30000001192092896\n",
      "Epoch 10, iter 244, loss 2.0650343894958496, acc 0.44999998807907104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 245, loss 2.075016736984253, acc 0.4300000071525574\n",
      "Epoch 10, iter 246, loss 2.180266857147217, acc 0.27000001072883606\n",
      "Epoch 10, iter 247, loss 2.0702686309814453, acc 0.4699999988079071\n",
      "Epoch 10, iter 248, loss 2.1402928829193115, acc 0.3199999928474426\n",
      "Epoch 10, iter 249, loss 2.1457412242889404, acc 0.3199999928474426\n",
      "Epoch 10, iter 250, loss 2.040640115737915, acc 0.5\n",
      "Epoch 10, iter 251, loss 2.1273622512817383, acc 0.3199999928474426\n",
      "Epoch 10, iter 252, loss 2.086174726486206, acc 0.4099999964237213\n",
      "Epoch 10, iter 253, loss 2.1437902450561523, acc 0.3700000047683716\n",
      "Epoch 10, iter 254, loss 2.127432346343994, acc 0.38999998569488525\n",
      "Epoch 10, iter 255, loss 2.1239285469055176, acc 0.3400000035762787\n",
      "Epoch 10, iter 256, loss 2.078380823135376, acc 0.46000000834465027\n",
      "Epoch 10, iter 257, loss 2.121580123901367, acc 0.3100000023841858\n",
      "Epoch 10, iter 258, loss 2.1094110012054443, acc 0.3700000047683716\n",
      "Epoch 10, iter 259, loss 2.1211092472076416, acc 0.3799999952316284\n",
      "Epoch 10, iter 260, loss 2.1059093475341797, acc 0.3499999940395355\n",
      "Epoch 10, iter 261, loss 2.0743815898895264, acc 0.41999998688697815\n",
      "Epoch 10, iter 262, loss 2.1350104808807373, acc 0.3499999940395355\n",
      "Epoch 10, iter 263, loss 2.0484488010406494, acc 0.4399999976158142\n",
      "Epoch 10, iter 264, loss 2.094511032104492, acc 0.38999998569488525\n",
      "Epoch 10, iter 265, loss 2.143848180770874, acc 0.3499999940395355\n",
      "Epoch 10, iter 266, loss 2.07686185836792, acc 0.3799999952316284\n",
      "Epoch 10, iter 267, loss 2.076415538787842, acc 0.41999998688697815\n",
      "Epoch 10, iter 268, loss 2.1003453731536865, acc 0.3499999940395355\n",
      "Epoch 10, iter 269, loss 2.0991077423095703, acc 0.3799999952316284\n",
      "Epoch 10, iter 270, loss 2.0966501235961914, acc 0.3799999952316284\n",
      "Epoch 10, iter 271, loss 2.108905553817749, acc 0.4099999964237213\n",
      "Epoch 10, iter 272, loss 2.134385108947754, acc 0.3400000035762787\n",
      "Epoch 10, iter 273, loss 2.1299591064453125, acc 0.36000001430511475\n",
      "Epoch 10, iter 274, loss 2.0987398624420166, acc 0.36000001430511475\n",
      "Epoch 10, iter 275, loss 2.1574294567108154, acc 0.33000001311302185\n",
      "Epoch 10, iter 276, loss 2.1285622119903564, acc 0.3799999952316284\n",
      "Epoch 10, iter 277, loss 2.1066999435424805, acc 0.3799999952316284\n",
      "Epoch 10, iter 278, loss 2.060425043106079, acc 0.47999998927116394\n",
      "Epoch 10, iter 279, loss 2.0762455463409424, acc 0.4399999976158142\n",
      "Epoch 10, iter 280, loss 2.0816457271575928, acc 0.4000000059604645\n",
      "Epoch 10, iter 281, loss 2.0938494205474854, acc 0.4399999976158142\n",
      "Epoch 10, iter 282, loss 2.1373910903930664, acc 0.3799999952316284\n",
      "Epoch 10, iter 283, loss 2.103450059890747, acc 0.36000001430511475\n",
      "Epoch 10, iter 284, loss 2.049661874771118, acc 0.5099999904632568\n",
      "Epoch 10, iter 285, loss 2.0902392864227295, acc 0.36000001430511475\n",
      "Epoch 10, iter 286, loss 2.065993070602417, acc 0.47999998927116394\n",
      "Epoch 10, iter 287, loss 2.115168809890747, acc 0.4000000059604645\n",
      "Epoch 10, iter 288, loss 2.0615057945251465, acc 0.41999998688697815\n",
      "Epoch 10, iter 289, loss 2.136784315109253, acc 0.36000001430511475\n",
      "Epoch 10, iter 290, loss 2.0895633697509766, acc 0.3799999952316284\n",
      "Epoch 10, iter 291, loss 2.102668046951294, acc 0.41999998688697815\n",
      "Epoch 10, iter 292, loss 2.0847601890563965, acc 0.4000000059604645\n",
      "Epoch 10, iter 293, loss 2.100714683532715, acc 0.3799999952316284\n",
      "Epoch 10, iter 294, loss 2.1664321422576904, acc 0.2800000011920929\n",
      "Epoch 10, iter 295, loss 2.117647647857666, acc 0.3799999952316284\n",
      "Epoch 10, iter 296, loss 2.0746254920959473, acc 0.4300000071525574\n",
      "Epoch 10, iter 297, loss 2.146974563598633, acc 0.36000001430511475\n",
      "Epoch 10, iter 298, loss 2.0708043575286865, acc 0.44999998807907104\n",
      "Epoch 10, iter 299, loss 2.1768975257873535, acc 0.30000001192092896\n",
      "Epoch 10, iter 300, loss 2.127774477005005, acc 0.3400000035762787\n",
      "Epoch 10, iter 301, loss 2.1245322227478027, acc 0.36000001430511475\n",
      "Epoch 10, iter 302, loss 2.070831537246704, acc 0.44999998807907104\n",
      "Epoch 10, iter 303, loss 2.118028163909912, acc 0.36000001430511475\n",
      "Epoch 10, iter 304, loss 2.155564308166504, acc 0.3199999928474426\n",
      "Epoch 10, iter 305, loss 2.1888725757598877, acc 0.2800000011920929\n",
      "Epoch 10, iter 306, loss 2.0512185096740723, acc 0.44999998807907104\n",
      "Epoch 10, iter 307, loss 2.09574556350708, acc 0.3700000047683716\n",
      "Epoch 10, iter 308, loss 2.1813502311706543, acc 0.2800000011920929\n",
      "Epoch 10, iter 309, loss 2.0988309383392334, acc 0.38999998569488525\n",
      "Epoch 10, iter 310, loss 2.1379594802856445, acc 0.33000001311302185\n",
      "Epoch 10, iter 311, loss 2.1079206466674805, acc 0.3700000047683716\n",
      "Epoch 10, iter 312, loss 2.0955584049224854, acc 0.38999998569488525\n",
      "Epoch 10, iter 313, loss 2.2059078216552734, acc 0.20999999344348907\n",
      "Epoch 10, iter 314, loss 2.068056583404541, acc 0.41999998688697815\n",
      "Epoch 10, iter 315, loss 2.1012799739837646, acc 0.4300000071525574\n",
      "Epoch 10, iter 316, loss 2.1508617401123047, acc 0.3400000035762787\n",
      "Epoch 10, iter 317, loss 2.1289899349212646, acc 0.3799999952316284\n",
      "Epoch 10, iter 318, loss 2.0876662731170654, acc 0.4099999964237213\n",
      "Epoch 10, iter 319, loss 2.1022520065307617, acc 0.3700000047683716\n",
      "Epoch 10, iter 320, loss 2.1822588443756104, acc 0.3199999928474426\n",
      "Epoch 10, iter 321, loss 2.1555275917053223, acc 0.3100000023841858\n",
      "Epoch 10, iter 322, loss 2.1164095401763916, acc 0.3700000047683716\n",
      "Epoch 10, iter 323, loss 2.125941276550293, acc 0.33000001311302185\n",
      "Epoch 10, iter 324, loss 2.051124334335327, acc 0.4300000071525574\n",
      "Epoch 10, iter 325, loss 2.142312526702881, acc 0.3700000047683716\n",
      "Epoch 10, iter 326, loss 2.0621659755706787, acc 0.4699999988079071\n",
      "Epoch 10, iter 327, loss 2.1396422386169434, acc 0.36000001430511475\n",
      "Epoch 10, iter 328, loss 2.090482711791992, acc 0.3799999952316284\n",
      "Epoch 10, iter 329, loss 2.0909371376037598, acc 0.3700000047683716\n",
      "Epoch 10, iter 330, loss 2.1224794387817383, acc 0.38999998569488525\n",
      "Epoch 10, iter 331, loss 2.1062958240509033, acc 0.36000001430511475\n",
      "Epoch 10, iter 332, loss 2.127096652984619, acc 0.4000000059604645\n",
      "Epoch 10, iter 333, loss 2.0901126861572266, acc 0.4399999976158142\n",
      "Epoch 10, iter 334, loss 2.1413886547088623, acc 0.3499999940395355\n",
      "Epoch 10, iter 335, loss 2.0191307067871094, acc 0.47999998927116394\n",
      "Epoch 10, iter 336, loss 2.1039438247680664, acc 0.3499999940395355\n",
      "Epoch 10, iter 337, loss 2.112356185913086, acc 0.3700000047683716\n",
      "Epoch 10, iter 338, loss 2.097670078277588, acc 0.36000001430511475\n",
      "Epoch 10, iter 339, loss 2.1016926765441895, acc 0.4000000059604645\n",
      "Epoch 10, iter 340, loss 2.1009273529052734, acc 0.4300000071525574\n",
      "Epoch 10, iter 341, loss 2.0695252418518066, acc 0.44999998807907104\n",
      "Epoch 10, iter 342, loss 2.0856618881225586, acc 0.38999998569488525\n",
      "Epoch 10, iter 343, loss 2.1633713245391846, acc 0.30000001192092896\n",
      "Epoch 10, iter 344, loss 2.0724055767059326, acc 0.38999998569488525\n",
      "Epoch 10, iter 345, loss 2.13562273979187, acc 0.33000001311302185\n",
      "Epoch 10, iter 346, loss 2.062969923019409, acc 0.4300000071525574\n",
      "Epoch 10, iter 347, loss 2.1583962440490723, acc 0.30000001192092896\n",
      "Epoch 10, iter 348, loss 2.0431652069091797, acc 0.4699999988079071\n",
      "Epoch 10, iter 349, loss 2.0364174842834473, acc 0.46000000834465027\n",
      "Epoch 10, iter 350, loss 2.0969438552856445, acc 0.4399999976158142\n",
      "Epoch 10, iter 351, loss 2.0823888778686523, acc 0.4300000071525574\n",
      "Epoch 10, iter 352, loss 2.1151163578033447, acc 0.3799999952316284\n",
      "Epoch 10, iter 353, loss 2.1164920330047607, acc 0.41999998688697815\n",
      "Epoch 10, iter 354, loss 2.061089277267456, acc 0.4300000071525574\n",
      "Epoch 10, iter 355, loss 2.12174654006958, acc 0.3700000047683716\n",
      "Epoch 10, iter 356, loss 2.0991742610931396, acc 0.4099999964237213\n",
      "Epoch 10, iter 357, loss 2.1199791431427, acc 0.3799999952316284\n",
      "Epoch 10, iter 358, loss 2.1888906955718994, acc 0.27000001072883606\n",
      "Epoch 10, iter 359, loss 2.113197088241577, acc 0.36000001430511475\n",
      "Epoch 10, iter 360, loss 2.099086046218872, acc 0.4099999964237213\n",
      "Epoch 10, iter 361, loss 2.084589719772339, acc 0.4300000071525574\n",
      "Epoch 10, iter 362, loss 2.1680893898010254, acc 0.27000001072883606\n",
      "Epoch 10, iter 363, loss 2.1042494773864746, acc 0.38999998569488525\n",
      "Epoch 10, iter 364, loss 2.1016016006469727, acc 0.3700000047683716\n",
      "Epoch 10, iter 365, loss 2.097248077392578, acc 0.38999998569488525\n",
      "Epoch 10, iter 366, loss 2.0475261211395264, acc 0.4399999976158142\n",
      "Epoch 10, iter 367, loss 2.0667688846588135, acc 0.4399999976158142\n",
      "Epoch 10, iter 368, loss 2.075183868408203, acc 0.4300000071525574\n",
      "Epoch 10, iter 369, loss 2.0781021118164062, acc 0.4399999976158142\n",
      "Epoch 10, iter 370, loss 2.082218885421753, acc 0.3799999952316284\n",
      "Epoch 10, iter 371, loss 2.0400328636169434, acc 0.4699999988079071\n",
      "Epoch 10, iter 372, loss 2.087888717651367, acc 0.4000000059604645\n",
      "Epoch 10, iter 373, loss 2.118023157119751, acc 0.3400000035762787\n",
      "Epoch 10, iter 374, loss 2.122279405593872, acc 0.4000000059604645\n",
      "Epoch 10, iter 375, loss 2.1249308586120605, acc 0.36000001430511475\n",
      "Epoch 10, iter 376, loss 2.1177752017974854, acc 0.33000001311302185\n",
      "Epoch 10, iter 377, loss 2.0770580768585205, acc 0.4099999964237213\n",
      "Epoch 10, iter 378, loss 2.0639493465423584, acc 0.44999998807907104\n",
      "Epoch 10, iter 379, loss 2.148956537246704, acc 0.33000001311302185\n",
      "Epoch 10, iter 380, loss 2.111989974975586, acc 0.3700000047683716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, iter 381, loss 2.11588716506958, acc 0.36000001430511475\n",
      "Epoch 10, iter 382, loss 2.059401273727417, acc 0.4399999976158142\n",
      "Epoch 10, iter 383, loss 2.0546741485595703, acc 0.5\n",
      "Epoch 10, iter 384, loss 2.138575553894043, acc 0.3400000035762787\n",
      "Epoch 10, iter 385, loss 2.0975584983825684, acc 0.3799999952316284\n",
      "Epoch 10, iter 386, loss 2.097726821899414, acc 0.3499999940395355\n",
      "Epoch 10, iter 387, loss 2.118339776992798, acc 0.3700000047683716\n",
      "Epoch 10, iter 388, loss 2.1041417121887207, acc 0.3799999952316284\n",
      "Epoch 10, iter 389, loss 2.1124062538146973, acc 0.3700000047683716\n",
      "Epoch 10, iter 390, loss 2.167238712310791, acc 0.28999999165534973\n",
      "Epoch 10, iter 391, loss 2.105762243270874, acc 0.4000000059604645\n",
      "Epoch 10, iter 392, loss 2.1035680770874023, acc 0.4000000059604645\n",
      "Epoch 10, iter 393, loss 2.105919361114502, acc 0.3799999952316284\n",
      "Epoch 10, iter 394, loss 2.0649912357330322, acc 0.4399999976158142\n",
      "Epoch 10, iter 395, loss 2.0330233573913574, acc 0.46000000834465027\n",
      "Epoch 10, iter 396, loss 2.1166019439697266, acc 0.3400000035762787\n",
      "Epoch 10, iter 397, loss 2.094460964202881, acc 0.41999998688697815\n",
      "Epoch 10, iter 398, loss 2.116379737854004, acc 0.38999998569488525\n",
      "Epoch 10, iter 399, loss 2.083799123764038, acc 0.41999998688697815\n",
      "Epoch 10, iter 400, loss 2.040642738342285, acc 0.5\n",
      "Epoch 10, iter 401, loss 2.0663678646087646, acc 0.41999998688697815\n",
      "Epoch 10, iter 402, loss 2.0678834915161133, acc 0.41999998688697815\n",
      "Epoch 10, iter 403, loss 2.101202964782715, acc 0.4000000059604645\n",
      "Epoch 10, iter 404, loss 2.132218599319458, acc 0.33000001311302185\n",
      "Epoch 10, iter 405, loss 2.105358123779297, acc 0.41999998688697815\n",
      "Epoch 10, iter 406, loss 2.1333208084106445, acc 0.3100000023841858\n",
      "Epoch 10, iter 407, loss 2.120459794998169, acc 0.33000001311302185\n",
      "Epoch 10, iter 408, loss 2.1283702850341797, acc 0.3700000047683716\n",
      "Epoch 10, iter 409, loss 2.080415725708008, acc 0.44999998807907104\n",
      "Epoch 10, iter 410, loss 2.0575859546661377, acc 0.4399999976158142\n",
      "Epoch 10, iter 411, loss 2.0933847427368164, acc 0.3799999952316284\n",
      "Epoch 10, iter 412, loss 2.071876287460327, acc 0.46000000834465027\n",
      "Epoch 10, iter 413, loss 2.104604721069336, acc 0.4000000059604645\n",
      "Epoch 10, iter 414, loss 2.1204233169555664, acc 0.33000001311302185\n",
      "Epoch 10, iter 415, loss 2.141392946243286, acc 0.3400000035762787\n",
      "Epoch 10, iter 416, loss 2.0805695056915283, acc 0.38999998569488525\n",
      "Epoch 10, iter 417, loss 2.0468218326568604, acc 0.47999998927116394\n",
      "Epoch 10, iter 418, loss 2.0815117359161377, acc 0.3700000047683716\n",
      "Epoch 10, iter 419, loss 2.065376043319702, acc 0.4099999964237213\n",
      "Epoch 10, iter 420, loss 2.1064465045928955, acc 0.36000001430511475\n"
     ]
    }
   ],
   "source": [
    "mod=MLP()\n",
    "opt=optim.SGD(mod.parameters(),lr=0.1)\n",
    "Loss=[]\n",
    "num_epoch=10\n",
    "for i in range(num_epoch):\n",
    "    for j,batch in enumerate(mnist_batched):\n",
    "        x=batch['X']\n",
    "        Y=batch['y']\n",
    "        p=mod(x.float())\n",
    "        loss=criterion(p,Y)\n",
    "        loss.backward()\n",
    "        Loss.append(loss.item())\n",
    "        acc=(p.argmax(axis=1)==Y).float().mean().item()\n",
    "        print(f\"Epoch {i+1}, iter {j+1}, loss {loss.item()}, acc {acc}\")\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1340d4590>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(Loss)),Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
